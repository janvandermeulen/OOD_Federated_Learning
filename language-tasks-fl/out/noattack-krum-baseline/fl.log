INFO:root:Backdoor type: greek-director-backdoor
INFO:root: noDefense: False
INFO:root:Initialising training data for greek director backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 10000000
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [1606, 1878, 861, 1181, 1091, 729, 1170, 785, 593, 621]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :1606
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698303
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697776
INFO:root:FL Epoch: 1 Norm Difference for worker 1606 is 0.315865
INFO:root:FL Epoch: 1 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1878
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690026
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661391
INFO:root:FL Epoch: 1 Norm Difference for worker 1878 is 0.410548
INFO:root:FL Epoch: 1 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :861
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693828
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675604
INFO:root:FL Epoch: 1 Norm Difference for worker 861 is 0.337092
INFO:root:FL Epoch: 1 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1181
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695318
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680206
INFO:root:FL Epoch: 1 Norm Difference for worker 1181 is 0.31391
INFO:root:FL Epoch: 1 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1091
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697777
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685816
INFO:root:FL Epoch: 1 Norm Difference for worker 1091 is 0.284129
INFO:root:FL Epoch: 1 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :729
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677249
INFO:root:FL Epoch: 1 Norm Difference for worker 729 is 0.311815
INFO:root:FL Epoch: 1 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1170
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689709
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704755
INFO:root:FL Epoch: 1 Norm Difference for worker 1170 is 0.275845
INFO:root:FL Epoch: 1 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :785
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693009
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718629
INFO:root:FL Epoch: 1 Norm Difference for worker 785 is 0.286856
INFO:root:FL Epoch: 1 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :593
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694222
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689735
INFO:root:FL Epoch: 1 Norm Difference for worker 593 is 0.259885
INFO:root:FL Epoch: 1 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :621
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690946
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686094
INFO:root:FL Epoch: 1 Norm Difference for worker 621 is 0.303241
INFO:root:FL Epoch: 1 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 593
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 1 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 1 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6914178027826197 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6742842197418213                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1013, 540, 1234, 1384, 765, 1090, 1597, 273, 204, 156]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1013
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689798
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680074
INFO:root:FL Epoch: 2 Norm Difference for worker 1013 is 0.312612
INFO:root:FL Epoch: 2 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :540
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693850
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681430
INFO:root:FL Epoch: 2 Norm Difference for worker 540 is 0.354225
INFO:root:FL Epoch: 2 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1234
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695203
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692834
INFO:root:FL Epoch: 2 Norm Difference for worker 1234 is 0.373177
INFO:root:FL Epoch: 2 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1384
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685539
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693505
INFO:root:FL Epoch: 2 Norm Difference for worker 1384 is 0.295285
INFO:root:FL Epoch: 2 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :765
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688020
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685125
INFO:root:FL Epoch: 2 Norm Difference for worker 765 is 0.323125
INFO:root:FL Epoch: 2 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1090
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689399
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678905
INFO:root:FL Epoch: 2 Norm Difference for worker 1090 is 0.368282
INFO:root:FL Epoch: 2 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1597
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699712
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686644
INFO:root:FL Epoch: 2 Norm Difference for worker 1597 is 0.276638
INFO:root:FL Epoch: 2 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :273
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 273 is 0.293222
INFO:root:FL Epoch: 2 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :204
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693477
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 204 is 0.291375
INFO:root:FL Epoch: 2 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :156
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 156 is 0.328303
INFO:root:FL Epoch: 2 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 273
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 2 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 2 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6877976340406081 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.7219874362150828                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [518, 894, 617, 1462, 1278, 960, 426, 1464, 1105, 973]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 3 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :518
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690295
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690352
INFO:root:FL Epoch: 3 Norm Difference for worker 518 is 0.362363
INFO:root:FL Epoch: 3 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :894
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691278
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696286
INFO:root:FL Epoch: 3 Norm Difference for worker 894 is 0.294804
INFO:root:FL Epoch: 3 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :617
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688532
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660709
INFO:root:FL Epoch: 3 Norm Difference for worker 617 is 0.453988
INFO:root:FL Epoch: 3 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1462
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682961
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710777
INFO:root:FL Epoch: 3 Norm Difference for worker 1462 is 0.428227
INFO:root:FL Epoch: 3 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685651
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660991
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.304174
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :960
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684080
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701726
INFO:root:FL Epoch: 3 Norm Difference for worker 960 is 0.307429
INFO:root:FL Epoch: 3 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :426
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684295
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677151
INFO:root:FL Epoch: 3 Norm Difference for worker 426 is 0.326557
INFO:root:FL Epoch: 3 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1464
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693651
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686731
INFO:root:FL Epoch: 3 Norm Difference for worker 1464 is 0.337261
INFO:root:FL Epoch: 3 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1105
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689504
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710951
INFO:root:FL Epoch: 3 Norm Difference for worker 1105 is 0.322236
INFO:root:FL Epoch: 3 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :973
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692737
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661609
INFO:root:FL Epoch: 3 Norm Difference for worker 973 is 0.367486
INFO:root:FL Epoch: 3 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 3 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 3 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6841186530449811 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.7271402180194855                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [949, 1405, 1255, 1069, 1079, 1610, 531, 871, 618, 1156]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :949
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668274
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708273
INFO:root:FL Epoch: 4 Norm Difference for worker 949 is 0.359252
INFO:root:FL Epoch: 4 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1405
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693641
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627769
INFO:root:FL Epoch: 4 Norm Difference for worker 1405 is 0.401132
INFO:root:FL Epoch: 4 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1255
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696944
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680447
INFO:root:FL Epoch: 4 Norm Difference for worker 1255 is 0.492075
INFO:root:FL Epoch: 4 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1069
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677201
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706991
INFO:root:FL Epoch: 4 Norm Difference for worker 1069 is 0.367923
INFO:root:FL Epoch: 4 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1079
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678905
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671867
INFO:root:FL Epoch: 4 Norm Difference for worker 1079 is 0.445816
INFO:root:FL Epoch: 4 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1610
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695194
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689709
INFO:root:FL Epoch: 4 Norm Difference for worker 1610 is 0.346424
INFO:root:FL Epoch: 4 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :531
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722076
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688332
INFO:root:FL Epoch: 4 Norm Difference for worker 531 is 0.397597
INFO:root:FL Epoch: 4 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :871
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676664
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692609
INFO:root:FL Epoch: 4 Norm Difference for worker 871 is 0.47168
INFO:root:FL Epoch: 4 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :618
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701976
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669586
INFO:root:FL Epoch: 4 Norm Difference for worker 618 is 0.423093
INFO:root:FL Epoch: 4 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1156
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687073
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665270
INFO:root:FL Epoch: 4 Norm Difference for worker 1156 is 0.322441
INFO:root:FL Epoch: 4 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 949
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6834794949082768 and Test Accuracy:55.0 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.6485794981320699                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [1364, 449, 757, 469, 1689, 1699, 1623, 1625, 137, 130]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 5 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :1364
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686201
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667393
INFO:root:FL Epoch: 5 Norm Difference for worker 1364 is 0.417307
INFO:root:FL Epoch: 5 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :449
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683234
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665206
INFO:root:FL Epoch: 5 Norm Difference for worker 449 is 0.441797
INFO:root:FL Epoch: 5 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :757
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699228
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689087
INFO:root:FL Epoch: 5 Norm Difference for worker 757 is 0.35862
INFO:root:FL Epoch: 5 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :469
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694210
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656507
INFO:root:FL Epoch: 5 Norm Difference for worker 469 is 0.464616
INFO:root:FL Epoch: 5 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1689
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701628
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680250
INFO:root:FL Epoch: 5 Norm Difference for worker 1689 is 0.369152
INFO:root:FL Epoch: 5 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1699
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691523
INFO:root:Worker: 1699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687034
INFO:root:FL Epoch: 5 Norm Difference for worker 1699 is 0.432112
INFO:root:FL Epoch: 5 Done on worker:1699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1623
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676487
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696332
INFO:root:FL Epoch: 5 Norm Difference for worker 1623 is 0.438855
INFO:root:FL Epoch: 5 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1625
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678469
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653095
INFO:root:FL Epoch: 5 Norm Difference for worker 1625 is 0.361388
INFO:root:FL Epoch: 5 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :137
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 137 is 0.372611
INFO:root:FL Epoch: 5 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :130
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 130 is 0.347163
INFO:root:FL Epoch: 5 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1689
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 5 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 5 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6794971052338096 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.7070683836936951                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [30, 1356, 314, 1846, 245, 621, 808, 1763, 1349, 1676]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 6 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :30
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 30 is 0.37763
INFO:root:FL Epoch: 6 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1356
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683696
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678477
INFO:root:FL Epoch: 6 Norm Difference for worker 1356 is 0.391988
INFO:root:FL Epoch: 6 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :314
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 314 is 0.383673
INFO:root:FL Epoch: 6 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1846
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660873
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649240
INFO:root:FL Epoch: 6 Norm Difference for worker 1846 is 0.448138
INFO:root:FL Epoch: 6 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :245
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 245 is 0.42726
INFO:root:FL Epoch: 6 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :621
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686624
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647273
INFO:root:FL Epoch: 6 Norm Difference for worker 621 is 0.41316
INFO:root:FL Epoch: 6 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :808
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694817
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680464
INFO:root:FL Epoch: 6 Norm Difference for worker 808 is 0.395106
INFO:root:FL Epoch: 6 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1763
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673706
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677008
INFO:root:FL Epoch: 6 Norm Difference for worker 1763 is 0.383746
INFO:root:FL Epoch: 6 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1349
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678200
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686412
INFO:root:FL Epoch: 6 Norm Difference for worker 1349 is 0.41567
INFO:root:FL Epoch: 6 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1676
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695711
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654274
INFO:root:FL Epoch: 6 Norm Difference for worker 1676 is 0.430471
INFO:root:FL Epoch: 6 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 314
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6825909369132098 and Test Accuracy:51.470588235294116 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7876336872577667                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [132, 1254, 1015, 293, 1554, 625, 128, 420, 348, 1736]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 7 Num points on workers: [201 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :132
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670609
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 132 is 0.485394
INFO:root:FL Epoch: 7 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1254
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677595
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702531
INFO:root:FL Epoch: 7 Norm Difference for worker 1254 is 0.386275
INFO:root:FL Epoch: 7 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1015
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670253
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647861
INFO:root:FL Epoch: 7 Norm Difference for worker 1015 is 0.557621
INFO:root:FL Epoch: 7 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :293
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701744
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673611
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 293 is 0.441233
INFO:root:FL Epoch: 7 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1554
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708999
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634087
INFO:root:FL Epoch: 7 Norm Difference for worker 1554 is 0.670211
INFO:root:FL Epoch: 7 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :625
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709216
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658389
INFO:root:FL Epoch: 7 Norm Difference for worker 625 is 0.557343
INFO:root:FL Epoch: 7 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :128
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 128 is 0.465213
INFO:root:FL Epoch: 7 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :420
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688930
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674126
INFO:root:FL Epoch: 7 Norm Difference for worker 420 is 0.442795
INFO:root:FL Epoch: 7 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :348
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709367
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688539
INFO:root:FL Epoch: 7 Norm Difference for worker 348 is 0.416401
INFO:root:FL Epoch: 7 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1736
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690515
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692535
INFO:root:FL Epoch: 7 Norm Difference for worker 1736 is 0.403577
INFO:root:FL Epoch: 7 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 128
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6784486104460323 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.64474089940389                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1734, 828, 386, 922, 161, 1926, 1234, 473, 1585, 269]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1734
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671380
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636761
INFO:root:FL Epoch: 8 Norm Difference for worker 1734 is 0.484598
INFO:root:FL Epoch: 8 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :828
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693485
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715313
INFO:root:FL Epoch: 8 Norm Difference for worker 828 is 0.526279
INFO:root:FL Epoch: 8 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :386
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641666
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703588
INFO:root:FL Epoch: 8 Norm Difference for worker 386 is 0.471034
INFO:root:FL Epoch: 8 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :922
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718251
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693956
INFO:root:FL Epoch: 8 Norm Difference for worker 922 is 0.445836
INFO:root:FL Epoch: 8 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :161
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677655
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 161 is 0.450754
INFO:root:FL Epoch: 8 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1926
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637341
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614190
INFO:root:FL Epoch: 8 Norm Difference for worker 1926 is 0.560716
INFO:root:FL Epoch: 8 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1234
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699183
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680973
INFO:root:FL Epoch: 8 Norm Difference for worker 1234 is 0.548208
INFO:root:FL Epoch: 8 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :473
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663956
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630723
INFO:root:FL Epoch: 8 Norm Difference for worker 473 is 0.436593
INFO:root:FL Epoch: 8 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1585
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713637
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682299
INFO:root:FL Epoch: 8 Norm Difference for worker 1585 is 0.531796
INFO:root:FL Epoch: 8 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.750639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.492106
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.677226185798645 and Test Accuracy:58.529411764705884 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7094549834728241                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1240, 254, 1011, 1068, 1612, 632, 756, 655, 25, 341]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1240
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686267
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698835
INFO:root:FL Epoch: 9 Norm Difference for worker 1240 is 0.578319
INFO:root:FL Epoch: 9 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :254
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.732348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 254 is 0.512651
INFO:root:FL Epoch: 9 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1011
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666068
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682492
INFO:root:FL Epoch: 9 Norm Difference for worker 1011 is 0.542275
INFO:root:FL Epoch: 9 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1068
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660099
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626648
INFO:root:FL Epoch: 9 Norm Difference for worker 1068 is 0.527532
INFO:root:FL Epoch: 9 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1612
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703976
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681851
INFO:root:FL Epoch: 9 Norm Difference for worker 1612 is 0.469829
INFO:root:FL Epoch: 9 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668535
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678324
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.50744
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :756
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684702
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663168
INFO:root:FL Epoch: 9 Norm Difference for worker 756 is 0.498825
INFO:root:FL Epoch: 9 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :655
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680756
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655036
INFO:root:FL Epoch: 9 Norm Difference for worker 655 is 0.571024
INFO:root:FL Epoch: 9 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :25
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 25 is 0.502035
INFO:root:FL Epoch: 9 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :341
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668243
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683767
INFO:root:FL Epoch: 9 Norm Difference for worker 341 is 0.469484
INFO:root:FL Epoch: 9 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 341
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6738854331128737 and Test Accuracy:57.94117647058823 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.7160618901252747                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [319, 1504, 1454, 770, 401, 1275, 713, 24, 533, 288]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :319
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 319 is 0.606387
INFO:root:FL Epoch: 10 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1504
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706826
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663240
INFO:root:FL Epoch: 10 Norm Difference for worker 1504 is 0.571257
INFO:root:FL Epoch: 10 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641919
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678689
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.547623
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :770
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747409
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662066
INFO:root:FL Epoch: 10 Norm Difference for worker 770 is 0.561294
INFO:root:FL Epoch: 10 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :401
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691775
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697916
INFO:root:FL Epoch: 10 Norm Difference for worker 401 is 0.571428
INFO:root:FL Epoch: 10 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1275
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677725
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634775
INFO:root:FL Epoch: 10 Norm Difference for worker 1275 is 0.601962
INFO:root:FL Epoch: 10 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :713
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692550
INFO:root:Worker: 713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682160
INFO:root:FL Epoch: 10 Norm Difference for worker 713 is 0.574572
INFO:root:FL Epoch: 10 Done on worker:713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :24
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.718304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 24 is 0.568719
INFO:root:FL Epoch: 10 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :533
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687651
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659096
INFO:root:FL Epoch: 10 Norm Difference for worker 533 is 0.522838
INFO:root:FL Epoch: 10 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :288
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 288 is 0.517742
INFO:root:FL Epoch: 10 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 288
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6767870573436513 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.6866538226604462                             and Backdoor Test Accuracy:60.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [897, 1496, 1771, 1163, 370, 1009, 816, 1242, 94, 292]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :897
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719661
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711116
INFO:root:FL Epoch: 11 Norm Difference for worker 897 is 0.555911
INFO:root:FL Epoch: 11 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1496
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666812
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614501
INFO:root:FL Epoch: 11 Norm Difference for worker 1496 is 0.71276
INFO:root:FL Epoch: 11 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1771
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755378
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736240
INFO:root:FL Epoch: 11 Norm Difference for worker 1771 is 0.574322
INFO:root:FL Epoch: 11 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1163
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710545
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635256
INFO:root:FL Epoch: 11 Norm Difference for worker 1163 is 0.557617
INFO:root:FL Epoch: 11 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :370
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752948
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687239
INFO:root:FL Epoch: 11 Norm Difference for worker 370 is 0.564427
INFO:root:FL Epoch: 11 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1009
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605434
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670082
INFO:root:FL Epoch: 11 Norm Difference for worker 1009 is 0.587429
INFO:root:FL Epoch: 11 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :816
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655450
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666080
INFO:root:FL Epoch: 11 Norm Difference for worker 816 is 0.595695
INFO:root:FL Epoch: 11 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1242
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653044
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684685
INFO:root:FL Epoch: 11 Norm Difference for worker 1242 is 0.608753
INFO:root:FL Epoch: 11 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :94
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 94 is 0.592243
INFO:root:FL Epoch: 11 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :292
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 292 is 0.582286
INFO:root:FL Epoch: 11 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 370
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6790259866153493 and Test Accuracy:54.411764705882355 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.6741587519645691                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1404, 1622, 377, 122, 799, 837, 1333, 1733, 686, 1641]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1404
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655851
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607752
INFO:root:FL Epoch: 12 Norm Difference for worker 1404 is 0.754105
INFO:root:FL Epoch: 12 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1622
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712821
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722706
INFO:root:FL Epoch: 12 Norm Difference for worker 1622 is 0.664446
INFO:root:FL Epoch: 12 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :377
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697044
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638343
INFO:root:FL Epoch: 12 Norm Difference for worker 377 is 0.6914
INFO:root:FL Epoch: 12 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :122
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 122 is 0.689546
INFO:root:FL Epoch: 12 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :799
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721626
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561779
INFO:root:FL Epoch: 12 Norm Difference for worker 799 is 0.717606
INFO:root:FL Epoch: 12 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :837
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643147
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630434
INFO:root:FL Epoch: 12 Norm Difference for worker 837 is 0.781422
INFO:root:FL Epoch: 12 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1333
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741722
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664924
INFO:root:FL Epoch: 12 Norm Difference for worker 1333 is 0.620036
INFO:root:FL Epoch: 12 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641231
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617393
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.705723
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :686
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684811
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610931
INFO:root:FL Epoch: 12 Norm Difference for worker 686 is 0.708894
INFO:root:FL Epoch: 12 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1641
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678854
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580015
INFO:root:FL Epoch: 12 Norm Difference for worker 1641 is 0.617847
INFO:root:FL Epoch: 12 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1333
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6709393473232493 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.7982416450977325                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [579, 698, 1302, 1411, 1564, 1255, 673, 659, 277, 1634]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :579
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661937
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655477
INFO:root:FL Epoch: 13 Norm Difference for worker 579 is 0.659924
INFO:root:FL Epoch: 13 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :698
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657816
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664144
INFO:root:FL Epoch: 13 Norm Difference for worker 698 is 0.685135
INFO:root:FL Epoch: 13 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1302
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697537
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602466
INFO:root:FL Epoch: 13 Norm Difference for worker 1302 is 0.742893
INFO:root:FL Epoch: 13 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1411
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655547
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591827
INFO:root:FL Epoch: 13 Norm Difference for worker 1411 is 0.67289
INFO:root:FL Epoch: 13 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1564
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688867
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665249
INFO:root:FL Epoch: 13 Norm Difference for worker 1564 is 0.68244
INFO:root:FL Epoch: 13 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1255
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629903
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551236
INFO:root:FL Epoch: 13 Norm Difference for worker 1255 is 0.750115
INFO:root:FL Epoch: 13 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :673
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678097
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643936
INFO:root:FL Epoch: 13 Norm Difference for worker 673 is 0.718734
INFO:root:FL Epoch: 13 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :659
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630799
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584916
INFO:root:FL Epoch: 13 Norm Difference for worker 659 is 0.6722
INFO:root:FL Epoch: 13 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :277
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 277 is 0.742455
INFO:root:FL Epoch: 13 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1634
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697130
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736660
INFO:root:FL Epoch: 13 Norm Difference for worker 1634 is 0.65396
INFO:root:FL Epoch: 13 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1411
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6668344140052795 and Test Accuracy:58.529411764705884 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.8294865985711416                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [648, 909, 777, 1122, 905, 458, 1615, 550, 606, 84]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :648
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638512
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589809
INFO:root:FL Epoch: 14 Norm Difference for worker 648 is 0.764589
INFO:root:FL Epoch: 14 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :909
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640221
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645059
INFO:root:FL Epoch: 14 Norm Difference for worker 909 is 0.761605
INFO:root:FL Epoch: 14 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :777
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683786
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699340
INFO:root:FL Epoch: 14 Norm Difference for worker 777 is 0.721464
INFO:root:FL Epoch: 14 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1122
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638854
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647651
INFO:root:FL Epoch: 14 Norm Difference for worker 1122 is 0.757884
INFO:root:FL Epoch: 14 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :905
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704869
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665715
INFO:root:FL Epoch: 14 Norm Difference for worker 905 is 0.750833
INFO:root:FL Epoch: 14 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :458
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678927
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615837
INFO:root:FL Epoch: 14 Norm Difference for worker 458 is 0.76055
INFO:root:FL Epoch: 14 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1615
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554725
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654359
INFO:root:FL Epoch: 14 Norm Difference for worker 1615 is 0.762106
INFO:root:FL Epoch: 14 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :550
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698199
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631350
INFO:root:FL Epoch: 14 Norm Difference for worker 550 is 0.743684
INFO:root:FL Epoch: 14 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :606
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760815
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646074
INFO:root:FL Epoch: 14 Norm Difference for worker 606 is 0.701807
INFO:root:FL Epoch: 14 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :84
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 84 is 0.753616
INFO:root:FL Epoch: 14 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 905
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6693856330478892 and Test Accuracy:57.05882352941177 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:0.8652294377485911                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [44, 1162, 1156, 1595, 1797, 1768, 612, 451, 688, 349]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 15 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :44
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 44 is 0.91166
INFO:root:FL Epoch: 15 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1162
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699152
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727522
INFO:root:FL Epoch: 15 Norm Difference for worker 1162 is 0.961456
INFO:root:FL Epoch: 15 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1156
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562596
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509094
INFO:root:FL Epoch: 15 Norm Difference for worker 1156 is 0.957794
INFO:root:FL Epoch: 15 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611865
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525845
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 0.969954
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1797
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643856
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613077
INFO:root:FL Epoch: 15 Norm Difference for worker 1797 is 0.891077
INFO:root:FL Epoch: 15 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1768
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584788
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592216
INFO:root:FL Epoch: 15 Norm Difference for worker 1768 is 0.92658
INFO:root:FL Epoch: 15 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :612
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623451
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670717
INFO:root:FL Epoch: 15 Norm Difference for worker 612 is 0.884782
INFO:root:FL Epoch: 15 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :451
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595114
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671092
INFO:root:FL Epoch: 15 Norm Difference for worker 451 is 0.902892
INFO:root:FL Epoch: 15 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :688
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642561
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614633
INFO:root:FL Epoch: 15 Norm Difference for worker 688 is 0.960201
INFO:root:FL Epoch: 15 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :349
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679567
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580262
INFO:root:FL Epoch: 15 Norm Difference for worker 349 is 0.898764
INFO:root:FL Epoch: 15 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1797
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.7129613406517926 and Test Accuracy:52.64705882352941 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:0.765030046304067                             and Backdoor Test Accuracy:39.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [865, 324, 500, 1892, 837, 469, 271, 478, 1187, 1605]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :865
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620115
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597720
INFO:root:FL Epoch: 16 Norm Difference for worker 865 is 0.985758
INFO:root:FL Epoch: 16 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :324
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 324 is 0.985259
INFO:root:FL Epoch: 16 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :500
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718095
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617456
INFO:root:FL Epoch: 16 Norm Difference for worker 500 is 0.931492
INFO:root:FL Epoch: 16 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1892
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696281
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582925
INFO:root:FL Epoch: 16 Norm Difference for worker 1892 is 0.976539
INFO:root:FL Epoch: 16 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :837
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604724
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591886
INFO:root:FL Epoch: 16 Norm Difference for worker 837 is 1.068469
INFO:root:FL Epoch: 16 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :469
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670713
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548553
INFO:root:FL Epoch: 16 Norm Difference for worker 469 is 0.966734
INFO:root:FL Epoch: 16 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :271
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 271 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 271 Train Epoch: 1 [0/201 (0%)]	Loss: 0.756577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 271 is 0.948061
INFO:root:FL Epoch: 16 Done on worker:271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :478
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619434
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576428
INFO:root:FL Epoch: 16 Norm Difference for worker 478 is 0.939318
INFO:root:FL Epoch: 16 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1187
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597849
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663097
INFO:root:FL Epoch: 16 Norm Difference for worker 1187 is 0.98363
INFO:root:FL Epoch: 16 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1605
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578783
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593495
INFO:root:FL Epoch: 16 Norm Difference for worker 1605 is 0.953321
INFO:root:FL Epoch: 16 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 271
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6608430322478799 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.1191421151161194                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [944, 1613, 174, 623, 1869, 205, 763, 211, 1273, 1147]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :944
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573907
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651287
INFO:root:FL Epoch: 17 Norm Difference for worker 944 is 1.002485
INFO:root:FL Epoch: 17 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1613
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661818
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711845
INFO:root:FL Epoch: 17 Norm Difference for worker 1613 is 1.023262
INFO:root:FL Epoch: 17 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :174
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671193
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649636
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 174 is 0.969882
INFO:root:FL Epoch: 17 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :623
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682476
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677489
INFO:root:FL Epoch: 17 Norm Difference for worker 623 is 1.003572
INFO:root:FL Epoch: 17 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1869
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579696
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658895
INFO:root:FL Epoch: 17 Norm Difference for worker 1869 is 1.020065
INFO:root:FL Epoch: 17 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :205
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696327
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 205 is 0.968778
INFO:root:FL Epoch: 17 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :763
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611585
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550521
INFO:root:FL Epoch: 17 Norm Difference for worker 763 is 1.046811
INFO:root:FL Epoch: 17 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :211
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 211 is 0.998694
INFO:root:FL Epoch: 17 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1273
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546537
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608394
INFO:root:FL Epoch: 17 Norm Difference for worker 1273 is 1.021558
INFO:root:FL Epoch: 17 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1147
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779013
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658651
INFO:root:FL Epoch: 17 Norm Difference for worker 1147 is 0.990147
INFO:root:FL Epoch: 17 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 174
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6671726949074689 and Test Accuracy:54.705882352941174 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:0.8821799556414286                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1083, 654, 39, 511, 1530, 1859, 1600, 1619, 1874, 1557]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1083
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740035
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666230
INFO:root:FL Epoch: 18 Norm Difference for worker 1083 is 0.972342
INFO:root:FL Epoch: 18 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :654
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684013
INFO:root:Worker: 654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624325
INFO:root:FL Epoch: 18 Norm Difference for worker 654 is 0.928831
INFO:root:FL Epoch: 18 Done on worker:654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :39
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 39 is 1.001461
INFO:root:FL Epoch: 18 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :511
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683663
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670089
INFO:root:FL Epoch: 18 Norm Difference for worker 511 is 0.980402
INFO:root:FL Epoch: 18 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1530
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670998
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545878
INFO:root:FL Epoch: 18 Norm Difference for worker 1530 is 1.014498
INFO:root:FL Epoch: 18 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1859
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671365
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725485
INFO:root:FL Epoch: 18 Norm Difference for worker 1859 is 0.9762
INFO:root:FL Epoch: 18 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1600
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699208
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648127
INFO:root:FL Epoch: 18 Norm Difference for worker 1600 is 1.007785
INFO:root:FL Epoch: 18 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1619
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646342
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634352
INFO:root:FL Epoch: 18 Norm Difference for worker 1619 is 0.96793
INFO:root:FL Epoch: 18 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1874
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711425
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605227
INFO:root:FL Epoch: 18 Norm Difference for worker 1874 is 0.922293
INFO:root:FL Epoch: 18 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1557
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792162
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636107
INFO:root:FL Epoch: 18 Norm Difference for worker 1557 is 0.903273
INFO:root:FL Epoch: 18 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6678571280311135 and Test Accuracy:56.470588235294116 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.0508052110671997                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [16, 320, 1662, 812, 1791, 1781, 1404, 1090, 1076, 1196]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 19 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :16
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 16 is 0.984541
INFO:root:FL Epoch: 19 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :320
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609289
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 320 is 0.966306
INFO:root:FL Epoch: 19 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1662
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615431
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683566
INFO:root:FL Epoch: 19 Norm Difference for worker 1662 is 0.951891
INFO:root:FL Epoch: 19 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :812
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636649
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607083
INFO:root:FL Epoch: 19 Norm Difference for worker 812 is 1.013918
INFO:root:FL Epoch: 19 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1791
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710769
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651604
INFO:root:FL Epoch: 19 Norm Difference for worker 1791 is 0.931648
INFO:root:FL Epoch: 19 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1781
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570747
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554805
INFO:root:FL Epoch: 19 Norm Difference for worker 1781 is 1.033475
INFO:root:FL Epoch: 19 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1404
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611142
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604076
INFO:root:FL Epoch: 19 Norm Difference for worker 1404 is 0.99773
INFO:root:FL Epoch: 19 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1090
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672673
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610029
INFO:root:FL Epoch: 19 Norm Difference for worker 1090 is 0.987849
INFO:root:FL Epoch: 19 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1076
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662387
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599954
INFO:root:FL Epoch: 19 Norm Difference for worker 1076 is 0.925289
INFO:root:FL Epoch: 19 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1196
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652587
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673588
INFO:root:FL Epoch: 19 Norm Difference for worker 1196 is 0.94792
INFO:root:FL Epoch: 19 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1662
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6570203058859881 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.2147242625554402                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [468, 1021, 1405, 1477, 277, 1482, 140, 1135, 1757, 308]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :468
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600147
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662023
INFO:root:FL Epoch: 20 Norm Difference for worker 468 is 1.062757
INFO:root:FL Epoch: 20 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1021
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499077
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526457
INFO:root:FL Epoch: 20 Norm Difference for worker 1021 is 1.042027
INFO:root:FL Epoch: 20 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1405
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561246
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700414
INFO:root:FL Epoch: 20 Norm Difference for worker 1405 is 1.066194
INFO:root:FL Epoch: 20 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1477
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677515
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610925
INFO:root:FL Epoch: 20 Norm Difference for worker 1477 is 1.052343
INFO:root:FL Epoch: 20 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :277
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 277 is 1.093967
INFO:root:FL Epoch: 20 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1482
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559225
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503805
INFO:root:FL Epoch: 20 Norm Difference for worker 1482 is 1.057072
INFO:root:FL Epoch: 20 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :140
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694960
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 140 is 1.145448
INFO:root:FL Epoch: 20 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1135
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738079
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538221
INFO:root:FL Epoch: 20 Norm Difference for worker 1135 is 1.061943
INFO:root:FL Epoch: 20 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1757
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759466
INFO:root:Worker: 1757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639984
INFO:root:FL Epoch: 20 Norm Difference for worker 1757 is 1.038156
INFO:root:FL Epoch: 20 Done on worker:1757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :308
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541789
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 308 is 1.162896
INFO:root:FL Epoch: 20 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1757
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 20 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 20 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6585970538503984 and Test Accuracy:62.05882352941177 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:0.9808830718199412                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [1104, 509, 148, 374, 916, 71, 1279, 1093, 985, 1252]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :1104
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725988
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664307
INFO:root:FL Epoch: 21 Norm Difference for worker 1104 is 1.023017
INFO:root:FL Epoch: 21 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :509
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642007
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559678
INFO:root:FL Epoch: 21 Norm Difference for worker 509 is 1.029015
INFO:root:FL Epoch: 21 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :148
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696720
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 148 is 0.969948
INFO:root:FL Epoch: 21 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :374
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685489
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572392
INFO:root:FL Epoch: 21 Norm Difference for worker 374 is 1.034616
INFO:root:FL Epoch: 21 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :916
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869743
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702580
INFO:root:FL Epoch: 21 Norm Difference for worker 916 is 1.080333
INFO:root:FL Epoch: 21 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :71
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 71 is 1.073168
INFO:root:FL Epoch: 21 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1279
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819075
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574031
INFO:root:FL Epoch: 21 Norm Difference for worker 1279 is 0.968706
INFO:root:FL Epoch: 21 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1093
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510589
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604272
INFO:root:FL Epoch: 21 Norm Difference for worker 1093 is 1.062419
INFO:root:FL Epoch: 21 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :985
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772922
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613469
INFO:root:FL Epoch: 21 Norm Difference for worker 985 is 1.044286
INFO:root:FL Epoch: 21 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1252
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654559
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537011
INFO:root:FL Epoch: 21 Norm Difference for worker 1252 is 1.087396
INFO:root:FL Epoch: 21 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1279
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 21 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 21 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6527663013514351 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:1.2998279134432476                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [30, 1403, 732, 167, 45, 34, 710, 109, 60, 690]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.1001994 0.1001994 0.1001994 0.0997009
 0.1001994 0.1001994 0.0997009]
INFO:root:FL Epoch: 22 Num points on workers: [201 200 200 201 201 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :30
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722065
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 30 is 1.103213
INFO:root:FL Epoch: 22 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1403
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587873
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.815686
INFO:root:FL Epoch: 22 Norm Difference for worker 1403 is 1.093436
INFO:root:FL Epoch: 22 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :732
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704589
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552936
INFO:root:FL Epoch: 22 Norm Difference for worker 732 is 1.159307
INFO:root:FL Epoch: 22 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :167
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 167 is 1.115526
INFO:root:FL Epoch: 22 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :45
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 45 is 1.123791
INFO:root:FL Epoch: 22 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :34
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 34 is 1.101659
INFO:root:FL Epoch: 22 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :710
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622121
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526345
INFO:root:FL Epoch: 22 Norm Difference for worker 710 is 1.150251
INFO:root:FL Epoch: 22 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :109
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644976
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 109 is 1.093523
INFO:root:FL Epoch: 22 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :60
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 60 is 1.150314
INFO:root:FL Epoch: 22 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :690
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591008
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480477
INFO:root:FL Epoch: 22 Norm Difference for worker 690 is 1.137978
INFO:root:FL Epoch: 22 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 34
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6662879060296452 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:1.156217873096466                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1050, 1151, 1663, 1810, 651, 1557, 1014, 292, 440, 1628]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1050
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682496
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692970
INFO:root:FL Epoch: 23 Norm Difference for worker 1050 is 1.117999
INFO:root:FL Epoch: 23 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1151
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645586
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578836
INFO:root:FL Epoch: 23 Norm Difference for worker 1151 is 1.083959
INFO:root:FL Epoch: 23 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1663
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646295
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559059
INFO:root:FL Epoch: 23 Norm Difference for worker 1663 is 1.108368
INFO:root:FL Epoch: 23 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1810
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798460
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586496
INFO:root:FL Epoch: 23 Norm Difference for worker 1810 is 1.05248
INFO:root:FL Epoch: 23 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :651
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544901
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468057
INFO:root:FL Epoch: 23 Norm Difference for worker 651 is 1.047773
INFO:root:FL Epoch: 23 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633645
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654841
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 1.039686
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1014
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761178
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519702
INFO:root:FL Epoch: 23 Norm Difference for worker 1014 is 1.072013
INFO:root:FL Epoch: 23 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :292
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612431
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 292 is 1.170801
INFO:root:FL Epoch: 23 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :440
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648075
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611935
INFO:root:FL Epoch: 23 Norm Difference for worker 440 is 1.017403
INFO:root:FL Epoch: 23 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1628
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526295
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616928
INFO:root:FL Epoch: 23 Norm Difference for worker 1628 is 1.1058
INFO:root:FL Epoch: 23 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 440
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.668067513143315 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:1.2346914807955425                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [90, 806, 1676, 259, 631, 903, 4, 726, 1694, 639]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 24 Num points on workers: [201 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :90
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.725083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 90 is 1.161744
INFO:root:FL Epoch: 24 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :806
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638081
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673922
INFO:root:FL Epoch: 24 Norm Difference for worker 806 is 1.190516
INFO:root:FL Epoch: 24 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1676
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846704
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647590
INFO:root:FL Epoch: 24 Norm Difference for worker 1676 is 1.167441
INFO:root:FL Epoch: 24 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :259
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 259 is 1.146527
INFO:root:FL Epoch: 24 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :631
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737558
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681085
INFO:root:FL Epoch: 24 Norm Difference for worker 631 is 1.193265
INFO:root:FL Epoch: 24 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :903
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488774
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443592
INFO:root:FL Epoch: 24 Norm Difference for worker 903 is 1.270343
INFO:root:FL Epoch: 24 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :4
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 4 is 1.112324
INFO:root:FL Epoch: 24 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :726
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612074
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578600
INFO:root:FL Epoch: 24 Norm Difference for worker 726 is 1.258367
INFO:root:FL Epoch: 24 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1694
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526550
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567199
INFO:root:FL Epoch: 24 Norm Difference for worker 1694 is 1.13591
INFO:root:FL Epoch: 24 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :639
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626818
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695194
INFO:root:FL Epoch: 24 Norm Difference for worker 639 is 1.25722
INFO:root:FL Epoch: 24 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 4
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6606259871931637 and Test Accuracy:60.0 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:1.0909664630889893                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1939, 531, 1416, 1309, 862, 672, 1082, 1799, 96, 1920]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1939
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597090
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669573
INFO:root:FL Epoch: 25 Norm Difference for worker 1939 is 1.039641
INFO:root:FL Epoch: 25 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :531
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502220
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415359
INFO:root:FL Epoch: 25 Norm Difference for worker 531 is 1.085338
INFO:root:FL Epoch: 25 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1416
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806187
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600414
INFO:root:FL Epoch: 25 Norm Difference for worker 1416 is 1.155981
INFO:root:FL Epoch: 25 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1309
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624710
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628793
INFO:root:FL Epoch: 25 Norm Difference for worker 1309 is 1.070219
INFO:root:FL Epoch: 25 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :862
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806461
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694697
INFO:root:FL Epoch: 25 Norm Difference for worker 862 is 1.128094
INFO:root:FL Epoch: 25 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :672
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736171
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611823
INFO:root:FL Epoch: 25 Norm Difference for worker 672 is 1.062119
INFO:root:FL Epoch: 25 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1082
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677193
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561360
INFO:root:FL Epoch: 25 Norm Difference for worker 1082 is 1.095846
INFO:root:FL Epoch: 25 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1799
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686699
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606447
INFO:root:FL Epoch: 25 Norm Difference for worker 1799 is 1.038275
INFO:root:FL Epoch: 25 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :96
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.722220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 96 is 1.016488
INFO:root:FL Epoch: 25 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1920
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555624
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650629
INFO:root:FL Epoch: 25 Norm Difference for worker 1920 is 1.003958
INFO:root:FL Epoch: 25 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1799
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6550235572983237 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.0631161431471507                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [72, 1202, 209, 638, 991, 200, 1343, 135, 1782, 1709]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 26 Num points on workers: [201 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :72
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 72 is 1.004116
INFO:root:FL Epoch: 26 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1202
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652850
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514964
INFO:root:FL Epoch: 26 Norm Difference for worker 1202 is 0.976019
INFO:root:FL Epoch: 26 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :209
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 209 is 1.024517
INFO:root:FL Epoch: 26 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :638
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687623
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571548
INFO:root:FL Epoch: 26 Norm Difference for worker 638 is 1.005387
INFO:root:FL Epoch: 26 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :991
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813219
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576213
INFO:root:FL Epoch: 26 Norm Difference for worker 991 is 0.90316
INFO:root:FL Epoch: 26 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :200
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 200 is 0.946487
INFO:root:FL Epoch: 26 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1343
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477889
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566313
INFO:root:FL Epoch: 26 Norm Difference for worker 1343 is 1.058256
INFO:root:FL Epoch: 26 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :135
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759982
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 135 is 0.937121
INFO:root:FL Epoch: 26 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1782
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677539
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568994
INFO:root:FL Epoch: 26 Norm Difference for worker 1782 is 1.044754
INFO:root:FL Epoch: 26 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1709
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779926
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629359
INFO:root:FL Epoch: 26 Norm Difference for worker 1709 is 0.962584
INFO:root:FL Epoch: 26 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 200
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6746807343819562 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:1.4295586744944255                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [36, 216, 1355, 192, 1300, 131, 955, 1644, 451, 161]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.10024938 0.09975062 0.10024938
 0.09975062 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 27 Num points on workers: [201 201 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :36
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635192
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 36 is 1.150548
INFO:root:FL Epoch: 27 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :216
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 216 is 1.146029
INFO:root:FL Epoch: 27 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1355
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706168
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690072
INFO:root:FL Epoch: 27 Norm Difference for worker 1355 is 1.166132
INFO:root:FL Epoch: 27 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :192
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 192 is 1.147206
INFO:root:FL Epoch: 27 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1300
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679609
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633391
INFO:root:FL Epoch: 27 Norm Difference for worker 1300 is 1.097763
INFO:root:FL Epoch: 27 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :131
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 131 is 1.1805
INFO:root:FL Epoch: 27 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :955
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604344
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655042
INFO:root:FL Epoch: 27 Norm Difference for worker 955 is 1.136999
INFO:root:FL Epoch: 27 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1644
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685214
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665147
INFO:root:FL Epoch: 27 Norm Difference for worker 1644 is 1.039268
INFO:root:FL Epoch: 27 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :451
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503739
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437340
INFO:root:FL Epoch: 27 Norm Difference for worker 451 is 1.136062
INFO:root:FL Epoch: 27 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 1.092773
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1644
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 27 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 27 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6411366147153518 and Test Accuracy:62.94117647058823 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:1.1531598567962646                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [1845, 70, 1716, 1178, 512, 244, 126, 320, 176, 1378]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.09975062 0.10024938
 0.10024938 0.10024938 0.10024938 0.09975062]
INFO:root:FL Epoch: 28 Num points on workers: [200 201 200 200 200 201 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :1845
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605848
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565589
INFO:root:FL Epoch: 28 Norm Difference for worker 1845 is 1.157979
INFO:root:FL Epoch: 28 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :70
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 70 is 1.046768
INFO:root:FL Epoch: 28 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1716
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647259
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569094
INFO:root:FL Epoch: 28 Norm Difference for worker 1716 is 1.099147
INFO:root:FL Epoch: 28 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1178
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587421
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507721
INFO:root:FL Epoch: 28 Norm Difference for worker 1178 is 1.13704
INFO:root:FL Epoch: 28 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :512
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559297
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591751
INFO:root:FL Epoch: 28 Norm Difference for worker 512 is 1.113612
INFO:root:FL Epoch: 28 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :244
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490030
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604454
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 244 is 1.068201
INFO:root:FL Epoch: 28 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :126
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 126 is 1.074728
INFO:root:FL Epoch: 28 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :320
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722456
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489976
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 320 is 1.078632
INFO:root:FL Epoch: 28 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :176
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 176 is 1.12965
INFO:root:FL Epoch: 28 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1378
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644866
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666703
INFO:root:FL Epoch: 28 Norm Difference for worker 1378 is 1.110379
INFO:root:FL Epoch: 28 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6484738272779128 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.2313808004061382                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [162, 1727, 1793, 266, 1256, 579, 1535, 1621, 973, 1700]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :162
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 162 is 1.064505
INFO:root:FL Epoch: 29 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1727
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655674
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592897
INFO:root:FL Epoch: 29 Norm Difference for worker 1727 is 1.045001
INFO:root:FL Epoch: 29 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1793
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659086
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529498
INFO:root:FL Epoch: 29 Norm Difference for worker 1793 is 1.130049
INFO:root:FL Epoch: 29 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :266
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 266 is 1.114696
INFO:root:FL Epoch: 29 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1256
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739232
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508025
INFO:root:FL Epoch: 29 Norm Difference for worker 1256 is 1.099104
INFO:root:FL Epoch: 29 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :579
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794320
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709916
INFO:root:FL Epoch: 29 Norm Difference for worker 579 is 1.100149
INFO:root:FL Epoch: 29 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1535
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515354
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540266
INFO:root:FL Epoch: 29 Norm Difference for worker 1535 is 1.127251
INFO:root:FL Epoch: 29 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1621
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598050
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479494
INFO:root:FL Epoch: 29 Norm Difference for worker 1621 is 1.056042
INFO:root:FL Epoch: 29 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :973
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614054
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536755
INFO:root:FL Epoch: 29 Norm Difference for worker 973 is 1.115622
INFO:root:FL Epoch: 29 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1700
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669486
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769640
INFO:root:FL Epoch: 29 Norm Difference for worker 1700 is 1.076799
INFO:root:FL Epoch: 29 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1700
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 29 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 29 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6460678577423096 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:1.1193611025810242                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [380, 267, 1612, 1153, 1392, 24, 1850, 1465, 1517, 907]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :380
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696507
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.774273
INFO:root:FL Epoch: 30 Norm Difference for worker 380 is 1.156372
INFO:root:FL Epoch: 30 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :267
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.728518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 267 is 1.067966
INFO:root:FL Epoch: 30 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1612
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541708
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594727
INFO:root:FL Epoch: 30 Norm Difference for worker 1612 is 1.096373
INFO:root:FL Epoch: 30 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1153
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604157
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561883
INFO:root:FL Epoch: 30 Norm Difference for worker 1153 is 1.068947
INFO:root:FL Epoch: 30 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1392
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631914
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555287
INFO:root:FL Epoch: 30 Norm Difference for worker 1392 is 1.012929
INFO:root:FL Epoch: 30 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :24
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630440
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572989
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 24 is 1.092459
INFO:root:FL Epoch: 30 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1850
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508022
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449097
INFO:root:FL Epoch: 30 Norm Difference for worker 1850 is 1.040625
INFO:root:FL Epoch: 30 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1465
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548125
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582516
INFO:root:FL Epoch: 30 Norm Difference for worker 1465 is 1.048144
INFO:root:FL Epoch: 30 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553253
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656304
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 1.072469
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :907
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526666
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499487
INFO:root:FL Epoch: 30 Norm Difference for worker 907 is 1.097112
INFO:root:FL Epoch: 30 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1392
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6611161109279183 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:1.4354134798049927                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [978, 184, 892, 381, 1259, 916, 834, 744, 145, 1472]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 31 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :978
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678645
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683268
INFO:root:FL Epoch: 31 Norm Difference for worker 978 is 1.29428
INFO:root:FL Epoch: 31 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :184
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 184 is 1.199172
INFO:root:FL Epoch: 31 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :892
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610707
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696897
INFO:root:FL Epoch: 31 Norm Difference for worker 892 is 1.225029
INFO:root:FL Epoch: 31 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :381
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599227
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.789655
INFO:root:FL Epoch: 31 Norm Difference for worker 381 is 1.236303
INFO:root:FL Epoch: 31 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1259
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415840
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493459
INFO:root:FL Epoch: 31 Norm Difference for worker 1259 is 1.215867
INFO:root:FL Epoch: 31 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :916
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727611
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706763
INFO:root:FL Epoch: 31 Norm Difference for worker 916 is 1.334531
INFO:root:FL Epoch: 31 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :834
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626412
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463462
INFO:root:FL Epoch: 31 Norm Difference for worker 834 is 1.244213
INFO:root:FL Epoch: 31 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :744
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775856
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600939
INFO:root:FL Epoch: 31 Norm Difference for worker 744 is 1.342389
INFO:root:FL Epoch: 31 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :145
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537568
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 145 is 1.191124
INFO:root:FL Epoch: 31 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1472
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691890
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439164
INFO:root:FL Epoch: 31 Norm Difference for worker 1472 is 1.31033
INFO:root:FL Epoch: 31 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 31 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 31 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6181993046227623 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:1.2139002680778503                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [903, 616, 1733, 822, 997, 579, 643, 510, 1467, 1167]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :903
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639621
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632395
INFO:root:FL Epoch: 32 Norm Difference for worker 903 is 1.167541
INFO:root:FL Epoch: 32 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :616
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626375
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699798
INFO:root:FL Epoch: 32 Norm Difference for worker 616 is 1.109422
INFO:root:FL Epoch: 32 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1733
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669441
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674864
INFO:root:FL Epoch: 32 Norm Difference for worker 1733 is 1.185195
INFO:root:FL Epoch: 32 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :822
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747900
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510599
INFO:root:FL Epoch: 32 Norm Difference for worker 822 is 1.182286
INFO:root:FL Epoch: 32 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :997
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652451
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511513
INFO:root:FL Epoch: 32 Norm Difference for worker 997 is 1.099959
INFO:root:FL Epoch: 32 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :579
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584629
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476052
INFO:root:FL Epoch: 32 Norm Difference for worker 579 is 1.16865
INFO:root:FL Epoch: 32 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :643
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664465
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588022
INFO:root:FL Epoch: 32 Norm Difference for worker 643 is 1.07654
INFO:root:FL Epoch: 32 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :510
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481959
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.830294
INFO:root:FL Epoch: 32 Norm Difference for worker 510 is 1.161706
INFO:root:FL Epoch: 32 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1467
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608566
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633660
INFO:root:FL Epoch: 32 Norm Difference for worker 1467 is 1.097975
INFO:root:FL Epoch: 32 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1167
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584811
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617367
INFO:root:FL Epoch: 32 Norm Difference for worker 1167 is 1.101815
INFO:root:FL Epoch: 32 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1467
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6294500599889195 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.1241849263509114                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1274, 1195, 596, 322, 1683, 833, 1035, 508, 1137, 295]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1274
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620645
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700254
INFO:root:FL Epoch: 33 Norm Difference for worker 1274 is 1.046961
INFO:root:FL Epoch: 33 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1195
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727846
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650307
INFO:root:FL Epoch: 33 Norm Difference for worker 1195 is 0.917758
INFO:root:FL Epoch: 33 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :596
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599888
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627418
INFO:root:FL Epoch: 33 Norm Difference for worker 596 is 0.943363
INFO:root:FL Epoch: 33 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :322
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 322 is 1.085657
INFO:root:FL Epoch: 33 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1683
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622864
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653490
INFO:root:FL Epoch: 33 Norm Difference for worker 1683 is 0.878562
INFO:root:FL Epoch: 33 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :833
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626806
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448979
INFO:root:FL Epoch: 33 Norm Difference for worker 833 is 0.903307
INFO:root:FL Epoch: 33 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1035
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801003
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544054
INFO:root:FL Epoch: 33 Norm Difference for worker 1035 is 0.977186
INFO:root:FL Epoch: 33 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :508
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654651
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616548
INFO:root:FL Epoch: 33 Norm Difference for worker 508 is 0.959424
INFO:root:FL Epoch: 33 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1137
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782666
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678249
INFO:root:FL Epoch: 33 Norm Difference for worker 1137 is 0.902958
INFO:root:FL Epoch: 33 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :295
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 295 is 0.959638
INFO:root:FL Epoch: 33 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1195
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 33 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 33 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.6218242259586558 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:1.0792450706164043                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1510, 1123, 344, 458, 1551, 1376, 28, 1272, 879, 1250]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1510
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715166
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524392
INFO:root:FL Epoch: 34 Norm Difference for worker 1510 is 0.89586
INFO:root:FL Epoch: 34 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1123
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572232
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668226
INFO:root:FL Epoch: 34 Norm Difference for worker 1123 is 0.911445
INFO:root:FL Epoch: 34 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :344
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634373
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609769
INFO:root:FL Epoch: 34 Norm Difference for worker 344 is 0.868645
INFO:root:FL Epoch: 34 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :458
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595561
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587156
INFO:root:FL Epoch: 34 Norm Difference for worker 458 is 0.909511
INFO:root:FL Epoch: 34 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1551
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607764
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541879
INFO:root:FL Epoch: 34 Norm Difference for worker 1551 is 0.859508
INFO:root:FL Epoch: 34 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1376
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755442
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570031
INFO:root:FL Epoch: 34 Norm Difference for worker 1376 is 0.885455
INFO:root:FL Epoch: 34 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :28
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572874
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 28 is 0.898296
INFO:root:FL Epoch: 34 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1272
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617332
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635056
INFO:root:FL Epoch: 34 Norm Difference for worker 1272 is 0.903012
INFO:root:FL Epoch: 34 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :879
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604006
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634477
INFO:root:FL Epoch: 34 Norm Difference for worker 879 is 0.857545
INFO:root:FL Epoch: 34 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1250
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572355
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712797
INFO:root:FL Epoch: 34 Norm Difference for worker 1250 is 0.888248
INFO:root:FL Epoch: 34 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6085956640103284 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.2392380038897197                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [366, 571, 1908, 1611, 184, 1434, 922, 1568, 672, 321]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :366
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556635
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637596
INFO:root:FL Epoch: 35 Norm Difference for worker 366 is 1.138969
INFO:root:FL Epoch: 35 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :571
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632633
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611787
INFO:root:FL Epoch: 35 Norm Difference for worker 571 is 1.131255
INFO:root:FL Epoch: 35 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1908
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462804
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590871
INFO:root:FL Epoch: 35 Norm Difference for worker 1908 is 1.101903
INFO:root:FL Epoch: 35 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1611
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481303
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467743
INFO:root:FL Epoch: 35 Norm Difference for worker 1611 is 1.074071
INFO:root:FL Epoch: 35 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :184
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 184 is 1.062811
INFO:root:FL Epoch: 35 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1434
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613501
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643256
INFO:root:FL Epoch: 35 Norm Difference for worker 1434 is 1.103882
INFO:root:FL Epoch: 35 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :922
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522797
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618007
INFO:root:FL Epoch: 35 Norm Difference for worker 922 is 1.141343
INFO:root:FL Epoch: 35 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1568
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548392
INFO:root:Worker: 1568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646646
INFO:root:FL Epoch: 35 Norm Difference for worker 1568 is 1.084159
INFO:root:FL Epoch: 35 Done on worker:1568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :672
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606408
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517913
INFO:root:FL Epoch: 35 Norm Difference for worker 672 is 1.082919
INFO:root:FL Epoch: 35 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :321
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 321 is 1.057418
INFO:root:FL Epoch: 35 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6495731806053835 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.4799553553263347                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1866, 642, 1942, 924, 367, 1644, 637, 1651, 1361, 188]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1866
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607188
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766548
INFO:root:FL Epoch: 36 Norm Difference for worker 1866 is 1.236823
INFO:root:FL Epoch: 36 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :642
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521597
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508057
INFO:root:FL Epoch: 36 Norm Difference for worker 642 is 1.193541
INFO:root:FL Epoch: 36 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1942
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542210
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580648
INFO:root:FL Epoch: 36 Norm Difference for worker 1942 is 1.199432
INFO:root:FL Epoch: 36 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :924
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441550
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732975
INFO:root:FL Epoch: 36 Norm Difference for worker 924 is 1.225686
INFO:root:FL Epoch: 36 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :367
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895255
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534599
INFO:root:FL Epoch: 36 Norm Difference for worker 367 is 1.251556
INFO:root:FL Epoch: 36 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1644
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502364
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556743
INFO:root:FL Epoch: 36 Norm Difference for worker 1644 is 1.173497
INFO:root:FL Epoch: 36 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :637
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723797
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470859
INFO:root:FL Epoch: 36 Norm Difference for worker 637 is 1.246398
INFO:root:FL Epoch: 36 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1651
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717192
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632020
INFO:root:FL Epoch: 36 Norm Difference for worker 1651 is 1.198506
INFO:root:FL Epoch: 36 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1361
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661663
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575786
INFO:root:FL Epoch: 36 Norm Difference for worker 1361 is 1.198752
INFO:root:FL Epoch: 36 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :188
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669303
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 188 is 1.163581
INFO:root:FL Epoch: 36 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1651
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6078508461222929 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.2848159273465474                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [693, 406, 1226, 859, 1290, 5, 1911, 0, 1626, 803]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 37 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :693
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664986
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615632
INFO:root:FL Epoch: 37 Norm Difference for worker 693 is 1.000912
INFO:root:FL Epoch: 37 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :406
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671021
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621579
INFO:root:FL Epoch: 37 Norm Difference for worker 406 is 0.993247
INFO:root:FL Epoch: 37 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1226
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573635
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694062
INFO:root:FL Epoch: 37 Norm Difference for worker 1226 is 0.994896
INFO:root:FL Epoch: 37 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :859
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571282
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596733
INFO:root:FL Epoch: 37 Norm Difference for worker 859 is 1.015793
INFO:root:FL Epoch: 37 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1290
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606495
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541288
INFO:root:FL Epoch: 37 Norm Difference for worker 1290 is 0.985633
INFO:root:FL Epoch: 37 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :5
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.864702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608309
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 5 is 0.94417
INFO:root:FL Epoch: 37 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1911
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673026
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590305
INFO:root:FL Epoch: 37 Norm Difference for worker 1911 is 1.065731
INFO:root:FL Epoch: 37 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :0
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 0 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 0 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 0 is 0.987047
INFO:root:FL Epoch: 37 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1626
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591157
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665470
INFO:root:FL Epoch: 37 Norm Difference for worker 1626 is 0.99547
INFO:root:FL Epoch: 37 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :803
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665857
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519247
INFO:root:FL Epoch: 37 Norm Difference for worker 803 is 1.018539
INFO:root:FL Epoch: 37 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 5
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.6243149550522075 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.3570232192675273                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [1592, 261, 935, 1608, 1090, 1662, 1596, 1651, 1859, 1579]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 38 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :1592
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587440
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532881
INFO:root:FL Epoch: 38 Norm Difference for worker 1592 is 0.947255
INFO:root:FL Epoch: 38 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :261
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 261 is 0.957457
INFO:root:FL Epoch: 38 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :935
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653803
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602894
INFO:root:FL Epoch: 38 Norm Difference for worker 935 is 0.934308
INFO:root:FL Epoch: 38 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1608
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700287
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730422
INFO:root:FL Epoch: 38 Norm Difference for worker 1608 is 0.974305
INFO:root:FL Epoch: 38 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1090
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677802
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643863
INFO:root:FL Epoch: 38 Norm Difference for worker 1090 is 0.972217
INFO:root:FL Epoch: 38 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1662
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662367
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540232
INFO:root:FL Epoch: 38 Norm Difference for worker 1662 is 0.999108
INFO:root:FL Epoch: 38 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1596
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629348
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586075
INFO:root:FL Epoch: 38 Norm Difference for worker 1596 is 0.947999
INFO:root:FL Epoch: 38 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1651
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515675
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417094
INFO:root:FL Epoch: 38 Norm Difference for worker 1651 is 1.010324
INFO:root:FL Epoch: 38 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1859
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752040
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672307
INFO:root:FL Epoch: 38 Norm Difference for worker 1859 is 0.902017
INFO:root:FL Epoch: 38 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1579
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737286
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654892
INFO:root:FL Epoch: 38 Norm Difference for worker 1579 is 0.928162
INFO:root:FL Epoch: 38 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 935
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 38 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 38 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6088104861624101 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:1.1049525141716003                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [1583, 630, 1358, 1392, 961, 99, 1105, 705, 1828, 1912]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :1583
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555458
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449350
INFO:root:FL Epoch: 39 Norm Difference for worker 1583 is 0.993957
INFO:root:FL Epoch: 39 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :630
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651253
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755427
INFO:root:FL Epoch: 39 Norm Difference for worker 630 is 1.084844
INFO:root:FL Epoch: 39 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1358
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572749
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452675
INFO:root:FL Epoch: 39 Norm Difference for worker 1358 is 0.995689
INFO:root:FL Epoch: 39 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1392
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460716
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465939
INFO:root:FL Epoch: 39 Norm Difference for worker 1392 is 1.054927
INFO:root:FL Epoch: 39 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :961
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578540
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647362
INFO:root:FL Epoch: 39 Norm Difference for worker 961 is 0.957862
INFO:root:FL Epoch: 39 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :99
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522135
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 99 is 1.07911
INFO:root:FL Epoch: 39 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1105
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592949
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664504
INFO:root:FL Epoch: 39 Norm Difference for worker 1105 is 0.982621
INFO:root:FL Epoch: 39 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :705
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452434
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630800
INFO:root:FL Epoch: 39 Norm Difference for worker 705 is 1.00914
INFO:root:FL Epoch: 39 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1828
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663749
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614160
INFO:root:FL Epoch: 39 Norm Difference for worker 1828 is 1.010957
INFO:root:FL Epoch: 39 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1912
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903717
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565246
INFO:root:FL Epoch: 39 Norm Difference for worker 1912 is 1.114259
INFO:root:FL Epoch: 39 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 961
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6226799698436961 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:1.4312748908996582                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [88, 1028, 1721, 740, 792, 820, 552, 859, 1212, 1538]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :88
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.643139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 88 is 1.054448
INFO:root:FL Epoch: 40 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1028
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732292
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566678
INFO:root:FL Epoch: 40 Norm Difference for worker 1028 is 1.042836
INFO:root:FL Epoch: 40 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1721
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513167
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472965
INFO:root:FL Epoch: 40 Norm Difference for worker 1721 is 1.110456
INFO:root:FL Epoch: 40 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :740
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611920
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480611
INFO:root:FL Epoch: 40 Norm Difference for worker 740 is 1.059968
INFO:root:FL Epoch: 40 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :792
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653089
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554399
INFO:root:FL Epoch: 40 Norm Difference for worker 792 is 1.021575
INFO:root:FL Epoch: 40 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :820
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731230
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708785
INFO:root:FL Epoch: 40 Norm Difference for worker 820 is 1.037464
INFO:root:FL Epoch: 40 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :552
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774776
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.754487
INFO:root:FL Epoch: 40 Norm Difference for worker 552 is 1.115816
INFO:root:FL Epoch: 40 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :859
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704943
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534482
INFO:root:FL Epoch: 40 Norm Difference for worker 859 is 1.087915
INFO:root:FL Epoch: 40 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1212
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538057
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476785
INFO:root:FL Epoch: 40 Norm Difference for worker 1212 is 1.074536
INFO:root:FL Epoch: 40 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1538
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586542
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540622
INFO:root:FL Epoch: 40 Norm Difference for worker 1538 is 0.984398
INFO:root:FL Epoch: 40 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.6151415127165177 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.3444081544876099                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [535, 112, 1179, 1629, 515, 21, 1530, 116, 1156, 233]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 41 Num points on workers: [200 201 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :535
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599584
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648513
INFO:root:FL Epoch: 41 Norm Difference for worker 535 is 0.978937
INFO:root:FL Epoch: 41 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :112
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.757616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 112 is 1.071314
INFO:root:FL Epoch: 41 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1179
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632285
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561268
INFO:root:FL Epoch: 41 Norm Difference for worker 1179 is 0.948044
INFO:root:FL Epoch: 41 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1629
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629126
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659949
INFO:root:FL Epoch: 41 Norm Difference for worker 1629 is 1.051875
INFO:root:FL Epoch: 41 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :515
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638638
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471197
INFO:root:FL Epoch: 41 Norm Difference for worker 515 is 1.001567
INFO:root:FL Epoch: 41 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :21
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 21 is 0.973261
INFO:root:FL Epoch: 41 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1530
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684871
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686825
INFO:root:FL Epoch: 41 Norm Difference for worker 1530 is 1.018515
INFO:root:FL Epoch: 41 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :116
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629893
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 116 is 1.00992
INFO:root:FL Epoch: 41 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1156
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729380
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.854145
INFO:root:FL Epoch: 41 Norm Difference for worker 1156 is 0.979801
INFO:root:FL Epoch: 41 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :233
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 233 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 233 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 233 is 0.97242
INFO:root:FL Epoch: 41 Done on worker:233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1179
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 41 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 41 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.5968271651688744 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:1.276541034380595                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1141, 130, 1795, 362, 1761, 119, 264, 784, 1928, 1269]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 42 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1141
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622130
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551172
INFO:root:FL Epoch: 42 Norm Difference for worker 1141 is 1.077687
INFO:root:FL Epoch: 42 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :130
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 130 is 0.949846
INFO:root:FL Epoch: 42 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1795
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701632
INFO:root:Worker: 1795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693777
INFO:root:FL Epoch: 42 Norm Difference for worker 1795 is 1.014094
INFO:root:FL Epoch: 42 Done on worker:1795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :362
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654572
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464546
INFO:root:FL Epoch: 42 Norm Difference for worker 362 is 1.062437
INFO:root:FL Epoch: 42 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1761
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677086
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719879
INFO:root:FL Epoch: 42 Norm Difference for worker 1761 is 1.030604
INFO:root:FL Epoch: 42 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :119
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573675
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 119 is 1.052718
INFO:root:FL Epoch: 42 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :264
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626257
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 264 is 1.044118
INFO:root:FL Epoch: 42 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :784
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647976
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528291
INFO:root:FL Epoch: 42 Norm Difference for worker 784 is 0.954216
INFO:root:FL Epoch: 42 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1928
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609987
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555596
INFO:root:FL Epoch: 42 Norm Difference for worker 1928 is 1.011904
INFO:root:FL Epoch: 42 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1269
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494608
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633740
INFO:root:FL Epoch: 42 Norm Difference for worker 1269 is 1.039843
INFO:root:FL Epoch: 42 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 784
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 42 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 42 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.5902516841888428 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:1.4314660628636677                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [1159, 1856, 275, 1724, 1508, 1733, 1417, 1630, 1187, 918]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 43 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :1159
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690241
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612912
INFO:root:FL Epoch: 43 Norm Difference for worker 1159 is 1.044548
INFO:root:FL Epoch: 43 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1856
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774169
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543484
INFO:root:FL Epoch: 43 Norm Difference for worker 1856 is 1.096229
INFO:root:FL Epoch: 43 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :275
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 275 Train Epoch: 0 [0/201 (0%)]	Loss: 0.731755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 275 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561881
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 275 is 1.107105
INFO:root:FL Epoch: 43 Done on worker:275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1724
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646198
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572648
INFO:root:FL Epoch: 43 Norm Difference for worker 1724 is 1.125018
INFO:root:FL Epoch: 43 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1508
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617008
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676705
INFO:root:FL Epoch: 43 Norm Difference for worker 1508 is 1.09412
INFO:root:FL Epoch: 43 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1733
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746028
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613037
INFO:root:FL Epoch: 43 Norm Difference for worker 1733 is 1.062044
INFO:root:FL Epoch: 43 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1417
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718498
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489391
INFO:root:FL Epoch: 43 Norm Difference for worker 1417 is 1.016302
INFO:root:FL Epoch: 43 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1630
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622418
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585361
INFO:root:FL Epoch: 43 Norm Difference for worker 1630 is 1.034419
INFO:root:FL Epoch: 43 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1187
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597532
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554049
INFO:root:FL Epoch: 43 Norm Difference for worker 1187 is 1.094458
INFO:root:FL Epoch: 43 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :918
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702326
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628263
INFO:root:FL Epoch: 43 Norm Difference for worker 918 is 1.097598
INFO:root:FL Epoch: 43 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1417
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.588752376682618 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:1.35787429412206                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [1518, 1034, 655, 126, 238, 312, 371, 601, 524, 1069]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :1518
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564559
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609114
INFO:root:FL Epoch: 44 Norm Difference for worker 1518 is 1.112691
INFO:root:FL Epoch: 44 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1034
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538298
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588088
INFO:root:FL Epoch: 44 Norm Difference for worker 1034 is 1.12488
INFO:root:FL Epoch: 44 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :655
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686458
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570660
INFO:root:FL Epoch: 44 Norm Difference for worker 655 is 1.021646
INFO:root:FL Epoch: 44 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :126
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.745145
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.662908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 126 is 1.019862
INFO:root:FL Epoch: 44 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :238
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 238 is 1.038235
INFO:root:FL Epoch: 44 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :312
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 312 is 1.03377
INFO:root:FL Epoch: 44 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :371
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582816
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697523
INFO:root:FL Epoch: 44 Norm Difference for worker 371 is 1.057648
INFO:root:FL Epoch: 44 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :601
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668417
INFO:root:Worker: 601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632364
INFO:root:FL Epoch: 44 Norm Difference for worker 601 is 1.035334
INFO:root:FL Epoch: 44 Done on worker:601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :524
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699024
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506549
INFO:root:FL Epoch: 44 Norm Difference for worker 524 is 1.013138
INFO:root:FL Epoch: 44 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1069
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732176
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614073
INFO:root:FL Epoch: 44 Norm Difference for worker 1069 is 1.096194
INFO:root:FL Epoch: 44 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 126
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6159172601559583 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:1.259312669436137                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [1888, 1353, 1165, 1072, 575, 1767, 401, 1724, 855, 527]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 45 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :1888
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569421
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672213
INFO:root:FL Epoch: 45 Norm Difference for worker 1888 is 0.979075
INFO:root:FL Epoch: 45 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1353
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573802
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618863
INFO:root:FL Epoch: 45 Norm Difference for worker 1353 is 1.014736
INFO:root:FL Epoch: 45 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1165
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508594
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396950
INFO:root:FL Epoch: 45 Norm Difference for worker 1165 is 1.140351
INFO:root:FL Epoch: 45 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1072
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702500
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650620
INFO:root:FL Epoch: 45 Norm Difference for worker 1072 is 0.983606
INFO:root:FL Epoch: 45 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :575
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698439
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716355
INFO:root:FL Epoch: 45 Norm Difference for worker 575 is 0.935192
INFO:root:FL Epoch: 45 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1767
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607708
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678887
INFO:root:FL Epoch: 45 Norm Difference for worker 1767 is 0.974006
INFO:root:FL Epoch: 45 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :401
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708190
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424879
INFO:root:FL Epoch: 45 Norm Difference for worker 401 is 0.960022
INFO:root:FL Epoch: 45 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1724
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698634
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537943
INFO:root:FL Epoch: 45 Norm Difference for worker 1724 is 1.043014
INFO:root:FL Epoch: 45 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :855
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564867
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493627
INFO:root:FL Epoch: 45 Norm Difference for worker 855 is 0.962691
INFO:root:FL Epoch: 45 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :527
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642766
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584959
INFO:root:FL Epoch: 45 Norm Difference for worker 527 is 0.987239
INFO:root:FL Epoch: 45 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 401
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6220891913946938 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:1.2629610300064087                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1806, 1474, 1595, 512, 446, 1283, 1655, 128, 825, 1174]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1806
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621063
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514308
INFO:root:FL Epoch: 46 Norm Difference for worker 1806 is 1.017453
INFO:root:FL Epoch: 46 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1474
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708461
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601192
INFO:root:FL Epoch: 46 Norm Difference for worker 1474 is 1.087771
INFO:root:FL Epoch: 46 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1595
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533435
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276120
INFO:root:FL Epoch: 46 Norm Difference for worker 1595 is 1.050805
INFO:root:FL Epoch: 46 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :512
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634745
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687659
INFO:root:FL Epoch: 46 Norm Difference for worker 512 is 1.114504
INFO:root:FL Epoch: 46 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :446
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478330
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449892
INFO:root:FL Epoch: 46 Norm Difference for worker 446 is 1.109321
INFO:root:FL Epoch: 46 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1283
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613925
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466769
INFO:root:FL Epoch: 46 Norm Difference for worker 1283 is 1.082779
INFO:root:FL Epoch: 46 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1655
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574590
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599255
INFO:root:FL Epoch: 46 Norm Difference for worker 1655 is 1.113256
INFO:root:FL Epoch: 46 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :128
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 128 is 1.06063
INFO:root:FL Epoch: 46 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :825
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700322
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493014
INFO:root:FL Epoch: 46 Norm Difference for worker 825 is 1.039189
INFO:root:FL Epoch: 46 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1174
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491526
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593372
INFO:root:FL Epoch: 46 Norm Difference for worker 1174 is 1.092844
INFO:root:FL Epoch: 46 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1806
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6166139490464154 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:1.2507755359013875                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1317, 487, 866, 1113, 233, 926, 1178, 1290, 1444, 572]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1317
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591572
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667564
INFO:root:FL Epoch: 47 Norm Difference for worker 1317 is 0.957335
INFO:root:FL Epoch: 47 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :487
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615898
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614930
INFO:root:FL Epoch: 47 Norm Difference for worker 487 is 0.889725
INFO:root:FL Epoch: 47 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :866
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518059
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596911
INFO:root:FL Epoch: 47 Norm Difference for worker 866 is 0.937842
INFO:root:FL Epoch: 47 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1113
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660597
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495761
INFO:root:FL Epoch: 47 Norm Difference for worker 1113 is 0.960957
INFO:root:FL Epoch: 47 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :233
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 233 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 233 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 47 Norm Difference for worker 233 is 0.969462
INFO:root:FL Epoch: 47 Done on worker:233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :926
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534479
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700385
INFO:root:FL Epoch: 47 Norm Difference for worker 926 is 0.956775
INFO:root:FL Epoch: 47 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1178
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705054
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644870
INFO:root:FL Epoch: 47 Norm Difference for worker 1178 is 1.013228
INFO:root:FL Epoch: 47 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1290
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645710
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827792
INFO:root:FL Epoch: 47 Norm Difference for worker 1290 is 0.955114
INFO:root:FL Epoch: 47 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1444
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794139
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486639
INFO:root:FL Epoch: 47 Norm Difference for worker 1444 is 0.937869
INFO:root:FL Epoch: 47 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :572
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674566
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566448
INFO:root:FL Epoch: 47 Norm Difference for worker 572 is 0.972929
INFO:root:FL Epoch: 47 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1444
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.5963138604865355 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:1.2462510466575623                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [869, 77, 1050, 881, 1915, 545, 1306, 1810, 527, 282]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 48 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :869
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408920
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407153
INFO:root:FL Epoch: 48 Norm Difference for worker 869 is 1.124312
INFO:root:FL Epoch: 48 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :77
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 77 is 1.156018
INFO:root:FL Epoch: 48 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1050
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008578
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669569
INFO:root:FL Epoch: 48 Norm Difference for worker 1050 is 1.183398
INFO:root:FL Epoch: 48 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :881
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528755
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509112
INFO:root:FL Epoch: 48 Norm Difference for worker 881 is 1.156598
INFO:root:FL Epoch: 48 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1915
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536588
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571049
INFO:root:FL Epoch: 48 Norm Difference for worker 1915 is 1.139364
INFO:root:FL Epoch: 48 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :545
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487746
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581979
INFO:root:FL Epoch: 48 Norm Difference for worker 545 is 1.071973
INFO:root:FL Epoch: 48 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1306
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839585
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523330
INFO:root:FL Epoch: 48 Norm Difference for worker 1306 is 1.107031
INFO:root:FL Epoch: 48 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1810
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567754
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537009
INFO:root:FL Epoch: 48 Norm Difference for worker 1810 is 1.08097
INFO:root:FL Epoch: 48 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540783
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513831
INFO:root:FL Epoch: 48 Norm Difference for worker 527 is 1.108494
INFO:root:FL Epoch: 48 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :282
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.796366
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613874
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 282 is 1.19448
INFO:root:FL Epoch: 48 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 545
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.6384619772434235 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.1965722441673279                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [902, 1862, 1841, 805, 19, 1053, 1431, 1287, 1519, 748]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :902
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641242
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387226
INFO:root:FL Epoch: 49 Norm Difference for worker 902 is 1.171967
INFO:root:FL Epoch: 49 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598148
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543710
INFO:root:FL Epoch: 49 Norm Difference for worker 1862 is 1.278925
INFO:root:FL Epoch: 49 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1841
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740243
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533605
INFO:root:FL Epoch: 49 Norm Difference for worker 1841 is 1.180744
INFO:root:FL Epoch: 49 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :805
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529169
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568665
INFO:root:FL Epoch: 49 Norm Difference for worker 805 is 1.163558
INFO:root:FL Epoch: 49 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :19
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 19 is 1.147605
INFO:root:FL Epoch: 49 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1053
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652685
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487808
INFO:root:FL Epoch: 49 Norm Difference for worker 1053 is 1.113995
INFO:root:FL Epoch: 49 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1431
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670626
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597073
INFO:root:FL Epoch: 49 Norm Difference for worker 1431 is 1.141204
INFO:root:FL Epoch: 49 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1287
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653868
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572015
INFO:root:FL Epoch: 49 Norm Difference for worker 1287 is 1.131509
INFO:root:FL Epoch: 49 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1519
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519901
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656817
INFO:root:FL Epoch: 49 Norm Difference for worker 1519 is 1.091168
INFO:root:FL Epoch: 49 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :748
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566167
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631020
INFO:root:FL Epoch: 49 Norm Difference for worker 748 is 1.300317
INFO:root:FL Epoch: 49 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1519
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.623627096414566 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:0.9984456400076548                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [75, 1384, 238, 1404, 172, 74, 453, 812, 1345, 204]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.10024938 0.09975062 0.10024938 0.10024938
 0.09975062 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 50 Num points on workers: [201 200 201 200 201 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :75
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.770926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 75 is 1.025292
INFO:root:FL Epoch: 50 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1384
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452787
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571525
INFO:root:FL Epoch: 50 Norm Difference for worker 1384 is 1.055125
INFO:root:FL Epoch: 50 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :238
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 238 is 1.049384
INFO:root:FL Epoch: 50 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1404
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655209
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518803
INFO:root:FL Epoch: 50 Norm Difference for worker 1404 is 1.080251
INFO:root:FL Epoch: 50 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :172
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 172 is 0.982196
INFO:root:FL Epoch: 50 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :74
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 74 is 1.039974
INFO:root:FL Epoch: 50 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :453
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689276
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649553
INFO:root:FL Epoch: 50 Norm Difference for worker 453 is 0.991172
INFO:root:FL Epoch: 50 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :812
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509022
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595669
INFO:root:FL Epoch: 50 Norm Difference for worker 812 is 1.113714
INFO:root:FL Epoch: 50 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1345
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570958
INFO:root:Worker: 1345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524154
INFO:root:FL Epoch: 50 Norm Difference for worker 1345 is 0.999979
INFO:root:FL Epoch: 50 Done on worker:1345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :204
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.743855
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537704
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 204 is 1.064632
INFO:root:FL Epoch: 50 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 172
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.5932677861522225 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.228959580262502                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [172, 180, 1824, 1527, 308, 497, 886, 170, 1838, 190]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.09975062 0.10024938 0.09975062 0.10024938]
INFO:root:FL Epoch: 51 Num points on workers: [201 201 200 200 201 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :172
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 172 is 0.990222
INFO:root:FL Epoch: 51 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :180
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484639
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 180 is 1.041747
INFO:root:FL Epoch: 51 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1824
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611458
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566754
INFO:root:FL Epoch: 51 Norm Difference for worker 1824 is 1.004816
INFO:root:FL Epoch: 51 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1527
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534827
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523055
INFO:root:FL Epoch: 51 Norm Difference for worker 1527 is 1.044131
INFO:root:FL Epoch: 51 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :308
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 308 is 0.939447
INFO:root:FL Epoch: 51 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :497
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657470
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735857
INFO:root:FL Epoch: 51 Norm Difference for worker 497 is 0.975008
INFO:root:FL Epoch: 51 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :886
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586927
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561611
INFO:root:FL Epoch: 51 Norm Difference for worker 886 is 1.00079
INFO:root:FL Epoch: 51 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :170
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 170 is 0.99512
INFO:root:FL Epoch: 51 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1838
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618486
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593915
INFO:root:FL Epoch: 51 Norm Difference for worker 1838 is 0.924358
INFO:root:FL Epoch: 51 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :190
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561366
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657909
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 190 is 0.994745
INFO:root:FL Epoch: 51 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.5913279389633852 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:1.135616143544515                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [220, 523, 1136, 569, 813, 527, 1785, 1259, 1025, 1122]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 52 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :220
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 220 is 0.943968
INFO:root:FL Epoch: 52 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :523
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562947
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603688
INFO:root:FL Epoch: 52 Norm Difference for worker 523 is 1.054155
INFO:root:FL Epoch: 52 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1136
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782300
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699202
INFO:root:FL Epoch: 52 Norm Difference for worker 1136 is 0.983378
INFO:root:FL Epoch: 52 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :569
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534488
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524566
INFO:root:FL Epoch: 52 Norm Difference for worker 569 is 1.079678
INFO:root:FL Epoch: 52 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :813
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613986
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677854
INFO:root:FL Epoch: 52 Norm Difference for worker 813 is 1.005277
INFO:root:FL Epoch: 52 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :527
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800857
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571840
INFO:root:FL Epoch: 52 Norm Difference for worker 527 is 1.022943
INFO:root:FL Epoch: 52 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1785
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788977
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608920
INFO:root:FL Epoch: 52 Norm Difference for worker 1785 is 1.029892
INFO:root:FL Epoch: 52 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1259
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647311
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667390
INFO:root:FL Epoch: 52 Norm Difference for worker 1259 is 0.991718
INFO:root:FL Epoch: 52 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1025
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547223
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692805
INFO:root:FL Epoch: 52 Norm Difference for worker 1025 is 1.031404
INFO:root:FL Epoch: 52 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1122
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444244
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486069
INFO:root:FL Epoch: 52 Norm Difference for worker 1122 is 1.036075
INFO:root:FL Epoch: 52 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 52 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 52 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.5973656124928418 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:1.1389769911766052                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1471, 939, 1153, 1087, 1046, 295, 437, 1187, 233, 1255]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1471
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566877
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463024
INFO:root:FL Epoch: 53 Norm Difference for worker 1471 is 0.931255
INFO:root:FL Epoch: 53 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :939
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846103
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589594
INFO:root:FL Epoch: 53 Norm Difference for worker 939 is 0.876749
INFO:root:FL Epoch: 53 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1153
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628991
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610260
INFO:root:FL Epoch: 53 Norm Difference for worker 1153 is 0.994768
INFO:root:FL Epoch: 53 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1087
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703919
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538702
INFO:root:FL Epoch: 53 Norm Difference for worker 1087 is 1.02747
INFO:root:FL Epoch: 53 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1046
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543667
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433046
INFO:root:FL Epoch: 53 Norm Difference for worker 1046 is 0.985034
INFO:root:FL Epoch: 53 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :295
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 295 is 0.976226
INFO:root:FL Epoch: 53 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :437
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581981
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575655
INFO:root:FL Epoch: 53 Norm Difference for worker 437 is 1.029053
INFO:root:FL Epoch: 53 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1187
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705475
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489143
INFO:root:FL Epoch: 53 Norm Difference for worker 1187 is 0.963787
INFO:root:FL Epoch: 53 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :233
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 233 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 233 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 233 is 0.963815
INFO:root:FL Epoch: 53 Done on worker:233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1255
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491900
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391198
INFO:root:FL Epoch: 53 Norm Difference for worker 1255 is 1.038471
INFO:root:FL Epoch: 53 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1187
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.5941647501552806 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.5626135269800823                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [325, 1317, 1329, 1162, 172, 631, 310, 407, 653, 229]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 54 Num points on workers: [201 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :325
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.719460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 325 is 1.194017
INFO:root:FL Epoch: 54 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1317
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568284
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645115
INFO:root:FL Epoch: 54 Norm Difference for worker 1317 is 1.167055
INFO:root:FL Epoch: 54 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1329
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556121
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497285
INFO:root:FL Epoch: 54 Norm Difference for worker 1329 is 1.180262
INFO:root:FL Epoch: 54 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1162
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664151
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698179
INFO:root:FL Epoch: 54 Norm Difference for worker 1162 is 1.238544
INFO:root:FL Epoch: 54 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :172
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 172 is 1.049287
INFO:root:FL Epoch: 54 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :631
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554628
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371935
INFO:root:FL Epoch: 54 Norm Difference for worker 631 is 1.161017
INFO:root:FL Epoch: 54 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :310
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.775828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 310 is 1.172543
INFO:root:FL Epoch: 54 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :407
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528545
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552427
INFO:root:FL Epoch: 54 Norm Difference for worker 407 is 1.144653
INFO:root:FL Epoch: 54 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :653
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852648
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.814167
INFO:root:FL Epoch: 54 Norm Difference for worker 653 is 1.132691
INFO:root:FL Epoch: 54 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :229
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 229 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 229 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686737
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 229 is 1.118131
INFO:root:FL Epoch: 54 Done on worker:229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 653
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 54 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 54 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.5852499884717605 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:1.3183394869168599                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [627, 1645, 96, 610, 400, 1660, 417, 1827, 1109, 818]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :627
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553967
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643717
INFO:root:FL Epoch: 55 Norm Difference for worker 627 is 0.987387
INFO:root:FL Epoch: 55 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1645
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490388
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424591
INFO:root:FL Epoch: 55 Norm Difference for worker 1645 is 1.052913
INFO:root:FL Epoch: 55 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :96
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.810899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 96 is 1.010115
INFO:root:FL Epoch: 55 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :610
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494861
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458235
INFO:root:FL Epoch: 55 Norm Difference for worker 610 is 1.049671
INFO:root:FL Epoch: 55 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :400
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631734
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729007
INFO:root:FL Epoch: 55 Norm Difference for worker 400 is 1.017656
INFO:root:FL Epoch: 55 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1660
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623407
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649521
INFO:root:FL Epoch: 55 Norm Difference for worker 1660 is 0.998704
INFO:root:FL Epoch: 55 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :417
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584988
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551229
INFO:root:FL Epoch: 55 Norm Difference for worker 417 is 1.053083
INFO:root:FL Epoch: 55 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1827
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613695
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513712
INFO:root:FL Epoch: 55 Norm Difference for worker 1827 is 0.981007
INFO:root:FL Epoch: 55 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1109
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684532
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666716
INFO:root:FL Epoch: 55 Norm Difference for worker 1109 is 0.963609
INFO:root:FL Epoch: 55 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :818
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604486
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584505
INFO:root:FL Epoch: 55 Norm Difference for worker 818 is 1.061944
INFO:root:FL Epoch: 55 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1109
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.5988239470650168 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:1.4626910885175068                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [1564, 1475, 1289, 1188, 1613, 110, 1873, 367, 1228, 1586]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 56 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :1564
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576720
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568533
INFO:root:FL Epoch: 56 Norm Difference for worker 1564 is 1.002966
INFO:root:FL Epoch: 56 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1475
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524517
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604427
INFO:root:FL Epoch: 56 Norm Difference for worker 1475 is 1.034513
INFO:root:FL Epoch: 56 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1289
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770149
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590632
INFO:root:FL Epoch: 56 Norm Difference for worker 1289 is 0.933295
INFO:root:FL Epoch: 56 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1188
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624596
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565365
INFO:root:FL Epoch: 56 Norm Difference for worker 1188 is 0.994285
INFO:root:FL Epoch: 56 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1613
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616159
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607374
INFO:root:FL Epoch: 56 Norm Difference for worker 1613 is 0.998006
INFO:root:FL Epoch: 56 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :110
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 110 is 1.015422
INFO:root:FL Epoch: 56 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1873
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624630
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534349
INFO:root:FL Epoch: 56 Norm Difference for worker 1873 is 1.066025
INFO:root:FL Epoch: 56 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :367
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537663
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481337
INFO:root:FL Epoch: 56 Norm Difference for worker 367 is 1.02088
INFO:root:FL Epoch: 56 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1228
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571553
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597062
INFO:root:FL Epoch: 56 Norm Difference for worker 1228 is 0.963266
INFO:root:FL Epoch: 56 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1586
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678998
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708066
INFO:root:FL Epoch: 56 Norm Difference for worker 1586 is 1.030327
INFO:root:FL Epoch: 56 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1289
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.6102956533432007 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.623198966185252                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [320, 808, 802, 102, 21, 531, 1340, 1145, 1578, 925]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 57 Num points on workers: [201 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :320
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 320 is 1.099424
INFO:root:FL Epoch: 57 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :808
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638396
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393791
INFO:root:FL Epoch: 57 Norm Difference for worker 808 is 1.069534
INFO:root:FL Epoch: 57 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :802
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569535
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542281
INFO:root:FL Epoch: 57 Norm Difference for worker 802 is 1.046197
INFO:root:FL Epoch: 57 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :102
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465104
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 102 is 1.099479
INFO:root:FL Epoch: 57 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :21
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641643
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 21 is 1.020252
INFO:root:FL Epoch: 57 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :531
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561456
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406810
INFO:root:FL Epoch: 57 Norm Difference for worker 531 is 1.037252
INFO:root:FL Epoch: 57 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1340
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553038
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488949
INFO:root:FL Epoch: 57 Norm Difference for worker 1340 is 1.066988
INFO:root:FL Epoch: 57 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1145
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396761
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543126
INFO:root:FL Epoch: 57 Norm Difference for worker 1145 is 1.0605
INFO:root:FL Epoch: 57 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1578
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674681
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597755
INFO:root:FL Epoch: 57 Norm Difference for worker 1578 is 1.043096
INFO:root:FL Epoch: 57 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :925
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592891
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466828
INFO:root:FL Epoch: 57 Norm Difference for worker 925 is 1.021336
INFO:root:FL Epoch: 57 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6098920019233928 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:1.7698394656181335                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [803, 1489, 1608, 204, 1557, 1857, 1340, 1736, 657, 997]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :803
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540117
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530764
INFO:root:FL Epoch: 58 Norm Difference for worker 803 is 1.126108
INFO:root:FL Epoch: 58 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1489
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808408
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556744
INFO:root:FL Epoch: 58 Norm Difference for worker 1489 is 1.165161
INFO:root:FL Epoch: 58 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1608
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629070
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459073
INFO:root:FL Epoch: 58 Norm Difference for worker 1608 is 1.136735
INFO:root:FL Epoch: 58 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :204
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 204 is 1.202542
INFO:root:FL Epoch: 58 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1557
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735648
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554207
INFO:root:FL Epoch: 58 Norm Difference for worker 1557 is 1.056014
INFO:root:FL Epoch: 58 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1857
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520358
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714300
INFO:root:FL Epoch: 58 Norm Difference for worker 1857 is 1.167763
INFO:root:FL Epoch: 58 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1340
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709915
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544273
INFO:root:FL Epoch: 58 Norm Difference for worker 1340 is 1.164505
INFO:root:FL Epoch: 58 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1736
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521032
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582893
INFO:root:FL Epoch: 58 Norm Difference for worker 1736 is 1.116331
INFO:root:FL Epoch: 58 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :657
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546346
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627043
INFO:root:FL Epoch: 58 Norm Difference for worker 657 is 1.17482
INFO:root:FL Epoch: 58 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :997
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442460
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559595
INFO:root:FL Epoch: 58 Norm Difference for worker 997 is 1.133931
INFO:root:FL Epoch: 58 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6134998325039359 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:1.9127244750658672                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [871, 454, 900, 1156, 1716, 400, 865, 273, 468, 1708]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :871
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509180
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495200
INFO:root:FL Epoch: 59 Norm Difference for worker 871 is 1.219138
INFO:root:FL Epoch: 59 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :454
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659278
INFO:root:Worker: 454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505761
INFO:root:FL Epoch: 59 Norm Difference for worker 454 is 1.183939
INFO:root:FL Epoch: 59 Done on worker:454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :900
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495568
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519571
INFO:root:FL Epoch: 59 Norm Difference for worker 900 is 1.220954
INFO:root:FL Epoch: 59 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1156
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647303
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683330
INFO:root:FL Epoch: 59 Norm Difference for worker 1156 is 1.260455
INFO:root:FL Epoch: 59 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1716
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629473
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526338
INFO:root:FL Epoch: 59 Norm Difference for worker 1716 is 1.179418
INFO:root:FL Epoch: 59 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :400
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564712
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746714
INFO:root:FL Epoch: 59 Norm Difference for worker 400 is 1.198573
INFO:root:FL Epoch: 59 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :865
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621929
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647317
INFO:root:FL Epoch: 59 Norm Difference for worker 865 is 1.184449
INFO:root:FL Epoch: 59 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :273
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 273 is 1.143915
INFO:root:FL Epoch: 59 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :468
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685944
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377362
INFO:root:FL Epoch: 59 Norm Difference for worker 468 is 1.099292
INFO:root:FL Epoch: 59 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1708
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594820
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533380
INFO:root:FL Epoch: 59 Norm Difference for worker 1708 is 1.123798
INFO:root:FL Epoch: 59 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1708
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6071434389142429 and Test Accuracy:62.94117647058823 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.7148565848668416                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [847, 1512, 1411, 455, 1723, 285, 893, 1918, 1462, 596]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 60 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :847
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584285
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653345
INFO:root:FL Epoch: 60 Norm Difference for worker 847 is 0.996201
INFO:root:FL Epoch: 60 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1512
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547097
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532920
INFO:root:FL Epoch: 60 Norm Difference for worker 1512 is 1.08929
INFO:root:FL Epoch: 60 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1411
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551901
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756487
INFO:root:FL Epoch: 60 Norm Difference for worker 1411 is 1.003162
INFO:root:FL Epoch: 60 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :455
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594107
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500994
INFO:root:FL Epoch: 60 Norm Difference for worker 455 is 1.071241
INFO:root:FL Epoch: 60 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1723
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673585
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552499
INFO:root:FL Epoch: 60 Norm Difference for worker 1723 is 1.012142
INFO:root:FL Epoch: 60 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :285
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 285 is 1.002543
INFO:root:FL Epoch: 60 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :893
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552569
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532288
INFO:root:FL Epoch: 60 Norm Difference for worker 893 is 1.1256
INFO:root:FL Epoch: 60 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1918
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375563
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543853
INFO:root:FL Epoch: 60 Norm Difference for worker 1918 is 1.048404
INFO:root:FL Epoch: 60 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1462
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775027
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573299
INFO:root:FL Epoch: 60 Norm Difference for worker 1462 is 1.070029
INFO:root:FL Epoch: 60 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :596
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626712
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508828
INFO:root:FL Epoch: 60 Norm Difference for worker 596 is 1.056444
INFO:root:FL Epoch: 60 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1411
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.5937032699584961 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:1.6680481632550557                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [905, 85, 105, 381, 113, 46, 72, 1695, 10, 207]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.09965122 0.10014948 0.10014948 0.09965122 0.10014948 0.10014948
 0.10014948 0.09965122 0.10014948 0.10014948]
INFO:root:FL Epoch: 61 Num points on workers: [200 201 201 200 201 201 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :905
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430411
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447230
INFO:root:FL Epoch: 61 Norm Difference for worker 905 is 1.065259
INFO:root:FL Epoch: 61 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :85
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 85 is 1.099667
INFO:root:FL Epoch: 61 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :105
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 105 is 1.040501
INFO:root:FL Epoch: 61 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :381
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575429
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672858
INFO:root:FL Epoch: 61 Norm Difference for worker 381 is 1.059022
INFO:root:FL Epoch: 61 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :113
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 113 is 1.027093
INFO:root:FL Epoch: 61 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :46
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495480
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 46 is 1.078888
INFO:root:FL Epoch: 61 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :72
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 72 is 1.086591
INFO:root:FL Epoch: 61 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1695
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743088
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462056
INFO:root:FL Epoch: 61 Norm Difference for worker 1695 is 1.020986
INFO:root:FL Epoch: 61 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :10
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546707
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538231
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 10 is 1.167557
INFO:root:FL Epoch: 61 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :207
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560711
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 207 is 1.035
INFO:root:FL Epoch: 61 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 113
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.5829229232142953 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.9579343795776367                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [259, 486, 1499, 1500, 1119, 1166, 1750, 139, 326, 1297]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :259
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 259 is 1.130154
INFO:root:FL Epoch: 62 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :486
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596033
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569010
INFO:root:FL Epoch: 62 Norm Difference for worker 486 is 1.104528
INFO:root:FL Epoch: 62 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1499
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579051
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455012
INFO:root:FL Epoch: 62 Norm Difference for worker 1499 is 1.147708
INFO:root:FL Epoch: 62 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1500
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556809
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507954
INFO:root:FL Epoch: 62 Norm Difference for worker 1500 is 1.115297
INFO:root:FL Epoch: 62 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1119
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632950
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543191
INFO:root:FL Epoch: 62 Norm Difference for worker 1119 is 1.146634
INFO:root:FL Epoch: 62 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1166
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1166 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727594
INFO:root:Worker: 1166 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644461
INFO:root:FL Epoch: 62 Norm Difference for worker 1166 is 1.14282
INFO:root:FL Epoch: 62 Done on worker:1166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1750
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.972976
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586983
INFO:root:FL Epoch: 62 Norm Difference for worker 1750 is 1.127441
INFO:root:FL Epoch: 62 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :139
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540285
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 139 is 1.134163
INFO:root:FL Epoch: 62 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :326
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 326 is 1.14912
INFO:root:FL Epoch: 62 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1297
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599622
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762063
INFO:root:FL Epoch: 62 Norm Difference for worker 1297 is 1.234908
INFO:root:FL Epoch: 62 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1750
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.6023154767120585 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.4007069667180378                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1468, 598, 152, 1876, 1359, 830, 303, 1423, 1586, 913]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1468
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631558
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637004
INFO:root:FL Epoch: 63 Norm Difference for worker 1468 is 0.800826
INFO:root:FL Epoch: 63 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :598
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503959
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641767
INFO:root:FL Epoch: 63 Norm Difference for worker 598 is 0.883689
INFO:root:FL Epoch: 63 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :152
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593009
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 152 is 0.885271
INFO:root:FL Epoch: 63 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1876
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655648
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522424
INFO:root:FL Epoch: 63 Norm Difference for worker 1876 is 0.983923
INFO:root:FL Epoch: 63 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1359
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594078
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537257
INFO:root:FL Epoch: 63 Norm Difference for worker 1359 is 0.905681
INFO:root:FL Epoch: 63 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :830
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585130
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563033
INFO:root:FL Epoch: 63 Norm Difference for worker 830 is 0.979215
INFO:root:FL Epoch: 63 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :303
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 303 is 0.811818
INFO:root:FL Epoch: 63 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1423
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576553
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494989
INFO:root:FL Epoch: 63 Norm Difference for worker 1423 is 0.904143
INFO:root:FL Epoch: 63 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1586
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494590
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501280
INFO:root:FL Epoch: 63 Norm Difference for worker 1586 is 0.951929
INFO:root:FL Epoch: 63 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :913
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646185
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651859
INFO:root:FL Epoch: 63 Norm Difference for worker 913 is 0.864544
INFO:root:FL Epoch: 63 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 303
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.592239697189892 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.4916506210962932                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [372, 696, 856, 1090, 1878, 1272, 1369, 255, 1056, 1918]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :372
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589646
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542084
INFO:root:FL Epoch: 64 Norm Difference for worker 372 is 0.895597
INFO:root:FL Epoch: 64 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :696
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595435
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503203
INFO:root:FL Epoch: 64 Norm Difference for worker 696 is 0.97344
INFO:root:FL Epoch: 64 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :856
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749795
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497190
INFO:root:FL Epoch: 64 Norm Difference for worker 856 is 0.99028
INFO:root:FL Epoch: 64 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1090
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595349
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612451
INFO:root:FL Epoch: 64 Norm Difference for worker 1090 is 0.952167
INFO:root:FL Epoch: 64 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1878
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723086
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568737
INFO:root:FL Epoch: 64 Norm Difference for worker 1878 is 0.912694
INFO:root:FL Epoch: 64 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1272
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604828
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655906
INFO:root:FL Epoch: 64 Norm Difference for worker 1272 is 0.921894
INFO:root:FL Epoch: 64 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1369
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582767
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599886
INFO:root:FL Epoch: 64 Norm Difference for worker 1369 is 0.915001
INFO:root:FL Epoch: 64 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :255
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 255 is 0.920141
INFO:root:FL Epoch: 64 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1056
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535117
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564475
INFO:root:FL Epoch: 64 Norm Difference for worker 1056 is 0.919074
INFO:root:FL Epoch: 64 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1918
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669222
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518121
INFO:root:FL Epoch: 64 Norm Difference for worker 1918 is 0.932957
INFO:root:FL Epoch: 64 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 372
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5871797502040863 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:1.7781381607055664                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [999, 1345, 1481, 589, 1039, 331, 1322, 1682, 1204, 569]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 65 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :999
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698165
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437629
INFO:root:FL Epoch: 65 Norm Difference for worker 999 is 1.021153
INFO:root:FL Epoch: 65 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1345
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630465
INFO:root:Worker: 1345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442968
INFO:root:FL Epoch: 65 Norm Difference for worker 1345 is 1.015688
INFO:root:FL Epoch: 65 Done on worker:1345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1481
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580375
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658620
INFO:root:FL Epoch: 65 Norm Difference for worker 1481 is 1.098414
INFO:root:FL Epoch: 65 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :589
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457916
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749057
INFO:root:FL Epoch: 65 Norm Difference for worker 589 is 1.024588
INFO:root:FL Epoch: 65 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1039
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571029
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578446
INFO:root:FL Epoch: 65 Norm Difference for worker 1039 is 1.043562
INFO:root:FL Epoch: 65 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :331
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667916
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 331 is 1.050948
INFO:root:FL Epoch: 65 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1322
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661449
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640444
INFO:root:FL Epoch: 65 Norm Difference for worker 1322 is 1.070472
INFO:root:FL Epoch: 65 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1682
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566451
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514179
INFO:root:FL Epoch: 65 Norm Difference for worker 1682 is 1.01798
INFO:root:FL Epoch: 65 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1204
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582618
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561360
INFO:root:FL Epoch: 65 Norm Difference for worker 1204 is 1.019486
INFO:root:FL Epoch: 65 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :569
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491950
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501685
INFO:root:FL Epoch: 65 Norm Difference for worker 569 is 1.126338
INFO:root:FL Epoch: 65 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 999
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.6069809461341185 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.7996872663497925                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [677, 222, 1873, 1719, 403, 1188, 844, 1619, 1295, 1459]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 66 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :677
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710019
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416271
INFO:root:FL Epoch: 66 Norm Difference for worker 677 is 0.994589
INFO:root:FL Epoch: 66 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :222
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544747
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 222 is 1.039798
INFO:root:FL Epoch: 66 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1873
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493268
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515997
INFO:root:FL Epoch: 66 Norm Difference for worker 1873 is 1.104341
INFO:root:FL Epoch: 66 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1719
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591593
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574288
INFO:root:FL Epoch: 66 Norm Difference for worker 1719 is 1.019329
INFO:root:FL Epoch: 66 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :403
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764554
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.812542
INFO:root:FL Epoch: 66 Norm Difference for worker 403 is 1.099611
INFO:root:FL Epoch: 66 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1188
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763579
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643362
INFO:root:FL Epoch: 66 Norm Difference for worker 1188 is 0.986303
INFO:root:FL Epoch: 66 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :844
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491161
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650511
INFO:root:FL Epoch: 66 Norm Difference for worker 844 is 1.028669
INFO:root:FL Epoch: 66 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1619
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566944
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604562
INFO:root:FL Epoch: 66 Norm Difference for worker 1619 is 1.011089
INFO:root:FL Epoch: 66 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1295
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612969
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638367
INFO:root:FL Epoch: 66 Norm Difference for worker 1295 is 0.961122
INFO:root:FL Epoch: 66 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1459
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452529
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684508
INFO:root:FL Epoch: 66 Norm Difference for worker 1459 is 1.015364
INFO:root:FL Epoch: 66 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.6076002541710349 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:1.5744760632514954                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [656, 321, 1045, 415, 343, 346, 185, 691, 1578, 720]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :656
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631945
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608052
INFO:root:FL Epoch: 67 Norm Difference for worker 656 is 0.988565
INFO:root:FL Epoch: 67 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :321
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 321 is 1.01256
INFO:root:FL Epoch: 67 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1045
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572669
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427997
INFO:root:FL Epoch: 67 Norm Difference for worker 1045 is 0.943394
INFO:root:FL Epoch: 67 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :415
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564256
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728342
INFO:root:FL Epoch: 67 Norm Difference for worker 415 is 0.980291
INFO:root:FL Epoch: 67 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :343
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526938
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700635
INFO:root:FL Epoch: 67 Norm Difference for worker 343 is 0.992434
INFO:root:FL Epoch: 67 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :346
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619697
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660209
INFO:root:FL Epoch: 67 Norm Difference for worker 346 is 1.041775
INFO:root:FL Epoch: 67 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :185
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 185 is 0.960846
INFO:root:FL Epoch: 67 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :691
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537567
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361668
INFO:root:FL Epoch: 67 Norm Difference for worker 691 is 1.001724
INFO:root:FL Epoch: 67 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1578
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635597
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508811
INFO:root:FL Epoch: 67 Norm Difference for worker 1578 is 0.952204
INFO:root:FL Epoch: 67 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :720
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537927
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648405
INFO:root:FL Epoch: 67 Norm Difference for worker 720 is 0.92399
INFO:root:FL Epoch: 67 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 720
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5929237656733569 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.4105577667554219                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1553, 165, 269, 898, 1354, 1164, 865, 1788, 1919, 974]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1553
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459873
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721922
INFO:root:FL Epoch: 68 Norm Difference for worker 1553 is 0.934732
INFO:root:FL Epoch: 68 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :165
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541448
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 165 is 0.912886
INFO:root:FL Epoch: 68 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :269
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628107
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 269 is 0.915045
INFO:root:FL Epoch: 68 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :898
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755385
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559389
INFO:root:FL Epoch: 68 Norm Difference for worker 898 is 0.932197
INFO:root:FL Epoch: 68 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1354
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671238
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609403
INFO:root:FL Epoch: 68 Norm Difference for worker 1354 is 0.924123
INFO:root:FL Epoch: 68 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1164
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509396
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681314
INFO:root:FL Epoch: 68 Norm Difference for worker 1164 is 0.961596
INFO:root:FL Epoch: 68 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :865
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623494
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562664
INFO:root:FL Epoch: 68 Norm Difference for worker 865 is 0.954995
INFO:root:FL Epoch: 68 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1788
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582680
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550074
INFO:root:FL Epoch: 68 Norm Difference for worker 1788 is 0.925719
INFO:root:FL Epoch: 68 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1919
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634477
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524582
INFO:root:FL Epoch: 68 Norm Difference for worker 1919 is 0.934594
INFO:root:FL Epoch: 68 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :974
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500491
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484509
INFO:root:FL Epoch: 68 Norm Difference for worker 974 is 0.904791
INFO:root:FL Epoch: 68 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 974
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5798965920420254 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.6326478123664856                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [724, 11, 80, 1777, 1506, 1773, 1850, 864, 1602, 465]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 69 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :724
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492130
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544043
INFO:root:FL Epoch: 69 Norm Difference for worker 724 is 1.061747
INFO:root:FL Epoch: 69 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :11
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575825
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 11 is 1.055721
INFO:root:FL Epoch: 69 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :80
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 80 is 1.049035
INFO:root:FL Epoch: 69 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1777
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515505
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575368
INFO:root:FL Epoch: 69 Norm Difference for worker 1777 is 1.054073
INFO:root:FL Epoch: 69 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1506
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556156
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336432
INFO:root:FL Epoch: 69 Norm Difference for worker 1506 is 1.028364
INFO:root:FL Epoch: 69 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1773
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543917
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320420
INFO:root:FL Epoch: 69 Norm Difference for worker 1773 is 1.100286
INFO:root:FL Epoch: 69 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1850
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618587
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518334
INFO:root:FL Epoch: 69 Norm Difference for worker 1850 is 0.96727
INFO:root:FL Epoch: 69 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :864
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740930
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512554
INFO:root:FL Epoch: 69 Norm Difference for worker 864 is 1.045998
INFO:root:FL Epoch: 69 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1602
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594259
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658689
INFO:root:FL Epoch: 69 Norm Difference for worker 1602 is 1.015814
INFO:root:FL Epoch: 69 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :465
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544065
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510853
INFO:root:FL Epoch: 69 Norm Difference for worker 465 is 1.038698
INFO:root:FL Epoch: 69 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1850
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.6019705954719993 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.6012818217277527                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1759, 611, 1776, 260, 571, 677, 885, 429, 59, 912]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1759
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540733
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376457
INFO:root:FL Epoch: 70 Norm Difference for worker 1759 is 1.044884
INFO:root:FL Epoch: 70 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :611
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738531
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614199
INFO:root:FL Epoch: 70 Norm Difference for worker 611 is 1.142067
INFO:root:FL Epoch: 70 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1776
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716168
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439985
INFO:root:FL Epoch: 70 Norm Difference for worker 1776 is 0.985116
INFO:root:FL Epoch: 70 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :260
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.750630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435797
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 260 is 1.023305
INFO:root:FL Epoch: 70 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :571
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726186
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663091
INFO:root:FL Epoch: 70 Norm Difference for worker 571 is 1.059794
INFO:root:FL Epoch: 70 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :677
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588373
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765259
INFO:root:FL Epoch: 70 Norm Difference for worker 677 is 1.009622
INFO:root:FL Epoch: 70 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :885
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724963
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593232
INFO:root:FL Epoch: 70 Norm Difference for worker 885 is 1.066692
INFO:root:FL Epoch: 70 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :429
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490312
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635712
INFO:root:FL Epoch: 70 Norm Difference for worker 429 is 1.074922
INFO:root:FL Epoch: 70 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :59
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 59 is 1.067256
INFO:root:FL Epoch: 70 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :912
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774067
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542437
INFO:root:FL Epoch: 70 Norm Difference for worker 912 is 0.982357
INFO:root:FL Epoch: 70 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 912
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.6274795409511117 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.7421091198921204                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [888, 1165, 1381, 1938, 501, 930, 710, 127, 586, 1286]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :888
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662331
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487180
INFO:root:FL Epoch: 71 Norm Difference for worker 888 is 1.024382
INFO:root:FL Epoch: 71 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1165
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519414
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552252
INFO:root:FL Epoch: 71 Norm Difference for worker 1165 is 1.019412
INFO:root:FL Epoch: 71 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1381
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521738
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650627
INFO:root:FL Epoch: 71 Norm Difference for worker 1381 is 1.014982
INFO:root:FL Epoch: 71 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1938
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719180
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666334
INFO:root:FL Epoch: 71 Norm Difference for worker 1938 is 0.954811
INFO:root:FL Epoch: 71 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :501
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667884
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402037
INFO:root:FL Epoch: 71 Norm Difference for worker 501 is 0.985939
INFO:root:FL Epoch: 71 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :930
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621232
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627645
INFO:root:FL Epoch: 71 Norm Difference for worker 930 is 0.956113
INFO:root:FL Epoch: 71 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :710
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529363
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433491
INFO:root:FL Epoch: 71 Norm Difference for worker 710 is 1.022138
INFO:root:FL Epoch: 71 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :127
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 127 is 1.009385
INFO:root:FL Epoch: 71 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :586
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599573
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441938
INFO:root:FL Epoch: 71 Norm Difference for worker 586 is 0.981616
INFO:root:FL Epoch: 71 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1286
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652176
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614817
INFO:root:FL Epoch: 71 Norm Difference for worker 1286 is 0.961946
INFO:root:FL Epoch: 71 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1938
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.6219778884859646 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.6222287615140278                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1172, 1066, 1150, 1713, 685, 1128, 989, 730, 943, 1318]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1172
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669030
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527897
INFO:root:FL Epoch: 72 Norm Difference for worker 1172 is 0.947767
INFO:root:FL Epoch: 72 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1066
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613666
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556851
INFO:root:FL Epoch: 72 Norm Difference for worker 1066 is 1.058175
INFO:root:FL Epoch: 72 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1150
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565981
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569639
INFO:root:FL Epoch: 72 Norm Difference for worker 1150 is 0.938441
INFO:root:FL Epoch: 72 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1713
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727165
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571548
INFO:root:FL Epoch: 72 Norm Difference for worker 1713 is 0.943932
INFO:root:FL Epoch: 72 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :685
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610183
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537659
INFO:root:FL Epoch: 72 Norm Difference for worker 685 is 0.991818
INFO:root:FL Epoch: 72 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1128
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677153
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737426
INFO:root:FL Epoch: 72 Norm Difference for worker 1128 is 0.927333
INFO:root:FL Epoch: 72 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :989
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658158
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503139
INFO:root:FL Epoch: 72 Norm Difference for worker 989 is 0.878467
INFO:root:FL Epoch: 72 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :730
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571731
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527197
INFO:root:FL Epoch: 72 Norm Difference for worker 730 is 0.961356
INFO:root:FL Epoch: 72 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :943
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580022
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591634
INFO:root:FL Epoch: 72 Norm Difference for worker 943 is 0.917347
INFO:root:FL Epoch: 72 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1318
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567181
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406051
INFO:root:FL Epoch: 72 Norm Difference for worker 1318 is 1.01498
INFO:root:FL Epoch: 72 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 989
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5984301724854637 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:1.531138797601064                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [10, 1748, 1752, 829, 898, 145, 646, 1652, 111, 1330]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 73 Num points on workers: [201 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :10
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506451
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 10 is 1.112611
INFO:root:FL Epoch: 73 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1748
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651845
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619288
INFO:root:FL Epoch: 73 Norm Difference for worker 1748 is 0.910916
INFO:root:FL Epoch: 73 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1752
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615869
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552137
INFO:root:FL Epoch: 73 Norm Difference for worker 1752 is 0.953109
INFO:root:FL Epoch: 73 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :829
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644608
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474162
INFO:root:FL Epoch: 73 Norm Difference for worker 829 is 0.903595
INFO:root:FL Epoch: 73 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :898
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578952
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556866
INFO:root:FL Epoch: 73 Norm Difference for worker 898 is 1.020793
INFO:root:FL Epoch: 73 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :145
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.754806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 145 is 0.882288
INFO:root:FL Epoch: 73 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :646
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524859
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491743
INFO:root:FL Epoch: 73 Norm Difference for worker 646 is 0.928193
INFO:root:FL Epoch: 73 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1652
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651784
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606386
INFO:root:FL Epoch: 73 Norm Difference for worker 1652 is 0.935091
INFO:root:FL Epoch: 73 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :111
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.859048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694547
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 111 is 0.926872
INFO:root:FL Epoch: 73 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1330
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632139
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735978
INFO:root:FL Epoch: 73 Norm Difference for worker 1330 is 0.975934
INFO:root:FL Epoch: 73 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.5853243207230288 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:1.590637465318044                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [921, 176, 1313, 740, 1376, 1824, 1015, 1053, 244, 405]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 74 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :921
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559288
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591185
INFO:root:FL Epoch: 74 Norm Difference for worker 921 is 1.087171
INFO:root:FL Epoch: 74 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :176
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 176 is 1.028564
INFO:root:FL Epoch: 74 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1313
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506245
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546932
INFO:root:FL Epoch: 74 Norm Difference for worker 1313 is 1.08993
INFO:root:FL Epoch: 74 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :740
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571521
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611318
INFO:root:FL Epoch: 74 Norm Difference for worker 740 is 1.026938
INFO:root:FL Epoch: 74 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1376
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614813
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467144
INFO:root:FL Epoch: 74 Norm Difference for worker 1376 is 1.091503
INFO:root:FL Epoch: 74 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1824
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719878
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426883
INFO:root:FL Epoch: 74 Norm Difference for worker 1824 is 1.065407
INFO:root:FL Epoch: 74 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1015
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705985
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619386
INFO:root:FL Epoch: 74 Norm Difference for worker 1015 is 1.029858
INFO:root:FL Epoch: 74 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1053
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593105
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484317
INFO:root:FL Epoch: 74 Norm Difference for worker 1053 is 0.99143
INFO:root:FL Epoch: 74 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :244
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 244 is 1.027881
INFO:root:FL Epoch: 74 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :405
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432606
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622180
INFO:root:FL Epoch: 74 Norm Difference for worker 405 is 0.977118
INFO:root:FL Epoch: 74 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1053
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.5814898610115051 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.8431694110234578                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [1890, 1365, 1036, 1329, 852, 41, 588, 502, 137, 1061]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :1890
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570821
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440741
INFO:root:FL Epoch: 75 Norm Difference for worker 1890 is 1.03466
INFO:root:FL Epoch: 75 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1365
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420757
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427362
INFO:root:FL Epoch: 75 Norm Difference for worker 1365 is 1.157987
INFO:root:FL Epoch: 75 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1036
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615360
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407789
INFO:root:FL Epoch: 75 Norm Difference for worker 1036 is 1.108879
INFO:root:FL Epoch: 75 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1329
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438010
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456778
INFO:root:FL Epoch: 75 Norm Difference for worker 1329 is 1.114027
INFO:root:FL Epoch: 75 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :852
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491196
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446816
INFO:root:FL Epoch: 75 Norm Difference for worker 852 is 1.085097
INFO:root:FL Epoch: 75 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :41
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 41 is 1.088338
INFO:root:FL Epoch: 75 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :588
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685400
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491627
INFO:root:FL Epoch: 75 Norm Difference for worker 588 is 1.071392
INFO:root:FL Epoch: 75 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :502
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429019
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507359
INFO:root:FL Epoch: 75 Norm Difference for worker 502 is 1.085754
INFO:root:FL Epoch: 75 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :137
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 137 is 1.196285
INFO:root:FL Epoch: 75 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1061
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697767
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591641
INFO:root:FL Epoch: 75 Norm Difference for worker 1061 is 1.079554
INFO:root:FL Epoch: 75 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.5871680834714104 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:1.6486935218175252                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1498, 36, 976, 849, 220, 935, 1135, 1938, 1315, 1347]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 76 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1498
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705199
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767371
INFO:root:FL Epoch: 76 Norm Difference for worker 1498 is 0.916427
INFO:root:FL Epoch: 76 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :36
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 36 is 1.011832
INFO:root:FL Epoch: 76 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :976
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515264
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402650
INFO:root:FL Epoch: 76 Norm Difference for worker 976 is 0.97017
INFO:root:FL Epoch: 76 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :849
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614681
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499133
INFO:root:FL Epoch: 76 Norm Difference for worker 849 is 0.964324
INFO:root:FL Epoch: 76 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :220
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 220 is 0.910378
INFO:root:FL Epoch: 76 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :935
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611539
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554573
INFO:root:FL Epoch: 76 Norm Difference for worker 935 is 1.02561
INFO:root:FL Epoch: 76 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1135
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561318
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452770
INFO:root:FL Epoch: 76 Norm Difference for worker 1135 is 0.904374
INFO:root:FL Epoch: 76 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1938
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509958
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590975
INFO:root:FL Epoch: 76 Norm Difference for worker 1938 is 0.964286
INFO:root:FL Epoch: 76 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1315
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614284
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622151
INFO:root:FL Epoch: 76 Norm Difference for worker 1315 is 0.983045
INFO:root:FL Epoch: 76 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1347
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590071
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598245
INFO:root:FL Epoch: 76 Norm Difference for worker 1347 is 0.948123
INFO:root:FL Epoch: 76 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5670458095915177 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.8824201226234436                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [1198, 1303, 223, 260, 442, 128, 1162, 957, 1214, 753]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :1198
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414959
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647040
INFO:root:FL Epoch: 77 Norm Difference for worker 1198 is 1.152978
INFO:root:FL Epoch: 77 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509778
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599570
INFO:root:FL Epoch: 77 Norm Difference for worker 1303 is 1.167691
INFO:root:FL Epoch: 77 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :223
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 223 is 1.21904
INFO:root:FL Epoch: 77 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :260
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 260 is 1.085989
INFO:root:FL Epoch: 77 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :442
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461689
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562789
INFO:root:FL Epoch: 77 Norm Difference for worker 442 is 1.147117
INFO:root:FL Epoch: 77 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 128 is 1.16628
INFO:root:FL Epoch: 77 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1162
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503078
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582924
INFO:root:FL Epoch: 77 Norm Difference for worker 1162 is 1.170363
INFO:root:FL Epoch: 77 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :957
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758183
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622571
INFO:root:FL Epoch: 77 Norm Difference for worker 957 is 1.065464
INFO:root:FL Epoch: 77 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1214
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531775
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481708
INFO:root:FL Epoch: 77 Norm Difference for worker 1214 is 1.157769
INFO:root:FL Epoch: 77 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :753
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554572
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454986
INFO:root:FL Epoch: 77 Norm Difference for worker 753 is 1.099562
INFO:root:FL Epoch: 77 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 957
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5843956102343166 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.672781725724538                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [806, 99, 1930, 16, 1330, 1039, 1305, 1306, 1091, 1490]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 78 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :806
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451780
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557575
INFO:root:FL Epoch: 78 Norm Difference for worker 806 is 1.014963
INFO:root:FL Epoch: 78 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :99
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.740175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 99 is 1.050859
INFO:root:FL Epoch: 78 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1930
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696100
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610637
INFO:root:FL Epoch: 78 Norm Difference for worker 1930 is 1.01605
INFO:root:FL Epoch: 78 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :16
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.779997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 16 is 1.017457
INFO:root:FL Epoch: 78 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1330
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735822
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466467
INFO:root:FL Epoch: 78 Norm Difference for worker 1330 is 1.072808
INFO:root:FL Epoch: 78 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1039
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434997
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641577
INFO:root:FL Epoch: 78 Norm Difference for worker 1039 is 1.071446
INFO:root:FL Epoch: 78 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1305
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508344
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474076
INFO:root:FL Epoch: 78 Norm Difference for worker 1305 is 1.074269
INFO:root:FL Epoch: 78 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1306
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553933
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482759
INFO:root:FL Epoch: 78 Norm Difference for worker 1306 is 1.031475
INFO:root:FL Epoch: 78 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1091
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729823
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522836
INFO:root:FL Epoch: 78 Norm Difference for worker 1091 is 0.986297
INFO:root:FL Epoch: 78 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1490
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560223
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693607
INFO:root:FL Epoch: 78 Norm Difference for worker 1490 is 1.037503
INFO:root:FL Epoch: 78 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1091
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.5895033636513878 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.7353266477584839                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [351, 1313, 401, 1698, 252, 1618, 361, 312, 75, 607]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 200 200 200 201 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :351
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591965
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600671
INFO:root:FL Epoch: 79 Norm Difference for worker 351 is 1.108921
INFO:root:FL Epoch: 79 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1313
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706070
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476541
INFO:root:FL Epoch: 79 Norm Difference for worker 1313 is 1.137329
INFO:root:FL Epoch: 79 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :401
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489951
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533574
INFO:root:FL Epoch: 79 Norm Difference for worker 401 is 1.085979
INFO:root:FL Epoch: 79 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1698
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570518
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513856
INFO:root:FL Epoch: 79 Norm Difference for worker 1698 is 1.092407
INFO:root:FL Epoch: 79 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :252
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530056
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 252 is 1.102809
INFO:root:FL Epoch: 79 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1618
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670673
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454624
INFO:root:FL Epoch: 79 Norm Difference for worker 1618 is 1.074199
INFO:root:FL Epoch: 79 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :361
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558407
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511414
INFO:root:FL Epoch: 79 Norm Difference for worker 361 is 1.117586
INFO:root:FL Epoch: 79 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :312
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 312 is 1.053
INFO:root:FL Epoch: 79 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :75
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547605
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 75 is 1.07911
INFO:root:FL Epoch: 79 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :607
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472114
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493870
INFO:root:FL Epoch: 79 Norm Difference for worker 607 is 1.065199
INFO:root:FL Epoch: 79 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1618
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.5885417882133933 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.6845693786938984                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [226, 964, 1059, 1365, 823, 1679, 1491, 231, 1584, 1498]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 80 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :226
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 226 is 1.097017
INFO:root:FL Epoch: 80 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :964
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 964 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632979
INFO:root:Worker: 964 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568315
INFO:root:FL Epoch: 80 Norm Difference for worker 964 is 1.04054
INFO:root:FL Epoch: 80 Done on worker:964
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1059
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593396
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471617
INFO:root:FL Epoch: 80 Norm Difference for worker 1059 is 1.101506
INFO:root:FL Epoch: 80 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1365
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580165
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469927
INFO:root:FL Epoch: 80 Norm Difference for worker 1365 is 1.078871
INFO:root:FL Epoch: 80 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :823
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542792
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486615
INFO:root:FL Epoch: 80 Norm Difference for worker 823 is 1.148931
INFO:root:FL Epoch: 80 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1679
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712144
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648649
INFO:root:FL Epoch: 80 Norm Difference for worker 1679 is 1.134441
INFO:root:FL Epoch: 80 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1491
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623726
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482488
INFO:root:FL Epoch: 80 Norm Difference for worker 1491 is 1.028921
INFO:root:FL Epoch: 80 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :231
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 231 is 1.059016
INFO:root:FL Epoch: 80 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1584
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601143
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726467
INFO:root:FL Epoch: 80 Norm Difference for worker 1584 is 1.048764
INFO:root:FL Epoch: 80 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1498
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651723
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420003
INFO:root:FL Epoch: 80 Norm Difference for worker 1498 is 1.067192
INFO:root:FL Epoch: 80 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1491
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5883986353874207 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:1.712259332338969                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [821, 565, 1046, 245, 1369, 655, 289, 1697, 1883, 985]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :821
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643238
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657909
INFO:root:FL Epoch: 81 Norm Difference for worker 821 is 1.132807
INFO:root:FL Epoch: 81 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :565
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690555
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623450
INFO:root:FL Epoch: 81 Norm Difference for worker 565 is 1.112152
INFO:root:FL Epoch: 81 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1046
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514073
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516884
INFO:root:FL Epoch: 81 Norm Difference for worker 1046 is 1.123626
INFO:root:FL Epoch: 81 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :245
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462995
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473924
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 245 is 1.162736
INFO:root:FL Epoch: 81 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1369
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420746
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634061
INFO:root:FL Epoch: 81 Norm Difference for worker 1369 is 1.144351
INFO:root:FL Epoch: 81 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :655
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421585
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636644
INFO:root:FL Epoch: 81 Norm Difference for worker 655 is 1.100725
INFO:root:FL Epoch: 81 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :289
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 289 is 1.10673
INFO:root:FL Epoch: 81 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1697
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.983777
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460684
INFO:root:FL Epoch: 81 Norm Difference for worker 1697 is 1.161745
INFO:root:FL Epoch: 81 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1883
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478578
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556180
INFO:root:FL Epoch: 81 Norm Difference for worker 1883 is 1.063091
INFO:root:FL Epoch: 81 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :985
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387748
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484272
INFO:root:FL Epoch: 81 Norm Difference for worker 985 is 1.148991
INFO:root:FL Epoch: 81 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1883
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.6098486395443187 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.4752784967422485                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [380, 680, 149, 1800, 552, 304, 350, 965, 1083, 608]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :380
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579958
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527576
INFO:root:FL Epoch: 82 Norm Difference for worker 380 is 1.019603
INFO:root:FL Epoch: 82 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :680
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571005
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451201
INFO:root:FL Epoch: 82 Norm Difference for worker 680 is 1.016023
INFO:root:FL Epoch: 82 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :149
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698523
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 149 is 1.078255
INFO:root:FL Epoch: 82 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1800
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585814
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656010
INFO:root:FL Epoch: 82 Norm Difference for worker 1800 is 0.960866
INFO:root:FL Epoch: 82 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :552
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629568
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556759
INFO:root:FL Epoch: 82 Norm Difference for worker 552 is 0.991144
INFO:root:FL Epoch: 82 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :304
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 304 is 0.979935
INFO:root:FL Epoch: 82 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :350
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668781
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451351
INFO:root:FL Epoch: 82 Norm Difference for worker 350 is 1.037501
INFO:root:FL Epoch: 82 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :965
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512296
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554162
INFO:root:FL Epoch: 82 Norm Difference for worker 965 is 1.055261
INFO:root:FL Epoch: 82 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1083
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751501
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598463
INFO:root:FL Epoch: 82 Norm Difference for worker 1083 is 1.044294
INFO:root:FL Epoch: 82 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :608
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623348
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535680
INFO:root:FL Epoch: 82 Norm Difference for worker 608 is 1.035409
INFO:root:FL Epoch: 82 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 304
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.5946246140143451 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.6005100011825562                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1477, 1667, 652, 1454, 1174, 88, 99, 1694, 1701, 579]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1477
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493326
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643646
INFO:root:FL Epoch: 83 Norm Difference for worker 1477 is 1.09811
INFO:root:FL Epoch: 83 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1667
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593857
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660447
INFO:root:FL Epoch: 83 Norm Difference for worker 1667 is 1.121632
INFO:root:FL Epoch: 83 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :652
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607796
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491060
INFO:root:FL Epoch: 83 Norm Difference for worker 652 is 1.080169
INFO:root:FL Epoch: 83 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1454
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627534
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495735
INFO:root:FL Epoch: 83 Norm Difference for worker 1454 is 1.080572
INFO:root:FL Epoch: 83 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1174
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636433
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504515
INFO:root:FL Epoch: 83 Norm Difference for worker 1174 is 1.12929
INFO:root:FL Epoch: 83 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :88
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 88 is 1.081223
INFO:root:FL Epoch: 83 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :99
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 99 is 1.11259
INFO:root:FL Epoch: 83 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1694
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522138
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391446
INFO:root:FL Epoch: 83 Norm Difference for worker 1694 is 1.117643
INFO:root:FL Epoch: 83 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1701
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664359
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443161
INFO:root:FL Epoch: 83 Norm Difference for worker 1701 is 1.106026
INFO:root:FL Epoch: 83 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :579
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515709
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461578
INFO:root:FL Epoch: 83 Norm Difference for worker 579 is 1.157098
INFO:root:FL Epoch: 83 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.5881082766196307 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.1936512390772502                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1473, 1641, 433, 1902, 1424, 1573, 613, 1700, 1577, 429]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1473
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753538
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660482
INFO:root:FL Epoch: 84 Norm Difference for worker 1473 is 0.98064
INFO:root:FL Epoch: 84 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1641
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557935
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608626
INFO:root:FL Epoch: 84 Norm Difference for worker 1641 is 0.941814
INFO:root:FL Epoch: 84 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :433
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713839
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547411
INFO:root:FL Epoch: 84 Norm Difference for worker 433 is 0.987824
INFO:root:FL Epoch: 84 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1902
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635864
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466180
INFO:root:FL Epoch: 84 Norm Difference for worker 1902 is 1.013439
INFO:root:FL Epoch: 84 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1424
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546124
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498753
INFO:root:FL Epoch: 84 Norm Difference for worker 1424 is 1.136748
INFO:root:FL Epoch: 84 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1573
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605254
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483370
INFO:root:FL Epoch: 84 Norm Difference for worker 1573 is 0.993082
INFO:root:FL Epoch: 84 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :613
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545057
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547826
INFO:root:FL Epoch: 84 Norm Difference for worker 613 is 0.987662
INFO:root:FL Epoch: 84 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1700
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667060
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525912
INFO:root:FL Epoch: 84 Norm Difference for worker 1700 is 0.964797
INFO:root:FL Epoch: 84 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1577
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694625
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681210
INFO:root:FL Epoch: 84 Norm Difference for worker 1577 is 0.940374
INFO:root:FL Epoch: 84 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :429
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634895
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454688
INFO:root:FL Epoch: 84 Norm Difference for worker 429 is 1.005653
INFO:root:FL Epoch: 84 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1700
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5746093392372131 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:1.3709769248962402                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [607, 1616, 1338, 161, 1353, 996, 955, 1247, 115, 191]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :607
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714268
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417385
INFO:root:FL Epoch: 85 Norm Difference for worker 607 is 1.089045
INFO:root:FL Epoch: 85 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1616
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581850
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569634
INFO:root:FL Epoch: 85 Norm Difference for worker 1616 is 1.08419
INFO:root:FL Epoch: 85 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1338
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731325
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496614
INFO:root:FL Epoch: 85 Norm Difference for worker 1338 is 1.058094
INFO:root:FL Epoch: 85 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :161
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528255
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 161 is 1.064885
INFO:root:FL Epoch: 85 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1353
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530254
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569225
INFO:root:FL Epoch: 85 Norm Difference for worker 1353 is 1.071503
INFO:root:FL Epoch: 85 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :996
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532107
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456644
INFO:root:FL Epoch: 85 Norm Difference for worker 996 is 1.09273
INFO:root:FL Epoch: 85 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :955
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716419
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644320
INFO:root:FL Epoch: 85 Norm Difference for worker 955 is 1.123755
INFO:root:FL Epoch: 85 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1247
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537647
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595494
INFO:root:FL Epoch: 85 Norm Difference for worker 1247 is 1.120595
INFO:root:FL Epoch: 85 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :115
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560413
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 115 is 1.097115
INFO:root:FL Epoch: 85 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :191
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 191 is 1.18099
INFO:root:FL Epoch: 85 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.592800003640792 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:1.4761481682459514                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1800, 1102, 293, 77, 1780, 469, 682, 123, 555, 747]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 201 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1800
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640694
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491486
INFO:root:FL Epoch: 86 Norm Difference for worker 1800 is 1.100365
INFO:root:FL Epoch: 86 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1102
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548033
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563201
INFO:root:FL Epoch: 86 Norm Difference for worker 1102 is 1.155706
INFO:root:FL Epoch: 86 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :293
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 293 is 1.173344
INFO:root:FL Epoch: 86 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :77
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 77 is 1.168243
INFO:root:FL Epoch: 86 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1780
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332068
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499981
INFO:root:FL Epoch: 86 Norm Difference for worker 1780 is 1.170759
INFO:root:FL Epoch: 86 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :469
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605981
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597446
INFO:root:FL Epoch: 86 Norm Difference for worker 469 is 1.143685
INFO:root:FL Epoch: 86 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :682
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776990
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649092
INFO:root:FL Epoch: 86 Norm Difference for worker 682 is 1.195212
INFO:root:FL Epoch: 86 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :123
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 123 is 1.172348
INFO:root:FL Epoch: 86 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :555
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504967
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551749
INFO:root:FL Epoch: 86 Norm Difference for worker 555 is 1.276897
INFO:root:FL Epoch: 86 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :747
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676458
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595643
INFO:root:FL Epoch: 86 Norm Difference for worker 747 is 1.193243
INFO:root:FL Epoch: 86 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1800
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5932629441513735 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:1.3172985315322876                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [977, 380, 1238, 1316, 1664, 631, 964, 634, 344, 1179]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 87 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :977
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690173
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640745
INFO:root:FL Epoch: 87 Norm Difference for worker 977 is 1.060841
INFO:root:FL Epoch: 87 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :380
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641359
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656987
INFO:root:FL Epoch: 87 Norm Difference for worker 380 is 1.07324
INFO:root:FL Epoch: 87 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1238
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540487
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662567
INFO:root:FL Epoch: 87 Norm Difference for worker 1238 is 1.085052
INFO:root:FL Epoch: 87 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1316
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645527
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462833
INFO:root:FL Epoch: 87 Norm Difference for worker 1316 is 0.950449
INFO:root:FL Epoch: 87 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1664
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648837
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740351
INFO:root:FL Epoch: 87 Norm Difference for worker 1664 is 1.032108
INFO:root:FL Epoch: 87 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :631
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773717
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361766
INFO:root:FL Epoch: 87 Norm Difference for worker 631 is 1.035798
INFO:root:FL Epoch: 87 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :964
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 964 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651021
INFO:root:Worker: 964 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457997
INFO:root:FL Epoch: 87 Norm Difference for worker 964 is 1.027778
INFO:root:FL Epoch: 87 Done on worker:964
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :634
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578494
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524629
INFO:root:FL Epoch: 87 Norm Difference for worker 634 is 1.037865
INFO:root:FL Epoch: 87 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :344
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416308
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707720
INFO:root:FL Epoch: 87 Norm Difference for worker 344 is 1.033977
INFO:root:FL Epoch: 87 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1179
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437879
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514530
INFO:root:FL Epoch: 87 Norm Difference for worker 1179 is 1.079729
INFO:root:FL Epoch: 87 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5811523181550643 and Test Accuracy:70.0 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.3057297070821126                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [649, 359, 661, 773, 974, 66, 1199, 1003, 167, 393]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :649
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543763
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711851
INFO:root:FL Epoch: 88 Norm Difference for worker 649 is 1.11015
INFO:root:FL Epoch: 88 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :359
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705250
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558891
INFO:root:FL Epoch: 88 Norm Difference for worker 359 is 0.998806
INFO:root:FL Epoch: 88 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :661
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544646
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479221
INFO:root:FL Epoch: 88 Norm Difference for worker 661 is 1.054557
INFO:root:FL Epoch: 88 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :773
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632898
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528191
INFO:root:FL Epoch: 88 Norm Difference for worker 773 is 1.063266
INFO:root:FL Epoch: 88 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :974
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605526
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395392
INFO:root:FL Epoch: 88 Norm Difference for worker 974 is 1.037874
INFO:root:FL Epoch: 88 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :66
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623344
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 66 is 1.067227
INFO:root:FL Epoch: 88 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1199
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793486
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534440
INFO:root:FL Epoch: 88 Norm Difference for worker 1199 is 1.071063
INFO:root:FL Epoch: 88 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1003
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670227
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572118
INFO:root:FL Epoch: 88 Norm Difference for worker 1003 is 1.06642
INFO:root:FL Epoch: 88 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :167
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.795661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483174
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 167 is 0.994428
INFO:root:FL Epoch: 88 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :393
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752025
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514078
INFO:root:FL Epoch: 88 Norm Difference for worker 393 is 1.010544
INFO:root:FL Epoch: 88 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 167
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 88 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 88 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5636184268137988 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.3200445373853047                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1919, 162, 1070, 1318, 189, 244, 284, 1227, 1574, 491]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 89 Num points on workers: [200 201 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1919
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500365
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606295
INFO:root:FL Epoch: 89 Norm Difference for worker 1919 is 1.104741
INFO:root:FL Epoch: 89 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :162
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 162 is 1.011971
INFO:root:FL Epoch: 89 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1070
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848721
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532362
INFO:root:FL Epoch: 89 Norm Difference for worker 1070 is 1.135475
INFO:root:FL Epoch: 89 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1318
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420055
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584591
INFO:root:FL Epoch: 89 Norm Difference for worker 1318 is 1.086552
INFO:root:FL Epoch: 89 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :189
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 189 is 1.05618
INFO:root:FL Epoch: 89 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :244
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 244 is 0.95619
INFO:root:FL Epoch: 89 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :284
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.718260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 284 is 1.07925
INFO:root:FL Epoch: 89 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1227
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660893
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521166
INFO:root:FL Epoch: 89 Norm Difference for worker 1227 is 1.037007
INFO:root:FL Epoch: 89 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1574
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562033
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621727
INFO:root:FL Epoch: 89 Norm Difference for worker 1574 is 1.067362
INFO:root:FL Epoch: 89 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :491
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630428
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452417
INFO:root:FL Epoch: 89 Norm Difference for worker 491 is 1.0062
INFO:root:FL Epoch: 89 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 244
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.567933540133869 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.4614036679267883                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1041, 1295, 895, 1337, 1589, 961, 887, 91, 1444, 946]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1041
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637998
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496245
INFO:root:FL Epoch: 90 Norm Difference for worker 1041 is 1.037789
INFO:root:FL Epoch: 90 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1295
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590299
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472284
INFO:root:FL Epoch: 90 Norm Difference for worker 1295 is 1.019246
INFO:root:FL Epoch: 90 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :895
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537730
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588546
INFO:root:FL Epoch: 90 Norm Difference for worker 895 is 1.080602
INFO:root:FL Epoch: 90 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1337
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559312
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486958
INFO:root:FL Epoch: 90 Norm Difference for worker 1337 is 1.015426
INFO:root:FL Epoch: 90 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1589
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658922
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631085
INFO:root:FL Epoch: 90 Norm Difference for worker 1589 is 1.066869
INFO:root:FL Epoch: 90 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :961
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473516
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446673
INFO:root:FL Epoch: 90 Norm Difference for worker 961 is 1.066563
INFO:root:FL Epoch: 90 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :887
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740890
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581665
INFO:root:FL Epoch: 90 Norm Difference for worker 887 is 1.05754
INFO:root:FL Epoch: 90 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :91
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721548
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496968
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 91 is 1.047145
INFO:root:FL Epoch: 90 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1444
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406676
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577604
INFO:root:FL Epoch: 90 Norm Difference for worker 1444 is 1.043997
INFO:root:FL Epoch: 90 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :946
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594143
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531479
INFO:root:FL Epoch: 90 Norm Difference for worker 946 is 1.061072
INFO:root:FL Epoch: 90 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5697218390072093 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.2412140369415283                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [283, 1226, 610, 1717, 1546, 232, 474, 941, 191, 1303]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 91 Num points on workers: [201 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :283
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586454
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 283 is 1.053543
INFO:root:FL Epoch: 91 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1226
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549820
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493669
INFO:root:FL Epoch: 91 Norm Difference for worker 1226 is 1.058408
INFO:root:FL Epoch: 91 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :610
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577435
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572607
INFO:root:FL Epoch: 91 Norm Difference for worker 610 is 1.03066
INFO:root:FL Epoch: 91 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1717
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548794
INFO:root:Worker: 1717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546186
INFO:root:FL Epoch: 91 Norm Difference for worker 1717 is 1.007203
INFO:root:FL Epoch: 91 Done on worker:1717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1546
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425806
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447918
INFO:root:FL Epoch: 91 Norm Difference for worker 1546 is 0.993257
INFO:root:FL Epoch: 91 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :232
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609257
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 232 is 1.047681
INFO:root:FL Epoch: 91 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :474
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834087
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702137
INFO:root:FL Epoch: 91 Norm Difference for worker 474 is 0.990152
INFO:root:FL Epoch: 91 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :941
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757334
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360725
INFO:root:FL Epoch: 91 Norm Difference for worker 941 is 0.984478
INFO:root:FL Epoch: 91 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :191
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512793
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 191 is 1.131742
INFO:root:FL Epoch: 91 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1303
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438220
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671187
INFO:root:FL Epoch: 91 Norm Difference for worker 1303 is 1.10493
INFO:root:FL Epoch: 91 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 474
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.5763683108722463 and Test Accuracy:70.0 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:1.2620201110839844                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [1667, 189, 1666, 264, 710, 1841, 1809, 1805, 1118, 1175]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 92 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :1667
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630312
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526505
INFO:root:FL Epoch: 92 Norm Difference for worker 1667 is 0.896135
INFO:root:FL Epoch: 92 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :189
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 189 is 0.960265
INFO:root:FL Epoch: 92 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1666
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692818
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554427
INFO:root:FL Epoch: 92 Norm Difference for worker 1666 is 0.862733
INFO:root:FL Epoch: 92 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :264
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490757
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610221
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 264 is 0.97763
INFO:root:FL Epoch: 92 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :710
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620035
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487305
INFO:root:FL Epoch: 92 Norm Difference for worker 710 is 0.966052
INFO:root:FL Epoch: 92 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1841
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502349
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570132
INFO:root:FL Epoch: 92 Norm Difference for worker 1841 is 0.902342
INFO:root:FL Epoch: 92 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1809
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699556
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529589
INFO:root:FL Epoch: 92 Norm Difference for worker 1809 is 0.890596
INFO:root:FL Epoch: 92 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1805
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492218
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519859
INFO:root:FL Epoch: 92 Norm Difference for worker 1805 is 0.929765
INFO:root:FL Epoch: 92 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1118
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387948
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537112
INFO:root:FL Epoch: 92 Norm Difference for worker 1118 is 0.916166
INFO:root:FL Epoch: 92 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639294
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426389
INFO:root:FL Epoch: 92 Norm Difference for worker 1175 is 0.933831
INFO:root:FL Epoch: 92 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1666
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.5772783195271212 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:1.2217099865277607                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [1627, 1385, 691, 420, 1538, 645, 1552, 242, 1663, 1365]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 93 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :1627
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515976
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540200
INFO:root:FL Epoch: 93 Norm Difference for worker 1627 is 0.936636
INFO:root:FL Epoch: 93 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1385
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659076
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538284
INFO:root:FL Epoch: 93 Norm Difference for worker 1385 is 0.912799
INFO:root:FL Epoch: 93 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :691
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565388
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353053
INFO:root:FL Epoch: 93 Norm Difference for worker 691 is 0.943797
INFO:root:FL Epoch: 93 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :420
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728240
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487690
INFO:root:FL Epoch: 93 Norm Difference for worker 420 is 0.981028
INFO:root:FL Epoch: 93 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1538
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559248
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599231
INFO:root:FL Epoch: 93 Norm Difference for worker 1538 is 0.939438
INFO:root:FL Epoch: 93 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :645
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613987
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552776
INFO:root:FL Epoch: 93 Norm Difference for worker 645 is 0.974484
INFO:root:FL Epoch: 93 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1552
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716542
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617516
INFO:root:FL Epoch: 93 Norm Difference for worker 1552 is 0.949784
INFO:root:FL Epoch: 93 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :242
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 242 is 0.941359
INFO:root:FL Epoch: 93 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1663
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516267
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450687
INFO:root:FL Epoch: 93 Norm Difference for worker 1663 is 0.942114
INFO:root:FL Epoch: 93 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1365
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604966
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637752
INFO:root:FL Epoch: 93 Norm Difference for worker 1365 is 0.984724
INFO:root:FL Epoch: 93 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.5706644864643321 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:1.5202351609865825                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1083, 986, 915, 33, 367, 1177, 510, 1124, 1515, 799]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 94 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1083
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501402
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607913
INFO:root:FL Epoch: 94 Norm Difference for worker 1083 is 1.021112
INFO:root:FL Epoch: 94 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :986
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735459
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523920
INFO:root:FL Epoch: 94 Norm Difference for worker 986 is 1.010384
INFO:root:FL Epoch: 94 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :915
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672214
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570197
INFO:root:FL Epoch: 94 Norm Difference for worker 915 is 0.984462
INFO:root:FL Epoch: 94 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :33
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 33 is 1.020486
INFO:root:FL Epoch: 94 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :367
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535726
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576043
INFO:root:FL Epoch: 94 Norm Difference for worker 367 is 1.051296
INFO:root:FL Epoch: 94 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1177
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555883
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545570
INFO:root:FL Epoch: 94 Norm Difference for worker 1177 is 1.015342
INFO:root:FL Epoch: 94 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :510
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625567
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424996
INFO:root:FL Epoch: 94 Norm Difference for worker 510 is 1.011942
INFO:root:FL Epoch: 94 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1124
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555674
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778509
INFO:root:FL Epoch: 94 Norm Difference for worker 1124 is 1.014174
INFO:root:FL Epoch: 94 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1515
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725418
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609395
INFO:root:FL Epoch: 94 Norm Difference for worker 1515 is 1.014196
INFO:root:FL Epoch: 94 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :799
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568984
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641316
INFO:root:FL Epoch: 94 Norm Difference for worker 799 is 1.041908
INFO:root:FL Epoch: 94 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 915
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.5749902427196503 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.093521813551585                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [669, 1111, 1322, 12, 1020, 339, 1337, 1348, 941, 1830]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :669
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657065
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479052
INFO:root:FL Epoch: 95 Norm Difference for worker 669 is 0.968048
INFO:root:FL Epoch: 95 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1111
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653679
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557449
INFO:root:FL Epoch: 95 Norm Difference for worker 1111 is 0.925005
INFO:root:FL Epoch: 95 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1322
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632273
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593309
INFO:root:FL Epoch: 95 Norm Difference for worker 1322 is 0.941257
INFO:root:FL Epoch: 95 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :12
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 12 is 0.884321
INFO:root:FL Epoch: 95 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1020
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687292
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651284
INFO:root:FL Epoch: 95 Norm Difference for worker 1020 is 0.9
INFO:root:FL Epoch: 95 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :339
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504127
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 339 is 0.900447
INFO:root:FL Epoch: 95 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1337
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457309
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455698
INFO:root:FL Epoch: 95 Norm Difference for worker 1337 is 0.900646
INFO:root:FL Epoch: 95 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1348
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574479
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592196
INFO:root:FL Epoch: 95 Norm Difference for worker 1348 is 0.894662
INFO:root:FL Epoch: 95 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :941
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762887
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595161
INFO:root:FL Epoch: 95 Norm Difference for worker 941 is 0.928694
INFO:root:FL Epoch: 95 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1830
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558545
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600044
INFO:root:FL Epoch: 95 Norm Difference for worker 1830 is 0.965957
INFO:root:FL Epoch: 95 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.5666509691406699 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.33563898007075                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [867, 1444, 1605, 358, 1793, 835, 506, 1386, 1886, 1517]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :867
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683641
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416335
INFO:root:FL Epoch: 96 Norm Difference for worker 867 is 1.166091
INFO:root:FL Epoch: 96 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1444
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546841
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408313
INFO:root:FL Epoch: 96 Norm Difference for worker 1444 is 1.163257
INFO:root:FL Epoch: 96 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1605
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594352
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558775
INFO:root:FL Epoch: 96 Norm Difference for worker 1605 is 1.197037
INFO:root:FL Epoch: 96 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :358
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824317
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485492
INFO:root:FL Epoch: 96 Norm Difference for worker 358 is 1.160839
INFO:root:FL Epoch: 96 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1793
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351507
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514913
INFO:root:FL Epoch: 96 Norm Difference for worker 1793 is 1.208744
INFO:root:FL Epoch: 96 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :835
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594775
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567762
INFO:root:FL Epoch: 96 Norm Difference for worker 835 is 1.265365
INFO:root:FL Epoch: 96 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :506
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702964
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371633
INFO:root:FL Epoch: 96 Norm Difference for worker 506 is 1.287426
INFO:root:FL Epoch: 96 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1386
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658420
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711704
INFO:root:FL Epoch: 96 Norm Difference for worker 1386 is 1.154955
INFO:root:FL Epoch: 96 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1886
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616567
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673904
INFO:root:FL Epoch: 96 Norm Difference for worker 1886 is 1.241344
INFO:root:FL Epoch: 96 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1517
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445242
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596566
INFO:root:FL Epoch: 96 Norm Difference for worker 1517 is 1.176615
INFO:root:FL Epoch: 96 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 358
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.5681264558259178 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.390142798423767                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [10, 1791, 1090, 1820, 514, 1786, 1792, 1648, 640, 1773]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 97 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :10
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 10 is 1.126082
INFO:root:FL Epoch: 97 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1791
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601402
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613574
INFO:root:FL Epoch: 97 Norm Difference for worker 1791 is 1.047232
INFO:root:FL Epoch: 97 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1090
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439603
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499244
INFO:root:FL Epoch: 97 Norm Difference for worker 1090 is 1.0965
INFO:root:FL Epoch: 97 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1820
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517528
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529995
INFO:root:FL Epoch: 97 Norm Difference for worker 1820 is 1.060347
INFO:root:FL Epoch: 97 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :514
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536685
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451639
INFO:root:FL Epoch: 97 Norm Difference for worker 514 is 1.043885
INFO:root:FL Epoch: 97 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1786
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555709
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576068
INFO:root:FL Epoch: 97 Norm Difference for worker 1786 is 1.038439
INFO:root:FL Epoch: 97 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1792
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672783
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604146
INFO:root:FL Epoch: 97 Norm Difference for worker 1792 is 1.016349
INFO:root:FL Epoch: 97 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1648
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394567
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.782589
INFO:root:FL Epoch: 97 Norm Difference for worker 1648 is 1.013561
INFO:root:FL Epoch: 97 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :640
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699628
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676959
INFO:root:FL Epoch: 97 Norm Difference for worker 640 is 1.059039
INFO:root:FL Epoch: 97 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1773
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541654
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515368
INFO:root:FL Epoch: 97 Norm Difference for worker 1773 is 1.07685
INFO:root:FL Epoch: 97 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1792
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5726173502557418 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:1.8662002881368                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [282, 1423, 1120, 108, 519, 61, 432, 233, 1892, 797]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 98 Num points on workers: [201 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :282
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 282 is 1.237085
INFO:root:FL Epoch: 98 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1423
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454227
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375346
INFO:root:FL Epoch: 98 Norm Difference for worker 1423 is 1.068589
INFO:root:FL Epoch: 98 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1120
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486209
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618175
INFO:root:FL Epoch: 98 Norm Difference for worker 1120 is 1.14514
INFO:root:FL Epoch: 98 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :108
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 108 is 1.114089
INFO:root:FL Epoch: 98 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :519
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388239
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465830
INFO:root:FL Epoch: 98 Norm Difference for worker 519 is 1.155765
INFO:root:FL Epoch: 98 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :61
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 61 is 1.157467
INFO:root:FL Epoch: 98 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :432
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392666
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524171
INFO:root:FL Epoch: 98 Norm Difference for worker 432 is 1.047765
INFO:root:FL Epoch: 98 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :233
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 233 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 233 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616140
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 233 is 1.176852
INFO:root:FL Epoch: 98 Done on worker:233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1892
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417472
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374704
INFO:root:FL Epoch: 98 Norm Difference for worker 1892 is 1.149103
INFO:root:FL Epoch: 98 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :797
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689594
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441644
INFO:root:FL Epoch: 98 Norm Difference for worker 797 is 1.14404
INFO:root:FL Epoch: 98 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.5683356611167684 and Test Accuracy:70.0 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.8483420610427856                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [147, 1585, 377, 1945, 613, 0, 101, 289, 813, 804]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 99 Num points on workers: [201 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :147
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 147 is 1.092685
INFO:root:FL Epoch: 99 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1585
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647947
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741784
INFO:root:FL Epoch: 99 Norm Difference for worker 1585 is 1.103647
INFO:root:FL Epoch: 99 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :377
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676196
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397543
INFO:root:FL Epoch: 99 Norm Difference for worker 377 is 1.19534
INFO:root:FL Epoch: 99 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1945
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383660
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462490
INFO:root:FL Epoch: 99 Norm Difference for worker 1945 is 1.100745
INFO:root:FL Epoch: 99 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :613
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677425
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617420
INFO:root:FL Epoch: 99 Norm Difference for worker 613 is 1.160545
INFO:root:FL Epoch: 99 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :0
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 0 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 0 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 0 is 1.081627
INFO:root:FL Epoch: 99 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :101
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658375
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485306
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 101 is 1.154578
INFO:root:FL Epoch: 99 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :289
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594461
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 289 is 1.070709
INFO:root:FL Epoch: 99 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :813
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625562
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559958
INFO:root:FL Epoch: 99 Norm Difference for worker 813 is 1.105475
INFO:root:FL Epoch: 99 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :804
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697985
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563046
INFO:root:FL Epoch: 99 Norm Difference for worker 804 is 1.143472
INFO:root:FL Epoch: 99 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.5482547283172607 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.7738697330156963                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1052, 567, 1765, 572, 546, 1804, 1441, 519, 1269, 981]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1052
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651594
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542299
INFO:root:FL Epoch: 100 Norm Difference for worker 1052 is 1.033049
INFO:root:FL Epoch: 100 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :567
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494853
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436416
INFO:root:FL Epoch: 100 Norm Difference for worker 567 is 1.050558
INFO:root:FL Epoch: 100 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1765
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647373
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625126
INFO:root:FL Epoch: 100 Norm Difference for worker 1765 is 1.079468
INFO:root:FL Epoch: 100 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :572
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437641
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436643
INFO:root:FL Epoch: 100 Norm Difference for worker 572 is 1.129728
INFO:root:FL Epoch: 100 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :546
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441361
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549938
INFO:root:FL Epoch: 100 Norm Difference for worker 546 is 1.179688
INFO:root:FL Epoch: 100 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1804
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541744
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541168
INFO:root:FL Epoch: 100 Norm Difference for worker 1804 is 1.103642
INFO:root:FL Epoch: 100 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1441
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743271
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506663
INFO:root:FL Epoch: 100 Norm Difference for worker 1441 is 1.106009
INFO:root:FL Epoch: 100 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :519
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619496
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553420
INFO:root:FL Epoch: 100 Norm Difference for worker 519 is 1.082147
INFO:root:FL Epoch: 100 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1269
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599606
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428827
INFO:root:FL Epoch: 100 Norm Difference for worker 1269 is 1.196681
INFO:root:FL Epoch: 100 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :981
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557357
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512034
INFO:root:FL Epoch: 100 Norm Difference for worker 981 is 1.108821
INFO:root:FL Epoch: 100 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 100 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saved Best Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saved Checkpoint at this epoch.
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5465831283260795 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:1.71040540933609                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [1921, 560, 1670, 1278, 1241, 703, 859, 368, 1408, 1633]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :1921
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450634
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738008
INFO:root:FL Epoch: 101 Norm Difference for worker 1921 is 1.026526
INFO:root:FL Epoch: 101 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :560
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554345
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477212
INFO:root:FL Epoch: 101 Norm Difference for worker 560 is 1.029612
INFO:root:FL Epoch: 101 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1670
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427840
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706460
INFO:root:FL Epoch: 101 Norm Difference for worker 1670 is 1.034329
INFO:root:FL Epoch: 101 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1278
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643570
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531437
INFO:root:FL Epoch: 101 Norm Difference for worker 1278 is 0.986843
INFO:root:FL Epoch: 101 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1241
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534776
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360851
INFO:root:FL Epoch: 101 Norm Difference for worker 1241 is 1.027777
INFO:root:FL Epoch: 101 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :703
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684716
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448162
INFO:root:FL Epoch: 101 Norm Difference for worker 703 is 1.056837
INFO:root:FL Epoch: 101 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :859
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593888
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579681
INFO:root:FL Epoch: 101 Norm Difference for worker 859 is 1.127022
INFO:root:FL Epoch: 101 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :368
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659293
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509435
INFO:root:FL Epoch: 101 Norm Difference for worker 368 is 1.055083
INFO:root:FL Epoch: 101 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1408
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513834
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478358
INFO:root:FL Epoch: 101 Norm Difference for worker 1408 is 1.081916
INFO:root:FL Epoch: 101 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1633
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597690
INFO:root:Worker: 1633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608231
INFO:root:FL Epoch: 101 Norm Difference for worker 1633 is 1.016062
INFO:root:FL Epoch: 101 Done on worker:1633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.5481888494070839 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:1.694879154364268                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [325, 1346, 1272, 740, 929, 1298, 389, 1055, 1168, 811]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :325
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 325 is 1.063748
INFO:root:FL Epoch: 102 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1346
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632312
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579143
INFO:root:FL Epoch: 102 Norm Difference for worker 1346 is 1.021692
INFO:root:FL Epoch: 102 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1272
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558155
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462912
INFO:root:FL Epoch: 102 Norm Difference for worker 1272 is 0.993698
INFO:root:FL Epoch: 102 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :740
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511579
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357754
INFO:root:FL Epoch: 102 Norm Difference for worker 740 is 1.058384
INFO:root:FL Epoch: 102 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :929
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800842
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444862
INFO:root:FL Epoch: 102 Norm Difference for worker 929 is 1.006956
INFO:root:FL Epoch: 102 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1298
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707826
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447278
INFO:root:FL Epoch: 102 Norm Difference for worker 1298 is 1.081397
INFO:root:FL Epoch: 102 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :389
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732253
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586329
INFO:root:FL Epoch: 102 Norm Difference for worker 389 is 1.04179
INFO:root:FL Epoch: 102 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1055
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496597
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465036
INFO:root:FL Epoch: 102 Norm Difference for worker 1055 is 1.018575
INFO:root:FL Epoch: 102 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1168
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577808
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553690
INFO:root:FL Epoch: 102 Norm Difference for worker 1168 is 1.062461
INFO:root:FL Epoch: 102 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :811
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525293
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471011
INFO:root:FL Epoch: 102 Norm Difference for worker 811 is 1.081899
INFO:root:FL Epoch: 102 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1272
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 102 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 102 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5401186066515306 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:2.0166821678479514                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [707, 1292, 149, 1772, 1621, 1171, 1804, 14, 1531, 1917]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :707
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705601
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507221
INFO:root:FL Epoch: 103 Norm Difference for worker 707 is 1.170653
INFO:root:FL Epoch: 103 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1292
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457735
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514444
INFO:root:FL Epoch: 103 Norm Difference for worker 1292 is 1.246286
INFO:root:FL Epoch: 103 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :149
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425975
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 149 is 1.205086
INFO:root:FL Epoch: 103 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1772
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695137
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479086
INFO:root:FL Epoch: 103 Norm Difference for worker 1772 is 1.157341
INFO:root:FL Epoch: 103 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1621
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458504
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498486
INFO:root:FL Epoch: 103 Norm Difference for worker 1621 is 1.161953
INFO:root:FL Epoch: 103 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1171
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605535
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432234
INFO:root:FL Epoch: 103 Norm Difference for worker 1171 is 1.21319
INFO:root:FL Epoch: 103 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1804
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537294
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657288
INFO:root:FL Epoch: 103 Norm Difference for worker 1804 is 1.201804
INFO:root:FL Epoch: 103 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :14
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 14 is 1.178244
INFO:root:FL Epoch: 103 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1531
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564178
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544683
INFO:root:FL Epoch: 103 Norm Difference for worker 1531 is 1.217607
INFO:root:FL Epoch: 103 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1917
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504800
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553269
INFO:root:FL Epoch: 103 Norm Difference for worker 1917 is 1.156872
INFO:root:FL Epoch: 103 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1917
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.5635439315262962 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:1.6326309045155842                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [145, 785, 1422, 1843, 191, 1743, 675, 1735, 1134, 423]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 104 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :145
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 145 is 1.029332
INFO:root:FL Epoch: 104 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :785
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456477
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550306
INFO:root:FL Epoch: 104 Norm Difference for worker 785 is 1.091838
INFO:root:FL Epoch: 104 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1422
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373862
INFO:root:Worker: 1422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534187
INFO:root:FL Epoch: 104 Norm Difference for worker 1422 is 1.125862
INFO:root:FL Epoch: 104 Done on worker:1422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1843
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732649
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521621
INFO:root:FL Epoch: 104 Norm Difference for worker 1843 is 1.110643
INFO:root:FL Epoch: 104 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :191
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.365035
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 191 is 1.266037
INFO:root:FL Epoch: 104 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1743
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523900
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433859
INFO:root:FL Epoch: 104 Norm Difference for worker 1743 is 1.130317
INFO:root:FL Epoch: 104 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :675
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686877
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672321
INFO:root:FL Epoch: 104 Norm Difference for worker 675 is 1.144729
INFO:root:FL Epoch: 104 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1735
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556723
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488754
INFO:root:FL Epoch: 104 Norm Difference for worker 1735 is 1.05099
INFO:root:FL Epoch: 104 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1134
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392085
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323066
INFO:root:FL Epoch: 104 Norm Difference for worker 1134 is 1.135191
INFO:root:FL Epoch: 104 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :423
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758325
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500300
INFO:root:FL Epoch: 104 Norm Difference for worker 423 is 1.073471
INFO:root:FL Epoch: 104 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5535428401301888 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:1.9688249627749126                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1487, 1653, 741, 1240, 919, 1138, 0, 634, 1281, 1003]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1487
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476225
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392343
INFO:root:FL Epoch: 105 Norm Difference for worker 1487 is 1.327162
INFO:root:FL Epoch: 105 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1653
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691265
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609672
INFO:root:FL Epoch: 105 Norm Difference for worker 1653 is 1.332221
INFO:root:FL Epoch: 105 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :741
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580518
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508220
INFO:root:FL Epoch: 105 Norm Difference for worker 741 is 1.380424
INFO:root:FL Epoch: 105 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1240
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551247
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688042
INFO:root:FL Epoch: 105 Norm Difference for worker 1240 is 1.317268
INFO:root:FL Epoch: 105 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :919
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612919
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621228
INFO:root:FL Epoch: 105 Norm Difference for worker 919 is 1.428313
INFO:root:FL Epoch: 105 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1138
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559340
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475083
INFO:root:FL Epoch: 105 Norm Difference for worker 1138 is 1.329651
INFO:root:FL Epoch: 105 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :0
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 0 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 0 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 0 is 1.271245
INFO:root:FL Epoch: 105 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :634
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635248
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702060
INFO:root:FL Epoch: 105 Norm Difference for worker 634 is 1.346844
INFO:root:FL Epoch: 105 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1281
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364146
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550492
INFO:root:FL Epoch: 105 Norm Difference for worker 1281 is 1.263879
INFO:root:FL Epoch: 105 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1003
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712620
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423546
INFO:root:FL Epoch: 105 Norm Difference for worker 1003 is 1.294958
INFO:root:FL Epoch: 105 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1653
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5574329162345213 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:1.5095963676770527                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [25, 1097, 1109, 1168, 669, 2, 1641, 1221, 1330, 583]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :25
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537288
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 25 is 1.039634
INFO:root:FL Epoch: 106 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1097
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593321
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583964
INFO:root:FL Epoch: 106 Norm Difference for worker 1097 is 1.110906
INFO:root:FL Epoch: 106 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1109
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551869
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690764
INFO:root:FL Epoch: 106 Norm Difference for worker 1109 is 1.036684
INFO:root:FL Epoch: 106 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1168
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580378
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490320
INFO:root:FL Epoch: 106 Norm Difference for worker 1168 is 1.065009
INFO:root:FL Epoch: 106 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :669
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614862
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590405
INFO:root:FL Epoch: 106 Norm Difference for worker 669 is 1.139171
INFO:root:FL Epoch: 106 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :2
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 2 is 1.059572
INFO:root:FL Epoch: 106 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1641
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439959
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487868
INFO:root:FL Epoch: 106 Norm Difference for worker 1641 is 1.066938
INFO:root:FL Epoch: 106 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1221
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769777
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586897
INFO:root:FL Epoch: 106 Norm Difference for worker 1221 is 1.053533
INFO:root:FL Epoch: 106 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1330
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679286
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518311
INFO:root:FL Epoch: 106 Norm Difference for worker 1330 is 1.183272
INFO:root:FL Epoch: 106 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :583
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536269
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563391
INFO:root:FL Epoch: 106 Norm Difference for worker 583 is 1.06421
INFO:root:FL Epoch: 106 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1109
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5854949127225315 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.8218780159950256                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1310, 1035, 1502, 1744, 1268, 1799, 1425, 872, 1416, 1042]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1310
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467638
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518015
INFO:root:FL Epoch: 107 Norm Difference for worker 1310 is 1.183864
INFO:root:FL Epoch: 107 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1035
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741426
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570091
INFO:root:FL Epoch: 107 Norm Difference for worker 1035 is 1.194529
INFO:root:FL Epoch: 107 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1502
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569473
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433078
INFO:root:FL Epoch: 107 Norm Difference for worker 1502 is 1.192402
INFO:root:FL Epoch: 107 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1744
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455184
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440057
INFO:root:FL Epoch: 107 Norm Difference for worker 1744 is 1.109059
INFO:root:FL Epoch: 107 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1268
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510071
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450632
INFO:root:FL Epoch: 107 Norm Difference for worker 1268 is 1.17886
INFO:root:FL Epoch: 107 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1799
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488965
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419920
INFO:root:FL Epoch: 107 Norm Difference for worker 1799 is 1.107787
INFO:root:FL Epoch: 107 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1425
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667772
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499905
INFO:root:FL Epoch: 107 Norm Difference for worker 1425 is 1.165334
INFO:root:FL Epoch: 107 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :872
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496834
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556636
INFO:root:FL Epoch: 107 Norm Difference for worker 872 is 1.159438
INFO:root:FL Epoch: 107 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1416
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522111
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484925
INFO:root:FL Epoch: 107 Norm Difference for worker 1416 is 1.185701
INFO:root:FL Epoch: 107 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1042
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455895
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538830
INFO:root:FL Epoch: 107 Norm Difference for worker 1042 is 1.178108
INFO:root:FL Epoch: 107 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1799
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.5583951613482308 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.5641932686169941                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [1826, 429, 169, 1338, 107, 1360, 1268, 529, 475, 1165]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 108 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :1826
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446877
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628710
INFO:root:FL Epoch: 108 Norm Difference for worker 1826 is 1.121204
INFO:root:FL Epoch: 108 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :429
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493891
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725104
INFO:root:FL Epoch: 108 Norm Difference for worker 429 is 1.201197
INFO:root:FL Epoch: 108 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :169
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 169 is 1.138307
INFO:root:FL Epoch: 108 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1338
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669350
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489987
INFO:root:FL Epoch: 108 Norm Difference for worker 1338 is 1.092348
INFO:root:FL Epoch: 108 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :107
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626615
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 107 is 1.14306
INFO:root:FL Epoch: 108 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1360
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454399
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505980
INFO:root:FL Epoch: 108 Norm Difference for worker 1360 is 1.174945
INFO:root:FL Epoch: 108 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1268
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634971
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442341
INFO:root:FL Epoch: 108 Norm Difference for worker 1268 is 1.157187
INFO:root:FL Epoch: 108 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :529
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467477
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713327
INFO:root:FL Epoch: 108 Norm Difference for worker 529 is 1.17726
INFO:root:FL Epoch: 108 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :475
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724941
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593959
INFO:root:FL Epoch: 108 Norm Difference for worker 475 is 1.190717
INFO:root:FL Epoch: 108 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1165
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377324
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493548
INFO:root:FL Epoch: 108 Norm Difference for worker 1165 is 1.123755
INFO:root:FL Epoch: 108 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.5556851607911727 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:1.3426385521888733                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [1736, 1733, 399, 597, 1355, 911, 1702, 882, 76, 40]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :1736
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533685
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604021
INFO:root:FL Epoch: 109 Norm Difference for worker 1736 is 1.08125
INFO:root:FL Epoch: 109 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1733
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590645
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528487
INFO:root:FL Epoch: 109 Norm Difference for worker 1733 is 1.053956
INFO:root:FL Epoch: 109 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :399
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529330
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447311
INFO:root:FL Epoch: 109 Norm Difference for worker 399 is 1.050623
INFO:root:FL Epoch: 109 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :597
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502999
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511116
INFO:root:FL Epoch: 109 Norm Difference for worker 597 is 1.08906
INFO:root:FL Epoch: 109 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1355
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805941
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477809
INFO:root:FL Epoch: 109 Norm Difference for worker 1355 is 1.074474
INFO:root:FL Epoch: 109 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :911
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453781
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620777
INFO:root:FL Epoch: 109 Norm Difference for worker 911 is 1.074951
INFO:root:FL Epoch: 109 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1702
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538239
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542616
INFO:root:FL Epoch: 109 Norm Difference for worker 1702 is 1.107026
INFO:root:FL Epoch: 109 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :882
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542055
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598018
INFO:root:FL Epoch: 109 Norm Difference for worker 882 is 0.996942
INFO:root:FL Epoch: 109 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :76
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 76 is 1.044307
INFO:root:FL Epoch: 109 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :40
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 40 is 1.069823
INFO:root:FL Epoch: 109 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 882
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.551515973666135 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.3984035849571228                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [113, 1590, 956, 1686, 786, 771, 1021, 1265, 1035, 223]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :113
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487715
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 113 is 1.026862
INFO:root:FL Epoch: 110 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1590
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588131
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492961
INFO:root:FL Epoch: 110 Norm Difference for worker 1590 is 1.098418
INFO:root:FL Epoch: 110 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :956
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631487
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557629
INFO:root:FL Epoch: 110 Norm Difference for worker 956 is 1.057312
INFO:root:FL Epoch: 110 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1686
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439995
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497586
INFO:root:FL Epoch: 110 Norm Difference for worker 1686 is 1.120646
INFO:root:FL Epoch: 110 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :786
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574763
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522493
INFO:root:FL Epoch: 110 Norm Difference for worker 786 is 1.067766
INFO:root:FL Epoch: 110 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :771
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702047
INFO:root:Worker: 771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400865
INFO:root:FL Epoch: 110 Norm Difference for worker 771 is 0.962815
INFO:root:FL Epoch: 110 Done on worker:771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1021
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520700
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641611
INFO:root:FL Epoch: 110 Norm Difference for worker 1021 is 0.985917
INFO:root:FL Epoch: 110 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1265
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443177
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569040
INFO:root:FL Epoch: 110 Norm Difference for worker 1265 is 1.10021
INFO:root:FL Epoch: 110 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1035
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754770
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506990
INFO:root:FL Epoch: 110 Norm Difference for worker 1035 is 1.078161
INFO:root:FL Epoch: 110 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :223
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 223 is 1.119154
INFO:root:FL Epoch: 110 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 771
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.5691840911612791 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.2867831985155742                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [20, 404, 732, 1803, 1008, 138, 1701, 51, 1545, 640]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 111 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :20
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 20 is 0.968538
INFO:root:FL Epoch: 111 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :404
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456512
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546616
INFO:root:FL Epoch: 111 Norm Difference for worker 404 is 1.039124
INFO:root:FL Epoch: 111 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :732
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662871
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681301
INFO:root:FL Epoch: 111 Norm Difference for worker 732 is 1.003299
INFO:root:FL Epoch: 111 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1803
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561848
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537545
INFO:root:FL Epoch: 111 Norm Difference for worker 1803 is 1.070973
INFO:root:FL Epoch: 111 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1008
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556277
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604342
INFO:root:FL Epoch: 111 Norm Difference for worker 1008 is 1.005288
INFO:root:FL Epoch: 111 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :138
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 138 is 0.991862
INFO:root:FL Epoch: 111 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1701
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629289
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407686
INFO:root:FL Epoch: 111 Norm Difference for worker 1701 is 0.981175
INFO:root:FL Epoch: 111 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :51
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 51 is 1.028442
INFO:root:FL Epoch: 111 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1545
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611781
INFO:root:Worker: 1545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501379
INFO:root:FL Epoch: 111 Norm Difference for worker 1545 is 0.997378
INFO:root:FL Epoch: 111 Done on worker:1545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :640
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639361
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555864
INFO:root:FL Epoch: 111 Norm Difference for worker 640 is 1.008883
INFO:root:FL Epoch: 111 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.5518127294147716 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:1.5186668634414673                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [1229, 477, 1774, 1679, 1377, 1765, 479, 1354, 248, 405]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 112 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :1229
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634856
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488453
INFO:root:FL Epoch: 112 Norm Difference for worker 1229 is 1.212468
INFO:root:FL Epoch: 112 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :477
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597682
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524101
INFO:root:FL Epoch: 112 Norm Difference for worker 477 is 1.069471
INFO:root:FL Epoch: 112 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1774
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707329
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491868
INFO:root:FL Epoch: 112 Norm Difference for worker 1774 is 1.169906
INFO:root:FL Epoch: 112 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1679
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582802
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610104
INFO:root:FL Epoch: 112 Norm Difference for worker 1679 is 1.193358
INFO:root:FL Epoch: 112 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1377
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829137
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560879
INFO:root:FL Epoch: 112 Norm Difference for worker 1377 is 1.177235
INFO:root:FL Epoch: 112 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1765
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425161
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521122
INFO:root:FL Epoch: 112 Norm Difference for worker 1765 is 1.151935
INFO:root:FL Epoch: 112 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :479
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629162
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621259
INFO:root:FL Epoch: 112 Norm Difference for worker 479 is 1.10477
INFO:root:FL Epoch: 112 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1354
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762931
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413541
INFO:root:FL Epoch: 112 Norm Difference for worker 1354 is 1.135484
INFO:root:FL Epoch: 112 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :248
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.661290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 248 is 1.137191
INFO:root:FL Epoch: 112 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :405
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772620
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388102
INFO:root:FL Epoch: 112 Norm Difference for worker 405 is 1.118734
INFO:root:FL Epoch: 112 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.5483594869866091 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:1.67720760901769                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [462, 96, 1883, 1469, 1825, 692, 1698, 1764, 322, 217]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 113 Num points on workers: [200 201 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :462
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393358
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496440
INFO:root:FL Epoch: 113 Norm Difference for worker 462 is 1.131065
INFO:root:FL Epoch: 113 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :96
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536930
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 96 is 1.122538
INFO:root:FL Epoch: 113 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1883
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496444
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505713
INFO:root:FL Epoch: 113 Norm Difference for worker 1883 is 1.158698
INFO:root:FL Epoch: 113 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1469
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675174
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549737
INFO:root:FL Epoch: 113 Norm Difference for worker 1469 is 1.078104
INFO:root:FL Epoch: 113 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1825
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708727
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420546
INFO:root:FL Epoch: 113 Norm Difference for worker 1825 is 1.088003
INFO:root:FL Epoch: 113 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :692
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722624
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570506
INFO:root:FL Epoch: 113 Norm Difference for worker 692 is 1.092237
INFO:root:FL Epoch: 113 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1698
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609797
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529784
INFO:root:FL Epoch: 113 Norm Difference for worker 1698 is 1.118554
INFO:root:FL Epoch: 113 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1764
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832565
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526471
INFO:root:FL Epoch: 113 Norm Difference for worker 1764 is 1.159086
INFO:root:FL Epoch: 113 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :322
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 322 is 1.175801
INFO:root:FL Epoch: 113 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :217
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 217 is 1.080566
INFO:root:FL Epoch: 113 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1825
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.5488689997616936 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:1.9826291799545288                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [84, 884, 1616, 1334, 197, 31, 285, 1029, 1083, 1192]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 114 Num points on workers: [201 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :84
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 114 Norm Difference for worker 84 is 1.236291
INFO:root:FL Epoch: 114 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :884
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681592
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671083
INFO:root:FL Epoch: 114 Norm Difference for worker 884 is 1.260049
INFO:root:FL Epoch: 114 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1616
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445917
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715547
INFO:root:FL Epoch: 114 Norm Difference for worker 1616 is 1.247356
INFO:root:FL Epoch: 114 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1334
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410837
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554489
INFO:root:FL Epoch: 114 Norm Difference for worker 1334 is 1.245933
INFO:root:FL Epoch: 114 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :197
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.752160
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 114 Norm Difference for worker 197 is 1.305722
INFO:root:FL Epoch: 114 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :31
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.886618
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 114 Norm Difference for worker 31 is 1.21461
INFO:root:FL Epoch: 114 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :285
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 114 Norm Difference for worker 285 is 1.244492
INFO:root:FL Epoch: 114 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1029
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639012
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531208
INFO:root:FL Epoch: 114 Norm Difference for worker 1029 is 1.194148
INFO:root:FL Epoch: 114 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1083
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665764
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693456
INFO:root:FL Epoch: 114 Norm Difference for worker 1083 is 1.252228
INFO:root:FL Epoch: 114 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1192
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524320
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560031
INFO:root:FL Epoch: 114 Norm Difference for worker 1192 is 1.195896
INFO:root:FL Epoch: 114 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 31
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.5553872024311739 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:1.6439262827237446                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1926, 1429, 433, 536, 997, 97, 1825, 1083, 1544, 438]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1926
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439636
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447734
INFO:root:FL Epoch: 115 Norm Difference for worker 1926 is 1.229567
INFO:root:FL Epoch: 115 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1429
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444931
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705710
INFO:root:FL Epoch: 115 Norm Difference for worker 1429 is 1.086845
INFO:root:FL Epoch: 115 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :433
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469516
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565646
INFO:root:FL Epoch: 115 Norm Difference for worker 433 is 1.167277
INFO:root:FL Epoch: 115 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :536
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551757
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497167
INFO:root:FL Epoch: 115 Norm Difference for worker 536 is 1.161979
INFO:root:FL Epoch: 115 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :997
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470390
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480637
INFO:root:FL Epoch: 115 Norm Difference for worker 997 is 1.15652
INFO:root:FL Epoch: 115 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :97
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538848
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 97 is 1.202147
INFO:root:FL Epoch: 115 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1825
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564737
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267774
INFO:root:FL Epoch: 115 Norm Difference for worker 1825 is 1.082311
INFO:root:FL Epoch: 115 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1083
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552457
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559403
INFO:root:FL Epoch: 115 Norm Difference for worker 1083 is 1.176002
INFO:root:FL Epoch: 115 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1544
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752735
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581878
INFO:root:FL Epoch: 115 Norm Difference for worker 1544 is 1.204195
INFO:root:FL Epoch: 115 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :438
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771448
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552412
INFO:root:FL Epoch: 115 Norm Difference for worker 438 is 1.170526
INFO:root:FL Epoch: 115 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1429
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.5556310836006614 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:1.5122585892677307                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [852, 1427, 1939, 60, 553, 1018, 672, 1242, 1024, 1870]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 116 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :852
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740324
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671636
INFO:root:FL Epoch: 116 Norm Difference for worker 852 is 1.07894
INFO:root:FL Epoch: 116 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1427
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551669
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451106
INFO:root:FL Epoch: 116 Norm Difference for worker 1427 is 1.124112
INFO:root:FL Epoch: 116 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1939
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526423
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552667
INFO:root:FL Epoch: 116 Norm Difference for worker 1939 is 1.093316
INFO:root:FL Epoch: 116 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :60
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543941
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 60 is 1.148623
INFO:root:FL Epoch: 116 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :553
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774398
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388837
INFO:root:FL Epoch: 116 Norm Difference for worker 553 is 1.015295
INFO:root:FL Epoch: 116 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1018
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668640
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652683
INFO:root:FL Epoch: 116 Norm Difference for worker 1018 is 1.042966
INFO:root:FL Epoch: 116 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :672
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656461
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540872
INFO:root:FL Epoch: 116 Norm Difference for worker 672 is 1.111483
INFO:root:FL Epoch: 116 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1242
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420122
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442602
INFO:root:FL Epoch: 116 Norm Difference for worker 1242 is 1.077072
INFO:root:FL Epoch: 116 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1024
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684560
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419071
INFO:root:FL Epoch: 116 Norm Difference for worker 1024 is 1.018896
INFO:root:FL Epoch: 116 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1870
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490722
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445056
INFO:root:FL Epoch: 116 Norm Difference for worker 1870 is 1.137474
INFO:root:FL Epoch: 116 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 553
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.5441953785279218 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:1.8961552580197651                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [533, 1401, 1542, 355, 1259, 1664, 825, 1827, 217, 1627]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 117 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :533
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613898
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636775
INFO:root:FL Epoch: 117 Norm Difference for worker 533 is 1.219974
INFO:root:FL Epoch: 117 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1401
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661107
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552755
INFO:root:FL Epoch: 117 Norm Difference for worker 1401 is 1.169399
INFO:root:FL Epoch: 117 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1542
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573663
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298941
INFO:root:FL Epoch: 117 Norm Difference for worker 1542 is 1.207398
INFO:root:FL Epoch: 117 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :355
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438846
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462029
INFO:root:FL Epoch: 117 Norm Difference for worker 355 is 1.192598
INFO:root:FL Epoch: 117 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1259
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605023
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631325
INFO:root:FL Epoch: 117 Norm Difference for worker 1259 is 1.161847
INFO:root:FL Epoch: 117 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1664
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436949
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538432
INFO:root:FL Epoch: 117 Norm Difference for worker 1664 is 1.182133
INFO:root:FL Epoch: 117 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :825
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534945
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518189
INFO:root:FL Epoch: 117 Norm Difference for worker 825 is 1.140049
INFO:root:FL Epoch: 117 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1827
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635535
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367341
INFO:root:FL Epoch: 117 Norm Difference for worker 1827 is 1.177749
INFO:root:FL Epoch: 117 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :217
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505105
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 217 is 1.218299
INFO:root:FL Epoch: 117 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1627
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653750
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430157
INFO:root:FL Epoch: 117 Norm Difference for worker 1627 is 1.189522
INFO:root:FL Epoch: 117 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 117 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 117 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.5326034444219926 and Test Accuracy:75.0 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:1.718520204226176                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [1174, 354, 363, 915, 1806, 175, 1391, 335, 1300, 709]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 118 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :1174
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624300
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448119
INFO:root:FL Epoch: 118 Norm Difference for worker 1174 is 1.107987
INFO:root:FL Epoch: 118 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :354
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458390
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498462
INFO:root:FL Epoch: 118 Norm Difference for worker 354 is 1.1482
INFO:root:FL Epoch: 118 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :363
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557992
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404297
INFO:root:FL Epoch: 118 Norm Difference for worker 363 is 1.089651
INFO:root:FL Epoch: 118 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :915
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865865
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643173
INFO:root:FL Epoch: 118 Norm Difference for worker 915 is 1.050184
INFO:root:FL Epoch: 118 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1806
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715204
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584483
INFO:root:FL Epoch: 118 Norm Difference for worker 1806 is 1.031075
INFO:root:FL Epoch: 118 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :175
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 175 is 1.11375
INFO:root:FL Epoch: 118 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1391
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447248
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651004
INFO:root:FL Epoch: 118 Norm Difference for worker 1391 is 1.120757
INFO:root:FL Epoch: 118 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :335
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650759
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 335 is 1.156039
INFO:root:FL Epoch: 118 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1300
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471477
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480602
INFO:root:FL Epoch: 118 Norm Difference for worker 1300 is 1.120829
INFO:root:FL Epoch: 118 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :709
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407206
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602617
INFO:root:FL Epoch: 118 Norm Difference for worker 709 is 1.126063
INFO:root:FL Epoch: 118 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1806
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.5318665855071124 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:1.9320949912071228                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [1080, 316, 293, 1433, 951, 1380, 1719, 1703, 576, 1468]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :1080
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762294
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519112
INFO:root:FL Epoch: 119 Norm Difference for worker 1080 is 1.21587
INFO:root:FL Epoch: 119 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :316
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 316 is 1.217039
INFO:root:FL Epoch: 119 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :293
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463807
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 293 is 1.192672
INFO:root:FL Epoch: 119 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1433
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550781
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628912
INFO:root:FL Epoch: 119 Norm Difference for worker 1433 is 1.18692
INFO:root:FL Epoch: 119 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :951
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592088
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452789
INFO:root:FL Epoch: 119 Norm Difference for worker 951 is 1.177865
INFO:root:FL Epoch: 119 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1380
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514404
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411778
INFO:root:FL Epoch: 119 Norm Difference for worker 1380 is 1.13284
INFO:root:FL Epoch: 119 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1719
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471100
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419307
INFO:root:FL Epoch: 119 Norm Difference for worker 1719 is 1.203685
INFO:root:FL Epoch: 119 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1703
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706488
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651241
INFO:root:FL Epoch: 119 Norm Difference for worker 1703 is 1.245803
INFO:root:FL Epoch: 119 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :576
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560050
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524972
INFO:root:FL Epoch: 119 Norm Difference for worker 576 is 1.212901
INFO:root:FL Epoch: 119 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1468
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786961
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629796
INFO:root:FL Epoch: 119 Norm Difference for worker 1468 is 1.273345
INFO:root:FL Epoch: 119 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1380
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.5418368560426375 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:2.089177747567495                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [1180, 1466, 727, 569, 705, 1079, 761, 111, 381, 939]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :1180
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553372
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780210
INFO:root:FL Epoch: 120 Norm Difference for worker 1180 is 1.187614
INFO:root:FL Epoch: 120 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1466
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600046
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573535
INFO:root:FL Epoch: 120 Norm Difference for worker 1466 is 1.263653
INFO:root:FL Epoch: 120 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :727
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531889
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582255
INFO:root:FL Epoch: 120 Norm Difference for worker 727 is 1.226769
INFO:root:FL Epoch: 120 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :569
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488390
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485185
INFO:root:FL Epoch: 120 Norm Difference for worker 569 is 1.256014
INFO:root:FL Epoch: 120 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :705
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421916
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401973
INFO:root:FL Epoch: 120 Norm Difference for worker 705 is 1.229341
INFO:root:FL Epoch: 120 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1079
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402227
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607170
INFO:root:FL Epoch: 120 Norm Difference for worker 1079 is 1.262334
INFO:root:FL Epoch: 120 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :761
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411018
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632199
INFO:root:FL Epoch: 120 Norm Difference for worker 761 is 1.349679
INFO:root:FL Epoch: 120 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :111
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 111 is 1.247822
INFO:root:FL Epoch: 120 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :381
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385477
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232456
INFO:root:FL Epoch: 120 Norm Difference for worker 381 is 1.170255
INFO:root:FL Epoch: 120 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :939
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.975754
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545859
INFO:root:FL Epoch: 120 Norm Difference for worker 939 is 1.304911
INFO:root:FL Epoch: 120 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 381
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.5423959861783421 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:2.0560083389282227                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [1043, 845, 1637, 1740, 1420, 1925, 1761, 996, 1555, 1491]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :1043
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639554
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663441
INFO:root:FL Epoch: 121 Norm Difference for worker 1043 is 1.314789
INFO:root:FL Epoch: 121 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :845
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451350
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278859
INFO:root:FL Epoch: 121 Norm Difference for worker 845 is 1.304496
INFO:root:FL Epoch: 121 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1637
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789793
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550630
INFO:root:FL Epoch: 121 Norm Difference for worker 1637 is 1.282017
INFO:root:FL Epoch: 121 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1740
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839247
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337210
INFO:root:FL Epoch: 121 Norm Difference for worker 1740 is 1.196626
INFO:root:FL Epoch: 121 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1420
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546553
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437477
INFO:root:FL Epoch: 121 Norm Difference for worker 1420 is 1.316658
INFO:root:FL Epoch: 121 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1925
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607715
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634170
INFO:root:FL Epoch: 121 Norm Difference for worker 1925 is 1.385744
INFO:root:FL Epoch: 121 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1761
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558209
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353189
INFO:root:FL Epoch: 121 Norm Difference for worker 1761 is 1.288513
INFO:root:FL Epoch: 121 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482719
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666716
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 1.32419
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1555
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586181
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409576
INFO:root:FL Epoch: 121 Norm Difference for worker 1555 is 1.410541
INFO:root:FL Epoch: 121 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1491
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497430
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344526
INFO:root:FL Epoch: 121 Norm Difference for worker 1491 is 1.200996
INFO:root:FL Epoch: 121 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1740
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.5151790818747353 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:1.9098495443662007                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [620, 1206, 1419, 180, 1762, 1393, 1359, 1680, 324, 1742]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 122 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :620
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487406
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651639
INFO:root:FL Epoch: 122 Norm Difference for worker 620 is 1.129677
INFO:root:FL Epoch: 122 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1206
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530730
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490115
INFO:root:FL Epoch: 122 Norm Difference for worker 1206 is 1.174922
INFO:root:FL Epoch: 122 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1419
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597345
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399221
INFO:root:FL Epoch: 122 Norm Difference for worker 1419 is 1.184183
INFO:root:FL Epoch: 122 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :180
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648941
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 180 is 1.185596
INFO:root:FL Epoch: 122 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1762
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383103
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447171
INFO:root:FL Epoch: 122 Norm Difference for worker 1762 is 1.183624
INFO:root:FL Epoch: 122 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1393
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 1.000275
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505978
INFO:root:FL Epoch: 122 Norm Difference for worker 1393 is 1.240824
INFO:root:FL Epoch: 122 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1359
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405421
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304309
INFO:root:FL Epoch: 122 Norm Difference for worker 1359 is 1.15148
INFO:root:FL Epoch: 122 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1680
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579441
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633738
INFO:root:FL Epoch: 122 Norm Difference for worker 1680 is 1.269725
INFO:root:FL Epoch: 122 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :324
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 324 is 1.177143
INFO:root:FL Epoch: 122 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1742
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473501
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565774
INFO:root:FL Epoch: 122 Norm Difference for worker 1742 is 1.189077
INFO:root:FL Epoch: 122 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.5255416000590605 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:1.7281326254208882                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [723, 1126, 558, 1294, 1424, 686, 1894, 1934, 1152, 1308]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :723
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438607
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434178
INFO:root:FL Epoch: 123 Norm Difference for worker 723 is 1.054111
INFO:root:FL Epoch: 123 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1126
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540176
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613663
INFO:root:FL Epoch: 123 Norm Difference for worker 1126 is 1.195044
INFO:root:FL Epoch: 123 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :558
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766402
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590839
INFO:root:FL Epoch: 123 Norm Difference for worker 558 is 1.121046
INFO:root:FL Epoch: 123 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1294
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592583
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551110
INFO:root:FL Epoch: 123 Norm Difference for worker 1294 is 1.167477
INFO:root:FL Epoch: 123 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1424
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572360
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412652
INFO:root:FL Epoch: 123 Norm Difference for worker 1424 is 1.256649
INFO:root:FL Epoch: 123 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :686
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703966
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409500
INFO:root:FL Epoch: 123 Norm Difference for worker 686 is 1.086061
INFO:root:FL Epoch: 123 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1894
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474701
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654586
INFO:root:FL Epoch: 123 Norm Difference for worker 1894 is 1.155062
INFO:root:FL Epoch: 123 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1934
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747402
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372471
INFO:root:FL Epoch: 123 Norm Difference for worker 1934 is 1.124131
INFO:root:FL Epoch: 123 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1152
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632303
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356518
INFO:root:FL Epoch: 123 Norm Difference for worker 1152 is 1.129452
INFO:root:FL Epoch: 123 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1308
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755446
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649796
INFO:root:FL Epoch: 123 Norm Difference for worker 1308 is 1.150004
INFO:root:FL Epoch: 123 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5432573539369246 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:1.9489686886469524                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [498, 611, 1067, 1868, 1484, 1662, 1208, 508, 1698, 1761]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :498
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411247
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458747
INFO:root:FL Epoch: 124 Norm Difference for worker 498 is 1.18811
INFO:root:FL Epoch: 124 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :611
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610109
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383147
INFO:root:FL Epoch: 124 Norm Difference for worker 611 is 1.161335
INFO:root:FL Epoch: 124 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1067
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619360
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421981
INFO:root:FL Epoch: 124 Norm Difference for worker 1067 is 1.187514
INFO:root:FL Epoch: 124 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1868
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640008
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695217
INFO:root:FL Epoch: 124 Norm Difference for worker 1868 is 1.312136
INFO:root:FL Epoch: 124 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1484
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486651
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471401
INFO:root:FL Epoch: 124 Norm Difference for worker 1484 is 1.205821
INFO:root:FL Epoch: 124 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1662
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581162
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409845
INFO:root:FL Epoch: 124 Norm Difference for worker 1662 is 1.202563
INFO:root:FL Epoch: 124 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1208
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541670
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360465
INFO:root:FL Epoch: 124 Norm Difference for worker 1208 is 1.193162
INFO:root:FL Epoch: 124 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :508
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607021
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421052
INFO:root:FL Epoch: 124 Norm Difference for worker 508 is 1.203985
INFO:root:FL Epoch: 124 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1698
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593816
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538818
INFO:root:FL Epoch: 124 Norm Difference for worker 1698 is 1.244445
INFO:root:FL Epoch: 124 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1761
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489341
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487998
INFO:root:FL Epoch: 124 Norm Difference for worker 1761 is 1.211933
INFO:root:FL Epoch: 124 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 611
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.572221321218154 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:2.104368964831034                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [1510, 405, 1791, 1569, 1827, 1816, 1883, 71, 1688, 427]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :1510
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499646
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432473
INFO:root:FL Epoch: 125 Norm Difference for worker 1510 is 1.301182
INFO:root:FL Epoch: 125 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :405
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518999
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522080
INFO:root:FL Epoch: 125 Norm Difference for worker 405 is 1.162991
INFO:root:FL Epoch: 125 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1791
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570399
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443031
INFO:root:FL Epoch: 125 Norm Difference for worker 1791 is 1.253273
INFO:root:FL Epoch: 125 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1569
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442997
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326698
INFO:root:FL Epoch: 125 Norm Difference for worker 1569 is 1.235251
INFO:root:FL Epoch: 125 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1827
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704189
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377121
INFO:root:FL Epoch: 125 Norm Difference for worker 1827 is 1.242906
INFO:root:FL Epoch: 125 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1816
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564806
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359927
INFO:root:FL Epoch: 125 Norm Difference for worker 1816 is 1.148489
INFO:root:FL Epoch: 125 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1883
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553601
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449762
INFO:root:FL Epoch: 125 Norm Difference for worker 1883 is 1.182057
INFO:root:FL Epoch: 125 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :71
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 71 is 1.153023
INFO:root:FL Epoch: 125 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1688
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594512
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660984
INFO:root:FL Epoch: 125 Norm Difference for worker 1688 is 1.154494
INFO:root:FL Epoch: 125 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :427
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615638
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446493
INFO:root:FL Epoch: 125 Norm Difference for worker 427 is 1.265786
INFO:root:FL Epoch: 125 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1688
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.5623891125707066 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:2.082702120145162                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1925, 52, 957, 1132, 420, 1033, 841, 710, 200, 1606]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 126 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1925
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577380
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598199
INFO:root:FL Epoch: 126 Norm Difference for worker 1925 is 1.30712
INFO:root:FL Epoch: 126 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :52
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 52 is 1.229905
INFO:root:FL Epoch: 126 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :957
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584815
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406749
INFO:root:FL Epoch: 126 Norm Difference for worker 957 is 1.154256
INFO:root:FL Epoch: 126 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1132
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748295
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439776
INFO:root:FL Epoch: 126 Norm Difference for worker 1132 is 1.186109
INFO:root:FL Epoch: 126 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :420
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798755
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420849
INFO:root:FL Epoch: 126 Norm Difference for worker 420 is 1.212951
INFO:root:FL Epoch: 126 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1033
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481844
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529555
INFO:root:FL Epoch: 126 Norm Difference for worker 1033 is 1.220126
INFO:root:FL Epoch: 126 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :841
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481335
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759213
INFO:root:FL Epoch: 126 Norm Difference for worker 841 is 1.235568
INFO:root:FL Epoch: 126 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :710
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440581
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424898
INFO:root:FL Epoch: 126 Norm Difference for worker 710 is 1.20063
INFO:root:FL Epoch: 126 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :200
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 200 is 1.113649
INFO:root:FL Epoch: 126 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1606
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362724
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663896
INFO:root:FL Epoch: 126 Norm Difference for worker 1606 is 1.133298
INFO:root:FL Epoch: 126 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 200
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.5804378407842973 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:1.9314690430959065                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [854, 1751, 1343, 1118, 151, 169, 1332, 1872, 1363, 1180]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :854
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449487
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346406
INFO:root:FL Epoch: 127 Norm Difference for worker 854 is 1.23129
INFO:root:FL Epoch: 127 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1751
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750109
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415137
INFO:root:FL Epoch: 127 Norm Difference for worker 1751 is 1.12289
INFO:root:FL Epoch: 127 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1343
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587372
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302520
INFO:root:FL Epoch: 127 Norm Difference for worker 1343 is 1.13918
INFO:root:FL Epoch: 127 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1118
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637271
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596792
INFO:root:FL Epoch: 127 Norm Difference for worker 1118 is 1.140186
INFO:root:FL Epoch: 127 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :151
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627807
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.766891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 151 is 1.11294
INFO:root:FL Epoch: 127 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :169
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 169 is 1.149228
INFO:root:FL Epoch: 127 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1332
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643114
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402370
INFO:root:FL Epoch: 127 Norm Difference for worker 1332 is 1.055107
INFO:root:FL Epoch: 127 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1872
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478395
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431553
INFO:root:FL Epoch: 127 Norm Difference for worker 1872 is 1.118109
INFO:root:FL Epoch: 127 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1363
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516560
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573199
INFO:root:FL Epoch: 127 Norm Difference for worker 1363 is 1.202575
INFO:root:FL Epoch: 127 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1180
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420011
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506493
INFO:root:FL Epoch: 127 Norm Difference for worker 1180 is 1.104273
INFO:root:FL Epoch: 127 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1332
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.5869634379358852 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:1.7774635155995686                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [1139, 697, 680, 960, 69, 1147, 1285, 199, 1419, 1296]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 128 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :1139
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557356
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368592
INFO:root:FL Epoch: 128 Norm Difference for worker 1139 is 1.038508
INFO:root:FL Epoch: 128 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :697
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509599
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544541
INFO:root:FL Epoch: 128 Norm Difference for worker 697 is 1.060583
INFO:root:FL Epoch: 128 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :680
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633595
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459462
INFO:root:FL Epoch: 128 Norm Difference for worker 680 is 1.009525
INFO:root:FL Epoch: 128 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :960
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591199
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717406
INFO:root:FL Epoch: 128 Norm Difference for worker 960 is 0.992207
INFO:root:FL Epoch: 128 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :69
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.812506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 69 is 0.927279
INFO:root:FL Epoch: 128 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1147
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627385
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665523
INFO:root:FL Epoch: 128 Norm Difference for worker 1147 is 1.055351
INFO:root:FL Epoch: 128 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1285
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584123
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567210
INFO:root:FL Epoch: 128 Norm Difference for worker 1285 is 1.025402
INFO:root:FL Epoch: 128 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :199
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 199 is 1.040425
INFO:root:FL Epoch: 128 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1419
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643433
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583748
INFO:root:FL Epoch: 128 Norm Difference for worker 1419 is 1.029328
INFO:root:FL Epoch: 128 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1296
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631890
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419151
INFO:root:FL Epoch: 128 Norm Difference for worker 1296 is 1.05294
INFO:root:FL Epoch: 128 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.5755971792866202 and Test Accuracy:70.0 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:1.7302300532658894                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1799, 230, 1000, 270, 1506, 618, 1579, 118, 465, 776]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 129 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1799
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465636
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451352
INFO:root:FL Epoch: 129 Norm Difference for worker 1799 is 1.018682
INFO:root:FL Epoch: 129 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :230
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.823620
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 230 is 1.03979
INFO:root:FL Epoch: 129 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1000
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596344
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533714
INFO:root:FL Epoch: 129 Norm Difference for worker 1000 is 1.10956
INFO:root:FL Epoch: 129 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :270
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 270 is 1.020066
INFO:root:FL Epoch: 129 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1506
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722925
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542822
INFO:root:FL Epoch: 129 Norm Difference for worker 1506 is 0.978284
INFO:root:FL Epoch: 129 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :618
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439822
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398989
INFO:root:FL Epoch: 129 Norm Difference for worker 618 is 1.022828
INFO:root:FL Epoch: 129 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1579
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521903
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504900
INFO:root:FL Epoch: 129 Norm Difference for worker 1579 is 1.134519
INFO:root:FL Epoch: 129 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :118
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 118 is 1.088456
INFO:root:FL Epoch: 129 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :465
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640780
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533154
INFO:root:FL Epoch: 129 Norm Difference for worker 465 is 1.065197
INFO:root:FL Epoch: 129 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :776
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440950
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489943
INFO:root:FL Epoch: 129 Norm Difference for worker 776 is 1.11465
INFO:root:FL Epoch: 129 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.5982806612463558 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:2.009206016858419                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [590, 1314, 955, 901, 1608, 319, 1780, 560, 839, 725]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 130 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :590
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488352
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518544
INFO:root:FL Epoch: 130 Norm Difference for worker 590 is 1.151631
INFO:root:FL Epoch: 130 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1314
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747127
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563896
INFO:root:FL Epoch: 130 Norm Difference for worker 1314 is 1.095066
INFO:root:FL Epoch: 130 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :955
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480602
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529551
INFO:root:FL Epoch: 130 Norm Difference for worker 955 is 1.177691
INFO:root:FL Epoch: 130 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :901
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521202
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379261
INFO:root:FL Epoch: 130 Norm Difference for worker 901 is 1.077205
INFO:root:FL Epoch: 130 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1608
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737016
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661762
INFO:root:FL Epoch: 130 Norm Difference for worker 1608 is 1.171674
INFO:root:FL Epoch: 130 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :319
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447567
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 319 is 1.144149
INFO:root:FL Epoch: 130 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1780
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549984
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611601
INFO:root:FL Epoch: 130 Norm Difference for worker 1780 is 1.183051
INFO:root:FL Epoch: 130 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :560
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512100
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732457
INFO:root:FL Epoch: 130 Norm Difference for worker 560 is 1.185002
INFO:root:FL Epoch: 130 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :839
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449710
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320459
INFO:root:FL Epoch: 130 Norm Difference for worker 839 is 1.177304
INFO:root:FL Epoch: 130 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :725
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565545
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666977
INFO:root:FL Epoch: 130 Norm Difference for worker 725 is 1.190477
INFO:root:FL Epoch: 130 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 901
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.5738513680065379 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:1.9826574325561523                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [1068, 679, 1743, 523, 1507, 120, 1005, 1308, 557, 141]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :1068
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685800
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453427
INFO:root:FL Epoch: 131 Norm Difference for worker 1068 is 1.222479
INFO:root:FL Epoch: 131 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :679
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663507
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401410
INFO:root:FL Epoch: 131 Norm Difference for worker 679 is 1.175506
INFO:root:FL Epoch: 131 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1743
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527653
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553593
INFO:root:FL Epoch: 131 Norm Difference for worker 1743 is 1.241527
INFO:root:FL Epoch: 131 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :523
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570962
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461244
INFO:root:FL Epoch: 131 Norm Difference for worker 523 is 1.287035
INFO:root:FL Epoch: 131 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1507
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744304
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382822
INFO:root:FL Epoch: 131 Norm Difference for worker 1507 is 1.151734
INFO:root:FL Epoch: 131 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :120
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 120 is 1.208688
INFO:root:FL Epoch: 131 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1005
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592618
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.784244
INFO:root:FL Epoch: 131 Norm Difference for worker 1005 is 1.139504
INFO:root:FL Epoch: 131 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1308
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561926
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586758
INFO:root:FL Epoch: 131 Norm Difference for worker 1308 is 1.284797
INFO:root:FL Epoch: 131 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :557
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486626
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489680
INFO:root:FL Epoch: 131 Norm Difference for worker 557 is 1.124734
INFO:root:FL Epoch: 131 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :141
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.749438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 141 is 1.236696
INFO:root:FL Epoch: 131 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 679
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.5582207844537848 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:1.823574920495351                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [271, 1671, 401, 1337, 554, 1902, 1465, 1167, 527, 1036]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 132 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :271
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 271 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 271 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 271 is 1.145237
INFO:root:FL Epoch: 132 Done on worker:271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1671
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534499
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581305
INFO:root:FL Epoch: 132 Norm Difference for worker 1671 is 1.12182
INFO:root:FL Epoch: 132 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :401
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584659
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378624
INFO:root:FL Epoch: 132 Norm Difference for worker 401 is 1.114807
INFO:root:FL Epoch: 132 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1337
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422169
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358185
INFO:root:FL Epoch: 132 Norm Difference for worker 1337 is 1.026086
INFO:root:FL Epoch: 132 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :554
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499404
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414180
INFO:root:FL Epoch: 132 Norm Difference for worker 554 is 1.169699
INFO:root:FL Epoch: 132 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1902
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434834
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500089
INFO:root:FL Epoch: 132 Norm Difference for worker 1902 is 1.133526
INFO:root:FL Epoch: 132 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1465
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530392
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329931
INFO:root:FL Epoch: 132 Norm Difference for worker 1465 is 1.169265
INFO:root:FL Epoch: 132 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1167
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542514
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512713
INFO:root:FL Epoch: 132 Norm Difference for worker 1167 is 1.201241
INFO:root:FL Epoch: 132 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :527
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599187
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490747
INFO:root:FL Epoch: 132 Norm Difference for worker 527 is 1.187599
INFO:root:FL Epoch: 132 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1036
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412693
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522479
INFO:root:FL Epoch: 132 Norm Difference for worker 1036 is 1.198711
INFO:root:FL Epoch: 132 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.5544365171123954 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:1.7375829418500264                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1869, 1532, 1290, 1795, 1824, 76, 519, 1481, 249, 1206]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706032
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611021
INFO:root:FL Epoch: 133 Norm Difference for worker 1869 is 1.224579
INFO:root:FL Epoch: 133 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1532
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474152
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574354
INFO:root:FL Epoch: 133 Norm Difference for worker 1532 is 1.215565
INFO:root:FL Epoch: 133 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1290
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605323
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364481
INFO:root:FL Epoch: 133 Norm Difference for worker 1290 is 1.164564
INFO:root:FL Epoch: 133 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1795
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445965
INFO:root:Worker: 1795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641677
INFO:root:FL Epoch: 133 Norm Difference for worker 1795 is 1.173358
INFO:root:FL Epoch: 133 Done on worker:1795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1824
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701130
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534181
INFO:root:FL Epoch: 133 Norm Difference for worker 1824 is 1.306509
INFO:root:FL Epoch: 133 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :76
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 76 is 1.163799
INFO:root:FL Epoch: 133 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :519
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449622
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475002
INFO:root:FL Epoch: 133 Norm Difference for worker 519 is 1.213087
INFO:root:FL Epoch: 133 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1481
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620025
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460701
INFO:root:FL Epoch: 133 Norm Difference for worker 1481 is 1.199281
INFO:root:FL Epoch: 133 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :249
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 249 is 1.11365
INFO:root:FL Epoch: 133 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1206
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721079
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570433
INFO:root:FL Epoch: 133 Norm Difference for worker 1206 is 1.13966
INFO:root:FL Epoch: 133 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 249
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.5686778636539683 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:1.588679830233256                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [617, 1067, 503, 765, 25, 540, 825, 1501, 330, 333]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :617
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429651
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360357
INFO:root:FL Epoch: 134 Norm Difference for worker 617 is 1.269941
INFO:root:FL Epoch: 134 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1067
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552908
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530629
INFO:root:FL Epoch: 134 Norm Difference for worker 1067 is 1.127032
INFO:root:FL Epoch: 134 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :503
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476318
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346574
INFO:root:FL Epoch: 134 Norm Difference for worker 503 is 1.243443
INFO:root:FL Epoch: 134 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :765
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633469
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446810
INFO:root:FL Epoch: 134 Norm Difference for worker 765 is 1.150904
INFO:root:FL Epoch: 134 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :25
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.409973
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 25 is 1.10933
INFO:root:FL Epoch: 134 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :540
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838648
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458610
INFO:root:FL Epoch: 134 Norm Difference for worker 540 is 1.136502
INFO:root:FL Epoch: 134 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :825
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731087
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384141
INFO:root:FL Epoch: 134 Norm Difference for worker 825 is 1.122249
INFO:root:FL Epoch: 134 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1501
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694043
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484504
INFO:root:FL Epoch: 134 Norm Difference for worker 1501 is 1.195628
INFO:root:FL Epoch: 134 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :330
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.878507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612714
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 330 is 1.18573
INFO:root:FL Epoch: 134 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :333
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 333 is 1.211859
INFO:root:FL Epoch: 134 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 25
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.5753990744843203 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:1.6683717171351116                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1286, 1172, 1505, 950, 1463, 638, 1738, 1516, 206, 1092]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 135 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1286
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786355
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713166
INFO:root:FL Epoch: 135 Norm Difference for worker 1286 is 1.190453
INFO:root:FL Epoch: 135 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1172
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782187
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522566
INFO:root:FL Epoch: 135 Norm Difference for worker 1172 is 1.10213
INFO:root:FL Epoch: 135 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1505
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432225
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548520
INFO:root:FL Epoch: 135 Norm Difference for worker 1505 is 1.085923
INFO:root:FL Epoch: 135 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :950
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381562
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547178
INFO:root:FL Epoch: 135 Norm Difference for worker 950 is 1.061434
INFO:root:FL Epoch: 135 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1463
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691073
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502745
INFO:root:FL Epoch: 135 Norm Difference for worker 1463 is 1.067053
INFO:root:FL Epoch: 135 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :638
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449411
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426808
INFO:root:FL Epoch: 135 Norm Difference for worker 638 is 1.042432
INFO:root:FL Epoch: 135 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1738
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590062
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442695
INFO:root:FL Epoch: 135 Norm Difference for worker 1738 is 1.123211
INFO:root:FL Epoch: 135 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1516
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574629
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515282
INFO:root:FL Epoch: 135 Norm Difference for worker 1516 is 1.051335
INFO:root:FL Epoch: 135 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :206
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452930
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 206 is 1.051958
INFO:root:FL Epoch: 135 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1092
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683398
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604430
INFO:root:FL Epoch: 135 Norm Difference for worker 1092 is 1.058445
INFO:root:FL Epoch: 135 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 950
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.5670694463393268 and Test Accuracy:70.0 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:1.6365200877189636                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [940, 652, 1730, 731, 807, 168, 1020, 1662, 1498, 1223]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :940
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477549
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496310
INFO:root:FL Epoch: 136 Norm Difference for worker 940 is 1.029688
INFO:root:FL Epoch: 136 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :652
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596091
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436402
INFO:root:FL Epoch: 136 Norm Difference for worker 652 is 0.994318
INFO:root:FL Epoch: 136 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1730
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613657
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503455
INFO:root:FL Epoch: 136 Norm Difference for worker 1730 is 1.054076
INFO:root:FL Epoch: 136 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :731
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473487
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442072
INFO:root:FL Epoch: 136 Norm Difference for worker 731 is 1.026858
INFO:root:FL Epoch: 136 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :807
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593438
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496787
INFO:root:FL Epoch: 136 Norm Difference for worker 807 is 1.077139
INFO:root:FL Epoch: 136 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :168
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 168 is 1.031917
INFO:root:FL Epoch: 136 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1020
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438700
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522806
INFO:root:FL Epoch: 136 Norm Difference for worker 1020 is 1.01169
INFO:root:FL Epoch: 136 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1662
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690844
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438066
INFO:root:FL Epoch: 136 Norm Difference for worker 1662 is 1.011533
INFO:root:FL Epoch: 136 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1498
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693473
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477886
INFO:root:FL Epoch: 136 Norm Difference for worker 1498 is 0.969547
INFO:root:FL Epoch: 136 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1223
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569550
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494381
INFO:root:FL Epoch: 136 Norm Difference for worker 1223 is 1.013036
INFO:root:FL Epoch: 136 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1498
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.5491630066843594 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:1.6890371243158977                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [252, 1716, 1829, 797, 125, 1821, 1161, 710, 1154, 1202]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 137 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :252
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 252 is 1.112003
INFO:root:FL Epoch: 137 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1716
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611764
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736476
INFO:root:FL Epoch: 137 Norm Difference for worker 1716 is 1.063331
INFO:root:FL Epoch: 137 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1829
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729153
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623956
INFO:root:FL Epoch: 137 Norm Difference for worker 1829 is 1.035577
INFO:root:FL Epoch: 137 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :797
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728419
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684144
INFO:root:FL Epoch: 137 Norm Difference for worker 797 is 1.083827
INFO:root:FL Epoch: 137 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :125
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 125 is 1.100576
INFO:root:FL Epoch: 137 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1821
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473076
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548993
INFO:root:FL Epoch: 137 Norm Difference for worker 1821 is 1.130859
INFO:root:FL Epoch: 137 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1161
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821834
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542567
INFO:root:FL Epoch: 137 Norm Difference for worker 1161 is 1.142899
INFO:root:FL Epoch: 137 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :710
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570847
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373400
INFO:root:FL Epoch: 137 Norm Difference for worker 710 is 1.168899
INFO:root:FL Epoch: 137 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1154
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371569
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512291
INFO:root:FL Epoch: 137 Norm Difference for worker 1154 is 1.062649
INFO:root:FL Epoch: 137 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1202
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516974
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518400
INFO:root:FL Epoch: 137 Norm Difference for worker 1202 is 1.148658
INFO:root:FL Epoch: 137 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1829
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.5435798062997705 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:1.5183692574501038                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [765, 16, 253, 768, 652, 1774, 501, 1162, 676, 701]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :765
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699844
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670661
INFO:root:FL Epoch: 138 Norm Difference for worker 765 is 1.094526
INFO:root:FL Epoch: 138 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :16
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 16 is 1.143257
INFO:root:FL Epoch: 138 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :253
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569310
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 253 is 1.127163
INFO:root:FL Epoch: 138 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :768
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569706
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722935
INFO:root:FL Epoch: 138 Norm Difference for worker 768 is 1.065222
INFO:root:FL Epoch: 138 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :652
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476900
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337691
INFO:root:FL Epoch: 138 Norm Difference for worker 652 is 1.11695
INFO:root:FL Epoch: 138 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1774
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622490
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476321
INFO:root:FL Epoch: 138 Norm Difference for worker 1774 is 1.1137
INFO:root:FL Epoch: 138 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :501
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629853
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627565
INFO:root:FL Epoch: 138 Norm Difference for worker 501 is 1.147263
INFO:root:FL Epoch: 138 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1162
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657377
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685638
INFO:root:FL Epoch: 138 Norm Difference for worker 1162 is 1.086056
INFO:root:FL Epoch: 138 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :676
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683362
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435671
INFO:root:FL Epoch: 138 Norm Difference for worker 676 is 1.148904
INFO:root:FL Epoch: 138 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :701
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677700
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493547
INFO:root:FL Epoch: 138 Norm Difference for worker 701 is 1.14092
INFO:root:FL Epoch: 138 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 768
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.5476796013467452 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:1.5501624743143718                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [1164, 379, 1010, 1604, 570, 1169, 1120, 261, 62, 37]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 139 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :1164
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668146
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571575
INFO:root:FL Epoch: 139 Norm Difference for worker 1164 is 1.12759
INFO:root:FL Epoch: 139 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :379
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423670
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512349
INFO:root:FL Epoch: 139 Norm Difference for worker 379 is 1.119162
INFO:root:FL Epoch: 139 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1010
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582168
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536339
INFO:root:FL Epoch: 139 Norm Difference for worker 1010 is 1.070275
INFO:root:FL Epoch: 139 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1604
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570008
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517071
INFO:root:FL Epoch: 139 Norm Difference for worker 1604 is 1.089324
INFO:root:FL Epoch: 139 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :570
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736828
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565677
INFO:root:FL Epoch: 139 Norm Difference for worker 570 is 1.011759
INFO:root:FL Epoch: 139 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1169
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506916
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386226
INFO:root:FL Epoch: 139 Norm Difference for worker 1169 is 1.098642
INFO:root:FL Epoch: 139 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1120
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652230
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499287
INFO:root:FL Epoch: 139 Norm Difference for worker 1120 is 1.084548
INFO:root:FL Epoch: 139 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :261
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571510
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 261 is 1.12126
INFO:root:FL Epoch: 139 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :62
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 62 is 1.097618
INFO:root:FL Epoch: 139 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :37
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 37 is 1.087045
INFO:root:FL Epoch: 139 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.5368700167712044 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:1.659471293290456                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [151, 1683, 1819, 259, 1292, 1942, 420, 1587, 715, 1803]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :151
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.325865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 151 is 1.111622
INFO:root:FL Epoch: 140 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1683
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455413
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574204
INFO:root:FL Epoch: 140 Norm Difference for worker 1683 is 1.088392
INFO:root:FL Epoch: 140 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1819
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805011
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340624
INFO:root:FL Epoch: 140 Norm Difference for worker 1819 is 1.115459
INFO:root:FL Epoch: 140 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :259
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 259 is 1.090881
INFO:root:FL Epoch: 140 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1292
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606361
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443007
INFO:root:FL Epoch: 140 Norm Difference for worker 1292 is 1.151474
INFO:root:FL Epoch: 140 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1942
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573190
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414615
INFO:root:FL Epoch: 140 Norm Difference for worker 1942 is 1.119351
INFO:root:FL Epoch: 140 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :420
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453836
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660664
INFO:root:FL Epoch: 140 Norm Difference for worker 420 is 1.103762
INFO:root:FL Epoch: 140 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1587
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642989
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617001
INFO:root:FL Epoch: 140 Norm Difference for worker 1587 is 1.164362
INFO:root:FL Epoch: 140 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :715
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677399
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604514
INFO:root:FL Epoch: 140 Norm Difference for worker 715 is 1.093889
INFO:root:FL Epoch: 140 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1803
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781256
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615566
INFO:root:FL Epoch: 140 Norm Difference for worker 1803 is 1.19567
INFO:root:FL Epoch: 140 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 420
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.5599865124506109 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:1.5753362774848938                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [565, 1393, 584, 1848, 953, 1682, 367, 1817, 1518, 303]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :565
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644333
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486387
INFO:root:FL Epoch: 141 Norm Difference for worker 565 is 0.988273
INFO:root:FL Epoch: 141 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1393
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733258
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530850
INFO:root:FL Epoch: 141 Norm Difference for worker 1393 is 0.98874
INFO:root:FL Epoch: 141 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :584
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620576
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542991
INFO:root:FL Epoch: 141 Norm Difference for worker 584 is 0.974304
INFO:root:FL Epoch: 141 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1848
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569769
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618007
INFO:root:FL Epoch: 141 Norm Difference for worker 1848 is 0.980761
INFO:root:FL Epoch: 141 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :953
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710197
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537172
INFO:root:FL Epoch: 141 Norm Difference for worker 953 is 1.054516
INFO:root:FL Epoch: 141 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1682
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528709
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499074
INFO:root:FL Epoch: 141 Norm Difference for worker 1682 is 0.912677
INFO:root:FL Epoch: 141 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :367
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489384
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544431
INFO:root:FL Epoch: 141 Norm Difference for worker 367 is 0.932384
INFO:root:FL Epoch: 141 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1817
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403962
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645739
INFO:root:FL Epoch: 141 Norm Difference for worker 1817 is 0.953126
INFO:root:FL Epoch: 141 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1518
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721932
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486066
INFO:root:FL Epoch: 141 Norm Difference for worker 1518 is 0.957049
INFO:root:FL Epoch: 141 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :303
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452610
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 141 Norm Difference for worker 303 is 0.948213
INFO:root:FL Epoch: 141 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1682
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 141 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 141 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.5311621620374567 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:1.7065258423487346                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1331, 229, 369, 683, 258, 1115, 1930, 567, 1016, 1297]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 142 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1331
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1331 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564994
INFO:root:Worker: 1331 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688495
INFO:root:FL Epoch: 142 Norm Difference for worker 1331 is 1.115595
INFO:root:FL Epoch: 142 Done on worker:1331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :229
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 229 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 229 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 229 is 1.063184
INFO:root:FL Epoch: 142 Done on worker:229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :369
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751018
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420853
INFO:root:FL Epoch: 142 Norm Difference for worker 369 is 1.076346
INFO:root:FL Epoch: 142 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :683
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628869
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348160
INFO:root:FL Epoch: 142 Norm Difference for worker 683 is 1.027464
INFO:root:FL Epoch: 142 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :258
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 258 is 1.073476
INFO:root:FL Epoch: 142 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1115
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437456
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410101
INFO:root:FL Epoch: 142 Norm Difference for worker 1115 is 1.091433
INFO:root:FL Epoch: 142 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1930
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612924
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555709
INFO:root:FL Epoch: 142 Norm Difference for worker 1930 is 1.092202
INFO:root:FL Epoch: 142 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :567
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432250
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662370
INFO:root:FL Epoch: 142 Norm Difference for worker 567 is 0.993802
INFO:root:FL Epoch: 142 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1016
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652464
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643851
INFO:root:FL Epoch: 142 Norm Difference for worker 1016 is 1.095898
INFO:root:FL Epoch: 142 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1297
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690312
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666744
INFO:root:FL Epoch: 142 Norm Difference for worker 1297 is 1.066902
INFO:root:FL Epoch: 142 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 567
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.5340228133341846 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:1.849413812160492                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [786, 680, 1145, 837, 1885, 1204, 1838, 550, 1137, 558]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :786
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479804
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431681
INFO:root:FL Epoch: 143 Norm Difference for worker 786 is 1.027634
INFO:root:FL Epoch: 143 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :680
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552633
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562395
INFO:root:FL Epoch: 143 Norm Difference for worker 680 is 1.022629
INFO:root:FL Epoch: 143 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1145
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801413
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585988
INFO:root:FL Epoch: 143 Norm Difference for worker 1145 is 1.089862
INFO:root:FL Epoch: 143 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :837
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513111
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688777
INFO:root:FL Epoch: 143 Norm Difference for worker 837 is 1.00731
INFO:root:FL Epoch: 143 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1885
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637963
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601065
INFO:root:FL Epoch: 143 Norm Difference for worker 1885 is 0.955877
INFO:root:FL Epoch: 143 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1204
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482847
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340056
INFO:root:FL Epoch: 143 Norm Difference for worker 1204 is 1.110575
INFO:root:FL Epoch: 143 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1838
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743950
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350193
INFO:root:FL Epoch: 143 Norm Difference for worker 1838 is 0.95741
INFO:root:FL Epoch: 143 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :550
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380188
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539350
INFO:root:FL Epoch: 143 Norm Difference for worker 550 is 1.108289
INFO:root:FL Epoch: 143 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1137
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445358
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571437
INFO:root:FL Epoch: 143 Norm Difference for worker 1137 is 1.067231
INFO:root:FL Epoch: 143 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :558
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512812
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643633
INFO:root:FL Epoch: 143 Norm Difference for worker 558 is 1.116385
INFO:root:FL Epoch: 143 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.5334736582110909 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:1.790318489074707                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1323, 1097, 68, 826, 1634, 505, 140, 1271, 388, 1401]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1323
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665830
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516174
INFO:root:FL Epoch: 144 Norm Difference for worker 1323 is 1.042773
INFO:root:FL Epoch: 144 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1097
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446303
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587618
INFO:root:FL Epoch: 144 Norm Difference for worker 1097 is 1.013307
INFO:root:FL Epoch: 144 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :68
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 68 is 0.99492
INFO:root:FL Epoch: 144 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :826
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578330
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580992
INFO:root:FL Epoch: 144 Norm Difference for worker 826 is 1.032537
INFO:root:FL Epoch: 144 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1634
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523837
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628960
INFO:root:FL Epoch: 144 Norm Difference for worker 1634 is 1.04215
INFO:root:FL Epoch: 144 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :505
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595140
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512808
INFO:root:FL Epoch: 144 Norm Difference for worker 505 is 1.020252
INFO:root:FL Epoch: 144 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :140
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 140 is 0.996801
INFO:root:FL Epoch: 144 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1271
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458828
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410991
INFO:root:FL Epoch: 144 Norm Difference for worker 1271 is 1.025862
INFO:root:FL Epoch: 144 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :388
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556639
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623884
INFO:root:FL Epoch: 144 Norm Difference for worker 388 is 1.045075
INFO:root:FL Epoch: 144 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1401
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644221
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454659
INFO:root:FL Epoch: 144 Norm Difference for worker 1401 is 1.006267
INFO:root:FL Epoch: 144 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 68
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.5508281062631046 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:2.224915703137716                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [1438, 1272, 1019, 478, 1776, 1144, 774, 1482, 100, 1399]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :1438
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594048
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558958
INFO:root:FL Epoch: 145 Norm Difference for worker 1438 is 1.163358
INFO:root:FL Epoch: 145 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1272
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263244
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357374
INFO:root:FL Epoch: 145 Norm Difference for worker 1272 is 1.125731
INFO:root:FL Epoch: 145 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1019
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700827
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599900
INFO:root:FL Epoch: 145 Norm Difference for worker 1019 is 1.128398
INFO:root:FL Epoch: 145 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483358
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587053
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 1.187435
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1776
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551283
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685280
INFO:root:FL Epoch: 145 Norm Difference for worker 1776 is 1.128562
INFO:root:FL Epoch: 145 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1144
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382320
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488812
INFO:root:FL Epoch: 145 Norm Difference for worker 1144 is 1.122084
INFO:root:FL Epoch: 145 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :774
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494505
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436384
INFO:root:FL Epoch: 145 Norm Difference for worker 774 is 1.099044
INFO:root:FL Epoch: 145 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1482
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616946
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496446
INFO:root:FL Epoch: 145 Norm Difference for worker 1482 is 1.097124
INFO:root:FL Epoch: 145 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :100
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 100 is 1.173198
INFO:root:FL Epoch: 145 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1399
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448747
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521215
INFO:root:FL Epoch: 145 Norm Difference for worker 1399 is 1.046578
INFO:root:FL Epoch: 145 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1399
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.5564157822552849 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:2.2509542306264243                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [1018, 1260, 1503, 896, 1770, 1316, 624, 1361, 987, 1204]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :1018
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757396
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548356
INFO:root:FL Epoch: 146 Norm Difference for worker 1018 is 1.207879
INFO:root:FL Epoch: 146 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1260
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653580
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480404
INFO:root:FL Epoch: 146 Norm Difference for worker 1260 is 1.161866
INFO:root:FL Epoch: 146 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1503
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574704
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545837
INFO:root:FL Epoch: 146 Norm Difference for worker 1503 is 1.168267
INFO:root:FL Epoch: 146 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :896
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395063
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559783
INFO:root:FL Epoch: 146 Norm Difference for worker 896 is 1.153882
INFO:root:FL Epoch: 146 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1770
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559678
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420005
INFO:root:FL Epoch: 146 Norm Difference for worker 1770 is 1.192381
INFO:root:FL Epoch: 146 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1316
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796423
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394879
INFO:root:FL Epoch: 146 Norm Difference for worker 1316 is 1.09112
INFO:root:FL Epoch: 146 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :624
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471061
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347369
INFO:root:FL Epoch: 146 Norm Difference for worker 624 is 1.127008
INFO:root:FL Epoch: 146 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1361
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452194
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570040
INFO:root:FL Epoch: 146 Norm Difference for worker 1361 is 1.182022
INFO:root:FL Epoch: 146 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :987
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391322
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354615
INFO:root:FL Epoch: 146 Norm Difference for worker 987 is 1.215236
INFO:root:FL Epoch: 146 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1204
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626651
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338647
INFO:root:FL Epoch: 146 Norm Difference for worker 1204 is 1.23474
INFO:root:FL Epoch: 146 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.5282140251468209 and Test Accuracy:75.0 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:1.5642672379811604                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1417, 860, 888, 383, 13, 593, 1541, 1203, 438, 189]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1417
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757165
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374759
INFO:root:FL Epoch: 147 Norm Difference for worker 1417 is 0.934129
INFO:root:FL Epoch: 147 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :860
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520821
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542952
INFO:root:FL Epoch: 147 Norm Difference for worker 860 is 1.048546
INFO:root:FL Epoch: 147 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :888
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488286
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585394
INFO:root:FL Epoch: 147 Norm Difference for worker 888 is 1.091084
INFO:root:FL Epoch: 147 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :383
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602849
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457897
INFO:root:FL Epoch: 147 Norm Difference for worker 383 is 1.017042
INFO:root:FL Epoch: 147 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :13
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.815822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 13 is 1.029482
INFO:root:FL Epoch: 147 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :593
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604191
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597694
INFO:root:FL Epoch: 147 Norm Difference for worker 593 is 1.080252
INFO:root:FL Epoch: 147 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1541
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581043
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434595
INFO:root:FL Epoch: 147 Norm Difference for worker 1541 is 0.987647
INFO:root:FL Epoch: 147 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1203
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628581
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613603
INFO:root:FL Epoch: 147 Norm Difference for worker 1203 is 1.076589
INFO:root:FL Epoch: 147 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :438
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536849
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689017
INFO:root:FL Epoch: 147 Norm Difference for worker 438 is 0.976648
INFO:root:FL Epoch: 147 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :189
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.715207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 189 is 1.022043
INFO:root:FL Epoch: 147 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1417
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.5423702089225545 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:1.9235319296518962                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [1416, 1268, 1530, 453, 1904, 1454, 1132, 1513, 1816, 1502]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :1416
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460905
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398228
INFO:root:FL Epoch: 148 Norm Difference for worker 1416 is 1.153322
INFO:root:FL Epoch: 148 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1268
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382928
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380074
INFO:root:FL Epoch: 148 Norm Difference for worker 1268 is 1.071487
INFO:root:FL Epoch: 148 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1530
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625546
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369754
INFO:root:FL Epoch: 148 Norm Difference for worker 1530 is 1.073977
INFO:root:FL Epoch: 148 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :453
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487732
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505567
INFO:root:FL Epoch: 148 Norm Difference for worker 453 is 1.05796
INFO:root:FL Epoch: 148 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1904
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744567
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446212
INFO:root:FL Epoch: 148 Norm Difference for worker 1904 is 1.118546
INFO:root:FL Epoch: 148 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1454
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410058
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485353
INFO:root:FL Epoch: 148 Norm Difference for worker 1454 is 0.998594
INFO:root:FL Epoch: 148 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1132
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731785
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352692
INFO:root:FL Epoch: 148 Norm Difference for worker 1132 is 1.075346
INFO:root:FL Epoch: 148 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1513
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515727
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496439
INFO:root:FL Epoch: 148 Norm Difference for worker 1513 is 1.093859
INFO:root:FL Epoch: 148 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1816
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837089
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505482
INFO:root:FL Epoch: 148 Norm Difference for worker 1816 is 1.080133
INFO:root:FL Epoch: 148 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1502
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537150
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633287
INFO:root:FL Epoch: 148 Norm Difference for worker 1502 is 1.083745
INFO:root:FL Epoch: 148 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1454
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.5437317928847145 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:1.900018036365509                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [1379, 97, 1684, 257, 929, 1055, 449, 144, 684, 403]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 149 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :1379
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547167
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665168
INFO:root:FL Epoch: 149 Norm Difference for worker 1379 is 1.067287
INFO:root:FL Epoch: 149 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :97
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 97 is 1.179179
INFO:root:FL Epoch: 149 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1684
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673163
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528757
INFO:root:FL Epoch: 149 Norm Difference for worker 1684 is 1.119691
INFO:root:FL Epoch: 149 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :257
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.821738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 257 is 1.110517
INFO:root:FL Epoch: 149 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :929
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612625
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456912
INFO:root:FL Epoch: 149 Norm Difference for worker 929 is 1.032502
INFO:root:FL Epoch: 149 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1055
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586293
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646592
INFO:root:FL Epoch: 149 Norm Difference for worker 1055 is 1.060197
INFO:root:FL Epoch: 149 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :449
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776234
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474561
INFO:root:FL Epoch: 149 Norm Difference for worker 449 is 1.057244
INFO:root:FL Epoch: 149 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :144
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 144 is 1.086495
INFO:root:FL Epoch: 149 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :684
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387912
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495943
INFO:root:FL Epoch: 149 Norm Difference for worker 684 is 1.097449
INFO:root:FL Epoch: 149 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :403
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757864
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557696
INFO:root:FL Epoch: 149 Norm Difference for worker 403 is 1.18261
INFO:root:FL Epoch: 149 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 929
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.5365580022335052 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:1.5639891227086384                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [384, 246, 593, 564, 102, 1823, 1063, 1336, 1557, 660]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :384
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428454
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507929
INFO:root:FL Epoch: 150 Norm Difference for worker 384 is 0.989225
INFO:root:FL Epoch: 150 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :246
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 246 is 1.008513
INFO:root:FL Epoch: 150 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :593
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614260
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429326
INFO:root:FL Epoch: 150 Norm Difference for worker 593 is 1.024853
INFO:root:FL Epoch: 150 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :564
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645527
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404455
INFO:root:FL Epoch: 150 Norm Difference for worker 564 is 1.028245
INFO:root:FL Epoch: 150 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :102
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 102 is 1.012649
INFO:root:FL Epoch: 150 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1823
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561451
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526712
INFO:root:FL Epoch: 150 Norm Difference for worker 1823 is 1.089211
INFO:root:FL Epoch: 150 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1063
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412707
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479387
INFO:root:FL Epoch: 150 Norm Difference for worker 1063 is 0.976072
INFO:root:FL Epoch: 150 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1336
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624161
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582991
INFO:root:FL Epoch: 150 Norm Difference for worker 1336 is 0.990891
INFO:root:FL Epoch: 150 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1557
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493329
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460556
INFO:root:FL Epoch: 150 Norm Difference for worker 1557 is 0.967776
INFO:root:FL Epoch: 150 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :660
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576693
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554611
INFO:root:FL Epoch: 150 Norm Difference for worker 660 is 0.974088
INFO:root:FL Epoch: 150 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.5351941673194661 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:2.004197120666504                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [941, 145, 1145, 881, 1214, 1565, 892, 286, 236, 426]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 151 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :941
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499801
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576101
INFO:root:FL Epoch: 151 Norm Difference for worker 941 is 1.132176
INFO:root:FL Epoch: 151 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :145
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378525
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 145 is 1.040385
INFO:root:FL Epoch: 151 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1145
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469013
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365928
INFO:root:FL Epoch: 151 Norm Difference for worker 1145 is 1.283286
INFO:root:FL Epoch: 151 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :881
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508203
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423789
INFO:root:FL Epoch: 151 Norm Difference for worker 881 is 1.152128
INFO:root:FL Epoch: 151 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1214
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520225
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461326
INFO:root:FL Epoch: 151 Norm Difference for worker 1214 is 1.197055
INFO:root:FL Epoch: 151 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1565
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708103
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654863
INFO:root:FL Epoch: 151 Norm Difference for worker 1565 is 1.243043
INFO:root:FL Epoch: 151 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :892
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463257
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416974
INFO:root:FL Epoch: 151 Norm Difference for worker 892 is 1.12133
INFO:root:FL Epoch: 151 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :286
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 286 is 1.137629
INFO:root:FL Epoch: 151 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :236
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.768664
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 236 is 1.227351
INFO:root:FL Epoch: 151 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :426
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497133
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593026
INFO:root:FL Epoch: 151 Norm Difference for worker 426 is 1.116429
INFO:root:FL Epoch: 151 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.5326421646510854 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:2.085397561391195                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1192, 1759, 272, 832, 1610, 66, 581, 1143, 679, 62]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1192
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676018
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414957
INFO:root:FL Epoch: 152 Norm Difference for worker 1192 is 1.2285
INFO:root:FL Epoch: 152 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1759
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483885
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503578
INFO:root:FL Epoch: 152 Norm Difference for worker 1759 is 1.226438
INFO:root:FL Epoch: 152 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :272
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 272 is 1.20236
INFO:root:FL Epoch: 152 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :832
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564760
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618816
INFO:root:FL Epoch: 152 Norm Difference for worker 832 is 1.28273
INFO:root:FL Epoch: 152 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1610
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731759
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574638
INFO:root:FL Epoch: 152 Norm Difference for worker 1610 is 1.238447
INFO:root:FL Epoch: 152 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :66
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 66 is 1.27252
INFO:root:FL Epoch: 152 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :581
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800109
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635884
INFO:root:FL Epoch: 152 Norm Difference for worker 581 is 1.407789
INFO:root:FL Epoch: 152 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1143
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551123
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376555
INFO:root:FL Epoch: 152 Norm Difference for worker 1143 is 1.240612
INFO:root:FL Epoch: 152 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :679
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328873
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327156
INFO:root:FL Epoch: 152 Norm Difference for worker 679 is 1.14906
INFO:root:FL Epoch: 152 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :62
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 62 is 1.174819
INFO:root:FL Epoch: 152 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.5581521006191478 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:2.031243840853373                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [984, 33, 826, 1313, 1293, 1257, 1561, 1073, 1390, 208]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 153 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :984
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829256
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582238
INFO:root:FL Epoch: 153 Norm Difference for worker 984 is 1.109345
INFO:root:FL Epoch: 153 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :33
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358627
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 33 is 1.147963
INFO:root:FL Epoch: 153 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :826
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571094
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440878
INFO:root:FL Epoch: 153 Norm Difference for worker 826 is 1.165484
INFO:root:FL Epoch: 153 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1313
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459482
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461571
INFO:root:FL Epoch: 153 Norm Difference for worker 1313 is 1.172053
INFO:root:FL Epoch: 153 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1293
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615329
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497704
INFO:root:FL Epoch: 153 Norm Difference for worker 1293 is 1.153412
INFO:root:FL Epoch: 153 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1257
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736451
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526627
INFO:root:FL Epoch: 153 Norm Difference for worker 1257 is 1.15973
INFO:root:FL Epoch: 153 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1561
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834987
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578376
INFO:root:FL Epoch: 153 Norm Difference for worker 1561 is 1.187519
INFO:root:FL Epoch: 153 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1073
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598316
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490717
INFO:root:FL Epoch: 153 Norm Difference for worker 1073 is 1.155922
INFO:root:FL Epoch: 153 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1390
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429119
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573242
INFO:root:FL Epoch: 153 Norm Difference for worker 1390 is 1.187476
INFO:root:FL Epoch: 153 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :208
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617679
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 208 is 1.171157
INFO:root:FL Epoch: 153 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 984
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.5377084279761595 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:1.9512983957926433                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [841, 1420, 1083, 1482, 83, 42, 501, 61, 902, 356]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 201 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :841
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520709
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379950
INFO:root:FL Epoch: 154 Norm Difference for worker 841 is 1.120203
INFO:root:FL Epoch: 154 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1420
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817946
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613402
INFO:root:FL Epoch: 154 Norm Difference for worker 1420 is 1.172114
INFO:root:FL Epoch: 154 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1083
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628617
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713647
INFO:root:FL Epoch: 154 Norm Difference for worker 1083 is 1.171628
INFO:root:FL Epoch: 154 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1482
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564781
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445746
INFO:root:FL Epoch: 154 Norm Difference for worker 1482 is 1.137826
INFO:root:FL Epoch: 154 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :83
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585096
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 83 is 1.090168
INFO:root:FL Epoch: 154 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :42
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.400861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 42 is 1.100485
INFO:root:FL Epoch: 154 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :501
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499416
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527762
INFO:root:FL Epoch: 154 Norm Difference for worker 501 is 1.160897
INFO:root:FL Epoch: 154 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :61
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 61 is 1.162113
INFO:root:FL Epoch: 154 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :902
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589966
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582891
INFO:root:FL Epoch: 154 Norm Difference for worker 902 is 1.17953
INFO:root:FL Epoch: 154 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :356
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612707
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329972
INFO:root:FL Epoch: 154 Norm Difference for worker 356 is 1.136284
INFO:root:FL Epoch: 154 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 83
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.5444979439763462 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:1.6171262661616008                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1695, 515, 484, 1559, 1745, 9, 1831, 1108, 558, 247]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 155 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1695
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473345
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597757
INFO:root:FL Epoch: 155 Norm Difference for worker 1695 is 1.039293
INFO:root:FL Epoch: 155 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :515
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529775
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394103
INFO:root:FL Epoch: 155 Norm Difference for worker 515 is 1.064113
INFO:root:FL Epoch: 155 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :484
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633706
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545144
INFO:root:FL Epoch: 155 Norm Difference for worker 484 is 1.06553
INFO:root:FL Epoch: 155 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1559
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604466
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503306
INFO:root:FL Epoch: 155 Norm Difference for worker 1559 is 1.027945
INFO:root:FL Epoch: 155 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1745
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547417
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416111
INFO:root:FL Epoch: 155 Norm Difference for worker 1745 is 1.055064
INFO:root:FL Epoch: 155 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :9
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.744878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 9 is 1.045237
INFO:root:FL Epoch: 155 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1831
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671173
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475444
INFO:root:FL Epoch: 155 Norm Difference for worker 1831 is 1.061188
INFO:root:FL Epoch: 155 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1108
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609003
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457225
INFO:root:FL Epoch: 155 Norm Difference for worker 1108 is 1.088715
INFO:root:FL Epoch: 155 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :558
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590477
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501296
INFO:root:FL Epoch: 155 Norm Difference for worker 558 is 1.015427
INFO:root:FL Epoch: 155 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :247
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455869
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 247 is 1.10818
INFO:root:FL Epoch: 155 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1559
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.5406123469857609 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:1.4582727154095967                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [152, 1563, 1100, 1696, 308, 1105, 77, 271, 131, 19]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.1001994 0.0997009 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 156 Num points on workers: [201 200 200 200 201 200 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :152
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 152 is 0.978936
INFO:root:FL Epoch: 156 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1563
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603924
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556953
INFO:root:FL Epoch: 156 Norm Difference for worker 1563 is 0.985335
INFO:root:FL Epoch: 156 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1100
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518878
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515539
INFO:root:FL Epoch: 156 Norm Difference for worker 1100 is 0.958877
INFO:root:FL Epoch: 156 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1696
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612042
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478505
INFO:root:FL Epoch: 156 Norm Difference for worker 1696 is 1.049205
INFO:root:FL Epoch: 156 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :308
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 308 is 0.969843
INFO:root:FL Epoch: 156 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1105
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804658
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618047
INFO:root:FL Epoch: 156 Norm Difference for worker 1105 is 0.994484
INFO:root:FL Epoch: 156 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :77
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 77 is 1.0137
INFO:root:FL Epoch: 156 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :271
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 271 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 271 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428074
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 271 is 0.967655
INFO:root:FL Epoch: 156 Done on worker:271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :131
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 131 is 0.978511
INFO:root:FL Epoch: 156 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :19
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 19 is 0.963337
INFO:root:FL Epoch: 156 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1100
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.5432187196086434 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:1.8101005752881367                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [384, 1637, 834, 1348, 925, 1181, 1922, 86, 1796, 708]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :384
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508252
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450990
INFO:root:FL Epoch: 157 Norm Difference for worker 384 is 1.034293
INFO:root:FL Epoch: 157 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1637
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779837
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570407
INFO:root:FL Epoch: 157 Norm Difference for worker 1637 is 1.074363
INFO:root:FL Epoch: 157 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :834
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637679
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549590
INFO:root:FL Epoch: 157 Norm Difference for worker 834 is 1.060962
INFO:root:FL Epoch: 157 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1348
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476328
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488287
INFO:root:FL Epoch: 157 Norm Difference for worker 1348 is 1.052924
INFO:root:FL Epoch: 157 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :925
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379349
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389671
INFO:root:FL Epoch: 157 Norm Difference for worker 925 is 1.020724
INFO:root:FL Epoch: 157 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1181
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603711
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410910
INFO:root:FL Epoch: 157 Norm Difference for worker 1181 is 1.108501
INFO:root:FL Epoch: 157 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1922
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661033
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572829
INFO:root:FL Epoch: 157 Norm Difference for worker 1922 is 1.071676
INFO:root:FL Epoch: 157 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :86
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530639
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 86 is 1.031415
INFO:root:FL Epoch: 157 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1796
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711091
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542022
INFO:root:FL Epoch: 157 Norm Difference for worker 1796 is 1.088533
INFO:root:FL Epoch: 157 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :708
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668946
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594489
INFO:root:FL Epoch: 157 Norm Difference for worker 708 is 1.101608
INFO:root:FL Epoch: 157 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.5384086475652807 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:2.032496372858683                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [1899, 1131, 1360, 160, 703, 494, 202, 1831, 1585, 75]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 158 Num points on workers: [200 200 200 201 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :1899
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548628
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480749
INFO:root:FL Epoch: 158 Norm Difference for worker 1899 is 1.100285
INFO:root:FL Epoch: 158 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1131
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554124
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556750
INFO:root:FL Epoch: 158 Norm Difference for worker 1131 is 1.188671
INFO:root:FL Epoch: 158 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1360
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659375
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515807
INFO:root:FL Epoch: 158 Norm Difference for worker 1360 is 1.151109
INFO:root:FL Epoch: 158 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :160
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 160 is 1.264408
INFO:root:FL Epoch: 158 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :703
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556052
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286673
INFO:root:FL Epoch: 158 Norm Difference for worker 703 is 1.154508
INFO:root:FL Epoch: 158 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :494
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379120
INFO:root:Worker: 494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405135
INFO:root:FL Epoch: 158 Norm Difference for worker 494 is 1.164989
INFO:root:FL Epoch: 158 Done on worker:494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :202
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 202 is 1.152495
INFO:root:FL Epoch: 158 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1831
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619190
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499555
INFO:root:FL Epoch: 158 Norm Difference for worker 1831 is 1.133764
INFO:root:FL Epoch: 158 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1585
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843840
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614792
INFO:root:FL Epoch: 158 Norm Difference for worker 1585 is 1.179152
INFO:root:FL Epoch: 158 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :75
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 75 is 1.164108
INFO:root:FL Epoch: 158 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1899
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.5299522333285388 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:2.211114486058553                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [595, 800, 720, 1054, 859, 297, 1010, 1453, 893, 444]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :595
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461631
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623885
INFO:root:FL Epoch: 159 Norm Difference for worker 595 is 1.246293
INFO:root:FL Epoch: 159 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :800
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454004
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517098
INFO:root:FL Epoch: 159 Norm Difference for worker 800 is 1.275336
INFO:root:FL Epoch: 159 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :720
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572953
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475592
INFO:root:FL Epoch: 159 Norm Difference for worker 720 is 1.21425
INFO:root:FL Epoch: 159 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1054
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338181
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440785
INFO:root:FL Epoch: 159 Norm Difference for worker 1054 is 1.296236
INFO:root:FL Epoch: 159 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :859
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769579
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404204
INFO:root:FL Epoch: 159 Norm Difference for worker 859 is 1.309119
INFO:root:FL Epoch: 159 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :297
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 297 is 1.21938
INFO:root:FL Epoch: 159 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1010
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505119
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493469
INFO:root:FL Epoch: 159 Norm Difference for worker 1010 is 1.233005
INFO:root:FL Epoch: 159 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1453
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724228
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470702
INFO:root:FL Epoch: 159 Norm Difference for worker 1453 is 1.261583
INFO:root:FL Epoch: 159 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :893
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314682
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294932
INFO:root:FL Epoch: 159 Norm Difference for worker 893 is 1.320732
INFO:root:FL Epoch: 159 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :444
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629501
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397237
INFO:root:FL Epoch: 159 Norm Difference for worker 444 is 1.254528
INFO:root:FL Epoch: 159 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1010
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.5577771295519436 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:2.294436057408651                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [330, 1505, 631, 1884, 1049, 157, 1205, 1014, 710, 1931]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 160 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :330
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.894191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 330 is 1.27014
INFO:root:FL Epoch: 160 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1505
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601197
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523502
INFO:root:FL Epoch: 160 Norm Difference for worker 1505 is 1.318177
INFO:root:FL Epoch: 160 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :631
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367260
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469642
INFO:root:FL Epoch: 160 Norm Difference for worker 631 is 1.251592
INFO:root:FL Epoch: 160 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1884
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471188
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270603
INFO:root:FL Epoch: 160 Norm Difference for worker 1884 is 1.266942
INFO:root:FL Epoch: 160 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1049
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738506
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230873
INFO:root:FL Epoch: 160 Norm Difference for worker 1049 is 1.215348
INFO:root:FL Epoch: 160 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :157
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 157 is 1.333393
INFO:root:FL Epoch: 160 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1205
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549594
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481558
INFO:root:FL Epoch: 160 Norm Difference for worker 1205 is 1.261434
INFO:root:FL Epoch: 160 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1014
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811025
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446584
INFO:root:FL Epoch: 160 Norm Difference for worker 1014 is 1.356013
INFO:root:FL Epoch: 160 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :710
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762097
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458418
INFO:root:FL Epoch: 160 Norm Difference for worker 710 is 1.383382
INFO:root:FL Epoch: 160 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1931
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511411
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722537
INFO:root:FL Epoch: 160 Norm Difference for worker 1931 is 1.389407
INFO:root:FL Epoch: 160 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.5509575395023122 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:2.010400334993998                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [1070, 1702, 1778, 175, 1075, 1685, 1732, 1261, 1766, 249]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :1070
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739153
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354233
INFO:root:FL Epoch: 161 Norm Difference for worker 1070 is 1.117025
INFO:root:FL Epoch: 161 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1702
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658703
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566730
INFO:root:FL Epoch: 161 Norm Difference for worker 1702 is 1.119171
INFO:root:FL Epoch: 161 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1778
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648095
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571381
INFO:root:FL Epoch: 161 Norm Difference for worker 1778 is 1.153004
INFO:root:FL Epoch: 161 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :175
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325409
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 175 is 1.108681
INFO:root:FL Epoch: 161 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1075
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635744
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523076
INFO:root:FL Epoch: 161 Norm Difference for worker 1075 is 1.1165
INFO:root:FL Epoch: 161 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1685
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554438
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605151
INFO:root:FL Epoch: 161 Norm Difference for worker 1685 is 1.158831
INFO:root:FL Epoch: 161 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1732
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729215
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416734
INFO:root:FL Epoch: 161 Norm Difference for worker 1732 is 1.074051
INFO:root:FL Epoch: 161 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1261
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510857
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503486
INFO:root:FL Epoch: 161 Norm Difference for worker 1261 is 1.178295
INFO:root:FL Epoch: 161 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1766
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502220
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553487
INFO:root:FL Epoch: 161 Norm Difference for worker 1766 is 1.078677
INFO:root:FL Epoch: 161 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :249
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 249 is 1.057671
INFO:root:FL Epoch: 161 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 249
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.5630376321427962 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:2.2254801789919534                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [1558, 61, 1233, 1573, 647, 465, 1833, 504, 165, 1792]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 162 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :1558
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441045
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439255
INFO:root:FL Epoch: 162 Norm Difference for worker 1558 is 1.234689
INFO:root:FL Epoch: 162 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :61
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307600
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 61 is 1.298489
INFO:root:FL Epoch: 162 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1233
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600078
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501527
INFO:root:FL Epoch: 162 Norm Difference for worker 1233 is 1.4354
INFO:root:FL Epoch: 162 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1573
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576968
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619749
INFO:root:FL Epoch: 162 Norm Difference for worker 1573 is 1.322905
INFO:root:FL Epoch: 162 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :647
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738567
INFO:root:Worker: 647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666758
INFO:root:FL Epoch: 162 Norm Difference for worker 647 is 1.232009
INFO:root:FL Epoch: 162 Done on worker:647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :465
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382720
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504708
INFO:root:FL Epoch: 162 Norm Difference for worker 465 is 1.329703
INFO:root:FL Epoch: 162 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1833
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522989
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424343
INFO:root:FL Epoch: 162 Norm Difference for worker 1833 is 1.353215
INFO:root:FL Epoch: 162 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :504
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369224
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608753
INFO:root:FL Epoch: 162 Norm Difference for worker 504 is 1.340891
INFO:root:FL Epoch: 162 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :165
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 165 is 1.24337
INFO:root:FL Epoch: 162 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1792
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580930
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337684
INFO:root:FL Epoch: 162 Norm Difference for worker 1792 is 1.216772
INFO:root:FL Epoch: 162 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1792
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.582269631764468 and Test Accuracy:70.0 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:2.502532958984375                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1112, 1234, 20, 496, 1183, 836, 774, 298, 1652, 863]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1112
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377999
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492130
INFO:root:FL Epoch: 163 Norm Difference for worker 1112 is 1.265428
INFO:root:FL Epoch: 163 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1234
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499070
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539635
INFO:root:FL Epoch: 163 Norm Difference for worker 1234 is 1.288229
INFO:root:FL Epoch: 163 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :20
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 20 is 1.191421
INFO:root:FL Epoch: 163 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :496
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495669
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477764
INFO:root:FL Epoch: 163 Norm Difference for worker 496 is 1.26223
INFO:root:FL Epoch: 163 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1183
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629170
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718930
INFO:root:FL Epoch: 163 Norm Difference for worker 1183 is 1.323174
INFO:root:FL Epoch: 163 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :836
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652390
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630689
INFO:root:FL Epoch: 163 Norm Difference for worker 836 is 1.252984
INFO:root:FL Epoch: 163 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :774
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639788
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378029
INFO:root:FL Epoch: 163 Norm Difference for worker 774 is 1.178626
INFO:root:FL Epoch: 163 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :298
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 298 is 1.178338
INFO:root:FL Epoch: 163 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1652
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535464
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423985
INFO:root:FL Epoch: 163 Norm Difference for worker 1652 is 1.354377
INFO:root:FL Epoch: 163 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :863
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824495
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515582
INFO:root:FL Epoch: 163 Norm Difference for worker 863 is 1.320835
INFO:root:FL Epoch: 163 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.5829143524169922 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:2.1400368213653564                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1408, 200, 203, 1074, 550, 226, 1246, 1420, 277, 294]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.09975062 0.09975062 0.10024938
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 164 Num points on workers: [200 201 201 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1408
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720678
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686458
INFO:root:FL Epoch: 164 Norm Difference for worker 1408 is 1.266649
INFO:root:FL Epoch: 164 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :200
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431104
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 200 is 1.192586
INFO:root:FL Epoch: 164 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :203
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579672
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 203 is 1.179723
INFO:root:FL Epoch: 164 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1074
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566646
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526798
INFO:root:FL Epoch: 164 Norm Difference for worker 1074 is 1.234005
INFO:root:FL Epoch: 164 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :550
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367924
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639082
INFO:root:FL Epoch: 164 Norm Difference for worker 550 is 1.242508
INFO:root:FL Epoch: 164 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :226
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592335
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 226 is 1.25393
INFO:root:FL Epoch: 164 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1246
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522958
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414412
INFO:root:FL Epoch: 164 Norm Difference for worker 1246 is 1.193564
INFO:root:FL Epoch: 164 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1420
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341177
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407712
INFO:root:FL Epoch: 164 Norm Difference for worker 1420 is 1.251423
INFO:root:FL Epoch: 164 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :277
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 277 is 1.181762
INFO:root:FL Epoch: 164 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :294
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 294 is 1.317835
INFO:root:FL Epoch: 164 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1246
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.574178562444799 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:1.6075395941734314                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [27, 1801, 723, 145, 30, 776, 942, 1915, 1622, 375]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 165 Num points on workers: [201 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :27
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 27 is 1.116518
INFO:root:FL Epoch: 165 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1801
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608247
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579232
INFO:root:FL Epoch: 165 Norm Difference for worker 1801 is 1.093715
INFO:root:FL Epoch: 165 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :723
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524323
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502241
INFO:root:FL Epoch: 165 Norm Difference for worker 723 is 1.059204
INFO:root:FL Epoch: 165 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :145
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 145 is 0.919044
INFO:root:FL Epoch: 165 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :30
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 30 is 1.134454
INFO:root:FL Epoch: 165 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :776
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728612
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718121
INFO:root:FL Epoch: 165 Norm Difference for worker 776 is 1.065422
INFO:root:FL Epoch: 165 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :942
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532087
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524616
INFO:root:FL Epoch: 165 Norm Difference for worker 942 is 1.070947
INFO:root:FL Epoch: 165 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1915
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673171
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411976
INFO:root:FL Epoch: 165 Norm Difference for worker 1915 is 1.034204
INFO:root:FL Epoch: 165 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1622
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425616
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697237
INFO:root:FL Epoch: 165 Norm Difference for worker 1622 is 1.040376
INFO:root:FL Epoch: 165 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :375
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687551
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441592
INFO:root:FL Epoch: 165 Norm Difference for worker 375 is 1.025853
INFO:root:FL Epoch: 165 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.597246106933145 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:2.3031930526097617                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [461, 637, 1028, 627, 1083, 746, 1709, 1203, 1059, 991]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 166 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :461
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614573
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376204
INFO:root:FL Epoch: 166 Norm Difference for worker 461 is 1.385737
INFO:root:FL Epoch: 166 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :637
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749204
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439479
INFO:root:FL Epoch: 166 Norm Difference for worker 637 is 1.516298
INFO:root:FL Epoch: 166 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1028
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803408
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542606
INFO:root:FL Epoch: 166 Norm Difference for worker 1028 is 1.514668
INFO:root:FL Epoch: 166 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :627
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468103
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561543
INFO:root:FL Epoch: 166 Norm Difference for worker 627 is 1.519981
INFO:root:FL Epoch: 166 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1083
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.986245
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399985
INFO:root:FL Epoch: 166 Norm Difference for worker 1083 is 1.484995
INFO:root:FL Epoch: 166 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :746
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 1.123264
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587942
INFO:root:FL Epoch: 166 Norm Difference for worker 746 is 1.529643
INFO:root:FL Epoch: 166 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1709
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 1.089978
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531677
INFO:root:FL Epoch: 166 Norm Difference for worker 1709 is 1.438147
INFO:root:FL Epoch: 166 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1203
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693224
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561291
INFO:root:FL Epoch: 166 Norm Difference for worker 1203 is 1.57524
INFO:root:FL Epoch: 166 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1059
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405622
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289506
INFO:root:FL Epoch: 166 Norm Difference for worker 1059 is 1.380513
INFO:root:FL Epoch: 166 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :991
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587780
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321746
INFO:root:FL Epoch: 166 Norm Difference for worker 991 is 1.51058
INFO:root:FL Epoch: 166 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.6021205888074987 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:2.345749855041504                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [1082, 343, 945, 470, 958, 764, 766, 1802, 1524, 976]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 167 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :1082
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593919
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389516
INFO:root:FL Epoch: 167 Norm Difference for worker 1082 is 1.272371
INFO:root:FL Epoch: 167 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :343
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672762
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518675
INFO:root:FL Epoch: 167 Norm Difference for worker 343 is 1.306232
INFO:root:FL Epoch: 167 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :945
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843167
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621145
INFO:root:FL Epoch: 167 Norm Difference for worker 945 is 1.244748
INFO:root:FL Epoch: 167 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :470
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826387
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454878
INFO:root:FL Epoch: 167 Norm Difference for worker 470 is 1.377444
INFO:root:FL Epoch: 167 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :958
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 1.073409
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490038
INFO:root:FL Epoch: 167 Norm Difference for worker 958 is 1.428156
INFO:root:FL Epoch: 167 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :764
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551552
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343498
INFO:root:FL Epoch: 167 Norm Difference for worker 764 is 1.291348
INFO:root:FL Epoch: 167 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :766
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467792
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443600
INFO:root:FL Epoch: 167 Norm Difference for worker 766 is 1.209469
INFO:root:FL Epoch: 167 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1802
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546207
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524200
INFO:root:FL Epoch: 167 Norm Difference for worker 1802 is 1.324089
INFO:root:FL Epoch: 167 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1524
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416010
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631379
INFO:root:FL Epoch: 167 Norm Difference for worker 1524 is 1.372685
INFO:root:FL Epoch: 167 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :976
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624698
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397334
INFO:root:FL Epoch: 167 Norm Difference for worker 976 is 1.3108
INFO:root:FL Epoch: 167 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.5762115646811092 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:1.892862617969513                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1650, 979, 1662, 1844, 1722, 361, 1579, 875, 816, 1106]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1650
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695637
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740228
INFO:root:FL Epoch: 168 Norm Difference for worker 1650 is 1.19556
INFO:root:FL Epoch: 168 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :979
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883107
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655537
INFO:root:FL Epoch: 168 Norm Difference for worker 979 is 1.237243
INFO:root:FL Epoch: 168 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1662
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390815
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517223
INFO:root:FL Epoch: 168 Norm Difference for worker 1662 is 1.132059
INFO:root:FL Epoch: 168 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1844
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458141
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463194
INFO:root:FL Epoch: 168 Norm Difference for worker 1844 is 1.134703
INFO:root:FL Epoch: 168 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1722
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528875
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470290
INFO:root:FL Epoch: 168 Norm Difference for worker 1722 is 1.109685
INFO:root:FL Epoch: 168 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :361
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541370
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442822
INFO:root:FL Epoch: 168 Norm Difference for worker 361 is 1.168157
INFO:root:FL Epoch: 168 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1579
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711907
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493284
INFO:root:FL Epoch: 168 Norm Difference for worker 1579 is 1.165268
INFO:root:FL Epoch: 168 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :875
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368854
INFO:root:Worker: 875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.835450
INFO:root:FL Epoch: 168 Norm Difference for worker 875 is 1.172343
INFO:root:FL Epoch: 168 Done on worker:875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :816
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474972
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753986
INFO:root:FL Epoch: 168 Norm Difference for worker 816 is 1.24501
INFO:root:FL Epoch: 168 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1106
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525747
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592369
INFO:root:FL Epoch: 168 Norm Difference for worker 1106 is 1.172398
INFO:root:FL Epoch: 168 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1722
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.554421594914268 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:1.5739508072535198                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [175, 490, 160, 1508, 186, 1160, 1403, 681, 1715, 517]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 169 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :175
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 175 is 1.00016
INFO:root:FL Epoch: 169 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :490
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570939
INFO:root:Worker: 490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533826
INFO:root:FL Epoch: 169 Norm Difference for worker 490 is 1.034469
INFO:root:FL Epoch: 169 Done on worker:490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :160
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.709060
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 160 is 1.094676
INFO:root:FL Epoch: 169 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1508
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647133
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559829
INFO:root:FL Epoch: 169 Norm Difference for worker 1508 is 1.099994
INFO:root:FL Epoch: 169 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :186
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549804
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 186 is 1.028828
INFO:root:FL Epoch: 169 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1160
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631119
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623055
INFO:root:FL Epoch: 169 Norm Difference for worker 1160 is 1.048641
INFO:root:FL Epoch: 169 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1403
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746378
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706130
INFO:root:FL Epoch: 169 Norm Difference for worker 1403 is 1.075381
INFO:root:FL Epoch: 169 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :681
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581802
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612464
INFO:root:FL Epoch: 169 Norm Difference for worker 681 is 1.096531
INFO:root:FL Epoch: 169 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1715
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630389
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503011
INFO:root:FL Epoch: 169 Norm Difference for worker 1715 is 1.072861
INFO:root:FL Epoch: 169 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :517
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718838
INFO:root:Worker: 517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533046
INFO:root:FL Epoch: 169 Norm Difference for worker 517 is 1.090845
INFO:root:FL Epoch: 169 Done on worker:517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 490
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.5506256415563471 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:1.625697394212087                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [1516, 176, 1015, 1705, 1271, 1860, 1821, 722, 1108, 922]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :1516
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597662
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528293
INFO:root:FL Epoch: 170 Norm Difference for worker 1516 is 0.959102
INFO:root:FL Epoch: 170 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :176
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 176 is 1.04971
INFO:root:FL Epoch: 170 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1015
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468759
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386584
INFO:root:FL Epoch: 170 Norm Difference for worker 1015 is 0.932502
INFO:root:FL Epoch: 170 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1705
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523118
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456611
INFO:root:FL Epoch: 170 Norm Difference for worker 1705 is 0.933055
INFO:root:FL Epoch: 170 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1271
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415814
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474933
INFO:root:FL Epoch: 170 Norm Difference for worker 1271 is 0.994635
INFO:root:FL Epoch: 170 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1860
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614562
INFO:root:Worker: 1860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404730
INFO:root:FL Epoch: 170 Norm Difference for worker 1860 is 0.996435
INFO:root:FL Epoch: 170 Done on worker:1860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1821
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670840
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530197
INFO:root:FL Epoch: 170 Norm Difference for worker 1821 is 0.936376
INFO:root:FL Epoch: 170 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :722
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400963
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658334
INFO:root:FL Epoch: 170 Norm Difference for worker 722 is 1.010785
INFO:root:FL Epoch: 170 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1108
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517300
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667540
INFO:root:FL Epoch: 170 Norm Difference for worker 1108 is 0.993388
INFO:root:FL Epoch: 170 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :922
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354097
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506908
INFO:root:FL Epoch: 170 Norm Difference for worker 922 is 0.941152
INFO:root:FL Epoch: 170 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1015
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.5491534366327173 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:1.4731879432996113                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [1606, 1430, 830, 1920, 1816, 1678, 672, 1424, 182, 1736]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :1606
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643261
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451193
INFO:root:FL Epoch: 171 Norm Difference for worker 1606 is 0.990986
INFO:root:FL Epoch: 171 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1430
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609939
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356155
INFO:root:FL Epoch: 171 Norm Difference for worker 1430 is 1.045505
INFO:root:FL Epoch: 171 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :830
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496761
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525591
INFO:root:FL Epoch: 171 Norm Difference for worker 830 is 1.076147
INFO:root:FL Epoch: 171 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1920
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509331
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494313
INFO:root:FL Epoch: 171 Norm Difference for worker 1920 is 1.047445
INFO:root:FL Epoch: 171 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1816
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429337
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568403
INFO:root:FL Epoch: 171 Norm Difference for worker 1816 is 1.039812
INFO:root:FL Epoch: 171 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1678
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668377
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554251
INFO:root:FL Epoch: 171 Norm Difference for worker 1678 is 0.957808
INFO:root:FL Epoch: 171 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :672
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649440
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532291
INFO:root:FL Epoch: 171 Norm Difference for worker 672 is 1.058782
INFO:root:FL Epoch: 171 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1424
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497457
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418242
INFO:root:FL Epoch: 171 Norm Difference for worker 1424 is 1.058441
INFO:root:FL Epoch: 171 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :182
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 182 is 1.073648
INFO:root:FL Epoch: 171 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1736
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557231
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462265
INFO:root:FL Epoch: 171 Norm Difference for worker 1736 is 1.025566
INFO:root:FL Epoch: 171 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1678
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.5377762966296252 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:1.6064823468526204                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1318, 1689, 1485, 1665, 620, 1649, 1698, 913, 18, 103]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1318
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601694
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601225
INFO:root:FL Epoch: 172 Norm Difference for worker 1318 is 1.024675
INFO:root:FL Epoch: 172 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1689
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594553
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632561
INFO:root:FL Epoch: 172 Norm Difference for worker 1689 is 0.97504
INFO:root:FL Epoch: 172 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1485
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570495
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506493
INFO:root:FL Epoch: 172 Norm Difference for worker 1485 is 0.94727
INFO:root:FL Epoch: 172 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1665
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375614
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417144
INFO:root:FL Epoch: 172 Norm Difference for worker 1665 is 0.908249
INFO:root:FL Epoch: 172 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :620
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474960
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546248
INFO:root:FL Epoch: 172 Norm Difference for worker 620 is 0.918279
INFO:root:FL Epoch: 172 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1649
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640504
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540400
INFO:root:FL Epoch: 172 Norm Difference for worker 1649 is 0.975787
INFO:root:FL Epoch: 172 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1698
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603063
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511654
INFO:root:FL Epoch: 172 Norm Difference for worker 1698 is 0.929458
INFO:root:FL Epoch: 172 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :913
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635625
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421948
INFO:root:FL Epoch: 172 Norm Difference for worker 913 is 0.996701
INFO:root:FL Epoch: 172 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :18
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 18 is 0.966401
INFO:root:FL Epoch: 172 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :103
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 103 is 0.935734
INFO:root:FL Epoch: 172 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.5431622652446523 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:1.8233260711034138                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1633, 1076, 669, 1588, 1155, 1363, 236, 364, 78, 1015]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1633
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582263
INFO:root:Worker: 1633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468798
INFO:root:FL Epoch: 173 Norm Difference for worker 1633 is 1.122726
INFO:root:FL Epoch: 173 Done on worker:1633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1076
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468215
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457509
INFO:root:FL Epoch: 173 Norm Difference for worker 1076 is 1.079468
INFO:root:FL Epoch: 173 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :669
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707290
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577514
INFO:root:FL Epoch: 173 Norm Difference for worker 669 is 1.142481
INFO:root:FL Epoch: 173 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1588
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551474
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493009
INFO:root:FL Epoch: 173 Norm Difference for worker 1588 is 1.169951
INFO:root:FL Epoch: 173 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1155
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676060
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423058
INFO:root:FL Epoch: 173 Norm Difference for worker 1155 is 1.090585
INFO:root:FL Epoch: 173 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1363
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704847
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427841
INFO:root:FL Epoch: 173 Norm Difference for worker 1363 is 1.196913
INFO:root:FL Epoch: 173 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :236
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474585
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 236 is 1.294288
INFO:root:FL Epoch: 173 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :364
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387969
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336101
INFO:root:FL Epoch: 173 Norm Difference for worker 364 is 1.10911
INFO:root:FL Epoch: 173 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :78
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537332
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 78 is 1.083343
INFO:root:FL Epoch: 173 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1015
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320248
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284813
INFO:root:FL Epoch: 173 Norm Difference for worker 1015 is 0.949059
INFO:root:FL Epoch: 173 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1015
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.5592184049241683 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:2.0638675491015115                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [283, 1337, 1696, 374, 590, 1554, 1537, 235, 262, 1429]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 174 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :283
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.902083
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 283 is 1.358635
INFO:root:FL Epoch: 174 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1337
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314308
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381520
INFO:root:FL Epoch: 174 Norm Difference for worker 1337 is 1.207451
INFO:root:FL Epoch: 174 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1696
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536825
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305697
INFO:root:FL Epoch: 174 Norm Difference for worker 1696 is 1.242231
INFO:root:FL Epoch: 174 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :374
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490764
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396310
INFO:root:FL Epoch: 174 Norm Difference for worker 374 is 1.345021
INFO:root:FL Epoch: 174 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :590
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623143
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500383
INFO:root:FL Epoch: 174 Norm Difference for worker 590 is 1.459818
INFO:root:FL Epoch: 174 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1554
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668521
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360351
INFO:root:FL Epoch: 174 Norm Difference for worker 1554 is 1.196983
INFO:root:FL Epoch: 174 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1537
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520973
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691942
INFO:root:FL Epoch: 174 Norm Difference for worker 1537 is 1.495581
INFO:root:FL Epoch: 174 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :235
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584738
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 235 is 1.342008
INFO:root:FL Epoch: 174 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :262
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 262 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 262 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 262 is 1.283156
INFO:root:FL Epoch: 174 Done on worker:262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1429
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500285
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477142
INFO:root:FL Epoch: 174 Norm Difference for worker 1429 is 1.346536
INFO:root:FL Epoch: 174 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1554
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.5465744803933537 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:1.627830187479655                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [1748, 1061, 914, 1574, 1331, 1055, 1258, 1850, 644, 780]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :1748
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.915549
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530167
INFO:root:FL Epoch: 175 Norm Difference for worker 1748 is 1.215879
INFO:root:FL Epoch: 175 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1061
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543472
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212872
INFO:root:FL Epoch: 175 Norm Difference for worker 1061 is 1.09386
INFO:root:FL Epoch: 175 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548876
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536876
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 1.177894
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1574
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830817
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522252
INFO:root:FL Epoch: 175 Norm Difference for worker 1574 is 1.165582
INFO:root:FL Epoch: 175 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1331
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1331 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610082
INFO:root:Worker: 1331 Train Epoch: 1 [0/200 (0%)]	Loss: 0.845779
INFO:root:FL Epoch: 175 Norm Difference for worker 1331 is 1.168088
INFO:root:FL Epoch: 175 Done on worker:1331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1055
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674072
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271084
INFO:root:FL Epoch: 175 Norm Difference for worker 1055 is 1.166614
INFO:root:FL Epoch: 175 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1258
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663473
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497440
INFO:root:FL Epoch: 175 Norm Difference for worker 1258 is 1.150877
INFO:root:FL Epoch: 175 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607814
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508873
INFO:root:FL Epoch: 175 Norm Difference for worker 1850 is 1.103168
INFO:root:FL Epoch: 175 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :644
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705096
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530899
INFO:root:FL Epoch: 175 Norm Difference for worker 644 is 1.156499
INFO:root:FL Epoch: 175 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :780
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714947
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404008
INFO:root:FL Epoch: 175 Norm Difference for worker 780 is 1.080112
INFO:root:FL Epoch: 175 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.5176766795270583 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:1.6069044470787048                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [342, 934, 56, 44, 725, 1237, 1437, 397, 834, 1158]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :342
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 1.033259
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461554
INFO:root:FL Epoch: 176 Norm Difference for worker 342 is 1.064481
INFO:root:FL Epoch: 176 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :934
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 1.060480
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575465
INFO:root:FL Epoch: 176 Norm Difference for worker 934 is 1.1691
INFO:root:FL Epoch: 176 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :56
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538417
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 56 is 1.060954
INFO:root:FL Epoch: 176 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :44
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 176 Norm Difference for worker 44 is 1.065226
INFO:root:FL Epoch: 176 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :725
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688292
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476015
INFO:root:FL Epoch: 176 Norm Difference for worker 725 is 1.031505
INFO:root:FL Epoch: 176 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1237
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415383
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674287
INFO:root:FL Epoch: 176 Norm Difference for worker 1237 is 1.080846
INFO:root:FL Epoch: 176 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1437
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481018
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445689
INFO:root:FL Epoch: 176 Norm Difference for worker 1437 is 1.043402
INFO:root:FL Epoch: 176 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :397
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537961
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494473
INFO:root:FL Epoch: 176 Norm Difference for worker 397 is 1.079402
INFO:root:FL Epoch: 176 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :834
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430023
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495037
INFO:root:FL Epoch: 176 Norm Difference for worker 834 is 1.025897
INFO:root:FL Epoch: 176 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1158
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719084
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481229
INFO:root:FL Epoch: 176 Norm Difference for worker 1158 is 1.004088
INFO:root:FL Epoch: 176 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1158
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.5276443607666913 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:1.7438357472419739                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [1204, 598, 1885, 1659, 1248, 758, 663, 1341, 1638, 1065]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 177 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :1204
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551532
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594103
INFO:root:FL Epoch: 177 Norm Difference for worker 1204 is 1.148887
INFO:root:FL Epoch: 177 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :598
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683484
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394859
INFO:root:FL Epoch: 177 Norm Difference for worker 598 is 1.015014
INFO:root:FL Epoch: 177 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1885
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510722
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426190
INFO:root:FL Epoch: 177 Norm Difference for worker 1885 is 1.048978
INFO:root:FL Epoch: 177 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1659
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660156
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580245
INFO:root:FL Epoch: 177 Norm Difference for worker 1659 is 1.091354
INFO:root:FL Epoch: 177 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1248
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530269
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624910
INFO:root:FL Epoch: 177 Norm Difference for worker 1248 is 1.064863
INFO:root:FL Epoch: 177 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :758
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480420
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750973
INFO:root:FL Epoch: 177 Norm Difference for worker 758 is 1.048739
INFO:root:FL Epoch: 177 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :663
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414845
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518990
INFO:root:FL Epoch: 177 Norm Difference for worker 663 is 1.105194
INFO:root:FL Epoch: 177 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1341
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626147
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469992
INFO:root:FL Epoch: 177 Norm Difference for worker 1341 is 1.018363
INFO:root:FL Epoch: 177 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1638
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424272
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441970
INFO:root:FL Epoch: 177 Norm Difference for worker 1638 is 1.07383
INFO:root:FL Epoch: 177 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1065
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579296
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379474
INFO:root:FL Epoch: 177 Norm Difference for worker 1065 is 1.098904
INFO:root:FL Epoch: 177 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 598
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.5189493105692022 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:1.398733913898468                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [184, 724, 240, 1904, 645, 633, 1526, 1202, 696, 290]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 178 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :184
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317615
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 184 is 0.890026
INFO:root:FL Epoch: 178 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :724
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778812
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712893
INFO:root:FL Epoch: 178 Norm Difference for worker 724 is 0.947515
INFO:root:FL Epoch: 178 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :240
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 240 is 0.950477
INFO:root:FL Epoch: 178 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1904
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569468
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448805
INFO:root:FL Epoch: 178 Norm Difference for worker 1904 is 0.962826
INFO:root:FL Epoch: 178 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :645
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828953
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443035
INFO:root:FL Epoch: 178 Norm Difference for worker 645 is 0.96351
INFO:root:FL Epoch: 178 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :633
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678043
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592500
INFO:root:FL Epoch: 178 Norm Difference for worker 633 is 0.939963
INFO:root:FL Epoch: 178 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1526
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600203
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451774
INFO:root:FL Epoch: 178 Norm Difference for worker 1526 is 0.932797
INFO:root:FL Epoch: 178 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1202
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566168
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397209
INFO:root:FL Epoch: 178 Norm Difference for worker 1202 is 0.912684
INFO:root:FL Epoch: 178 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :696
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681076
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514840
INFO:root:FL Epoch: 178 Norm Difference for worker 696 is 1.001521
INFO:root:FL Epoch: 178 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :290
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 290 is 1.007772
INFO:root:FL Epoch: 178 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.5192413330078125 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:1.8275344967842102                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [463, 865, 1001, 322, 729, 1278, 1067, 821, 1501, 1236]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :463
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677372
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463566
INFO:root:FL Epoch: 179 Norm Difference for worker 463 is 1.214399
INFO:root:FL Epoch: 179 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :865
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485886
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395440
INFO:root:FL Epoch: 179 Norm Difference for worker 865 is 1.089636
INFO:root:FL Epoch: 179 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1001
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704969
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453618
INFO:root:FL Epoch: 179 Norm Difference for worker 1001 is 1.131977
INFO:root:FL Epoch: 179 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :322
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 322 is 1.148469
INFO:root:FL Epoch: 179 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :729
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511575
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520908
INFO:root:FL Epoch: 179 Norm Difference for worker 729 is 1.172195
INFO:root:FL Epoch: 179 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1278
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415697
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358390
INFO:root:FL Epoch: 179 Norm Difference for worker 1278 is 1.047971
INFO:root:FL Epoch: 179 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1067
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498945
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380718
INFO:root:FL Epoch: 179 Norm Difference for worker 1067 is 1.155026
INFO:root:FL Epoch: 179 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :821
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469379
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508987
INFO:root:FL Epoch: 179 Norm Difference for worker 821 is 1.0669
INFO:root:FL Epoch: 179 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1501
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482475
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415329
INFO:root:FL Epoch: 179 Norm Difference for worker 1501 is 1.078303
INFO:root:FL Epoch: 179 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1236
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1236 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728281
INFO:root:Worker: 1236 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407429
INFO:root:FL Epoch: 179 Norm Difference for worker 1236 is 1.071256
INFO:root:FL Epoch: 179 Done on worker:1236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.5295005686142865 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:1.74114191532135                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [674, 1588, 1474, 257, 1781, 1153, 1557, 2, 1828, 1408]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :674
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470693
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524235
INFO:root:FL Epoch: 180 Norm Difference for worker 674 is 1.110797
INFO:root:FL Epoch: 180 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1588
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536283
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292845
INFO:root:FL Epoch: 180 Norm Difference for worker 1588 is 1.095686
INFO:root:FL Epoch: 180 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1474
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466787
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427915
INFO:root:FL Epoch: 180 Norm Difference for worker 1474 is 1.143117
INFO:root:FL Epoch: 180 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :257
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 257 is 1.165622
INFO:root:FL Epoch: 180 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1781
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638365
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331260
INFO:root:FL Epoch: 180 Norm Difference for worker 1781 is 1.131697
INFO:root:FL Epoch: 180 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1153
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590412
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677895
INFO:root:FL Epoch: 180 Norm Difference for worker 1153 is 1.103762
INFO:root:FL Epoch: 180 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1557
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605285
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380040
INFO:root:FL Epoch: 180 Norm Difference for worker 1557 is 1.049089
INFO:root:FL Epoch: 180 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :2
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.329887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 2 is 1.12604
INFO:root:FL Epoch: 180 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1828
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569266
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777798
INFO:root:FL Epoch: 180 Norm Difference for worker 1828 is 1.149783
INFO:root:FL Epoch: 180 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1408
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376848
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375141
INFO:root:FL Epoch: 180 Norm Difference for worker 1408 is 1.12788
INFO:root:FL Epoch: 180 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.5332801718922222 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:2.0209577878316245                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [404, 1607, 27, 1079, 736, 643, 1909, 408, 1879, 1068]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :404
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509470
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367367
INFO:root:FL Epoch: 181 Norm Difference for worker 404 is 1.289045
INFO:root:FL Epoch: 181 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1607
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641977
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445458
INFO:root:FL Epoch: 181 Norm Difference for worker 1607 is 1.276435
INFO:root:FL Epoch: 181 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :27
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 27 is 1.287048
INFO:root:FL Epoch: 181 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1079
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930158
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.785743
INFO:root:FL Epoch: 181 Norm Difference for worker 1079 is 1.282969
INFO:root:FL Epoch: 181 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :736
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664711
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250608
INFO:root:FL Epoch: 181 Norm Difference for worker 736 is 1.225206
INFO:root:FL Epoch: 181 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :643
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333150
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508314
INFO:root:FL Epoch: 181 Norm Difference for worker 643 is 1.350632
INFO:root:FL Epoch: 181 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1909
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893171
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574533
INFO:root:FL Epoch: 181 Norm Difference for worker 1909 is 1.36086
INFO:root:FL Epoch: 181 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :408
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232783
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478159
INFO:root:FL Epoch: 181 Norm Difference for worker 408 is 1.275147
INFO:root:FL Epoch: 181 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1879
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770964
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522427
INFO:root:FL Epoch: 181 Norm Difference for worker 1879 is 1.250222
INFO:root:FL Epoch: 181 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1068
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389062
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337878
INFO:root:FL Epoch: 181 Norm Difference for worker 1068 is 1.250994
INFO:root:FL Epoch: 181 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 736
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.5251867648433236 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:1.618278702100118                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [527, 1596, 833, 982, 1394, 193, 1417, 112, 1788, 1219]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :527
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723593
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362509
INFO:root:FL Epoch: 182 Norm Difference for worker 527 is 1.09363
INFO:root:FL Epoch: 182 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1596
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686655
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459693
INFO:root:FL Epoch: 182 Norm Difference for worker 1596 is 1.087285
INFO:root:FL Epoch: 182 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :833
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537974
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633145
INFO:root:FL Epoch: 182 Norm Difference for worker 833 is 1.057366
INFO:root:FL Epoch: 182 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :982
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467913
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611193
INFO:root:FL Epoch: 182 Norm Difference for worker 982 is 1.082027
INFO:root:FL Epoch: 182 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1394
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413157
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581335
INFO:root:FL Epoch: 182 Norm Difference for worker 1394 is 1.139768
INFO:root:FL Epoch: 182 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :193
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526394
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 193 is 1.06844
INFO:root:FL Epoch: 182 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1417
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310815
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394806
INFO:root:FL Epoch: 182 Norm Difference for worker 1417 is 0.981389
INFO:root:FL Epoch: 182 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :112
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 112 is 1.031691
INFO:root:FL Epoch: 182 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1788
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732204
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353785
INFO:root:FL Epoch: 182 Norm Difference for worker 1788 is 1.028437
INFO:root:FL Epoch: 182 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1219
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427226
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412788
INFO:root:FL Epoch: 182 Norm Difference for worker 1219 is 1.125028
INFO:root:FL Epoch: 182 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1417
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.5318974624661839 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:1.8804518183072407                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [484, 558, 340, 1306, 1152, 354, 1538, 1926, 1788, 1524]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :484
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881042
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502943
INFO:root:FL Epoch: 183 Norm Difference for worker 484 is 1.192343
INFO:root:FL Epoch: 183 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :558
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492672
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.804865
INFO:root:FL Epoch: 183 Norm Difference for worker 558 is 1.193486
INFO:root:FL Epoch: 183 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :340
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705131
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419033
INFO:root:FL Epoch: 183 Norm Difference for worker 340 is 1.084726
INFO:root:FL Epoch: 183 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1306
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755641
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395855
INFO:root:FL Epoch: 183 Norm Difference for worker 1306 is 1.160117
INFO:root:FL Epoch: 183 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1152
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473705
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462566
INFO:root:FL Epoch: 183 Norm Difference for worker 1152 is 1.173384
INFO:root:FL Epoch: 183 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :354
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591146
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527242
INFO:root:FL Epoch: 183 Norm Difference for worker 354 is 1.190774
INFO:root:FL Epoch: 183 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1538
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442823
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338844
INFO:root:FL Epoch: 183 Norm Difference for worker 1538 is 1.153286
INFO:root:FL Epoch: 183 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1926
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554235
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398776
INFO:root:FL Epoch: 183 Norm Difference for worker 1926 is 1.1902
INFO:root:FL Epoch: 183 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1788
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507039
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598475
INFO:root:FL Epoch: 183 Norm Difference for worker 1788 is 1.188253
INFO:root:FL Epoch: 183 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1524
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783225
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498769
INFO:root:FL Epoch: 183 Norm Difference for worker 1524 is 1.16042
INFO:root:FL Epoch: 183 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 340
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.5467514869044808 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:1.9209599494934082                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1014, 492, 1914, 302, 1314, 124, 53, 1918, 536, 1705]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1014
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521721
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310953
INFO:root:FL Epoch: 184 Norm Difference for worker 1014 is 1.117618
INFO:root:FL Epoch: 184 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :492
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474499
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388463
INFO:root:FL Epoch: 184 Norm Difference for worker 492 is 1.115575
INFO:root:FL Epoch: 184 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1914
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724629
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605507
INFO:root:FL Epoch: 184 Norm Difference for worker 1914 is 1.110721
INFO:root:FL Epoch: 184 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :302
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 302 is 1.1508
INFO:root:FL Epoch: 184 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1314
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576928
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389034
INFO:root:FL Epoch: 184 Norm Difference for worker 1314 is 1.108073
INFO:root:FL Epoch: 184 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :124
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 124 is 1.115968
INFO:root:FL Epoch: 184 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :53
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 53 is 1.056604
INFO:root:FL Epoch: 184 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1918
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507653
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414219
INFO:root:FL Epoch: 184 Norm Difference for worker 1918 is 1.119158
INFO:root:FL Epoch: 184 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :536
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507614
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554263
INFO:root:FL Epoch: 184 Norm Difference for worker 536 is 1.182669
INFO:root:FL Epoch: 184 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1705
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381986
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426623
INFO:root:FL Epoch: 184 Norm Difference for worker 1705 is 1.104758
INFO:root:FL Epoch: 184 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 53
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.54122392745579 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:2.0537011424700418                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [187, 1907, 440, 66, 1832, 1905, 923, 214, 511, 330]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 185 Num points on workers: [201 200 200 201 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :187
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428615
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 187 is 1.14753
INFO:root:FL Epoch: 185 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1907
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518945
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586209
INFO:root:FL Epoch: 185 Norm Difference for worker 1907 is 1.218146
INFO:root:FL Epoch: 185 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :440
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656936
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531276
INFO:root:FL Epoch: 185 Norm Difference for worker 440 is 1.14634
INFO:root:FL Epoch: 185 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :66
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.825881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 66 is 1.186753
INFO:root:FL Epoch: 185 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1832
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630583
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460237
INFO:root:FL Epoch: 185 Norm Difference for worker 1832 is 1.221975
INFO:root:FL Epoch: 185 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1905
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557247
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341266
INFO:root:FL Epoch: 185 Norm Difference for worker 1905 is 1.091652
INFO:root:FL Epoch: 185 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :923
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716100
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486224
INFO:root:FL Epoch: 185 Norm Difference for worker 923 is 1.166778
INFO:root:FL Epoch: 185 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :214
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689193
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 214 is 1.277727
INFO:root:FL Epoch: 185 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :511
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584857
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426713
INFO:root:FL Epoch: 185 Norm Difference for worker 511 is 1.20038
INFO:root:FL Epoch: 185 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :330
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 330 is 1.161157
INFO:root:FL Epoch: 185 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.5232137099784964 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:2.099407990773519                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [466, 676, 967, 1905, 1772, 127, 89, 987, 1419, 1123]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :466
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522917
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400441
INFO:root:FL Epoch: 186 Norm Difference for worker 466 is 1.063298
INFO:root:FL Epoch: 186 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :676
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586509
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434363
INFO:root:FL Epoch: 186 Norm Difference for worker 676 is 1.224702
INFO:root:FL Epoch: 186 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :967
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690621
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591934
INFO:root:FL Epoch: 186 Norm Difference for worker 967 is 1.19586
INFO:root:FL Epoch: 186 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1905
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408168
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287295
INFO:root:FL Epoch: 186 Norm Difference for worker 1905 is 0.901504
INFO:root:FL Epoch: 186 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1772
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669604
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538089
INFO:root:FL Epoch: 186 Norm Difference for worker 1772 is 1.115953
INFO:root:FL Epoch: 186 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :127
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461488
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461160
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 127 is 1.135533
INFO:root:FL Epoch: 186 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :89
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358780
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 89 is 1.221692
INFO:root:FL Epoch: 186 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :987
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382060
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530604
INFO:root:FL Epoch: 186 Norm Difference for worker 987 is 1.181112
INFO:root:FL Epoch: 186 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1419
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345125
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453683
INFO:root:FL Epoch: 186 Norm Difference for worker 1419 is 1.135275
INFO:root:FL Epoch: 186 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1123
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651990
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425255
INFO:root:FL Epoch: 186 Norm Difference for worker 1123 is 1.126835
INFO:root:FL Epoch: 186 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.5537325327887255 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:2.9545024236043296                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [665, 1645, 1527, 1383, 1231, 462, 1943, 365, 964, 1412]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 187 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :665
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917915
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679782
INFO:root:FL Epoch: 187 Norm Difference for worker 665 is 1.498373
INFO:root:FL Epoch: 187 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1645
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459142
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463854
INFO:root:FL Epoch: 187 Norm Difference for worker 1645 is 1.428711
INFO:root:FL Epoch: 187 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1527
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496939
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371056
INFO:root:FL Epoch: 187 Norm Difference for worker 1527 is 1.48014
INFO:root:FL Epoch: 187 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1383
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1383 Train Epoch: 0 [0/200 (0%)]	Loss: 1.229399
INFO:root:Worker: 1383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434283
INFO:root:FL Epoch: 187 Norm Difference for worker 1383 is 1.427812
INFO:root:FL Epoch: 187 Done on worker:1383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1231
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884919
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540757
INFO:root:FL Epoch: 187 Norm Difference for worker 1231 is 1.456748
INFO:root:FL Epoch: 187 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :462
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471677
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335863
INFO:root:FL Epoch: 187 Norm Difference for worker 462 is 1.474617
INFO:root:FL Epoch: 187 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1943
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536431
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434599
INFO:root:FL Epoch: 187 Norm Difference for worker 1943 is 1.548374
INFO:root:FL Epoch: 187 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :365
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442320
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499884
INFO:root:FL Epoch: 187 Norm Difference for worker 365 is 1.469021
INFO:root:FL Epoch: 187 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :964
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 964 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778428
INFO:root:Worker: 964 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517650
INFO:root:FL Epoch: 187 Norm Difference for worker 964 is 1.455045
INFO:root:FL Epoch: 187 Done on worker:964
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1412
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.995746
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414687
INFO:root:FL Epoch: 187 Norm Difference for worker 1412 is 1.401223
INFO:root:FL Epoch: 187 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1383
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 187 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 187 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.49665919296881733 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:2.3337891499201455                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [38, 607, 1042, 535, 1476, 1693, 1832, 1654, 354, 1885]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 188 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :38
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 38 is 1.189978
INFO:root:FL Epoch: 188 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :607
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497938
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288051
INFO:root:FL Epoch: 188 Norm Difference for worker 607 is 1.161978
INFO:root:FL Epoch: 188 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1042
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389282
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343682
INFO:root:FL Epoch: 188 Norm Difference for worker 1042 is 1.300761
INFO:root:FL Epoch: 188 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :535
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516842
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501297
INFO:root:FL Epoch: 188 Norm Difference for worker 535 is 1.172919
INFO:root:FL Epoch: 188 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1476
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599291
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402038
INFO:root:FL Epoch: 188 Norm Difference for worker 1476 is 1.22631
INFO:root:FL Epoch: 188 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1693
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607884
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543694
INFO:root:FL Epoch: 188 Norm Difference for worker 1693 is 1.164271
INFO:root:FL Epoch: 188 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1832
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440892
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365935
INFO:root:FL Epoch: 188 Norm Difference for worker 1832 is 1.258412
INFO:root:FL Epoch: 188 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1654
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594524
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495974
INFO:root:FL Epoch: 188 Norm Difference for worker 1654 is 1.25641
INFO:root:FL Epoch: 188 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :354
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396990
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547923
INFO:root:FL Epoch: 188 Norm Difference for worker 354 is 1.247732
INFO:root:FL Epoch: 188 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1885
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443516
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499050
INFO:root:FL Epoch: 188 Norm Difference for worker 1885 is 1.219672
INFO:root:FL Epoch: 188 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.5021072222906 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:1.9513692259788513                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [1156, 955, 1121, 1173, 1837, 1693, 192, 1920, 1085, 1387]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :1156
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410305
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515456
INFO:root:FL Epoch: 189 Norm Difference for worker 1156 is 1.132756
INFO:root:FL Epoch: 189 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :955
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680994
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552771
INFO:root:FL Epoch: 189 Norm Difference for worker 955 is 1.101879
INFO:root:FL Epoch: 189 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1121
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465593
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535886
INFO:root:FL Epoch: 189 Norm Difference for worker 1121 is 1.130757
INFO:root:FL Epoch: 189 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1173
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508114
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436411
INFO:root:FL Epoch: 189 Norm Difference for worker 1173 is 1.065336
INFO:root:FL Epoch: 189 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1837
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509243
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461875
INFO:root:FL Epoch: 189 Norm Difference for worker 1837 is 1.093458
INFO:root:FL Epoch: 189 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1693
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481650
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322139
INFO:root:FL Epoch: 189 Norm Difference for worker 1693 is 0.922682
INFO:root:FL Epoch: 189 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :192
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 192 is 1.089644
INFO:root:FL Epoch: 189 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1920
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638546
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613352
INFO:root:FL Epoch: 189 Norm Difference for worker 1920 is 1.138919
INFO:root:FL Epoch: 189 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1085
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742287
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476039
INFO:root:FL Epoch: 189 Norm Difference for worker 1085 is 1.113195
INFO:root:FL Epoch: 189 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1387
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672070
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482031
INFO:root:FL Epoch: 189 Norm Difference for worker 1387 is 1.117568
INFO:root:FL Epoch: 189 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.5203882806441363 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:2.4566250244776406                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [89, 828, 192, 958, 1709, 67, 1824, 1005, 906, 1403]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :89
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 89 is 1.496874
INFO:root:FL Epoch: 190 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :828
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479784
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501405
INFO:root:FL Epoch: 190 Norm Difference for worker 828 is 1.577331
INFO:root:FL Epoch: 190 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :192
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 192 is 1.4114
INFO:root:FL Epoch: 190 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :958
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524461
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426992
INFO:root:FL Epoch: 190 Norm Difference for worker 958 is 1.527798
INFO:root:FL Epoch: 190 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1709
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439024
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528048
INFO:root:FL Epoch: 190 Norm Difference for worker 1709 is 1.438168
INFO:root:FL Epoch: 190 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :67
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 67 is 1.451916
INFO:root:FL Epoch: 190 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434965
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410604
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 1.497905
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1005
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442541
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652299
INFO:root:FL Epoch: 190 Norm Difference for worker 1005 is 1.439697
INFO:root:FL Epoch: 190 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :906
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852017
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276048
INFO:root:FL Epoch: 190 Norm Difference for worker 906 is 1.324145
INFO:root:FL Epoch: 190 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1403
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.880894
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551037
INFO:root:FL Epoch: 190 Norm Difference for worker 1403 is 1.431303
INFO:root:FL Epoch: 190 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.538620279115789 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:2.660922129948934                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [725, 70, 985, 1897, 854, 1555, 491, 477, 1921, 370]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :725
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461446
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526515
INFO:root:FL Epoch: 191 Norm Difference for worker 725 is 1.403017
INFO:root:FL Epoch: 191 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :70
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 70 is 1.206565
INFO:root:FL Epoch: 191 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :985
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425858
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483301
INFO:root:FL Epoch: 191 Norm Difference for worker 985 is 1.410512
INFO:root:FL Epoch: 191 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1897
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714121
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484686
INFO:root:FL Epoch: 191 Norm Difference for worker 1897 is 1.297465
INFO:root:FL Epoch: 191 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :854
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506223
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564929
INFO:root:FL Epoch: 191 Norm Difference for worker 854 is 1.377361
INFO:root:FL Epoch: 191 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481099
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690870
INFO:root:FL Epoch: 191 Norm Difference for worker 1555 is 1.342704
INFO:root:FL Epoch: 191 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :491
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326762
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431067
INFO:root:FL Epoch: 191 Norm Difference for worker 491 is 1.237364
INFO:root:FL Epoch: 191 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :477
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632851
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384237
INFO:root:FL Epoch: 191 Norm Difference for worker 477 is 1.153934
INFO:root:FL Epoch: 191 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1921
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526690
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224392
INFO:root:FL Epoch: 191 Norm Difference for worker 1921 is 1.326698
INFO:root:FL Epoch: 191 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :370
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407976
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329855
INFO:root:FL Epoch: 191 Norm Difference for worker 370 is 1.271166
INFO:root:FL Epoch: 191 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.5152789424447453 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:2.488637924194336                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [79, 1601, 255, 1815, 604, 801, 1532, 840, 886, 741]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 192 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :79
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569410
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.759695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 79 is 1.322216
INFO:root:FL Epoch: 192 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1601
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769745
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470967
INFO:root:FL Epoch: 192 Norm Difference for worker 1601 is 1.334854
INFO:root:FL Epoch: 192 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :255
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684070
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 255 is 1.340635
INFO:root:FL Epoch: 192 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1815
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408638
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309568
INFO:root:FL Epoch: 192 Norm Difference for worker 1815 is 1.28435
INFO:root:FL Epoch: 192 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :604
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694368
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202005
INFO:root:FL Epoch: 192 Norm Difference for worker 604 is 1.269663
INFO:root:FL Epoch: 192 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :801
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843789
INFO:root:Worker: 801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425232
INFO:root:FL Epoch: 192 Norm Difference for worker 801 is 1.334833
INFO:root:FL Epoch: 192 Done on worker:801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1532
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404807
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398289
INFO:root:FL Epoch: 192 Norm Difference for worker 1532 is 1.298486
INFO:root:FL Epoch: 192 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :840
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481900
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543218
INFO:root:FL Epoch: 192 Norm Difference for worker 840 is 1.36113
INFO:root:FL Epoch: 192 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :886
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237107
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421524
INFO:root:FL Epoch: 192 Norm Difference for worker 886 is 1.294237
INFO:root:FL Epoch: 192 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :741
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514050
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407532
INFO:root:FL Epoch: 192 Norm Difference for worker 741 is 1.427261
INFO:root:FL Epoch: 192 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 79
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.512430892271154 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:1.7289700905481975                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1844, 1459, 661, 880, 1034, 210, 1490, 1097, 934, 887]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1844
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443489
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399108
INFO:root:FL Epoch: 193 Norm Difference for worker 1844 is 1.056479
INFO:root:FL Epoch: 193 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1459
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590063
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384901
INFO:root:FL Epoch: 193 Norm Difference for worker 1459 is 1.071256
INFO:root:FL Epoch: 193 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :661
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674198
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521979
INFO:root:FL Epoch: 193 Norm Difference for worker 661 is 1.087468
INFO:root:FL Epoch: 193 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :880
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487139
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759530
INFO:root:FL Epoch: 193 Norm Difference for worker 880 is 1.111903
INFO:root:FL Epoch: 193 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1034
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597809
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514490
INFO:root:FL Epoch: 193 Norm Difference for worker 1034 is 1.08805
INFO:root:FL Epoch: 193 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :210
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644139
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 210 is 1.052265
INFO:root:FL Epoch: 193 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1490
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676446
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502581
INFO:root:FL Epoch: 193 Norm Difference for worker 1490 is 1.156972
INFO:root:FL Epoch: 193 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1097
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719041
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479896
INFO:root:FL Epoch: 193 Norm Difference for worker 1097 is 1.081844
INFO:root:FL Epoch: 193 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :934
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724929
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759034
INFO:root:FL Epoch: 193 Norm Difference for worker 934 is 1.220008
INFO:root:FL Epoch: 193 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :887
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693688
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601816
INFO:root:FL Epoch: 193 Norm Difference for worker 887 is 1.131006
INFO:root:FL Epoch: 193 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 210
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.5177152998307172 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:1.7545201778411865                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [1106, 1910, 1767, 868, 1738, 507, 477, 1135, 742, 1057]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 194 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :1106
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521131
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391969
INFO:root:FL Epoch: 194 Norm Difference for worker 1106 is 0.985977
INFO:root:FL Epoch: 194 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1910
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661416
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449325
INFO:root:FL Epoch: 194 Norm Difference for worker 1910 is 1.097048
INFO:root:FL Epoch: 194 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1767
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751824
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493650
INFO:root:FL Epoch: 194 Norm Difference for worker 1767 is 1.027755
INFO:root:FL Epoch: 194 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :868
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675469
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643641
INFO:root:FL Epoch: 194 Norm Difference for worker 868 is 1.093578
INFO:root:FL Epoch: 194 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1738
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453014
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507249
INFO:root:FL Epoch: 194 Norm Difference for worker 1738 is 1.057333
INFO:root:FL Epoch: 194 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :507
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620734
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489687
INFO:root:FL Epoch: 194 Norm Difference for worker 507 is 0.991106
INFO:root:FL Epoch: 194 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :477
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495977
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400330
INFO:root:FL Epoch: 194 Norm Difference for worker 477 is 0.913789
INFO:root:FL Epoch: 194 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599725
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667208
INFO:root:FL Epoch: 194 Norm Difference for worker 1135 is 1.029436
INFO:root:FL Epoch: 194 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :742
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612948
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265310
INFO:root:FL Epoch: 194 Norm Difference for worker 742 is 1.042808
INFO:root:FL Epoch: 194 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1057
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651092
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708715
INFO:root:FL Epoch: 194 Norm Difference for worker 1057 is 0.961152
INFO:root:FL Epoch: 194 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.5266104550922618 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:2.8311471939086914                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [1915, 1359, 1668, 1503, 621, 391, 1533, 407, 381, 1490]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 195 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :1915
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335593
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441562
INFO:root:FL Epoch: 195 Norm Difference for worker 1915 is 1.37572
INFO:root:FL Epoch: 195 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1359
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497287
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397035
INFO:root:FL Epoch: 195 Norm Difference for worker 1359 is 1.49055
INFO:root:FL Epoch: 195 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1668
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576857
INFO:root:Worker: 1668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454239
INFO:root:FL Epoch: 195 Norm Difference for worker 1668 is 1.447111
INFO:root:FL Epoch: 195 Done on worker:1668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1503
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.989931
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486440
INFO:root:FL Epoch: 195 Norm Difference for worker 1503 is 1.495828
INFO:root:FL Epoch: 195 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :621
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822131
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351675
INFO:root:FL Epoch: 195 Norm Difference for worker 621 is 1.425397
INFO:root:FL Epoch: 195 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :391
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516477
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592556
INFO:root:FL Epoch: 195 Norm Difference for worker 391 is 1.570579
INFO:root:FL Epoch: 195 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1533
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772573
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395163
INFO:root:FL Epoch: 195 Norm Difference for worker 1533 is 1.473567
INFO:root:FL Epoch: 195 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :407
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694011
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692104
INFO:root:FL Epoch: 195 Norm Difference for worker 407 is 1.434559
INFO:root:FL Epoch: 195 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :381
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478038
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633095
INFO:root:FL Epoch: 195 Norm Difference for worker 381 is 1.306867
INFO:root:FL Epoch: 195 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1490
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676772
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548763
INFO:root:FL Epoch: 195 Norm Difference for worker 1490 is 1.438874
INFO:root:FL Epoch: 195 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 381
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.5232166709268794 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:2.7177076737085977                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [391, 863, 1508, 1684, 1685, 411, 542, 10, 1425, 652]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 196 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :391
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721194
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589743
INFO:root:FL Epoch: 196 Norm Difference for worker 391 is 1.434639
INFO:root:FL Epoch: 196 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :863
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435460
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661023
INFO:root:FL Epoch: 196 Norm Difference for worker 863 is 1.449421
INFO:root:FL Epoch: 196 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1508
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587205
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303178
INFO:root:FL Epoch: 196 Norm Difference for worker 1508 is 1.38141
INFO:root:FL Epoch: 196 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1684
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755272
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376909
INFO:root:FL Epoch: 196 Norm Difference for worker 1684 is 1.391667
INFO:root:FL Epoch: 196 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1685
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729900
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408626
INFO:root:FL Epoch: 196 Norm Difference for worker 1685 is 1.325827
INFO:root:FL Epoch: 196 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :411
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817568
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452367
INFO:root:FL Epoch: 196 Norm Difference for worker 411 is 1.365087
INFO:root:FL Epoch: 196 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :542
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671624
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587321
INFO:root:FL Epoch: 196 Norm Difference for worker 542 is 1.323207
INFO:root:FL Epoch: 196 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :10
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 10 is 1.375371
INFO:root:FL Epoch: 196 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1425
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870839
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673431
INFO:root:FL Epoch: 196 Norm Difference for worker 1425 is 1.405888
INFO:root:FL Epoch: 196 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :652
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505806
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296827
INFO:root:FL Epoch: 196 Norm Difference for worker 652 is 1.337134
INFO:root:FL Epoch: 196 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1685
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.5119999314055723 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:2.236161470413208                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [586, 1416, 1264, 1653, 56, 1339, 1059, 1313, 610, 1437]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :586
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561876
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433663
INFO:root:FL Epoch: 197 Norm Difference for worker 586 is 1.151686
INFO:root:FL Epoch: 197 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1416
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611580
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640895
INFO:root:FL Epoch: 197 Norm Difference for worker 1416 is 1.155504
INFO:root:FL Epoch: 197 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1264
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693991
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515270
INFO:root:FL Epoch: 197 Norm Difference for worker 1264 is 1.149674
INFO:root:FL Epoch: 197 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1653
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583647
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496400
INFO:root:FL Epoch: 197 Norm Difference for worker 1653 is 1.115289
INFO:root:FL Epoch: 197 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :56
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490354
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 56 is 1.125644
INFO:root:FL Epoch: 197 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1339
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413240
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430064
INFO:root:FL Epoch: 197 Norm Difference for worker 1339 is 1.165059
INFO:root:FL Epoch: 197 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1059
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555291
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543926
INFO:root:FL Epoch: 197 Norm Difference for worker 1059 is 1.179819
INFO:root:FL Epoch: 197 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1313
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502067
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556402
INFO:root:FL Epoch: 197 Norm Difference for worker 1313 is 1.151369
INFO:root:FL Epoch: 197 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :610
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427089
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583374
INFO:root:FL Epoch: 197 Norm Difference for worker 610 is 1.132285
INFO:root:FL Epoch: 197 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1437
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752762
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333857
INFO:root:FL Epoch: 197 Norm Difference for worker 1437 is 1.120713
INFO:root:FL Epoch: 197 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1653
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.5226849562981549 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:2.5242817401885986                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [47, 860, 1672, 1209, 1364, 737, 1150, 1766, 1662, 396]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 198 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :47
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 47 is 1.158356
INFO:root:FL Epoch: 198 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :860
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698098
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663907
INFO:root:FL Epoch: 198 Norm Difference for worker 860 is 1.276483
INFO:root:FL Epoch: 198 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1672
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429566
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305057
INFO:root:FL Epoch: 198 Norm Difference for worker 1672 is 1.172165
INFO:root:FL Epoch: 198 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1209
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655943
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638483
INFO:root:FL Epoch: 198 Norm Difference for worker 1209 is 1.184377
INFO:root:FL Epoch: 198 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1364
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529405
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315686
INFO:root:FL Epoch: 198 Norm Difference for worker 1364 is 1.199611
INFO:root:FL Epoch: 198 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :737
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686963
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538970
INFO:root:FL Epoch: 198 Norm Difference for worker 737 is 1.232268
INFO:root:FL Epoch: 198 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1150
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558568
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341461
INFO:root:FL Epoch: 198 Norm Difference for worker 1150 is 1.141782
INFO:root:FL Epoch: 198 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1766
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558518
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454149
INFO:root:FL Epoch: 198 Norm Difference for worker 1766 is 1.2099
INFO:root:FL Epoch: 198 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1662
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448552
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417417
INFO:root:FL Epoch: 198 Norm Difference for worker 1662 is 1.152864
INFO:root:FL Epoch: 198 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :396
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373613
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661898
INFO:root:FL Epoch: 198 Norm Difference for worker 396 is 1.192631
INFO:root:FL Epoch: 198 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1150
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.5144600237117094 and Test Accuracy:75.0 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:2.4968281189600625                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [994, 1080, 767, 284, 384, 1121, 1757, 175, 862, 1427]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :994
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655472
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382159
INFO:root:FL Epoch: 199 Norm Difference for worker 994 is 1.082761
INFO:root:FL Epoch: 199 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1080
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565045
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462837
INFO:root:FL Epoch: 199 Norm Difference for worker 1080 is 1.099125
INFO:root:FL Epoch: 199 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :767
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441870
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461767
INFO:root:FL Epoch: 199 Norm Difference for worker 767 is 1.163675
INFO:root:FL Epoch: 199 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :284
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 284 is 1.216211
INFO:root:FL Epoch: 199 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :384
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622325
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620185
INFO:root:FL Epoch: 199 Norm Difference for worker 384 is 1.088888
INFO:root:FL Epoch: 199 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1121
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542790
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403023
INFO:root:FL Epoch: 199 Norm Difference for worker 1121 is 1.134601
INFO:root:FL Epoch: 199 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1757
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666118
INFO:root:Worker: 1757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496187
INFO:root:FL Epoch: 199 Norm Difference for worker 1757 is 1.154106
INFO:root:FL Epoch: 199 Done on worker:1757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :175
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 175 is 1.14564
INFO:root:FL Epoch: 199 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :862
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529230
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529421
INFO:root:FL Epoch: 199 Norm Difference for worker 862 is 1.179885
INFO:root:FL Epoch: 199 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1427
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859457
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554701
INFO:root:FL Epoch: 199 Norm Difference for worker 1427 is 1.14959
INFO:root:FL Epoch: 199 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 384
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.5024745832471287 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:2.2884145180384317                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [1702, 1697, 1463, 1829, 1243, 431, 403, 877, 59, 775]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :1702
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588260
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506068
INFO:root:FL Epoch: 200 Norm Difference for worker 1702 is 1.132097
INFO:root:FL Epoch: 200 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1697
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597870
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399522
INFO:root:FL Epoch: 200 Norm Difference for worker 1697 is 1.132192
INFO:root:FL Epoch: 200 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1463
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731430
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397704
INFO:root:FL Epoch: 200 Norm Difference for worker 1463 is 1.153091
INFO:root:FL Epoch: 200 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1829
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453308
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487263
INFO:root:FL Epoch: 200 Norm Difference for worker 1829 is 1.110961
INFO:root:FL Epoch: 200 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1243
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691229
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664826
INFO:root:FL Epoch: 200 Norm Difference for worker 1243 is 1.183166
INFO:root:FL Epoch: 200 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :431
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635770
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589807
INFO:root:FL Epoch: 200 Norm Difference for worker 431 is 1.141288
INFO:root:FL Epoch: 200 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :403
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571072
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518332
INFO:root:FL Epoch: 200 Norm Difference for worker 403 is 1.227027
INFO:root:FL Epoch: 200 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :877
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678723
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438143
INFO:root:FL Epoch: 200 Norm Difference for worker 877 is 1.133703
INFO:root:FL Epoch: 200 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :59
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396738
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 59 is 1.164202
INFO:root:FL Epoch: 200 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :775
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516665
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679311
INFO:root:FL Epoch: 200 Norm Difference for worker 775 is 1.150135
INFO:root:FL Epoch: 200 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 877
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.5164127595284406 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:1.7323331634203594                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [650, 429, 1151, 740, 1739, 542, 1654, 1374, 1336, 1026]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :650
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583995
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387712
INFO:root:FL Epoch: 201 Norm Difference for worker 650 is 0.957729
INFO:root:FL Epoch: 201 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :429
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672611
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646826
INFO:root:FL Epoch: 201 Norm Difference for worker 429 is 0.961744
INFO:root:FL Epoch: 201 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1151
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645640
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470497
INFO:root:FL Epoch: 201 Norm Difference for worker 1151 is 0.975066
INFO:root:FL Epoch: 201 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :740
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647667
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644106
INFO:root:FL Epoch: 201 Norm Difference for worker 740 is 1.004108
INFO:root:FL Epoch: 201 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1739
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687882
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572182
INFO:root:FL Epoch: 201 Norm Difference for worker 1739 is 0.92882
INFO:root:FL Epoch: 201 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :542
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486471
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723310
INFO:root:FL Epoch: 201 Norm Difference for worker 542 is 1.022159
INFO:root:FL Epoch: 201 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1654
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858708
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.826965
INFO:root:FL Epoch: 201 Norm Difference for worker 1654 is 1.024051
INFO:root:FL Epoch: 201 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1374
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492993
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384379
INFO:root:FL Epoch: 201 Norm Difference for worker 1374 is 0.993446
INFO:root:FL Epoch: 201 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1336
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582366
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742445
INFO:root:FL Epoch: 201 Norm Difference for worker 1336 is 1.026435
INFO:root:FL Epoch: 201 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1026
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542846
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492583
INFO:root:FL Epoch: 201 Norm Difference for worker 1026 is 1.039818
INFO:root:FL Epoch: 201 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1739
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.5133810797158409 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:1.8136525948842366                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [43, 961, 1507, 1890, 420, 1076, 1819, 60, 1734, 649]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 202 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :43
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 43 is 1.006557
INFO:root:FL Epoch: 202 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :961
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546751
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499482
INFO:root:FL Epoch: 202 Norm Difference for worker 961 is 1.022087
INFO:root:FL Epoch: 202 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1507
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646289
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458594
INFO:root:FL Epoch: 202 Norm Difference for worker 1507 is 0.976226
INFO:root:FL Epoch: 202 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1890
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401496
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630781
INFO:root:FL Epoch: 202 Norm Difference for worker 1890 is 1.049611
INFO:root:FL Epoch: 202 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :420
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430465
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538820
INFO:root:FL Epoch: 202 Norm Difference for worker 420 is 1.015409
INFO:root:FL Epoch: 202 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1076
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352292
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541904
INFO:root:FL Epoch: 202 Norm Difference for worker 1076 is 1.010283
INFO:root:FL Epoch: 202 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1819
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470105
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301779
INFO:root:FL Epoch: 202 Norm Difference for worker 1819 is 1.023749
INFO:root:FL Epoch: 202 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :60
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 60 is 1.060165
INFO:root:FL Epoch: 202 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1734
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425676
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510390
INFO:root:FL Epoch: 202 Norm Difference for worker 1734 is 1.054359
INFO:root:FL Epoch: 202 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :649
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381569
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408902
INFO:root:FL Epoch: 202 Norm Difference for worker 649 is 1.060228
INFO:root:FL Epoch: 202 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1734
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.522657564457725 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:1.7126421133677165                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1755, 911, 660, 91, 853, 967, 540, 1716, 1175, 884]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1755
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505337
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366730
INFO:root:FL Epoch: 203 Norm Difference for worker 1755 is 1.015506
INFO:root:FL Epoch: 203 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :911
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441619
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463229
INFO:root:FL Epoch: 203 Norm Difference for worker 911 is 1.043558
INFO:root:FL Epoch: 203 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :660
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625109
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435250
INFO:root:FL Epoch: 203 Norm Difference for worker 660 is 0.950634
INFO:root:FL Epoch: 203 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :91
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 91 is 0.971486
INFO:root:FL Epoch: 203 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :853
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545451
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644207
INFO:root:FL Epoch: 203 Norm Difference for worker 853 is 1.032298
INFO:root:FL Epoch: 203 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :967
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883593
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.793707
INFO:root:FL Epoch: 203 Norm Difference for worker 967 is 1.029148
INFO:root:FL Epoch: 203 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :540
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561816
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618962
INFO:root:FL Epoch: 203 Norm Difference for worker 540 is 1.007369
INFO:root:FL Epoch: 203 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1716
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661399
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638871
INFO:root:FL Epoch: 203 Norm Difference for worker 1716 is 1.024625
INFO:root:FL Epoch: 203 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1175
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591987
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639470
INFO:root:FL Epoch: 203 Norm Difference for worker 1175 is 0.997687
INFO:root:FL Epoch: 203 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :884
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534963
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310798
INFO:root:FL Epoch: 203 Norm Difference for worker 884 is 0.969042
INFO:root:FL Epoch: 203 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 660
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.5323739577742184 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:2.17789363861084                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [1812, 1034, 636, 1097, 1838, 38, 867, 566, 1323, 1318]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :1812
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439276
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509004
INFO:root:FL Epoch: 204 Norm Difference for worker 1812 is 1.06748
INFO:root:FL Epoch: 204 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1034
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621161
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481854
INFO:root:FL Epoch: 204 Norm Difference for worker 1034 is 1.045483
INFO:root:FL Epoch: 204 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :636
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683969
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637994
INFO:root:FL Epoch: 204 Norm Difference for worker 636 is 1.091259
INFO:root:FL Epoch: 204 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1097
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795703
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466572
INFO:root:FL Epoch: 204 Norm Difference for worker 1097 is 1.02242
INFO:root:FL Epoch: 204 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1838
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712922
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517426
INFO:root:FL Epoch: 204 Norm Difference for worker 1838 is 0.987197
INFO:root:FL Epoch: 204 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :38
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 38 is 1.00964
INFO:root:FL Epoch: 204 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :867
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345683
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456169
INFO:root:FL Epoch: 204 Norm Difference for worker 867 is 1.05768
INFO:root:FL Epoch: 204 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :566
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411835
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477427
INFO:root:FL Epoch: 204 Norm Difference for worker 566 is 1.082934
INFO:root:FL Epoch: 204 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1323
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573678
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603848
INFO:root:FL Epoch: 204 Norm Difference for worker 1323 is 1.06682
INFO:root:FL Epoch: 204 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1318
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571076
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477171
INFO:root:FL Epoch: 204 Norm Difference for worker 1318 is 1.10837
INFO:root:FL Epoch: 204 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.5142431101378273 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:1.889320174853007                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [692, 711, 821, 690, 1882, 1553, 514, 496, 161, 654]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 205 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :692
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804327
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472986
INFO:root:FL Epoch: 205 Norm Difference for worker 692 is 1.023845
INFO:root:FL Epoch: 205 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :711
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850612
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395384
INFO:root:FL Epoch: 205 Norm Difference for worker 711 is 0.991425
INFO:root:FL Epoch: 205 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :821
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488423
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458667
INFO:root:FL Epoch: 205 Norm Difference for worker 821 is 0.915083
INFO:root:FL Epoch: 205 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :690
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726820
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446686
INFO:root:FL Epoch: 205 Norm Difference for worker 690 is 1.095019
INFO:root:FL Epoch: 205 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1882
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513928
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579361
INFO:root:FL Epoch: 205 Norm Difference for worker 1882 is 1.035968
INFO:root:FL Epoch: 205 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1553
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435931
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559522
INFO:root:FL Epoch: 205 Norm Difference for worker 1553 is 1.018754
INFO:root:FL Epoch: 205 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :514
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429132
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269486
INFO:root:FL Epoch: 205 Norm Difference for worker 514 is 1.041873
INFO:root:FL Epoch: 205 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :496
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319306
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509232
INFO:root:FL Epoch: 205 Norm Difference for worker 496 is 1.035286
INFO:root:FL Epoch: 205 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :161
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 161 is 0.988478
INFO:root:FL Epoch: 205 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :654
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617472
INFO:root:Worker: 654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.795766
INFO:root:FL Epoch: 205 Norm Difference for worker 654 is 1.021236
INFO:root:FL Epoch: 205 Done on worker:654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 821
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.5354965241516337 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:1.8854066530863445                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [1331, 983, 171, 920, 1151, 1637, 178, 369, 1111, 1605]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 206 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :1331
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1331 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827843
INFO:root:Worker: 1331 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450209
INFO:root:FL Epoch: 206 Norm Difference for worker 1331 is 1.056043
INFO:root:FL Epoch: 206 Done on worker:1331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :983
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422783
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433936
INFO:root:FL Epoch: 206 Norm Difference for worker 983 is 1.053702
INFO:root:FL Epoch: 206 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :171
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510532
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 171 is 1.141531
INFO:root:FL Epoch: 206 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :920
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458604
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470829
INFO:root:FL Epoch: 206 Norm Difference for worker 920 is 1.09175
INFO:root:FL Epoch: 206 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1151
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503952
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522263
INFO:root:FL Epoch: 206 Norm Difference for worker 1151 is 0.994366
INFO:root:FL Epoch: 206 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1637
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694377
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543663
INFO:root:FL Epoch: 206 Norm Difference for worker 1637 is 1.064928
INFO:root:FL Epoch: 206 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :178
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 178 is 1.124277
INFO:root:FL Epoch: 206 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :369
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803006
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520749
INFO:root:FL Epoch: 206 Norm Difference for worker 369 is 1.155599
INFO:root:FL Epoch: 206 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1111
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534875
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561797
INFO:root:FL Epoch: 206 Norm Difference for worker 1111 is 1.057229
INFO:root:FL Epoch: 206 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1605
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725852
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707036
INFO:root:FL Epoch: 206 Norm Difference for worker 1605 is 1.097679
INFO:root:FL Epoch: 206 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1151
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5294220640378839 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:2.169394056002299                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1685, 189, 1002, 202, 1447, 1515, 1065, 74, 3, 1101]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 207 Num points on workers: [200 201 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1685
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394102
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601385
INFO:root:FL Epoch: 207 Norm Difference for worker 1685 is 0.956601
INFO:root:FL Epoch: 207 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :189
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 189 is 1.20306
INFO:root:FL Epoch: 207 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1002
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585765
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330792
INFO:root:FL Epoch: 207 Norm Difference for worker 1002 is 1.170819
INFO:root:FL Epoch: 207 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :202
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 202 is 1.085248
INFO:root:FL Epoch: 207 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1447
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450370
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522075
INFO:root:FL Epoch: 207 Norm Difference for worker 1447 is 1.151695
INFO:root:FL Epoch: 207 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1515
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443173
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509867
INFO:root:FL Epoch: 207 Norm Difference for worker 1515 is 1.098017
INFO:root:FL Epoch: 207 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1065
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382451
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.909405
INFO:root:FL Epoch: 207 Norm Difference for worker 1065 is 1.143595
INFO:root:FL Epoch: 207 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :74
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 74 is 1.159099
INFO:root:FL Epoch: 207 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :3
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 3 is 1.146048
INFO:root:FL Epoch: 207 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1101
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403893
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769710
INFO:root:FL Epoch: 207 Norm Difference for worker 1101 is 1.162306
INFO:root:FL Epoch: 207 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1685
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.535442038493998 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:2.4235992431640625                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [69, 440, 520, 420, 1157, 1592, 975, 1930, 605, 863]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 208 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :69
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 69 is 1.082924
INFO:root:FL Epoch: 208 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :440
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397166
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479804
INFO:root:FL Epoch: 208 Norm Difference for worker 440 is 1.188347
INFO:root:FL Epoch: 208 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :520
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711461
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465193
INFO:root:FL Epoch: 208 Norm Difference for worker 520 is 1.161549
INFO:root:FL Epoch: 208 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :420
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542405
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521032
INFO:root:FL Epoch: 208 Norm Difference for worker 420 is 1.196186
INFO:root:FL Epoch: 208 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1157
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563064
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492600
INFO:root:FL Epoch: 208 Norm Difference for worker 1157 is 1.266996
INFO:root:FL Epoch: 208 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1592
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552886
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569312
INFO:root:FL Epoch: 208 Norm Difference for worker 1592 is 1.300829
INFO:root:FL Epoch: 208 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :975
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613557
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491548
INFO:root:FL Epoch: 208 Norm Difference for worker 975 is 1.317926
INFO:root:FL Epoch: 208 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1930
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860851
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378723
INFO:root:FL Epoch: 208 Norm Difference for worker 1930 is 1.270629
INFO:root:FL Epoch: 208 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :605
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707338
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559854
INFO:root:FL Epoch: 208 Norm Difference for worker 605 is 1.192691
INFO:root:FL Epoch: 208 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :863
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524654
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445498
INFO:root:FL Epoch: 208 Norm Difference for worker 863 is 1.267473
INFO:root:FL Epoch: 208 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.5438212769873002 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:2.116933822631836                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [313, 677, 359, 484, 667, 1156, 1048, 503, 1380, 1624]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 209 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :313
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 313 is 1.245992
INFO:root:FL Epoch: 209 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :677
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512854
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563762
INFO:root:FL Epoch: 209 Norm Difference for worker 677 is 1.161836
INFO:root:FL Epoch: 209 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :359
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454017
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402146
INFO:root:FL Epoch: 209 Norm Difference for worker 359 is 1.098589
INFO:root:FL Epoch: 209 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :484
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576630
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489653
INFO:root:FL Epoch: 209 Norm Difference for worker 484 is 1.290354
INFO:root:FL Epoch: 209 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :667
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542801
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494781
INFO:root:FL Epoch: 209 Norm Difference for worker 667 is 1.1128
INFO:root:FL Epoch: 209 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1156
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718020
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446422
INFO:root:FL Epoch: 209 Norm Difference for worker 1156 is 1.187498
INFO:root:FL Epoch: 209 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1048
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607962
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533509
INFO:root:FL Epoch: 209 Norm Difference for worker 1048 is 1.332751
INFO:root:FL Epoch: 209 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :503
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281909
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564042
INFO:root:FL Epoch: 209 Norm Difference for worker 503 is 1.272057
INFO:root:FL Epoch: 209 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1380
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572309
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640891
INFO:root:FL Epoch: 209 Norm Difference for worker 1380 is 1.175133
INFO:root:FL Epoch: 209 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1624
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798370
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346896
INFO:root:FL Epoch: 209 Norm Difference for worker 1624 is 1.326086
INFO:root:FL Epoch: 209 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 359
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5443714804509107 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:1.685291012128194                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [1877, 579, 297, 409, 512, 733, 615, 1019, 1770, 299]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 210 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :1877
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432385
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480846
INFO:root:FL Epoch: 210 Norm Difference for worker 1877 is 1.077911
INFO:root:FL Epoch: 210 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :579
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358526
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506432
INFO:root:FL Epoch: 210 Norm Difference for worker 579 is 1.09909
INFO:root:FL Epoch: 210 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :297
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 297 is 1.119624
INFO:root:FL Epoch: 210 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :409
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429617
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389108
INFO:root:FL Epoch: 210 Norm Difference for worker 409 is 1.183213
INFO:root:FL Epoch: 210 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :512
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736309
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637072
INFO:root:FL Epoch: 210 Norm Difference for worker 512 is 1.143265
INFO:root:FL Epoch: 210 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :733
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550880
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539063
INFO:root:FL Epoch: 210 Norm Difference for worker 733 is 1.183322
INFO:root:FL Epoch: 210 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :615
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689996
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590496
INFO:root:FL Epoch: 210 Norm Difference for worker 615 is 1.089024
INFO:root:FL Epoch: 210 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1019
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609134
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719471
INFO:root:FL Epoch: 210 Norm Difference for worker 1019 is 1.061318
INFO:root:FL Epoch: 210 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1770
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571268
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602591
INFO:root:FL Epoch: 210 Norm Difference for worker 1770 is 1.114374
INFO:root:FL Epoch: 210 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :299
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541597
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 299 is 1.038237
INFO:root:FL Epoch: 210 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 299
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.5572201644673067 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:1.8954445719718933                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [27, 1009, 1817, 1636, 541, 1276, 1217, 554, 1442, 912]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :27
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 27 is 1.060203
INFO:root:FL Epoch: 211 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1009
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623098
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509399
INFO:root:FL Epoch: 211 Norm Difference for worker 1009 is 1.144356
INFO:root:FL Epoch: 211 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1817
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512402
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516387
INFO:root:FL Epoch: 211 Norm Difference for worker 1817 is 1.149723
INFO:root:FL Epoch: 211 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1636
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686084
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475736
INFO:root:FL Epoch: 211 Norm Difference for worker 1636 is 1.206113
INFO:root:FL Epoch: 211 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :541
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416209
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743202
INFO:root:FL Epoch: 211 Norm Difference for worker 541 is 1.05599
INFO:root:FL Epoch: 211 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1276
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340795
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598772
INFO:root:FL Epoch: 211 Norm Difference for worker 1276 is 1.142735
INFO:root:FL Epoch: 211 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1217
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741309
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473146
INFO:root:FL Epoch: 211 Norm Difference for worker 1217 is 1.137355
INFO:root:FL Epoch: 211 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :554
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750025
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417532
INFO:root:FL Epoch: 211 Norm Difference for worker 554 is 1.139687
INFO:root:FL Epoch: 211 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1442
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523932
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567027
INFO:root:FL Epoch: 211 Norm Difference for worker 1442 is 1.082422
INFO:root:FL Epoch: 211 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :912
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561052
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500517
INFO:root:FL Epoch: 211 Norm Difference for worker 912 is 1.088921
INFO:root:FL Epoch: 211 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 27
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5450635762775645 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:1.637795885403951                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [621, 1132, 1079, 760, 946, 1937, 215, 242, 1823, 207]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :621
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525023
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363843
INFO:root:FL Epoch: 212 Norm Difference for worker 621 is 1.021732
INFO:root:FL Epoch: 212 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1132
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628891
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381228
INFO:root:FL Epoch: 212 Norm Difference for worker 1132 is 0.994253
INFO:root:FL Epoch: 212 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1079
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396457
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466734
INFO:root:FL Epoch: 212 Norm Difference for worker 1079 is 0.997794
INFO:root:FL Epoch: 212 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :760
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706398
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362881
INFO:root:FL Epoch: 212 Norm Difference for worker 760 is 0.966576
INFO:root:FL Epoch: 212 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :946
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506746
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438091
INFO:root:FL Epoch: 212 Norm Difference for worker 946 is 1.029727
INFO:root:FL Epoch: 212 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1937
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789732
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549904
INFO:root:FL Epoch: 212 Norm Difference for worker 1937 is 1.101433
INFO:root:FL Epoch: 212 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :215
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 215 is 1.051606
INFO:root:FL Epoch: 212 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :242
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 242 is 0.99956
INFO:root:FL Epoch: 212 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1823
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533528
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475395
INFO:root:FL Epoch: 212 Norm Difference for worker 1823 is 1.077023
INFO:root:FL Epoch: 212 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :207
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 207 is 1.060265
INFO:root:FL Epoch: 212 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 760
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.541945054250605 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:1.5955954790115356                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [214, 1552, 801, 796, 643, 58, 1721, 761, 146, 1612]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 213 Num points on workers: [201 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :214
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 214 is 0.961388
INFO:root:FL Epoch: 213 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1552
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664696
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411767
INFO:root:FL Epoch: 213 Norm Difference for worker 1552 is 0.914878
INFO:root:FL Epoch: 213 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :801
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413944
INFO:root:Worker: 801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471329
INFO:root:FL Epoch: 213 Norm Difference for worker 801 is 1.006471
INFO:root:FL Epoch: 213 Done on worker:801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :796
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628594
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573968
INFO:root:FL Epoch: 213 Norm Difference for worker 796 is 0.998766
INFO:root:FL Epoch: 213 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :643
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626075
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550428
INFO:root:FL Epoch: 213 Norm Difference for worker 643 is 1.010995
INFO:root:FL Epoch: 213 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :58
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 58 is 0.940241
INFO:root:FL Epoch: 213 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1721
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510754
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480100
INFO:root:FL Epoch: 213 Norm Difference for worker 1721 is 0.9182
INFO:root:FL Epoch: 213 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :761
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661591
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545070
INFO:root:FL Epoch: 213 Norm Difference for worker 761 is 1.05259
INFO:root:FL Epoch: 213 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :146
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.569165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 146 is 0.991909
INFO:root:FL Epoch: 213 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1612
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365338
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579815
INFO:root:FL Epoch: 213 Norm Difference for worker 1612 is 0.940793
INFO:root:FL Epoch: 213 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1612
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5420815979733187 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:1.711376925309499                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [386, 175, 424, 1888, 1293, 624, 679, 1841, 1325, 542]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 214 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :386
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491374
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313108
INFO:root:FL Epoch: 214 Norm Difference for worker 386 is 1.042041
INFO:root:FL Epoch: 214 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :175
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318655
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 175 is 0.979971
INFO:root:FL Epoch: 214 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :424
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432300
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440467
INFO:root:FL Epoch: 214 Norm Difference for worker 424 is 0.955029
INFO:root:FL Epoch: 214 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1888
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467631
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502920
INFO:root:FL Epoch: 214 Norm Difference for worker 1888 is 1.038702
INFO:root:FL Epoch: 214 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1293
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703518
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726835
INFO:root:FL Epoch: 214 Norm Difference for worker 1293 is 1.031713
INFO:root:FL Epoch: 214 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :624
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630203
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412098
INFO:root:FL Epoch: 214 Norm Difference for worker 624 is 0.990294
INFO:root:FL Epoch: 214 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :679
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375911
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303810
INFO:root:FL Epoch: 214 Norm Difference for worker 679 is 1.047569
INFO:root:FL Epoch: 214 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1841
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680458
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573982
INFO:root:FL Epoch: 214 Norm Difference for worker 1841 is 1.016986
INFO:root:FL Epoch: 214 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1325
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496358
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388356
INFO:root:FL Epoch: 214 Norm Difference for worker 1325 is 1.055578
INFO:root:FL Epoch: 214 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :542
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484112
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440977
INFO:root:FL Epoch: 214 Norm Difference for worker 542 is 0.974685
INFO:root:FL Epoch: 214 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5528344862601337 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:1.8943415880203247                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [1788, 1063, 1171, 1786, 980, 1815, 955, 1664, 854, 822]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :1788
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632489
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400550
INFO:root:FL Epoch: 215 Norm Difference for worker 1788 is 1.142171
INFO:root:FL Epoch: 215 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1063
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463707
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437460
INFO:root:FL Epoch: 215 Norm Difference for worker 1063 is 1.100717
INFO:root:FL Epoch: 215 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1171
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491997
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487828
INFO:root:FL Epoch: 215 Norm Difference for worker 1171 is 1.05171
INFO:root:FL Epoch: 215 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1786
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520187
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364376
INFO:root:FL Epoch: 215 Norm Difference for worker 1786 is 1.097013
INFO:root:FL Epoch: 215 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :980
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736829
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578702
INFO:root:FL Epoch: 215 Norm Difference for worker 980 is 1.102022
INFO:root:FL Epoch: 215 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1815
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353103
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344476
INFO:root:FL Epoch: 215 Norm Difference for worker 1815 is 1.030364
INFO:root:FL Epoch: 215 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :955
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479708
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375779
INFO:root:FL Epoch: 215 Norm Difference for worker 955 is 1.104594
INFO:root:FL Epoch: 215 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1664
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667821
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589397
INFO:root:FL Epoch: 215 Norm Difference for worker 1664 is 1.038788
INFO:root:FL Epoch: 215 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :854
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536791
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547138
INFO:root:FL Epoch: 215 Norm Difference for worker 854 is 1.160936
INFO:root:FL Epoch: 215 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :822
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541106
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489833
INFO:root:FL Epoch: 215 Norm Difference for worker 822 is 1.100179
INFO:root:FL Epoch: 215 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1664
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5759070831186631 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:2.013652960459391                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1741, 942, 1295, 1349, 1180, 1912, 1903, 517, 1500, 1498]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1741
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386289
INFO:root:Worker: 1741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399678
INFO:root:FL Epoch: 216 Norm Difference for worker 1741 is 1.189754
INFO:root:FL Epoch: 216 Done on worker:1741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :942
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775961
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423358
INFO:root:FL Epoch: 216 Norm Difference for worker 942 is 1.138691
INFO:root:FL Epoch: 216 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1295
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452744
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261448
INFO:root:FL Epoch: 216 Norm Difference for worker 1295 is 1.033053
INFO:root:FL Epoch: 216 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1349
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493925
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400124
INFO:root:FL Epoch: 216 Norm Difference for worker 1349 is 1.156791
INFO:root:FL Epoch: 216 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1180
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814586
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370296
INFO:root:FL Epoch: 216 Norm Difference for worker 1180 is 1.080913
INFO:root:FL Epoch: 216 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1912
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644639
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.788256
INFO:root:FL Epoch: 216 Norm Difference for worker 1912 is 1.219034
INFO:root:FL Epoch: 216 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1903
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575174
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498777
INFO:root:FL Epoch: 216 Norm Difference for worker 1903 is 1.184357
INFO:root:FL Epoch: 216 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :517
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707994
INFO:root:Worker: 517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623565
INFO:root:FL Epoch: 216 Norm Difference for worker 517 is 1.191963
INFO:root:FL Epoch: 216 Done on worker:517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1500
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654549
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544286
INFO:root:FL Epoch: 216 Norm Difference for worker 1500 is 1.147669
INFO:root:FL Epoch: 216 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1498
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504762
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330536
INFO:root:FL Epoch: 216 Norm Difference for worker 1498 is 1.057678
INFO:root:FL Epoch: 216 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.5668644326574662 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:1.721899410088857                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [707, 1703, 1294, 526, 1078, 1861, 137, 1886, 1734, 76]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :707
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560372
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476454
INFO:root:FL Epoch: 217 Norm Difference for worker 707 is 1.058253
INFO:root:FL Epoch: 217 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1703
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577587
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517698
INFO:root:FL Epoch: 217 Norm Difference for worker 1703 is 1.054721
INFO:root:FL Epoch: 217 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1294
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505059
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486720
INFO:root:FL Epoch: 217 Norm Difference for worker 1294 is 1.103022
INFO:root:FL Epoch: 217 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :526
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569327
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586291
INFO:root:FL Epoch: 217 Norm Difference for worker 526 is 1.107816
INFO:root:FL Epoch: 217 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1078
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805008
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530573
INFO:root:FL Epoch: 217 Norm Difference for worker 1078 is 1.093282
INFO:root:FL Epoch: 217 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1861
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471686
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471368
INFO:root:FL Epoch: 217 Norm Difference for worker 1861 is 0.969615
INFO:root:FL Epoch: 217 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :137
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 137 is 1.058799
INFO:root:FL Epoch: 217 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1886
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653259
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633650
INFO:root:FL Epoch: 217 Norm Difference for worker 1886 is 1.103437
INFO:root:FL Epoch: 217 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1734
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487939
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322738
INFO:root:FL Epoch: 217 Norm Difference for worker 1734 is 0.947629
INFO:root:FL Epoch: 217 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :76
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 76 is 1.104336
INFO:root:FL Epoch: 217 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1734
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.5960464319762062 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:1.8801400264104207                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [326, 1116, 257, 1587, 440, 370, 1108, 779, 227, 849]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [201 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :326
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.400869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 326 is 1.209436
INFO:root:FL Epoch: 218 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1116
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1116 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796332
INFO:root:Worker: 1116 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521601
INFO:root:FL Epoch: 218 Norm Difference for worker 1116 is 1.265513
INFO:root:FL Epoch: 218 Done on worker:1116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :257
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 257 is 1.333578
INFO:root:FL Epoch: 218 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1587
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635339
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371089
INFO:root:FL Epoch: 218 Norm Difference for worker 1587 is 1.205243
INFO:root:FL Epoch: 218 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :440
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 1.020069
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341139
INFO:root:FL Epoch: 218 Norm Difference for worker 440 is 1.153941
INFO:root:FL Epoch: 218 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :370
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480639
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495720
INFO:root:FL Epoch: 218 Norm Difference for worker 370 is 1.347659
INFO:root:FL Epoch: 218 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1108
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699505
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417709
INFO:root:FL Epoch: 218 Norm Difference for worker 1108 is 1.213494
INFO:root:FL Epoch: 218 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :779
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784360
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781914
INFO:root:FL Epoch: 218 Norm Difference for worker 779 is 1.30172
INFO:root:FL Epoch: 218 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :227
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 227 is 1.269373
INFO:root:FL Epoch: 218 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :849
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517173
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540900
INFO:root:FL Epoch: 218 Norm Difference for worker 849 is 1.208176
INFO:root:FL Epoch: 218 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 440
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.5921950445455664 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:1.6352004806200664                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [1889, 645, 428, 1356, 1351, 1545, 565, 1919, 612, 1894]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 219 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :1889
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643148
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451797
INFO:root:FL Epoch: 219 Norm Difference for worker 1889 is 1.205325
INFO:root:FL Epoch: 219 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :645
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.961772
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468353
INFO:root:FL Epoch: 219 Norm Difference for worker 645 is 1.17607
INFO:root:FL Epoch: 219 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :428
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504678
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497053
INFO:root:FL Epoch: 219 Norm Difference for worker 428 is 1.120096
INFO:root:FL Epoch: 219 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1356
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710227
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441082
INFO:root:FL Epoch: 219 Norm Difference for worker 1356 is 1.167897
INFO:root:FL Epoch: 219 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1351
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700560
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546474
INFO:root:FL Epoch: 219 Norm Difference for worker 1351 is 1.152251
INFO:root:FL Epoch: 219 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1545
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877008
INFO:root:Worker: 1545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308688
INFO:root:FL Epoch: 219 Norm Difference for worker 1545 is 1.123097
INFO:root:FL Epoch: 219 Done on worker:1545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :565
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692741
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453970
INFO:root:FL Epoch: 219 Norm Difference for worker 565 is 1.153943
INFO:root:FL Epoch: 219 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1919
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495828
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562641
INFO:root:FL Epoch: 219 Norm Difference for worker 1919 is 1.214765
INFO:root:FL Epoch: 219 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :612
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586709
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556376
INFO:root:FL Epoch: 219 Norm Difference for worker 612 is 1.141565
INFO:root:FL Epoch: 219 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1894
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416140
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416911
INFO:root:FL Epoch: 219 Norm Difference for worker 1894 is 1.021572
INFO:root:FL Epoch: 219 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1894
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.603668410988415 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:1.9670325915018718                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1452, 1868, 549, 1736, 933, 1476, 1122, 1138, 105, 556]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1452
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903017
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553270
INFO:root:FL Epoch: 220 Norm Difference for worker 1452 is 1.214299
INFO:root:FL Epoch: 220 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1868
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722035
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440212
INFO:root:FL Epoch: 220 Norm Difference for worker 1868 is 1.180079
INFO:root:FL Epoch: 220 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :549
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496276
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467017
INFO:root:FL Epoch: 220 Norm Difference for worker 549 is 1.130476
INFO:root:FL Epoch: 220 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1736
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573457
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453919
INFO:root:FL Epoch: 220 Norm Difference for worker 1736 is 1.173287
INFO:root:FL Epoch: 220 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :933
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558192
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684332
INFO:root:FL Epoch: 220 Norm Difference for worker 933 is 1.110837
INFO:root:FL Epoch: 220 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1476
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598022
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369477
INFO:root:FL Epoch: 220 Norm Difference for worker 1476 is 1.170788
INFO:root:FL Epoch: 220 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1122
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604890
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449421
INFO:root:FL Epoch: 220 Norm Difference for worker 1122 is 1.130978
INFO:root:FL Epoch: 220 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1138
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757290
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387615
INFO:root:FL Epoch: 220 Norm Difference for worker 1138 is 1.226809
INFO:root:FL Epoch: 220 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :105
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 105 is 1.21707
INFO:root:FL Epoch: 220 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :556
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639444
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772018
INFO:root:FL Epoch: 220 Norm Difference for worker 556 is 1.220637
INFO:root:FL Epoch: 220 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 933
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.5791732633815092 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:1.6878367861111958                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [206, 1838, 1157, 1297, 1567, 1220, 165, 1029, 1033, 1673]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :206
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 206 is 0.877699
INFO:root:FL Epoch: 221 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1838
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490101
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542660
INFO:root:FL Epoch: 221 Norm Difference for worker 1838 is 0.844225
INFO:root:FL Epoch: 221 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1157
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471692
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568364
INFO:root:FL Epoch: 221 Norm Difference for worker 1157 is 0.919061
INFO:root:FL Epoch: 221 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1297
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533211
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693220
INFO:root:FL Epoch: 221 Norm Difference for worker 1297 is 0.953621
INFO:root:FL Epoch: 221 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1567
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635044
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483047
INFO:root:FL Epoch: 221 Norm Difference for worker 1567 is 0.906433
INFO:root:FL Epoch: 221 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1220
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459042
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590131
INFO:root:FL Epoch: 221 Norm Difference for worker 1220 is 0.874386
INFO:root:FL Epoch: 221 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :165
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 165 is 0.884812
INFO:root:FL Epoch: 221 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1029
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579423
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485204
INFO:root:FL Epoch: 221 Norm Difference for worker 1029 is 0.934634
INFO:root:FL Epoch: 221 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1033
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780035
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365618
INFO:root:FL Epoch: 221 Norm Difference for worker 1033 is 0.852223
INFO:root:FL Epoch: 221 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1673
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645713
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564370
INFO:root:FL Epoch: 221 Norm Difference for worker 1673 is 0.901462
INFO:root:FL Epoch: 221 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.5861570011166966 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:1.9897707899411519                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1694, 747, 1202, 1705, 486, 1481, 1890, 1797, 109, 1939]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1694
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517158
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430191
INFO:root:FL Epoch: 222 Norm Difference for worker 1694 is 1.139336
INFO:root:FL Epoch: 222 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :747
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544343
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467871
INFO:root:FL Epoch: 222 Norm Difference for worker 747 is 1.130497
INFO:root:FL Epoch: 222 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1202
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663271
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389757
INFO:root:FL Epoch: 222 Norm Difference for worker 1202 is 1.099666
INFO:root:FL Epoch: 222 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1705
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440558
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539534
INFO:root:FL Epoch: 222 Norm Difference for worker 1705 is 1.127919
INFO:root:FL Epoch: 222 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :486
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514716
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600458
INFO:root:FL Epoch: 222 Norm Difference for worker 486 is 1.034531
INFO:root:FL Epoch: 222 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1481
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 1.081300
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485298
INFO:root:FL Epoch: 222 Norm Difference for worker 1481 is 1.256855
INFO:root:FL Epoch: 222 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1890
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858292
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649462
INFO:root:FL Epoch: 222 Norm Difference for worker 1890 is 1.092074
INFO:root:FL Epoch: 222 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1797
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818184
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441941
INFO:root:FL Epoch: 222 Norm Difference for worker 1797 is 1.112877
INFO:root:FL Epoch: 222 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :109
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478125
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 109 is 1.226679
INFO:root:FL Epoch: 222 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1939
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622368
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531772
INFO:root:FL Epoch: 222 Norm Difference for worker 1939 is 1.236067
INFO:root:FL Epoch: 222 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 486
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.5757359774673686 and Test Accuracy:70.0 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:1.7027904391288757                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [1594, 213, 1268, 453, 1684, 641, 203, 1701, 234, 614]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [200 201 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :1594
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546074
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542623
INFO:root:FL Epoch: 223 Norm Difference for worker 1594 is 0.947466
INFO:root:FL Epoch: 223 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :213
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 213 is 1.036176
INFO:root:FL Epoch: 223 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1268
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601965
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432312
INFO:root:FL Epoch: 223 Norm Difference for worker 1268 is 0.995185
INFO:root:FL Epoch: 223 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :453
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704624
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662024
INFO:root:FL Epoch: 223 Norm Difference for worker 453 is 1.026835
INFO:root:FL Epoch: 223 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1684
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396228
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480365
INFO:root:FL Epoch: 223 Norm Difference for worker 1684 is 1.053311
INFO:root:FL Epoch: 223 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :641
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325337
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529395
INFO:root:FL Epoch: 223 Norm Difference for worker 641 is 1.086957
INFO:root:FL Epoch: 223 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :203
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.767322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 203 is 1.038306
INFO:root:FL Epoch: 223 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1701
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494589
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452684
INFO:root:FL Epoch: 223 Norm Difference for worker 1701 is 0.958301
INFO:root:FL Epoch: 223 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :234
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 234 is 1.037902
INFO:root:FL Epoch: 223 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :614
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553538
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363284
INFO:root:FL Epoch: 223 Norm Difference for worker 614 is 1.040153
INFO:root:FL Epoch: 223 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.564259855186238 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:1.7438139120737712                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [417, 364, 1721, 194, 679, 1614, 1044, 1094, 1684, 350]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :417
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555584
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476861
INFO:root:FL Epoch: 224 Norm Difference for worker 417 is 1.000484
INFO:root:FL Epoch: 224 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :364
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516786
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448647
INFO:root:FL Epoch: 224 Norm Difference for worker 364 is 0.997413
INFO:root:FL Epoch: 224 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1721
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546899
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455122
INFO:root:FL Epoch: 224 Norm Difference for worker 1721 is 0.930582
INFO:root:FL Epoch: 224 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :194
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592175
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 194 is 0.930494
INFO:root:FL Epoch: 224 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :679
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427718
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352544
INFO:root:FL Epoch: 224 Norm Difference for worker 679 is 0.896385
INFO:root:FL Epoch: 224 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1614
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614343
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368091
INFO:root:FL Epoch: 224 Norm Difference for worker 1614 is 0.984653
INFO:root:FL Epoch: 224 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1044
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774059
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609531
INFO:root:FL Epoch: 224 Norm Difference for worker 1044 is 0.983036
INFO:root:FL Epoch: 224 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1094
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562444
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631995
INFO:root:FL Epoch: 224 Norm Difference for worker 1094 is 0.977943
INFO:root:FL Epoch: 224 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1684
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540781
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422851
INFO:root:FL Epoch: 224 Norm Difference for worker 1684 is 1.006167
INFO:root:FL Epoch: 224 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :350
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555981
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435749
INFO:root:FL Epoch: 224 Norm Difference for worker 350 is 0.955775
INFO:root:FL Epoch: 224 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1721
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.556141685037052 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:1.7587537964185078                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [1638, 789, 1439, 1407, 618, 102, 1487, 657, 1440, 1016]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 225 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :1638
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727283
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314967
INFO:root:FL Epoch: 225 Norm Difference for worker 1638 is 1.0012
INFO:root:FL Epoch: 225 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :789
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677749
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559512
INFO:root:FL Epoch: 225 Norm Difference for worker 789 is 0.946754
INFO:root:FL Epoch: 225 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1439
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625601
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445748
INFO:root:FL Epoch: 225 Norm Difference for worker 1439 is 1.001889
INFO:root:FL Epoch: 225 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1407
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554592
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538332
INFO:root:FL Epoch: 225 Norm Difference for worker 1407 is 0.958737
INFO:root:FL Epoch: 225 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :618
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603223
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535904
INFO:root:FL Epoch: 225 Norm Difference for worker 618 is 0.965911
INFO:root:FL Epoch: 225 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :102
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608492
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 102 is 1.003524
INFO:root:FL Epoch: 225 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1487
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617122
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629658
INFO:root:FL Epoch: 225 Norm Difference for worker 1487 is 1.006881
INFO:root:FL Epoch: 225 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :657
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453164
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547063
INFO:root:FL Epoch: 225 Norm Difference for worker 657 is 0.970268
INFO:root:FL Epoch: 225 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1440
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522244
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493205
INFO:root:FL Epoch: 225 Norm Difference for worker 1440 is 0.936128
INFO:root:FL Epoch: 225 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1016
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487543
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469378
INFO:root:FL Epoch: 225 Norm Difference for worker 1016 is 0.970838
INFO:root:FL Epoch: 225 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 789
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.5534476988455829 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:1.983575125535329                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [316, 1393, 84, 1324, 1943, 1264, 991, 837, 1044, 360]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :316
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.282729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 316 is 1.052545
INFO:root:FL Epoch: 226 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1393
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443877
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678002
INFO:root:FL Epoch: 226 Norm Difference for worker 1393 is 1.036642
INFO:root:FL Epoch: 226 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :84
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 84 is 1.06533
INFO:root:FL Epoch: 226 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1324
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526242
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624647
INFO:root:FL Epoch: 226 Norm Difference for worker 1324 is 1.018765
INFO:root:FL Epoch: 226 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1943
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507051
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555306
INFO:root:FL Epoch: 226 Norm Difference for worker 1943 is 1.110884
INFO:root:FL Epoch: 226 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1264
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482209
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536535
INFO:root:FL Epoch: 226 Norm Difference for worker 1264 is 1.047364
INFO:root:FL Epoch: 226 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :991
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633000
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429855
INFO:root:FL Epoch: 226 Norm Difference for worker 991 is 1.0206
INFO:root:FL Epoch: 226 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :837
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319733
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479710
INFO:root:FL Epoch: 226 Norm Difference for worker 837 is 1.082944
INFO:root:FL Epoch: 226 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1044
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586604
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464040
INFO:root:FL Epoch: 226 Norm Difference for worker 1044 is 1.021708
INFO:root:FL Epoch: 226 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :360
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862429
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567456
INFO:root:FL Epoch: 226 Norm Difference for worker 360 is 1.051677
INFO:root:FL Epoch: 226 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 991
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.544181557262645 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:1.5099886655807495                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [748, 1560, 759, 1804, 1267, 1755, 1237, 177, 1195, 206]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 227 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :748
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778907
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530327
INFO:root:FL Epoch: 227 Norm Difference for worker 748 is 0.951907
INFO:root:FL Epoch: 227 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1560
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517312
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555423
INFO:root:FL Epoch: 227 Norm Difference for worker 1560 is 1.001768
INFO:root:FL Epoch: 227 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :759
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453220
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635256
INFO:root:FL Epoch: 227 Norm Difference for worker 759 is 0.918959
INFO:root:FL Epoch: 227 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1804
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579182
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571853
INFO:root:FL Epoch: 227 Norm Difference for worker 1804 is 0.962909
INFO:root:FL Epoch: 227 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1267
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359356
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410596
INFO:root:FL Epoch: 227 Norm Difference for worker 1267 is 0.916762
INFO:root:FL Epoch: 227 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1755
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532757
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425766
INFO:root:FL Epoch: 227 Norm Difference for worker 1755 is 0.996989
INFO:root:FL Epoch: 227 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1237
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618269
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583621
INFO:root:FL Epoch: 227 Norm Difference for worker 1237 is 0.903675
INFO:root:FL Epoch: 227 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :177
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631459
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 177 is 0.961732
INFO:root:FL Epoch: 227 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1195
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494521
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542002
INFO:root:FL Epoch: 227 Norm Difference for worker 1195 is 0.91794
INFO:root:FL Epoch: 227 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :206
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 206 is 0.91015
INFO:root:FL Epoch: 227 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 206
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.554463547818801 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:1.945130745569865                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [1553, 1469, 302, 449, 575, 446, 1900, 1809, 641, 317]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :1553
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608846
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707116
INFO:root:FL Epoch: 228 Norm Difference for worker 1553 is 1.04373
INFO:root:FL Epoch: 228 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1469
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668330
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.775965
INFO:root:FL Epoch: 228 Norm Difference for worker 1469 is 1.071263
INFO:root:FL Epoch: 228 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :302
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460404
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 302 is 1.062837
INFO:root:FL Epoch: 228 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :449
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396729
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373689
INFO:root:FL Epoch: 228 Norm Difference for worker 449 is 0.987367
INFO:root:FL Epoch: 228 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :575
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657482
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407178
INFO:root:FL Epoch: 228 Norm Difference for worker 575 is 1.113357
INFO:root:FL Epoch: 228 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :446
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353742
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470044
INFO:root:FL Epoch: 228 Norm Difference for worker 446 is 1.003913
INFO:root:FL Epoch: 228 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1900
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396436
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427632
INFO:root:FL Epoch: 228 Norm Difference for worker 1900 is 1.000359
INFO:root:FL Epoch: 228 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1809
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596817
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573124
INFO:root:FL Epoch: 228 Norm Difference for worker 1809 is 1.071177
INFO:root:FL Epoch: 228 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :641
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596515
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458039
INFO:root:FL Epoch: 228 Norm Difference for worker 641 is 1.04002
INFO:root:FL Epoch: 228 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :317
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664486
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 228 Norm Difference for worker 317 is 1.010991
INFO:root:FL Epoch: 228 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 449
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.5517894643194535 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:1.7193662524223328                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [361, 799, 463, 461, 723, 647, 1547, 835, 1060, 58]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :361
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473563
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451320
INFO:root:FL Epoch: 229 Norm Difference for worker 361 is 0.967843
INFO:root:FL Epoch: 229 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :799
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432952
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421801
INFO:root:FL Epoch: 229 Norm Difference for worker 799 is 0.983902
INFO:root:FL Epoch: 229 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :463
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792539
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515711
INFO:root:FL Epoch: 229 Norm Difference for worker 463 is 1.036107
INFO:root:FL Epoch: 229 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :461
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570783
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397564
INFO:root:FL Epoch: 229 Norm Difference for worker 461 is 0.937115
INFO:root:FL Epoch: 229 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :723
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505515
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436203
INFO:root:FL Epoch: 229 Norm Difference for worker 723 is 0.896132
INFO:root:FL Epoch: 229 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :647
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389052
INFO:root:Worker: 647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563638
INFO:root:FL Epoch: 229 Norm Difference for worker 647 is 0.996066
INFO:root:FL Epoch: 229 Done on worker:647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1547
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481264
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636730
INFO:root:FL Epoch: 229 Norm Difference for worker 1547 is 0.984046
INFO:root:FL Epoch: 229 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :835
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636259
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562652
INFO:root:FL Epoch: 229 Norm Difference for worker 835 is 0.991663
INFO:root:FL Epoch: 229 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1060
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737988
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.869957
INFO:root:FL Epoch: 229 Norm Difference for worker 1060 is 1.00983
INFO:root:FL Epoch: 229 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :58
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 58 is 1.003802
INFO:root:FL Epoch: 229 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.5656280184493345 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:1.9838555455207825                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [894, 1368, 1434, 1545, 1537, 1656, 1023, 118, 1117, 523]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :894
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526846
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540741
INFO:root:FL Epoch: 230 Norm Difference for worker 894 is 1.015762
INFO:root:FL Epoch: 230 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1368
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502873
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388919
INFO:root:FL Epoch: 230 Norm Difference for worker 1368 is 1.065121
INFO:root:FL Epoch: 230 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1434
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584550
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342852
INFO:root:FL Epoch: 230 Norm Difference for worker 1434 is 1.125602
INFO:root:FL Epoch: 230 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1545
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825430
INFO:root:Worker: 1545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404434
INFO:root:FL Epoch: 230 Norm Difference for worker 1545 is 1.01848
INFO:root:FL Epoch: 230 Done on worker:1545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1537
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582533
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456654
INFO:root:FL Epoch: 230 Norm Difference for worker 1537 is 1.172961
INFO:root:FL Epoch: 230 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1656
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721478
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459302
INFO:root:FL Epoch: 230 Norm Difference for worker 1656 is 1.013295
INFO:root:FL Epoch: 230 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1023
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671931
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545086
INFO:root:FL Epoch: 230 Norm Difference for worker 1023 is 1.005875
INFO:root:FL Epoch: 230 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :118
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 118 is 1.001393
INFO:root:FL Epoch: 230 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1117
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699332
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328103
INFO:root:FL Epoch: 230 Norm Difference for worker 1117 is 0.992845
INFO:root:FL Epoch: 230 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :523
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722111
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658710
INFO:root:FL Epoch: 230 Norm Difference for worker 523 is 1.127705
INFO:root:FL Epoch: 230 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 118
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.5733515804304796 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:2.07756644487381                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [1603, 1576, 1203, 1078, 694, 807, 497, 1584, 871, 793]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :1603
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443461
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584718
INFO:root:FL Epoch: 231 Norm Difference for worker 1603 is 0.98682
INFO:root:FL Epoch: 231 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1576
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490157
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565302
INFO:root:FL Epoch: 231 Norm Difference for worker 1576 is 1.088683
INFO:root:FL Epoch: 231 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1203
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758473
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534158
INFO:root:FL Epoch: 231 Norm Difference for worker 1203 is 1.11895
INFO:root:FL Epoch: 231 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1078
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690380
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592724
INFO:root:FL Epoch: 231 Norm Difference for worker 1078 is 1.073039
INFO:root:FL Epoch: 231 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :694
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637049
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409619
INFO:root:FL Epoch: 231 Norm Difference for worker 694 is 1.060279
INFO:root:FL Epoch: 231 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :807
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582568
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423892
INFO:root:FL Epoch: 231 Norm Difference for worker 807 is 1.145422
INFO:root:FL Epoch: 231 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :497
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581056
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510880
INFO:root:FL Epoch: 231 Norm Difference for worker 497 is 1.03207
INFO:root:FL Epoch: 231 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1584
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581622
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353138
INFO:root:FL Epoch: 231 Norm Difference for worker 1584 is 1.032698
INFO:root:FL Epoch: 231 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :871
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354793
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450552
INFO:root:FL Epoch: 231 Norm Difference for worker 871 is 1.112087
INFO:root:FL Epoch: 231 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :793
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469493
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601921
INFO:root:FL Epoch: 231 Norm Difference for worker 793 is 1.105235
INFO:root:FL Epoch: 231 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1603
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.5540231746785781 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:2.160584012667338                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [291, 477, 602, 1680, 495, 809, 553, 1782, 1013, 1351]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.375782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 291 is 1.00902
INFO:root:FL Epoch: 232 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :477
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380192
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178182
INFO:root:FL Epoch: 232 Norm Difference for worker 477 is 0.928797
INFO:root:FL Epoch: 232 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :602
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322417
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496771
INFO:root:FL Epoch: 232 Norm Difference for worker 602 is 1.101446
INFO:root:FL Epoch: 232 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1680
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693510
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501481
INFO:root:FL Epoch: 232 Norm Difference for worker 1680 is 1.124958
INFO:root:FL Epoch: 232 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :495
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502495
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487466
INFO:root:FL Epoch: 232 Norm Difference for worker 495 is 1.050766
INFO:root:FL Epoch: 232 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :809
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306148
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668075
INFO:root:FL Epoch: 232 Norm Difference for worker 809 is 1.066018
INFO:root:FL Epoch: 232 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :553
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398057
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515096
INFO:root:FL Epoch: 232 Norm Difference for worker 553 is 1.010951
INFO:root:FL Epoch: 232 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1782
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498223
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430253
INFO:root:FL Epoch: 232 Norm Difference for worker 1782 is 1.108558
INFO:root:FL Epoch: 232 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1013
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637533
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559322
INFO:root:FL Epoch: 232 Norm Difference for worker 1013 is 1.124071
INFO:root:FL Epoch: 232 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1351
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479122
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564537
INFO:root:FL Epoch: 232 Norm Difference for worker 1351 is 1.152222
INFO:root:FL Epoch: 232 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 553
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.5402939407264485 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:2.1393317381540933                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [455, 1250, 903, 1709, 1341, 1842, 1507, 1622, 1891, 665]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :455
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675839
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627329
INFO:root:FL Epoch: 233 Norm Difference for worker 455 is 1.19881
INFO:root:FL Epoch: 233 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1250
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452102
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361002
INFO:root:FL Epoch: 233 Norm Difference for worker 1250 is 1.076788
INFO:root:FL Epoch: 233 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :903
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452703
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509991
INFO:root:FL Epoch: 233 Norm Difference for worker 903 is 1.053114
INFO:root:FL Epoch: 233 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1709
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628346
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524784
INFO:root:FL Epoch: 233 Norm Difference for worker 1709 is 1.084804
INFO:root:FL Epoch: 233 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1341
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687414
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561125
INFO:root:FL Epoch: 233 Norm Difference for worker 1341 is 1.075915
INFO:root:FL Epoch: 233 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1842
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511340
INFO:root:Worker: 1842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427210
INFO:root:FL Epoch: 233 Norm Difference for worker 1842 is 0.998481
INFO:root:FL Epoch: 233 Done on worker:1842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1507
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607486
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497363
INFO:root:FL Epoch: 233 Norm Difference for worker 1507 is 1.081673
INFO:root:FL Epoch: 233 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1622
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833205
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577223
INFO:root:FL Epoch: 233 Norm Difference for worker 1622 is 1.052151
INFO:root:FL Epoch: 233 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1891
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724497
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408722
INFO:root:FL Epoch: 233 Norm Difference for worker 1891 is 1.069603
INFO:root:FL Epoch: 233 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :665
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556060
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462329
INFO:root:FL Epoch: 233 Norm Difference for worker 665 is 1.088041
INFO:root:FL Epoch: 233 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1842
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.5476806233910954 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:2.0828124284744263                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [212, 1398, 618, 1516, 1638, 1927, 705, 1553, 341, 819]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :212
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 212 is 1.009787
INFO:root:FL Epoch: 234 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1398
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485059
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400571
INFO:root:FL Epoch: 234 Norm Difference for worker 1398 is 0.954715
INFO:root:FL Epoch: 234 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :618
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718184
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626285
INFO:root:FL Epoch: 234 Norm Difference for worker 618 is 0.965599
INFO:root:FL Epoch: 234 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1516
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609018
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532911
INFO:root:FL Epoch: 234 Norm Difference for worker 1516 is 0.946176
INFO:root:FL Epoch: 234 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1638
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380936
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466318
INFO:root:FL Epoch: 234 Norm Difference for worker 1638 is 0.956833
INFO:root:FL Epoch: 234 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1927
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723169
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422503
INFO:root:FL Epoch: 234 Norm Difference for worker 1927 is 0.941638
INFO:root:FL Epoch: 234 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :705
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522872
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490744
INFO:root:FL Epoch: 234 Norm Difference for worker 705 is 0.895531
INFO:root:FL Epoch: 234 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1553
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748939
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544595
INFO:root:FL Epoch: 234 Norm Difference for worker 1553 is 0.965039
INFO:root:FL Epoch: 234 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :341
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814244
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568242
INFO:root:FL Epoch: 234 Norm Difference for worker 341 is 0.990584
INFO:root:FL Epoch: 234 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :819
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702866
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417486
INFO:root:FL Epoch: 234 Norm Difference for worker 819 is 0.928075
INFO:root:FL Epoch: 234 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 705
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.5447877294876996 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:2.034631152947744                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [503, 31, 249, 1083, 1700, 838, 1141, 180, 192, 313]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.10024938 0.10024938 0.10024938]
INFO:root:FL Epoch: 235 Num points on workers: [200 201 201 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :503
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531355
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487163
INFO:root:FL Epoch: 235 Norm Difference for worker 503 is 0.888705
INFO:root:FL Epoch: 235 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :31
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 31 is 0.951483
INFO:root:FL Epoch: 235 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :249
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 249 is 0.896485
INFO:root:FL Epoch: 235 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1083
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355320
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406050
INFO:root:FL Epoch: 235 Norm Difference for worker 1083 is 0.99735
INFO:root:FL Epoch: 235 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1700
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585912
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338076
INFO:root:FL Epoch: 235 Norm Difference for worker 1700 is 0.959628
INFO:root:FL Epoch: 235 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :838
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527481
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698756
INFO:root:FL Epoch: 235 Norm Difference for worker 838 is 0.98756
INFO:root:FL Epoch: 235 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1141
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455879
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417378
INFO:root:FL Epoch: 235 Norm Difference for worker 1141 is 0.966602
INFO:root:FL Epoch: 235 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.360051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 180 is 0.946495
INFO:root:FL Epoch: 235 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :192
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631636
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 192 is 0.981584
INFO:root:FL Epoch: 235 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :313
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 313 is 1.006876
INFO:root:FL Epoch: 235 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 503
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.5411611374686746 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:2.1922274430592856                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [335, 298, 831, 61, 1401, 737, 1219, 1494, 542, 356]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 236 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :335
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 335 is 1.138703
INFO:root:FL Epoch: 236 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :298
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 298 is 0.984551
INFO:root:FL Epoch: 236 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :831
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608743
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344182
INFO:root:FL Epoch: 236 Norm Difference for worker 831 is 1.079872
INFO:root:FL Epoch: 236 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :61
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447843
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 61 is 1.084339
INFO:root:FL Epoch: 236 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1401
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596769
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.828695
INFO:root:FL Epoch: 236 Norm Difference for worker 1401 is 1.05098
INFO:root:FL Epoch: 236 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :737
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733504
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543596
INFO:root:FL Epoch: 236 Norm Difference for worker 737 is 1.14405
INFO:root:FL Epoch: 236 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1219
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643008
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463509
INFO:root:FL Epoch: 236 Norm Difference for worker 1219 is 1.078957
INFO:root:FL Epoch: 236 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1494
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539285
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464788
INFO:root:FL Epoch: 236 Norm Difference for worker 1494 is 1.013942
INFO:root:FL Epoch: 236 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :542
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645316
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508664
INFO:root:FL Epoch: 236 Norm Difference for worker 542 is 0.968136
INFO:root:FL Epoch: 236 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412993
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284378
INFO:root:FL Epoch: 236 Norm Difference for worker 356 is 1.022207
INFO:root:FL Epoch: 236 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 298
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.5289085559985217 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:1.8996169567108154                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [329, 928, 884, 554, 731, 390, 596, 937, 1296, 1768]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :329
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 329 is 0.964852
INFO:root:FL Epoch: 237 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :928
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726820
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412765
INFO:root:FL Epoch: 237 Norm Difference for worker 928 is 0.931744
INFO:root:FL Epoch: 237 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :884
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662648
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406669
INFO:root:FL Epoch: 237 Norm Difference for worker 884 is 0.962978
INFO:root:FL Epoch: 237 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :554
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388931
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516902
INFO:root:FL Epoch: 237 Norm Difference for worker 554 is 0.965103
INFO:root:FL Epoch: 237 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :731
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523535
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473466
INFO:root:FL Epoch: 237 Norm Difference for worker 731 is 0.954101
INFO:root:FL Epoch: 237 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :390
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 1.009499
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712578
INFO:root:FL Epoch: 237 Norm Difference for worker 390 is 0.948741
INFO:root:FL Epoch: 237 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :596
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570071
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396054
INFO:root:FL Epoch: 237 Norm Difference for worker 596 is 0.970147
INFO:root:FL Epoch: 237 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :937
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419543
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588270
INFO:root:FL Epoch: 237 Norm Difference for worker 937 is 0.966767
INFO:root:FL Epoch: 237 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1296
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466372
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.842581
INFO:root:FL Epoch: 237 Norm Difference for worker 1296 is 0.969296
INFO:root:FL Epoch: 237 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1768
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662711
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690387
INFO:root:FL Epoch: 237 Norm Difference for worker 1768 is 0.96224
INFO:root:FL Epoch: 237 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 928
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.5215505887480343 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:2.0658883452415466                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [397, 5, 1913, 759, 946, 700, 593, 1313, 1300, 55]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 238 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :397
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565040
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496690
INFO:root:FL Epoch: 238 Norm Difference for worker 397 is 1.007072
INFO:root:FL Epoch: 238 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :5
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710855
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 5 is 0.987916
INFO:root:FL Epoch: 238 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1913
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797635
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418879
INFO:root:FL Epoch: 238 Norm Difference for worker 1913 is 0.994403
INFO:root:FL Epoch: 238 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :759
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502755
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687188
INFO:root:FL Epoch: 238 Norm Difference for worker 759 is 1.0172
INFO:root:FL Epoch: 238 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :946
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363050
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478820
INFO:root:FL Epoch: 238 Norm Difference for worker 946 is 0.995043
INFO:root:FL Epoch: 238 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :700
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600999
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503719
INFO:root:FL Epoch: 238 Norm Difference for worker 700 is 1.008195
INFO:root:FL Epoch: 238 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :593
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678061
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592619
INFO:root:FL Epoch: 238 Norm Difference for worker 593 is 1.095214
INFO:root:FL Epoch: 238 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1313
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556385
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325325
INFO:root:FL Epoch: 238 Norm Difference for worker 1313 is 1.048278
INFO:root:FL Epoch: 238 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1300
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544234
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356994
INFO:root:FL Epoch: 238 Norm Difference for worker 1300 is 1.007738
INFO:root:FL Epoch: 238 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :55
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 55 is 0.967305
INFO:root:FL Epoch: 238 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.5333542595891392 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:2.297775904337565                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [57, 1529, 1243, 1297, 46, 1843, 562, 291, 1628, 824]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :57
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396030
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.634793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 57 is 1.09489
INFO:root:FL Epoch: 239 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1529
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467073
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501514
INFO:root:FL Epoch: 239 Norm Difference for worker 1529 is 1.033763
INFO:root:FL Epoch: 239 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1243
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.923040
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416258
INFO:root:FL Epoch: 239 Norm Difference for worker 1243 is 1.123311
INFO:root:FL Epoch: 239 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1297
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913574
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630863
INFO:root:FL Epoch: 239 Norm Difference for worker 1297 is 1.320395
INFO:root:FL Epoch: 239 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :46
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 46 is 0.963536
INFO:root:FL Epoch: 239 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1843
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388212
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452446
INFO:root:FL Epoch: 239 Norm Difference for worker 1843 is 1.035799
INFO:root:FL Epoch: 239 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :562
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607848
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657978
INFO:root:FL Epoch: 239 Norm Difference for worker 562 is 1.242317
INFO:root:FL Epoch: 239 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :291
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.398706
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 291 is 1.049002
INFO:root:FL Epoch: 239 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1628
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408097
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352117
INFO:root:FL Epoch: 239 Norm Difference for worker 1628 is 1.253947
INFO:root:FL Epoch: 239 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :824
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744426
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.831422
INFO:root:FL Epoch: 239 Norm Difference for worker 824 is 1.061559
INFO:root:FL Epoch: 239 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 291
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.5144006785224465 and Test Accuracy:75.0 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:1.849786897500356                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1245, 1184, 1095, 1943, 822, 572, 1650, 846, 1852, 682]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1245
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420763
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595001
INFO:root:FL Epoch: 240 Norm Difference for worker 1245 is 0.919235
INFO:root:FL Epoch: 240 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1184
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433770
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573382
INFO:root:FL Epoch: 240 Norm Difference for worker 1184 is 0.903589
INFO:root:FL Epoch: 240 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1095
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576400
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487697
INFO:root:FL Epoch: 240 Norm Difference for worker 1095 is 0.854415
INFO:root:FL Epoch: 240 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1943
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881968
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474205
INFO:root:FL Epoch: 240 Norm Difference for worker 1943 is 0.903897
INFO:root:FL Epoch: 240 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :822
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323248
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507227
INFO:root:FL Epoch: 240 Norm Difference for worker 822 is 0.86966
INFO:root:FL Epoch: 240 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :572
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606012
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495122
INFO:root:FL Epoch: 240 Norm Difference for worker 572 is 0.890501
INFO:root:FL Epoch: 240 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1650
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676234
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591543
INFO:root:FL Epoch: 240 Norm Difference for worker 1650 is 0.869773
INFO:root:FL Epoch: 240 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :846
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530891
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389913
INFO:root:FL Epoch: 240 Norm Difference for worker 846 is 0.859692
INFO:root:FL Epoch: 240 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1852
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736266
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588958
INFO:root:FL Epoch: 240 Norm Difference for worker 1852 is 0.840385
INFO:root:FL Epoch: 240 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :682
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699025
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505171
INFO:root:FL Epoch: 240 Norm Difference for worker 682 is 0.934509
INFO:root:FL Epoch: 240 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1852
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.5125872668098 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:1.7363351583480835                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [1620, 1147, 1718, 867, 1693, 204, 39, 320, 650, 250]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 201 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :1620
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474104
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603926
INFO:root:FL Epoch: 241 Norm Difference for worker 1620 is 0.897121
INFO:root:FL Epoch: 241 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1147
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650915
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618775
INFO:root:FL Epoch: 241 Norm Difference for worker 1147 is 0.945471
INFO:root:FL Epoch: 241 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1718
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688455
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516898
INFO:root:FL Epoch: 241 Norm Difference for worker 1718 is 0.855591
INFO:root:FL Epoch: 241 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :867
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481456
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454171
INFO:root:FL Epoch: 241 Norm Difference for worker 867 is 0.889625
INFO:root:FL Epoch: 241 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1693
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505486
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302715
INFO:root:FL Epoch: 241 Norm Difference for worker 1693 is 0.820602
INFO:root:FL Epoch: 241 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :204
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508308
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 204 is 0.878512
INFO:root:FL Epoch: 241 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :39
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605859
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 39 is 0.848398
INFO:root:FL Epoch: 241 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :320
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.588624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 320 is 0.875325
INFO:root:FL Epoch: 241 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :650
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577666
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.912483
INFO:root:FL Epoch: 241 Norm Difference for worker 650 is 0.867222
INFO:root:FL Epoch: 241 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :250
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.328687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 250 is 0.856055
INFO:root:FL Epoch: 241 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5091865062713623 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:1.9239157636960347                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1931, 1878, 979, 719, 1081, 127, 1018, 770, 1511, 83]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1931
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481414
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260781
INFO:root:FL Epoch: 242 Norm Difference for worker 1931 is 0.944291
INFO:root:FL Epoch: 242 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1878
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457508
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482648
INFO:root:FL Epoch: 242 Norm Difference for worker 1878 is 1.110758
INFO:root:FL Epoch: 242 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :979
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694919
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401141
INFO:root:FL Epoch: 242 Norm Difference for worker 979 is 1.038912
INFO:root:FL Epoch: 242 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :719
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567044
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651318
INFO:root:FL Epoch: 242 Norm Difference for worker 719 is 1.023499
INFO:root:FL Epoch: 242 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1081
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478929
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619362
INFO:root:FL Epoch: 242 Norm Difference for worker 1081 is 1.034442
INFO:root:FL Epoch: 242 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :127
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 127 is 0.994659
INFO:root:FL Epoch: 242 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1018
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704686
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670509
INFO:root:FL Epoch: 242 Norm Difference for worker 1018 is 1.057849
INFO:root:FL Epoch: 242 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :770
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595420
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562676
INFO:root:FL Epoch: 242 Norm Difference for worker 770 is 1.014533
INFO:root:FL Epoch: 242 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1511
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738316
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564909
INFO:root:FL Epoch: 242 Norm Difference for worker 1511 is 1.007346
INFO:root:FL Epoch: 242 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :83
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521660
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 83 is 0.933522
INFO:root:FL Epoch: 242 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 83
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.5146061111898983 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:1.896097222963969                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [267, 1195, 529, 1566, 853, 1728, 554, 464, 1940, 314]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 243 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :267
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 267 is 0.989903
INFO:root:FL Epoch: 243 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1195
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496106
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355413
INFO:root:FL Epoch: 243 Norm Difference for worker 1195 is 0.967821
INFO:root:FL Epoch: 243 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :529
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472544
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492261
INFO:root:FL Epoch: 243 Norm Difference for worker 529 is 0.943169
INFO:root:FL Epoch: 243 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1566
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732447
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549000
INFO:root:FL Epoch: 243 Norm Difference for worker 1566 is 0.898768
INFO:root:FL Epoch: 243 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :853
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908686
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701459
INFO:root:FL Epoch: 243 Norm Difference for worker 853 is 1.066481
INFO:root:FL Epoch: 243 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1728
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390357
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664776
INFO:root:FL Epoch: 243 Norm Difference for worker 1728 is 1.009071
INFO:root:FL Epoch: 243 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :554
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647952
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456428
INFO:root:FL Epoch: 243 Norm Difference for worker 554 is 0.962381
INFO:root:FL Epoch: 243 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :464
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321529
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346448
INFO:root:FL Epoch: 243 Norm Difference for worker 464 is 0.971315
INFO:root:FL Epoch: 243 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1940
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778978
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493315
INFO:root:FL Epoch: 243 Norm Difference for worker 1940 is 0.934899
INFO:root:FL Epoch: 243 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :314
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376726
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 314 is 0.989738
INFO:root:FL Epoch: 243 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.5249038110761082 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:1.4016899069150288                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [520, 174, 1420, 860, 1205, 1426, 1074, 1068, 84, 1105]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :520
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621648
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603440
INFO:root:FL Epoch: 244 Norm Difference for worker 520 is 0.85463
INFO:root:FL Epoch: 244 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :174
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 174 is 0.89242
INFO:root:FL Epoch: 244 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1420
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606754
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320045
INFO:root:FL Epoch: 244 Norm Difference for worker 1420 is 0.967307
INFO:root:FL Epoch: 244 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :860
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362996
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446075
INFO:root:FL Epoch: 244 Norm Difference for worker 860 is 0.863553
INFO:root:FL Epoch: 244 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1205
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353195
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390113
INFO:root:FL Epoch: 244 Norm Difference for worker 1205 is 0.904465
INFO:root:FL Epoch: 244 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1426
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602641
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503825
INFO:root:FL Epoch: 244 Norm Difference for worker 1426 is 0.955796
INFO:root:FL Epoch: 244 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1074
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469876
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613997
INFO:root:FL Epoch: 244 Norm Difference for worker 1074 is 0.896442
INFO:root:FL Epoch: 244 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1068
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521584
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434764
INFO:root:FL Epoch: 244 Norm Difference for worker 1068 is 0.942169
INFO:root:FL Epoch: 244 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :84
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305239
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 84 is 0.868345
INFO:root:FL Epoch: 244 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1105
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490874
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397276
INFO:root:FL Epoch: 244 Norm Difference for worker 1105 is 0.909662
INFO:root:FL Epoch: 244 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 520
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.5244313408346737 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:1.8200902541478474                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [247, 961, 1469, 1024, 1558, 943, 1320, 23, 1139, 1519]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 245 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :247
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 247 is 1.010011
INFO:root:FL Epoch: 245 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :961
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622284
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328453
INFO:root:FL Epoch: 245 Norm Difference for worker 961 is 0.933644
INFO:root:FL Epoch: 245 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1469
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649807
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367009
INFO:root:FL Epoch: 245 Norm Difference for worker 1469 is 0.946404
INFO:root:FL Epoch: 245 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1024
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587896
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576528
INFO:root:FL Epoch: 245 Norm Difference for worker 1024 is 0.909025
INFO:root:FL Epoch: 245 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1558
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807560
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526424
INFO:root:FL Epoch: 245 Norm Difference for worker 1558 is 0.912273
INFO:root:FL Epoch: 245 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :943
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610751
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348592
INFO:root:FL Epoch: 245 Norm Difference for worker 943 is 0.915268
INFO:root:FL Epoch: 245 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499207
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378213
INFO:root:FL Epoch: 245 Norm Difference for worker 1320 is 0.974043
INFO:root:FL Epoch: 245 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :23
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627763
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 23 is 0.981339
INFO:root:FL Epoch: 245 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1139
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417472
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523559
INFO:root:FL Epoch: 245 Norm Difference for worker 1139 is 0.95573
INFO:root:FL Epoch: 245 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1519
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806838
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540992
INFO:root:FL Epoch: 245 Norm Difference for worker 1519 is 0.904756
INFO:root:FL Epoch: 245 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 943
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.5400652675067678 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:1.6885934670766194                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [169, 1649, 1435, 1104, 908, 1761, 1040, 1132, 1431, 99]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 246 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :169
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650040
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 169 is 0.824358
INFO:root:FL Epoch: 246 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1649
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429073
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529972
INFO:root:FL Epoch: 246 Norm Difference for worker 1649 is 0.873928
INFO:root:FL Epoch: 246 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1435
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532518
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555963
INFO:root:FL Epoch: 246 Norm Difference for worker 1435 is 0.882925
INFO:root:FL Epoch: 246 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1104
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672665
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710418
INFO:root:FL Epoch: 246 Norm Difference for worker 1104 is 0.880202
INFO:root:FL Epoch: 246 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :908
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588214
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434379
INFO:root:FL Epoch: 246 Norm Difference for worker 908 is 0.883776
INFO:root:FL Epoch: 246 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1761
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600382
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575072
INFO:root:FL Epoch: 246 Norm Difference for worker 1761 is 0.845661
INFO:root:FL Epoch: 246 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1040
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548042
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446633
INFO:root:FL Epoch: 246 Norm Difference for worker 1040 is 0.920153
INFO:root:FL Epoch: 246 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1132
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641298
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341826
INFO:root:FL Epoch: 246 Norm Difference for worker 1132 is 0.82179
INFO:root:FL Epoch: 246 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1431
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453811
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537741
INFO:root:FL Epoch: 246 Norm Difference for worker 1431 is 0.863988
INFO:root:FL Epoch: 246 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :99
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 99 is 0.868582
INFO:root:FL Epoch: 246 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1132
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.5411211935912862 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:1.7890548706054688                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1691, 27, 1052, 1921, 1776, 1243, 1906, 672, 1073, 1097]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1691
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543048
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572519
INFO:root:FL Epoch: 247 Norm Difference for worker 1691 is 1.038482
INFO:root:FL Epoch: 247 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :27
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.295617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 27 is 0.903572
INFO:root:FL Epoch: 247 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1052
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619274
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611707
INFO:root:FL Epoch: 247 Norm Difference for worker 1052 is 0.897142
INFO:root:FL Epoch: 247 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1921
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502475
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611785
INFO:root:FL Epoch: 247 Norm Difference for worker 1921 is 0.946469
INFO:root:FL Epoch: 247 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1776
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520124
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649179
INFO:root:FL Epoch: 247 Norm Difference for worker 1776 is 0.936458
INFO:root:FL Epoch: 247 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1243
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479298
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508168
INFO:root:FL Epoch: 247 Norm Difference for worker 1243 is 0.931958
INFO:root:FL Epoch: 247 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1906
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571683
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603837
INFO:root:FL Epoch: 247 Norm Difference for worker 1906 is 0.9616
INFO:root:FL Epoch: 247 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :672
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430965
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573093
INFO:root:FL Epoch: 247 Norm Difference for worker 672 is 0.963877
INFO:root:FL Epoch: 247 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1073
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768154
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455120
INFO:root:FL Epoch: 247 Norm Difference for worker 1073 is 0.931596
INFO:root:FL Epoch: 247 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1097
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517825
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383736
INFO:root:FL Epoch: 247 Norm Difference for worker 1097 is 0.982439
INFO:root:FL Epoch: 247 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.5274044099976035 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:1.800649344921112                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [114, 435, 803, 700, 41, 559, 18, 1520, 1441, 1044]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :114
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 114 is 0.939245
INFO:root:FL Epoch: 248 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :435
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601443
INFO:root:Worker: 435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336130
INFO:root:FL Epoch: 248 Norm Difference for worker 435 is 0.920049
INFO:root:FL Epoch: 248 Done on worker:435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :803
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415053
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257974
INFO:root:FL Epoch: 248 Norm Difference for worker 803 is 0.907834
INFO:root:FL Epoch: 248 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :700
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560177
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542690
INFO:root:FL Epoch: 248 Norm Difference for worker 700 is 0.972421
INFO:root:FL Epoch: 248 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :41
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 41 is 0.953312
INFO:root:FL Epoch: 248 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :559
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789673
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476252
INFO:root:FL Epoch: 248 Norm Difference for worker 559 is 0.958068
INFO:root:FL Epoch: 248 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :18
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463009
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 18 is 0.957197
INFO:root:FL Epoch: 248 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1520
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446835
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307090
INFO:root:FL Epoch: 248 Norm Difference for worker 1520 is 0.976475
INFO:root:FL Epoch: 248 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1441
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482040
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579670
INFO:root:FL Epoch: 248 Norm Difference for worker 1441 is 0.922634
INFO:root:FL Epoch: 248 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1044
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494256
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276970
INFO:root:FL Epoch: 248 Norm Difference for worker 1044 is 0.904085
INFO:root:FL Epoch: 248 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 803
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.5248309023240033 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:1.9003946781158447                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [431, 1573, 1043, 1645, 1549, 1315, 1718, 1189, 569, 1179]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :431
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734414
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443496
INFO:root:FL Epoch: 249 Norm Difference for worker 431 is 0.986998
INFO:root:FL Epoch: 249 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1573
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544239
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542487
INFO:root:FL Epoch: 249 Norm Difference for worker 1573 is 0.996715
INFO:root:FL Epoch: 249 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1043
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475481
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692815
INFO:root:FL Epoch: 249 Norm Difference for worker 1043 is 1.095351
INFO:root:FL Epoch: 249 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1645
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627317
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543776
INFO:root:FL Epoch: 249 Norm Difference for worker 1645 is 1.178942
INFO:root:FL Epoch: 249 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1549
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591804
INFO:root:Worker: 1549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504880
INFO:root:FL Epoch: 249 Norm Difference for worker 1549 is 1.026353
INFO:root:FL Epoch: 249 Done on worker:1549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1315
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677039
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552146
INFO:root:FL Epoch: 249 Norm Difference for worker 1315 is 1.046833
INFO:root:FL Epoch: 249 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1718
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573158
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401228
INFO:root:FL Epoch: 249 Norm Difference for worker 1718 is 1.031871
INFO:root:FL Epoch: 249 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1189
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542251
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473848
INFO:root:FL Epoch: 249 Norm Difference for worker 1189 is 1.075561
INFO:root:FL Epoch: 249 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :569
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555851
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715211
INFO:root:FL Epoch: 249 Norm Difference for worker 569 is 1.19567
INFO:root:FL Epoch: 249 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1179
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513280
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362182
INFO:root:FL Epoch: 249 Norm Difference for worker 1179 is 0.987085
INFO:root:FL Epoch: 249 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 431
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.5216050814179813 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:1.5567187865575154                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [718, 65, 372, 1163, 741, 1082, 830, 895, 1337, 1608]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 250 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :718
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437342
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489330
INFO:root:FL Epoch: 250 Norm Difference for worker 718 is 0.884555
INFO:root:FL Epoch: 250 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :65
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 65 is 0.923332
INFO:root:FL Epoch: 250 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :372
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869343
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425399
INFO:root:FL Epoch: 250 Norm Difference for worker 372 is 0.915568
INFO:root:FL Epoch: 250 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1163
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581349
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430425
INFO:root:FL Epoch: 250 Norm Difference for worker 1163 is 0.925035
INFO:root:FL Epoch: 250 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :741
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416960
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570318
INFO:root:FL Epoch: 250 Norm Difference for worker 741 is 0.963757
INFO:root:FL Epoch: 250 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1082
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297787
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291417
INFO:root:FL Epoch: 250 Norm Difference for worker 1082 is 0.926528
INFO:root:FL Epoch: 250 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :830
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343662
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468192
INFO:root:FL Epoch: 250 Norm Difference for worker 830 is 1.072047
INFO:root:FL Epoch: 250 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :895
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439701
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459719
INFO:root:FL Epoch: 250 Norm Difference for worker 895 is 0.963027
INFO:root:FL Epoch: 250 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1337
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352355
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343576
INFO:root:FL Epoch: 250 Norm Difference for worker 1337 is 0.892115
INFO:root:FL Epoch: 250 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1608
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435243
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525574
INFO:root:FL Epoch: 250 Norm Difference for worker 1608 is 0.950086
INFO:root:FL Epoch: 250 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.5494984774028554 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:2.1042879025141397                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [1227, 593, 1295, 447, 153, 377, 1093, 216, 1338, 771]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :1227
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599682
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551953
INFO:root:FL Epoch: 251 Norm Difference for worker 1227 is 0.910826
INFO:root:FL Epoch: 251 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :593
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629820
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564456
INFO:root:FL Epoch: 251 Norm Difference for worker 593 is 0.973512
INFO:root:FL Epoch: 251 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1295
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460099
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468150
INFO:root:FL Epoch: 251 Norm Difference for worker 1295 is 0.864576
INFO:root:FL Epoch: 251 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :447
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635118
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577004
INFO:root:FL Epoch: 251 Norm Difference for worker 447 is 1.003691
INFO:root:FL Epoch: 251 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :153
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.841808
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 153 is 0.935653
INFO:root:FL Epoch: 251 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :377
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819205
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466679
INFO:root:FL Epoch: 251 Norm Difference for worker 377 is 1.016958
INFO:root:FL Epoch: 251 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1093
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488017
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486310
INFO:root:FL Epoch: 251 Norm Difference for worker 1093 is 0.972654
INFO:root:FL Epoch: 251 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :216
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 216 is 0.938719
INFO:root:FL Epoch: 251 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1338
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699929
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535071
INFO:root:FL Epoch: 251 Norm Difference for worker 1338 is 0.949398
INFO:root:FL Epoch: 251 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :771
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563344
INFO:root:Worker: 771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413956
INFO:root:FL Epoch: 251 Norm Difference for worker 771 is 0.912502
INFO:root:FL Epoch: 251 Done on worker:771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.5139309115269605 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:1.7822680473327637                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1259, 1413, 1692, 266, 1555, 1928, 1811, 790, 545, 1342]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1259
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578544
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380403
INFO:root:FL Epoch: 252 Norm Difference for worker 1259 is 1.006829
INFO:root:FL Epoch: 252 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1413
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445295
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405878
INFO:root:FL Epoch: 252 Norm Difference for worker 1413 is 0.960408
INFO:root:FL Epoch: 252 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1692
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924313
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732740
INFO:root:FL Epoch: 252 Norm Difference for worker 1692 is 1.050373
INFO:root:FL Epoch: 252 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :266
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 266 is 1.013865
INFO:root:FL Epoch: 252 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1555
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780284
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520838
INFO:root:FL Epoch: 252 Norm Difference for worker 1555 is 0.965841
INFO:root:FL Epoch: 252 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1928
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309109
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564126
INFO:root:FL Epoch: 252 Norm Difference for worker 1928 is 0.96805
INFO:root:FL Epoch: 252 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1811
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732144
INFO:root:Worker: 1811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604993
INFO:root:FL Epoch: 252 Norm Difference for worker 1811 is 1.032614
INFO:root:FL Epoch: 252 Done on worker:1811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :790
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460817
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425949
INFO:root:FL Epoch: 252 Norm Difference for worker 790 is 1.04803
INFO:root:FL Epoch: 252 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :545
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511624
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569965
INFO:root:FL Epoch: 252 Norm Difference for worker 545 is 1.033979
INFO:root:FL Epoch: 252 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1342
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528980
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698155
INFO:root:FL Epoch: 252 Norm Difference for worker 1342 is 0.995831
INFO:root:FL Epoch: 252 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1413
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.515048994737513 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:1.8877811829249065                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1372, 1474, 1252, 141, 738, 1705, 247, 502, 292, 1353]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1372
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532660
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506932
INFO:root:FL Epoch: 253 Norm Difference for worker 1372 is 1.006985
INFO:root:FL Epoch: 253 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1474
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338551
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391569
INFO:root:FL Epoch: 253 Norm Difference for worker 1474 is 1.093342
INFO:root:FL Epoch: 253 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1252
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756966
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412430
INFO:root:FL Epoch: 253 Norm Difference for worker 1252 is 1.033627
INFO:root:FL Epoch: 253 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :141
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.366276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 141 is 1.055696
INFO:root:FL Epoch: 253 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :738
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644850
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.814280
INFO:root:FL Epoch: 253 Norm Difference for worker 738 is 1.074339
INFO:root:FL Epoch: 253 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1705
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653415
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571036
INFO:root:FL Epoch: 253 Norm Difference for worker 1705 is 1.048361
INFO:root:FL Epoch: 253 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :247
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527628
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493431
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 247 is 1.13159
INFO:root:FL Epoch: 253 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :502
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569937
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288289
INFO:root:FL Epoch: 253 Norm Difference for worker 502 is 1.018797
INFO:root:FL Epoch: 253 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :292
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560588
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 292 is 1.079731
INFO:root:FL Epoch: 253 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1353
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485344
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544623
INFO:root:FL Epoch: 253 Norm Difference for worker 1353 is 1.003823
INFO:root:FL Epoch: 253 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 502
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.5109216448138741 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:1.8549511830012004                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [68, 94, 689, 1477, 1070, 1582, 1776, 832, 1863, 1467]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 254 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :68
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 68 is 1.011337
INFO:root:FL Epoch: 254 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :94
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 94 is 1.066998
INFO:root:FL Epoch: 254 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :689
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610127
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598793
INFO:root:FL Epoch: 254 Norm Difference for worker 689 is 1.040824
INFO:root:FL Epoch: 254 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1477
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629998
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366208
INFO:root:FL Epoch: 254 Norm Difference for worker 1477 is 1.029194
INFO:root:FL Epoch: 254 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1070
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471219
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712211
INFO:root:FL Epoch: 254 Norm Difference for worker 1070 is 1.137224
INFO:root:FL Epoch: 254 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1582
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821054
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525371
INFO:root:FL Epoch: 254 Norm Difference for worker 1582 is 1.089398
INFO:root:FL Epoch: 254 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1776
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502932
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538723
INFO:root:FL Epoch: 254 Norm Difference for worker 1776 is 1.035146
INFO:root:FL Epoch: 254 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :832
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307692
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371184
INFO:root:FL Epoch: 254 Norm Difference for worker 832 is 1.134265
INFO:root:FL Epoch: 254 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1863
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442760
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340581
INFO:root:FL Epoch: 254 Norm Difference for worker 1863 is 0.970069
INFO:root:FL Epoch: 254 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1467
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436048
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470488
INFO:root:FL Epoch: 254 Norm Difference for worker 1467 is 1.005537
INFO:root:FL Epoch: 254 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1863
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.5185061535414528 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:1.9352049032847087                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1102, 1672, 926, 413, 1636, 131, 1873, 815, 828, 1596]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1102
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592512
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470740
INFO:root:FL Epoch: 255 Norm Difference for worker 1102 is 1.128965
INFO:root:FL Epoch: 255 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1672
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541479
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523269
INFO:root:FL Epoch: 255 Norm Difference for worker 1672 is 1.09193
INFO:root:FL Epoch: 255 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :926
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506633
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263883
INFO:root:FL Epoch: 255 Norm Difference for worker 926 is 0.937844
INFO:root:FL Epoch: 255 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :413
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406223
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370630
INFO:root:FL Epoch: 255 Norm Difference for worker 413 is 1.130555
INFO:root:FL Epoch: 255 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1636
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485650
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656097
INFO:root:FL Epoch: 255 Norm Difference for worker 1636 is 1.093782
INFO:root:FL Epoch: 255 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :131
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 131 is 1.133148
INFO:root:FL Epoch: 255 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1873
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562983
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280870
INFO:root:FL Epoch: 255 Norm Difference for worker 1873 is 0.977431
INFO:root:FL Epoch: 255 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :815
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669176
INFO:root:Worker: 815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407800
INFO:root:FL Epoch: 255 Norm Difference for worker 815 is 1.020611
INFO:root:FL Epoch: 255 Done on worker:815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :828
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539013
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453822
INFO:root:FL Epoch: 255 Norm Difference for worker 828 is 1.144094
INFO:root:FL Epoch: 255 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1596
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627633
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643202
INFO:root:FL Epoch: 255 Norm Difference for worker 1596 is 1.047341
INFO:root:FL Epoch: 255 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.506411703193889 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:1.907878816127777                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [261, 404, 1937, 1391, 1542, 438, 175, 952, 1228, 1854]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :261
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436781
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 261 is 1.109091
INFO:root:FL Epoch: 256 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :404
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444274
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743886
INFO:root:FL Epoch: 256 Norm Difference for worker 404 is 1.08712
INFO:root:FL Epoch: 256 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1937
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485686
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630534
INFO:root:FL Epoch: 256 Norm Difference for worker 1937 is 1.086657
INFO:root:FL Epoch: 256 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1391
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780676
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402921
INFO:root:FL Epoch: 256 Norm Difference for worker 1391 is 1.074793
INFO:root:FL Epoch: 256 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1542
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477815
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508729
INFO:root:FL Epoch: 256 Norm Difference for worker 1542 is 0.989782
INFO:root:FL Epoch: 256 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :438
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281061
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507811
INFO:root:FL Epoch: 256 Norm Difference for worker 438 is 1.18197
INFO:root:FL Epoch: 256 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :175
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611675
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 175 is 1.027954
INFO:root:FL Epoch: 256 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :952
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533767
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385714
INFO:root:FL Epoch: 256 Norm Difference for worker 952 is 1.097015
INFO:root:FL Epoch: 256 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1228
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552143
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594490
INFO:root:FL Epoch: 256 Norm Difference for worker 1228 is 1.087252
INFO:root:FL Epoch: 256 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1854
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637049
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621141
INFO:root:FL Epoch: 256 Norm Difference for worker 1854 is 1.133913
INFO:root:FL Epoch: 256 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 175
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.5052239211166606 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:1.9912277857462566                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [346, 1922, 361, 38, 1879, 596, 1555, 1613, 287, 1898]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 257 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :346
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656586
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360817
INFO:root:FL Epoch: 257 Norm Difference for worker 346 is 0.874568
INFO:root:FL Epoch: 257 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1922
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758483
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405203
INFO:root:FL Epoch: 257 Norm Difference for worker 1922 is 0.9452
INFO:root:FL Epoch: 257 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :361
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599335
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389535
INFO:root:FL Epoch: 257 Norm Difference for worker 361 is 0.981262
INFO:root:FL Epoch: 257 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :38
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 38 is 0.92756
INFO:root:FL Epoch: 257 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1879
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392041
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532398
INFO:root:FL Epoch: 257 Norm Difference for worker 1879 is 1.084069
INFO:root:FL Epoch: 257 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :596
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671362
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272514
INFO:root:FL Epoch: 257 Norm Difference for worker 596 is 1.037005
INFO:root:FL Epoch: 257 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1555
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411798
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526078
INFO:root:FL Epoch: 257 Norm Difference for worker 1555 is 0.901294
INFO:root:FL Epoch: 257 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1613
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558585
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498428
INFO:root:FL Epoch: 257 Norm Difference for worker 1613 is 0.941636
INFO:root:FL Epoch: 257 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :287
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 287 is 0.876509
INFO:root:FL Epoch: 257 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1898
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515216
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468513
INFO:root:FL Epoch: 257 Norm Difference for worker 1898 is 0.948772
INFO:root:FL Epoch: 257 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 346
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.4998154184397529 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:2.15682860215505                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [824, 1617, 300, 180, 857, 1448, 210, 644, 812, 637]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 201 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :824
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570281
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384235
INFO:root:FL Epoch: 258 Norm Difference for worker 824 is 1.018546
INFO:root:FL Epoch: 258 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1617
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.923827
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491289
INFO:root:FL Epoch: 258 Norm Difference for worker 1617 is 1.090548
INFO:root:FL Epoch: 258 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :300
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588719
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 300 is 1.106407
INFO:root:FL Epoch: 258 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :180
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 180 is 0.948833
INFO:root:FL Epoch: 258 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :857
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445325
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446662
INFO:root:FL Epoch: 258 Norm Difference for worker 857 is 1.116912
INFO:root:FL Epoch: 258 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1448
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566063
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676801
INFO:root:FL Epoch: 258 Norm Difference for worker 1448 is 1.042471
INFO:root:FL Epoch: 258 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :210
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 210 is 1.029441
INFO:root:FL Epoch: 258 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :644
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552218
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656462
INFO:root:FL Epoch: 258 Norm Difference for worker 644 is 1.084118
INFO:root:FL Epoch: 258 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :812
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724711
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402080
INFO:root:FL Epoch: 258 Norm Difference for worker 812 is 1.007141
INFO:root:FL Epoch: 258 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :637
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.946647
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601728
INFO:root:FL Epoch: 258 Norm Difference for worker 637 is 1.071564
INFO:root:FL Epoch: 258 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 824
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.5101217960610109 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:1.9835217595100403                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [814, 732, 1617, 49, 1881, 308, 136, 1141, 1581, 835]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 259 Num points on workers: [200 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :814
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677199
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583723
INFO:root:FL Epoch: 259 Norm Difference for worker 814 is 0.94851
INFO:root:FL Epoch: 259 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :732
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535440
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458053
INFO:root:FL Epoch: 259 Norm Difference for worker 732 is 0.94125
INFO:root:FL Epoch: 259 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1617
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854511
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553471
INFO:root:FL Epoch: 259 Norm Difference for worker 1617 is 0.917375
INFO:root:FL Epoch: 259 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :49
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515587
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 49 is 0.934803
INFO:root:FL Epoch: 259 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1881
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448399
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586515
INFO:root:FL Epoch: 259 Norm Difference for worker 1881 is 0.939552
INFO:root:FL Epoch: 259 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :308
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 308 is 0.873708
INFO:root:FL Epoch: 259 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :136
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382255
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 136 is 0.936619
INFO:root:FL Epoch: 259 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1141
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462702
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344371
INFO:root:FL Epoch: 259 Norm Difference for worker 1141 is 0.943933
INFO:root:FL Epoch: 259 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1581
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316849
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551695
INFO:root:FL Epoch: 259 Norm Difference for worker 1581 is 0.935842
INFO:root:FL Epoch: 259 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :835
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546222
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359087
INFO:root:FL Epoch: 259 Norm Difference for worker 835 is 1.186235
INFO:root:FL Epoch: 259 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 308
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.49679889047847076 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:1.896919270356496                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1152, 819, 1764, 256, 1047, 1451, 36, 1896, 398, 1809]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1152
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491697
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397542
INFO:root:FL Epoch: 260 Norm Difference for worker 1152 is 0.968369
INFO:root:FL Epoch: 260 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :819
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748873
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496416
INFO:root:FL Epoch: 260 Norm Difference for worker 819 is 0.815599
INFO:root:FL Epoch: 260 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1764
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508454
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659753
INFO:root:FL Epoch: 260 Norm Difference for worker 1764 is 0.971818
INFO:root:FL Epoch: 260 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :256
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 256 is 0.927646
INFO:root:FL Epoch: 260 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1047
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531429
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.754411
INFO:root:FL Epoch: 260 Norm Difference for worker 1047 is 1.008814
INFO:root:FL Epoch: 260 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1451
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699078
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534758
INFO:root:FL Epoch: 260 Norm Difference for worker 1451 is 1.442027
INFO:root:FL Epoch: 260 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :36
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 36 is 0.921208
INFO:root:FL Epoch: 260 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1896
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459543
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540968
INFO:root:FL Epoch: 260 Norm Difference for worker 1896 is 1.241045
INFO:root:FL Epoch: 260 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :398
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670530
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447469
INFO:root:FL Epoch: 260 Norm Difference for worker 398 is 1.074687
INFO:root:FL Epoch: 260 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1809
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572932
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584703
INFO:root:FL Epoch: 260 Norm Difference for worker 1809 is 0.953593
INFO:root:FL Epoch: 260 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 819
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.5104959519470439 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:1.9488391876220703                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [681, 1657, 1897, 200, 915, 1870, 1037, 1696, 630, 101]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :681
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524706
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501605
INFO:root:FL Epoch: 261 Norm Difference for worker 681 is 0.901322
INFO:root:FL Epoch: 261 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1657
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627102
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507102
INFO:root:FL Epoch: 261 Norm Difference for worker 1657 is 0.935578
INFO:root:FL Epoch: 261 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1897
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700541
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598433
INFO:root:FL Epoch: 261 Norm Difference for worker 1897 is 0.890017
INFO:root:FL Epoch: 261 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :200
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649751
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 200 is 0.879496
INFO:root:FL Epoch: 261 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :915
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335945
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344386
INFO:root:FL Epoch: 261 Norm Difference for worker 915 is 1.37019
INFO:root:FL Epoch: 261 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1870
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728614
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534312
INFO:root:FL Epoch: 261 Norm Difference for worker 1870 is 0.894109
INFO:root:FL Epoch: 261 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1037
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503913
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480991
INFO:root:FL Epoch: 261 Norm Difference for worker 1037 is 0.944495
INFO:root:FL Epoch: 261 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1696
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608731
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548061
INFO:root:FL Epoch: 261 Norm Difference for worker 1696 is 1.190808
INFO:root:FL Epoch: 261 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :630
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650025
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574865
INFO:root:FL Epoch: 261 Norm Difference for worker 630 is 0.990931
INFO:root:FL Epoch: 261 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :101
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495056
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542691
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 101 is 1.235634
INFO:root:FL Epoch: 261 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1897
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.5168018288472119 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:1.8861213326454163                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1105, 223, 903, 1546, 892, 1246, 437, 598, 540, 1761]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 262 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1105
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630313
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361632
INFO:root:FL Epoch: 262 Norm Difference for worker 1105 is 0.916823
INFO:root:FL Epoch: 262 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :223
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 223 is 0.967559
INFO:root:FL Epoch: 262 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :903
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790064
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670445
INFO:root:FL Epoch: 262 Norm Difference for worker 903 is 0.914574
INFO:root:FL Epoch: 262 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1546
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725984
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496468
INFO:root:FL Epoch: 262 Norm Difference for worker 1546 is 0.911231
INFO:root:FL Epoch: 262 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :892
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690592
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535457
INFO:root:FL Epoch: 262 Norm Difference for worker 892 is 0.807632
INFO:root:FL Epoch: 262 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1246
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421582
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426370
INFO:root:FL Epoch: 262 Norm Difference for worker 1246 is 0.912788
INFO:root:FL Epoch: 262 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :437
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347900
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419733
INFO:root:FL Epoch: 262 Norm Difference for worker 437 is 0.880049
INFO:root:FL Epoch: 262 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :598
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334192
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492345
INFO:root:FL Epoch: 262 Norm Difference for worker 598 is 0.859256
INFO:root:FL Epoch: 262 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :540
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501227
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454061
INFO:root:FL Epoch: 262 Norm Difference for worker 540 is 0.884728
INFO:root:FL Epoch: 262 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1761
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455699
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668842
INFO:root:FL Epoch: 262 Norm Difference for worker 1761 is 0.86437
INFO:root:FL Epoch: 262 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 892
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.5208845944965587 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:1.8028888901074727                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [527, 1744, 1397, 1608, 898, 1855, 770, 1396, 104, 58]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :527
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544292
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471135
INFO:root:FL Epoch: 263 Norm Difference for worker 527 is 0.864504
INFO:root:FL Epoch: 263 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1744
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598951
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375289
INFO:root:FL Epoch: 263 Norm Difference for worker 1744 is 0.841276
INFO:root:FL Epoch: 263 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1397
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598658
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571018
INFO:root:FL Epoch: 263 Norm Difference for worker 1397 is 0.86112
INFO:root:FL Epoch: 263 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1608
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544727
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694136
INFO:root:FL Epoch: 263 Norm Difference for worker 1608 is 0.883798
INFO:root:FL Epoch: 263 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :898
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662202
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530989
INFO:root:FL Epoch: 263 Norm Difference for worker 898 is 0.896977
INFO:root:FL Epoch: 263 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1855
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526669
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392297
INFO:root:FL Epoch: 263 Norm Difference for worker 1855 is 0.882654
INFO:root:FL Epoch: 263 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :770
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511867
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474251
INFO:root:FL Epoch: 263 Norm Difference for worker 770 is 0.910849
INFO:root:FL Epoch: 263 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1396
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617959
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413590
INFO:root:FL Epoch: 263 Norm Difference for worker 1396 is 0.838433
INFO:root:FL Epoch: 263 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :104
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 104 is 0.861233
INFO:root:FL Epoch: 263 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :58
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 58 is 0.883227
INFO:root:FL Epoch: 263 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1396
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.5251543925088995 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:2.062799115975698                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1156, 135, 1940, 57, 1619, 1198, 1293, 773, 98, 924]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 264 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1156
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353543
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557273
INFO:root:FL Epoch: 264 Norm Difference for worker 1156 is 0.845031
INFO:root:FL Epoch: 264 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :135
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 135 is 0.847227
INFO:root:FL Epoch: 264 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1940
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575606
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607336
INFO:root:FL Epoch: 264 Norm Difference for worker 1940 is 0.859725
INFO:root:FL Epoch: 264 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :57
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629637
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 57 is 0.872241
INFO:root:FL Epoch: 264 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1619
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708073
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396890
INFO:root:FL Epoch: 264 Norm Difference for worker 1619 is 0.859534
INFO:root:FL Epoch: 264 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1198
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484705
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436604
INFO:root:FL Epoch: 264 Norm Difference for worker 1198 is 0.904198
INFO:root:FL Epoch: 264 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1293
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646358
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429723
INFO:root:FL Epoch: 264 Norm Difference for worker 1293 is 0.895369
INFO:root:FL Epoch: 264 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :773
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509845
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535171
INFO:root:FL Epoch: 264 Norm Difference for worker 773 is 0.861246
INFO:root:FL Epoch: 264 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :98
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658109
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 98 is 0.907466
INFO:root:FL Epoch: 264 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :924
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710293
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483392
INFO:root:FL Epoch: 264 Norm Difference for worker 924 is 0.954239
INFO:root:FL Epoch: 264 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 135
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.516792463905671 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:1.7784284353256226                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [910, 1182, 462, 479, 140, 101, 583, 33, 1471, 341]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 265 Num points on workers: [200 200 200 200 201 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :910
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394140
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706621
INFO:root:FL Epoch: 265 Norm Difference for worker 910 is 0.923403
INFO:root:FL Epoch: 265 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1182
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598010
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492825
INFO:root:FL Epoch: 265 Norm Difference for worker 1182 is 0.836291
INFO:root:FL Epoch: 265 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :462
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617008
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592077
INFO:root:FL Epoch: 265 Norm Difference for worker 462 is 0.847552
INFO:root:FL Epoch: 265 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :479
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540994
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659319
INFO:root:FL Epoch: 265 Norm Difference for worker 479 is 0.819715
INFO:root:FL Epoch: 265 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :140
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 140 is 0.836795
INFO:root:FL Epoch: 265 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :101
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620678
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 101 is 0.94891
INFO:root:FL Epoch: 265 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :583
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433460
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435401
INFO:root:FL Epoch: 265 Norm Difference for worker 583 is 0.855559
INFO:root:FL Epoch: 265 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :33
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 33 is 0.876097
INFO:root:FL Epoch: 265 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1471
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564262
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694077
INFO:root:FL Epoch: 265 Norm Difference for worker 1471 is 0.836291
INFO:root:FL Epoch: 265 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :341
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572173
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565726
INFO:root:FL Epoch: 265 Norm Difference for worker 341 is 0.855112
INFO:root:FL Epoch: 265 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 479
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.5092696231954238 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:1.7858721017837524                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1837, 55, 1847, 944, 626, 1010, 1067, 1905, 547, 1782]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 266 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1837
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440084
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313742
INFO:root:FL Epoch: 266 Norm Difference for worker 1837 is 0.876043
INFO:root:FL Epoch: 266 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :55
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 55 is 0.916005
INFO:root:FL Epoch: 266 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1847
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552264
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464518
INFO:root:FL Epoch: 266 Norm Difference for worker 1847 is 0.81547
INFO:root:FL Epoch: 266 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :944
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510815
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611039
INFO:root:FL Epoch: 266 Norm Difference for worker 944 is 0.837693
INFO:root:FL Epoch: 266 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :626
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392598
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470479
INFO:root:FL Epoch: 266 Norm Difference for worker 626 is 0.875498
INFO:root:FL Epoch: 266 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1010
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458004
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454403
INFO:root:FL Epoch: 266 Norm Difference for worker 1010 is 0.920932
INFO:root:FL Epoch: 266 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1067
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480227
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453538
INFO:root:FL Epoch: 266 Norm Difference for worker 1067 is 0.851798
INFO:root:FL Epoch: 266 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1905
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375949
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417255
INFO:root:FL Epoch: 266 Norm Difference for worker 1905 is 0.847142
INFO:root:FL Epoch: 266 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :547
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601654
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711667
INFO:root:FL Epoch: 266 Norm Difference for worker 547 is 0.817424
INFO:root:FL Epoch: 266 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1782
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429177
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411265
INFO:root:FL Epoch: 266 Norm Difference for worker 1782 is 0.87342
INFO:root:FL Epoch: 266 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.5259010984617121 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:2.63408629099528                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [1504, 1620, 920, 1587, 733, 1718, 13, 256, 684, 750]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :1504
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815143
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372641
INFO:root:FL Epoch: 267 Norm Difference for worker 1504 is 1.132561
INFO:root:FL Epoch: 267 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1620
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348038
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533332
INFO:root:FL Epoch: 267 Norm Difference for worker 1620 is 1.141948
INFO:root:FL Epoch: 267 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :920
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618105
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453762
INFO:root:FL Epoch: 267 Norm Difference for worker 920 is 1.166012
INFO:root:FL Epoch: 267 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1587
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599530
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473329
INFO:root:FL Epoch: 267 Norm Difference for worker 1587 is 1.160247
INFO:root:FL Epoch: 267 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :733
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762848
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348770
INFO:root:FL Epoch: 267 Norm Difference for worker 733 is 1.112416
INFO:root:FL Epoch: 267 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1718
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277623
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595301
INFO:root:FL Epoch: 267 Norm Difference for worker 1718 is 1.163562
INFO:root:FL Epoch: 267 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :13
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 13 is 1.131547
INFO:root:FL Epoch: 267 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :256
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 256 is 1.143753
INFO:root:FL Epoch: 267 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449892
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231602
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 1.087044
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :750
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515364
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432897
INFO:root:FL Epoch: 267 Norm Difference for worker 750 is 1.309497
INFO:root:FL Epoch: 267 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 733
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.5284049616140478 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:2.1402191321055093                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1802, 722, 91, 736, 318, 1808, 1400, 220, 229, 1086]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 201 200 201 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1802
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446409
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558953
INFO:root:FL Epoch: 268 Norm Difference for worker 1802 is 0.913879
INFO:root:FL Epoch: 268 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :722
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489473
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379351
INFO:root:FL Epoch: 268 Norm Difference for worker 722 is 0.916541
INFO:root:FL Epoch: 268 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :91
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512636
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 91 is 0.917131
INFO:root:FL Epoch: 268 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :736
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631399
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568545
INFO:root:FL Epoch: 268 Norm Difference for worker 736 is 0.912208
INFO:root:FL Epoch: 268 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :318
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.352124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 318 is 0.829324
INFO:root:FL Epoch: 268 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1808
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296016
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440371
INFO:root:FL Epoch: 268 Norm Difference for worker 1808 is 0.934114
INFO:root:FL Epoch: 268 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1400
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567731
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422279
INFO:root:FL Epoch: 268 Norm Difference for worker 1400 is 0.933872
INFO:root:FL Epoch: 268 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :220
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 220 is 0.830959
INFO:root:FL Epoch: 268 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :229
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 229 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 229 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 229 is 0.937436
INFO:root:FL Epoch: 268 Done on worker:229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1086
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536193
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562898
INFO:root:FL Epoch: 268 Norm Difference for worker 1086 is 0.837969
INFO:root:FL Epoch: 268 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.5128721682464376 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:1.8888023893038433                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [240, 994, 1108, 217, 1074, 737, 685, 1061, 968, 825]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :240
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 240 is 0.978526
INFO:root:FL Epoch: 269 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :994
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570112
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557332
INFO:root:FL Epoch: 269 Norm Difference for worker 994 is 0.883586
INFO:root:FL Epoch: 269 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1108
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539890
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449783
INFO:root:FL Epoch: 269 Norm Difference for worker 1108 is 0.915878
INFO:root:FL Epoch: 269 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :217
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.251625
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 217 is 0.945496
INFO:root:FL Epoch: 269 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1074
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559873
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554033
INFO:root:FL Epoch: 269 Norm Difference for worker 1074 is 0.941875
INFO:root:FL Epoch: 269 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :737
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760080
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583920
INFO:root:FL Epoch: 269 Norm Difference for worker 737 is 0.953215
INFO:root:FL Epoch: 269 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :685
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592544
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440648
INFO:root:FL Epoch: 269 Norm Difference for worker 685 is 0.924048
INFO:root:FL Epoch: 269 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1061
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572415
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413023
INFO:root:FL Epoch: 269 Norm Difference for worker 1061 is 0.857443
INFO:root:FL Epoch: 269 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :968
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575541
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327195
INFO:root:FL Epoch: 269 Norm Difference for worker 968 is 0.918067
INFO:root:FL Epoch: 269 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :825
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611979
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487751
INFO:root:FL Epoch: 269 Norm Difference for worker 825 is 0.925141
INFO:root:FL Epoch: 269 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.5246936205555411 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:2.4484510819117227                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [739, 1886, 312, 1113, 984, 1803, 285, 1739, 793, 1295]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :739
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823393
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367547
INFO:root:FL Epoch: 270 Norm Difference for worker 739 is 1.036814
INFO:root:FL Epoch: 270 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1886
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618153
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439246
INFO:root:FL Epoch: 270 Norm Difference for worker 1886 is 1.119348
INFO:root:FL Epoch: 270 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :312
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639675
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 312 is 1.073688
INFO:root:FL Epoch: 270 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1113
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658265
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474523
INFO:root:FL Epoch: 270 Norm Difference for worker 1113 is 1.083425
INFO:root:FL Epoch: 270 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :984
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495695
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325916
INFO:root:FL Epoch: 270 Norm Difference for worker 984 is 0.969021
INFO:root:FL Epoch: 270 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1803
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586821
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426672
INFO:root:FL Epoch: 270 Norm Difference for worker 1803 is 1.092635
INFO:root:FL Epoch: 270 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :285
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510964
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 285 is 1.072614
INFO:root:FL Epoch: 270 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1739
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607166
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381552
INFO:root:FL Epoch: 270 Norm Difference for worker 1739 is 0.960412
INFO:root:FL Epoch: 270 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :793
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354429
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486489
INFO:root:FL Epoch: 270 Norm Difference for worker 793 is 1.10268
INFO:root:FL Epoch: 270 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1295
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219569
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232854
INFO:root:FL Epoch: 270 Norm Difference for worker 1295 is 0.894713
INFO:root:FL Epoch: 270 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.5402254392119015 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:2.670328934987386                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [1287, 984, 1817, 1773, 1887, 741, 619, 1016, 37, 767]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :1287
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601515
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337484
INFO:root:FL Epoch: 271 Norm Difference for worker 1287 is 1.363301
INFO:root:FL Epoch: 271 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :984
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549656
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420896
INFO:root:FL Epoch: 271 Norm Difference for worker 984 is 1.171062
INFO:root:FL Epoch: 271 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1817
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466862
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465374
INFO:root:FL Epoch: 271 Norm Difference for worker 1817 is 1.168511
INFO:root:FL Epoch: 271 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1773
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419028
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489637
INFO:root:FL Epoch: 271 Norm Difference for worker 1773 is 1.269709
INFO:root:FL Epoch: 271 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1887
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544983
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390692
INFO:root:FL Epoch: 271 Norm Difference for worker 1887 is 1.231092
INFO:root:FL Epoch: 271 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :741
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598456
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456468
INFO:root:FL Epoch: 271 Norm Difference for worker 741 is 1.353288
INFO:root:FL Epoch: 271 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :619
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711501
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664418
INFO:root:FL Epoch: 271 Norm Difference for worker 619 is 1.282453
INFO:root:FL Epoch: 271 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1016
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479607
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516671
INFO:root:FL Epoch: 271 Norm Difference for worker 1016 is 1.272248
INFO:root:FL Epoch: 271 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :37
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 37 is 1.31238
INFO:root:FL Epoch: 271 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :767
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496010
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260741
INFO:root:FL Epoch: 271 Norm Difference for worker 767 is 1.241683
INFO:root:FL Epoch: 271 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 984
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.5327576714403489 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:1.9210351705551147                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [53, 1388, 1689, 1751, 1008, 452, 550, 1363, 1424, 1929]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 272 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :53
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536704
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 53 is 1.038682
INFO:root:FL Epoch: 272 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1388
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400343
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692645
INFO:root:FL Epoch: 272 Norm Difference for worker 1388 is 1.075821
INFO:root:FL Epoch: 272 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1689
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448859
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454952
INFO:root:FL Epoch: 272 Norm Difference for worker 1689 is 1.069913
INFO:root:FL Epoch: 272 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1751
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662702
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286408
INFO:root:FL Epoch: 272 Norm Difference for worker 1751 is 1.028698
INFO:root:FL Epoch: 272 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1008
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369768
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558384
INFO:root:FL Epoch: 272 Norm Difference for worker 1008 is 1.165101
INFO:root:FL Epoch: 272 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :452
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632258
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501169
INFO:root:FL Epoch: 272 Norm Difference for worker 452 is 1.011058
INFO:root:FL Epoch: 272 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :550
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645280
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586034
INFO:root:FL Epoch: 272 Norm Difference for worker 550 is 1.043324
INFO:root:FL Epoch: 272 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1363
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626936
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455316
INFO:root:FL Epoch: 272 Norm Difference for worker 1363 is 1.153199
INFO:root:FL Epoch: 272 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1424
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504083
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384123
INFO:root:FL Epoch: 272 Norm Difference for worker 1424 is 1.052847
INFO:root:FL Epoch: 272 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1929
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443547
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378201
INFO:root:FL Epoch: 272 Norm Difference for worker 1929 is 1.00426
INFO:root:FL Epoch: 272 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.5522234807996189 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:2.2056904236475625                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1074, 478, 141, 1311, 44, 456, 799, 370, 178, 424]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1074
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907917
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550298
INFO:root:FL Epoch: 273 Norm Difference for worker 1074 is 1.096104
INFO:root:FL Epoch: 273 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :478
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361254
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607196
INFO:root:FL Epoch: 273 Norm Difference for worker 478 is 1.17537
INFO:root:FL Epoch: 273 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :141
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 141 is 1.135653
INFO:root:FL Epoch: 273 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1311
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540828
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348957
INFO:root:FL Epoch: 273 Norm Difference for worker 1311 is 1.152328
INFO:root:FL Epoch: 273 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :44
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.389005
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 44 is 1.066664
INFO:root:FL Epoch: 273 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :456
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566740
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400366
INFO:root:FL Epoch: 273 Norm Difference for worker 456 is 1.049171
INFO:root:FL Epoch: 273 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :799
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602661
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363312
INFO:root:FL Epoch: 273 Norm Difference for worker 799 is 1.115416
INFO:root:FL Epoch: 273 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :370
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552235
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559724
INFO:root:FL Epoch: 273 Norm Difference for worker 370 is 1.009485
INFO:root:FL Epoch: 273 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :178
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 178 is 1.160028
INFO:root:FL Epoch: 273 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :424
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471481
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374580
INFO:root:FL Epoch: 273 Norm Difference for worker 424 is 0.935199
INFO:root:FL Epoch: 273 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.5742887311121997 and Test Accuracy:70.0 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:2.4411192735036216                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [137, 1518, 472, 917, 1285, 883, 186, 189, 75, 802]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 274 Num points on workers: [201 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :137
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 137 is 1.249093
INFO:root:FL Epoch: 274 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1518
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668392
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452327
INFO:root:FL Epoch: 274 Norm Difference for worker 1518 is 1.199528
INFO:root:FL Epoch: 274 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :472
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701049
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449343
INFO:root:FL Epoch: 274 Norm Difference for worker 472 is 1.317641
INFO:root:FL Epoch: 274 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :917
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719557
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497053
INFO:root:FL Epoch: 274 Norm Difference for worker 917 is 1.273639
INFO:root:FL Epoch: 274 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1285
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822280
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377310
INFO:root:FL Epoch: 274 Norm Difference for worker 1285 is 1.23133
INFO:root:FL Epoch: 274 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :883
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510997
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595480
INFO:root:FL Epoch: 274 Norm Difference for worker 883 is 1.275503
INFO:root:FL Epoch: 274 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :186
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 186 is 1.230743
INFO:root:FL Epoch: 274 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :189
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 189 is 1.296199
INFO:root:FL Epoch: 274 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :75
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 75 is 1.144134
INFO:root:FL Epoch: 274 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :802
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360137
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352623
INFO:root:FL Epoch: 274 Norm Difference for worker 802 is 1.168353
INFO:root:FL Epoch: 274 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.5979701192939982 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:2.4781665802001953                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [932, 1498, 1517, 890, 1615, 1460, 1388, 93, 1803, 1086]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :932
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436845
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492141
INFO:root:FL Epoch: 275 Norm Difference for worker 932 is 1.087223
INFO:root:FL Epoch: 275 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1498
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698751
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478022
INFO:root:FL Epoch: 275 Norm Difference for worker 1498 is 1.042801
INFO:root:FL Epoch: 275 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1517
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584404
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414488
INFO:root:FL Epoch: 275 Norm Difference for worker 1517 is 1.080463
INFO:root:FL Epoch: 275 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :890
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739686
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429944
INFO:root:FL Epoch: 275 Norm Difference for worker 890 is 1.125458
INFO:root:FL Epoch: 275 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1615
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637711
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477066
INFO:root:FL Epoch: 275 Norm Difference for worker 1615 is 1.053597
INFO:root:FL Epoch: 275 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1460
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638844
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426209
INFO:root:FL Epoch: 275 Norm Difference for worker 1460 is 1.063168
INFO:root:FL Epoch: 275 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1388
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659012
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588027
INFO:root:FL Epoch: 275 Norm Difference for worker 1388 is 1.086988
INFO:root:FL Epoch: 275 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :93
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 93 is 1.062955
INFO:root:FL Epoch: 275 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1803
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596536
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426811
INFO:root:FL Epoch: 275 Norm Difference for worker 1803 is 1.129288
INFO:root:FL Epoch: 275 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1086
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689061
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679469
INFO:root:FL Epoch: 275 Norm Difference for worker 1086 is 0.957867
INFO:root:FL Epoch: 275 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.5695262428592233 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:1.934314767519633                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [1281, 624, 1648, 1600, 1606, 1207, 1226, 122, 86, 1926]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 276 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :1281
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462508
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397741
INFO:root:FL Epoch: 276 Norm Difference for worker 1281 is 0.978862
INFO:root:FL Epoch: 276 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :624
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625356
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613312
INFO:root:FL Epoch: 276 Norm Difference for worker 624 is 1.034005
INFO:root:FL Epoch: 276 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1648
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662277
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685789
INFO:root:FL Epoch: 276 Norm Difference for worker 1648 is 0.945654
INFO:root:FL Epoch: 276 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1600
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528569
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271419
INFO:root:FL Epoch: 276 Norm Difference for worker 1600 is 0.966067
INFO:root:FL Epoch: 276 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1606
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728817
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516043
INFO:root:FL Epoch: 276 Norm Difference for worker 1606 is 0.959268
INFO:root:FL Epoch: 276 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1207
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722828
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415844
INFO:root:FL Epoch: 276 Norm Difference for worker 1207 is 0.989649
INFO:root:FL Epoch: 276 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1226
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513640
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665154
INFO:root:FL Epoch: 276 Norm Difference for worker 1226 is 0.965919
INFO:root:FL Epoch: 276 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :122
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 122 is 0.94935
INFO:root:FL Epoch: 276 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :86
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 86 is 0.931298
INFO:root:FL Epoch: 276 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1926
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621680
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448880
INFO:root:FL Epoch: 276 Norm Difference for worker 1926 is 1.021846
INFO:root:FL Epoch: 276 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.5417880713939667 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:1.7252314289410908                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [102, 1309, 208, 1798, 430, 146, 24, 1621, 903, 237]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.10024938 0.09975062 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 201 200 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :102
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 102 is 0.925181
INFO:root:FL Epoch: 277 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1309
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714800
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454540
INFO:root:FL Epoch: 277 Norm Difference for worker 1309 is 0.836711
INFO:root:FL Epoch: 277 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :208
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 208 is 0.958154
INFO:root:FL Epoch: 277 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1798
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679850
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511723
INFO:root:FL Epoch: 277 Norm Difference for worker 1798 is 0.991818
INFO:root:FL Epoch: 277 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :430
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424269
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509013
INFO:root:FL Epoch: 277 Norm Difference for worker 430 is 0.904791
INFO:root:FL Epoch: 277 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :146
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592519
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 146 is 0.962508
INFO:root:FL Epoch: 277 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :24
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 24 is 0.990612
INFO:root:FL Epoch: 277 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1621
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425339
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404369
INFO:root:FL Epoch: 277 Norm Difference for worker 1621 is 0.924232
INFO:root:FL Epoch: 277 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :903
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489938
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511615
INFO:root:FL Epoch: 277 Norm Difference for worker 903 is 0.972452
INFO:root:FL Epoch: 277 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :237
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612050
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 237 is 0.912418
INFO:root:FL Epoch: 277 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1309
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.52764891000355 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:1.6678225596745808                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [316, 1309, 712, 1461, 1141, 729, 851, 1169, 1109, 1230]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 278 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :316
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 316 is 0.848131
INFO:root:FL Epoch: 278 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1309
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574048
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285468
INFO:root:FL Epoch: 278 Norm Difference for worker 1309 is 0.757262
INFO:root:FL Epoch: 278 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :712
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431970
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526816
INFO:root:FL Epoch: 278 Norm Difference for worker 712 is 0.934741
INFO:root:FL Epoch: 278 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1461
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739063
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362257
INFO:root:FL Epoch: 278 Norm Difference for worker 1461 is 0.86769
INFO:root:FL Epoch: 278 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1141
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421393
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441951
INFO:root:FL Epoch: 278 Norm Difference for worker 1141 is 0.939293
INFO:root:FL Epoch: 278 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :729
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639846
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486313
INFO:root:FL Epoch: 278 Norm Difference for worker 729 is 0.948011
INFO:root:FL Epoch: 278 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :851
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516797
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425924
INFO:root:FL Epoch: 278 Norm Difference for worker 851 is 0.832231
INFO:root:FL Epoch: 278 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1169
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506928
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667635
INFO:root:FL Epoch: 278 Norm Difference for worker 1169 is 0.921842
INFO:root:FL Epoch: 278 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1109
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487852
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446796
INFO:root:FL Epoch: 278 Norm Difference for worker 1109 is 0.829344
INFO:root:FL Epoch: 278 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1230
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707299
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440262
INFO:root:FL Epoch: 278 Norm Difference for worker 1230 is 0.990238
INFO:root:FL Epoch: 278 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1309
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.5337681279462927 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:2.03940357764562                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1802, 267, 1747, 1732, 1662, 871, 996, 306, 226, 1835]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 279 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1802
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654229
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454198
INFO:root:FL Epoch: 279 Norm Difference for worker 1802 is 0.976199
INFO:root:FL Epoch: 279 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :267
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342818
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 267 is 0.996036
INFO:root:FL Epoch: 279 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1747
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459342
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527973
INFO:root:FL Epoch: 279 Norm Difference for worker 1747 is 1.119415
INFO:root:FL Epoch: 279 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1732
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816004
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396155
INFO:root:FL Epoch: 279 Norm Difference for worker 1732 is 0.897711
INFO:root:FL Epoch: 279 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1662
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760304
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408277
INFO:root:FL Epoch: 279 Norm Difference for worker 1662 is 0.925086
INFO:root:FL Epoch: 279 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :871
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682158
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480568
INFO:root:FL Epoch: 279 Norm Difference for worker 871 is 0.998338
INFO:root:FL Epoch: 279 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :996
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453819
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398586
INFO:root:FL Epoch: 279 Norm Difference for worker 996 is 0.996203
INFO:root:FL Epoch: 279 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :306
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389968
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 306 is 0.994908
INFO:root:FL Epoch: 279 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :226
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 226 is 1.00461
INFO:root:FL Epoch: 279 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1835
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937991
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524935
INFO:root:FL Epoch: 279 Norm Difference for worker 1835 is 1.076278
INFO:root:FL Epoch: 279 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1732
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.5130873918533325 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:1.7714112401008606                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1457, 990, 1661, 1455, 11, 941, 224, 454, 1353, 1593]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1457
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529232
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407804
INFO:root:FL Epoch: 280 Norm Difference for worker 1457 is 0.905472
INFO:root:FL Epoch: 280 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :990
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551937
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559735
INFO:root:FL Epoch: 280 Norm Difference for worker 990 is 0.993737
INFO:root:FL Epoch: 280 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1661
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725414
INFO:root:Worker: 1661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387728
INFO:root:FL Epoch: 280 Norm Difference for worker 1661 is 0.91826
INFO:root:FL Epoch: 280 Done on worker:1661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1455
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693367
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557514
INFO:root:FL Epoch: 280 Norm Difference for worker 1455 is 0.959137
INFO:root:FL Epoch: 280 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :11
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 11 is 0.889903
INFO:root:FL Epoch: 280 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :941
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452756
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355941
INFO:root:FL Epoch: 280 Norm Difference for worker 941 is 0.898962
INFO:root:FL Epoch: 280 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :224
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.320119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 224 is 0.861091
INFO:root:FL Epoch: 280 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :454
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766886
INFO:root:Worker: 454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380549
INFO:root:FL Epoch: 280 Norm Difference for worker 454 is 0.917611
INFO:root:FL Epoch: 280 Done on worker:454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1353
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576200
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495345
INFO:root:FL Epoch: 280 Norm Difference for worker 1353 is 0.943913
INFO:root:FL Epoch: 280 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1593
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519787
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728290
INFO:root:FL Epoch: 280 Norm Difference for worker 1593 is 0.861774
INFO:root:FL Epoch: 280 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.5305175974088556 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:2.0393367608388266                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [464, 981, 1164, 578, 591, 1726, 1490, 846, 508, 1296]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :464
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440830
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420171
INFO:root:FL Epoch: 281 Norm Difference for worker 464 is 0.916805
INFO:root:FL Epoch: 281 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :981
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558372
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671979
INFO:root:FL Epoch: 281 Norm Difference for worker 981 is 1.04729
INFO:root:FL Epoch: 281 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1164
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580011
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577164
INFO:root:FL Epoch: 281 Norm Difference for worker 1164 is 1.010923
INFO:root:FL Epoch: 281 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :578
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319035
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383048
INFO:root:FL Epoch: 281 Norm Difference for worker 578 is 0.960978
INFO:root:FL Epoch: 281 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :591
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491414
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618326
INFO:root:FL Epoch: 281 Norm Difference for worker 591 is 1.015572
INFO:root:FL Epoch: 281 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1726
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382051
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643377
INFO:root:FL Epoch: 281 Norm Difference for worker 1726 is 0.920513
INFO:root:FL Epoch: 281 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1490
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528783
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543183
INFO:root:FL Epoch: 281 Norm Difference for worker 1490 is 0.940877
INFO:root:FL Epoch: 281 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :846
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440081
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428278
INFO:root:FL Epoch: 281 Norm Difference for worker 846 is 0.908882
INFO:root:FL Epoch: 281 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :508
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485607
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185839
INFO:root:FL Epoch: 281 Norm Difference for worker 508 is 0.897758
INFO:root:FL Epoch: 281 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1296
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728563
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769045
INFO:root:FL Epoch: 281 Norm Difference for worker 1296 is 1.006165
INFO:root:FL Epoch: 281 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 508
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.5166458697880015 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:1.9551270604133606                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [1404, 69, 553, 1738, 491, 324, 1824, 1398, 570, 451]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 282 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :1404
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387696
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202808
INFO:root:FL Epoch: 282 Norm Difference for worker 1404 is 0.88251
INFO:root:FL Epoch: 282 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :69
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 69 is 0.906436
INFO:root:FL Epoch: 282 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :553
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358992
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630790
INFO:root:FL Epoch: 282 Norm Difference for worker 553 is 0.843523
INFO:root:FL Epoch: 282 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1738
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497112
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389254
INFO:root:FL Epoch: 282 Norm Difference for worker 1738 is 1.022082
INFO:root:FL Epoch: 282 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :491
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443105
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357015
INFO:root:FL Epoch: 282 Norm Difference for worker 491 is 0.90948
INFO:root:FL Epoch: 282 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 0.925683
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1824
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959823
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715146
INFO:root:FL Epoch: 282 Norm Difference for worker 1824 is 1.037365
INFO:root:FL Epoch: 282 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1398
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557991
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397298
INFO:root:FL Epoch: 282 Norm Difference for worker 1398 is 0.990898
INFO:root:FL Epoch: 282 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :570
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561793
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347328
INFO:root:FL Epoch: 282 Norm Difference for worker 570 is 0.835061
INFO:root:FL Epoch: 282 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :451
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547880
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505287
INFO:root:FL Epoch: 282 Norm Difference for worker 451 is 1.009802
INFO:root:FL Epoch: 282 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 553
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.5257215640124153 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:2.1992422342300415                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [1175, 1783, 572, 1192, 362, 1442, 985, 581, 1562, 1803]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 283 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :1175
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764423
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448432
INFO:root:FL Epoch: 283 Norm Difference for worker 1175 is 1.04811
INFO:root:FL Epoch: 283 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1783
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480025
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527643
INFO:root:FL Epoch: 283 Norm Difference for worker 1783 is 1.05003
INFO:root:FL Epoch: 283 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :572
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439851
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585869
INFO:root:FL Epoch: 283 Norm Difference for worker 572 is 0.961531
INFO:root:FL Epoch: 283 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1192
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532277
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486927
INFO:root:FL Epoch: 283 Norm Difference for worker 1192 is 1.032223
INFO:root:FL Epoch: 283 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :362
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593589
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293254
INFO:root:FL Epoch: 283 Norm Difference for worker 362 is 0.965955
INFO:root:FL Epoch: 283 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1442
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527641
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582916
INFO:root:FL Epoch: 283 Norm Difference for worker 1442 is 1.016765
INFO:root:FL Epoch: 283 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :985
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493230
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532083
INFO:root:FL Epoch: 283 Norm Difference for worker 985 is 0.988355
INFO:root:FL Epoch: 283 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :581
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827284
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686411
INFO:root:FL Epoch: 283 Norm Difference for worker 581 is 1.124222
INFO:root:FL Epoch: 283 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1562
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453021
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404440
INFO:root:FL Epoch: 283 Norm Difference for worker 1562 is 0.983059
INFO:root:FL Epoch: 283 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1803
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682971
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672336
INFO:root:FL Epoch: 283 Norm Difference for worker 1803 is 1.038162
INFO:root:FL Epoch: 283 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 362
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.5172255968346315 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:2.076971491177877                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [1435, 1756, 1337, 1086, 468, 852, 1907, 700, 1750, 152]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :1435
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452316
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380660
INFO:root:FL Epoch: 284 Norm Difference for worker 1435 is 0.93826
INFO:root:FL Epoch: 284 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1756
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574252
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518549
INFO:root:FL Epoch: 284 Norm Difference for worker 1756 is 0.94433
INFO:root:FL Epoch: 284 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1337
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600056
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501724
INFO:root:FL Epoch: 284 Norm Difference for worker 1337 is 0.898573
INFO:root:FL Epoch: 284 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1086
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650258
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444104
INFO:root:FL Epoch: 284 Norm Difference for worker 1086 is 0.735386
INFO:root:FL Epoch: 284 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :468
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493122
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475068
INFO:root:FL Epoch: 284 Norm Difference for worker 468 is 0.91768
INFO:root:FL Epoch: 284 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542129
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640311
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 0.977922
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1907
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465667
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546130
INFO:root:FL Epoch: 284 Norm Difference for worker 1907 is 0.945584
INFO:root:FL Epoch: 284 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :700
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778687
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465068
INFO:root:FL Epoch: 284 Norm Difference for worker 700 is 0.93486
INFO:root:FL Epoch: 284 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1750
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440163
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681461
INFO:root:FL Epoch: 284 Norm Difference for worker 1750 is 0.905499
INFO:root:FL Epoch: 284 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :152
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 152 is 0.955474
INFO:root:FL Epoch: 284 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.5479132112334756 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:2.4102158149083457                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [361, 1228, 333, 14, 1645, 1180, 1154, 1387, 1261, 225]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :361
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658530
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354275
INFO:root:FL Epoch: 285 Norm Difference for worker 361 is 1.041409
INFO:root:FL Epoch: 285 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1228
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612378
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677077
INFO:root:FL Epoch: 285 Norm Difference for worker 1228 is 1.03987
INFO:root:FL Epoch: 285 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :333
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 333 is 1.019251
INFO:root:FL Epoch: 285 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :14
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 14 is 1.024855
INFO:root:FL Epoch: 285 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1645
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511089
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413098
INFO:root:FL Epoch: 285 Norm Difference for worker 1645 is 1.122168
INFO:root:FL Epoch: 285 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1180
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718974
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419080
INFO:root:FL Epoch: 285 Norm Difference for worker 1180 is 0.961561
INFO:root:FL Epoch: 285 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1154
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627419
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394525
INFO:root:FL Epoch: 285 Norm Difference for worker 1154 is 0.982035
INFO:root:FL Epoch: 285 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1387
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433998
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340432
INFO:root:FL Epoch: 285 Norm Difference for worker 1387 is 0.994673
INFO:root:FL Epoch: 285 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1261
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649423
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430932
INFO:root:FL Epoch: 285 Norm Difference for worker 1261 is 1.005188
INFO:root:FL Epoch: 285 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :225
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 225 is 1.032831
INFO:root:FL Epoch: 285 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.5184974091894486 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:1.9369082848230998                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [282, 800, 901, 1927, 1666, 194, 1064, 1377, 475, 1341]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 286 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :282
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 282 is 0.887229
INFO:root:FL Epoch: 286 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :800
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589477
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488575
INFO:root:FL Epoch: 286 Norm Difference for worker 800 is 0.826321
INFO:root:FL Epoch: 286 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :901
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326431
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354058
INFO:root:FL Epoch: 286 Norm Difference for worker 901 is 0.843796
INFO:root:FL Epoch: 286 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1927
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703526
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460134
INFO:root:FL Epoch: 286 Norm Difference for worker 1927 is 0.87866
INFO:root:FL Epoch: 286 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1666
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416014
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371282
INFO:root:FL Epoch: 286 Norm Difference for worker 1666 is 0.89692
INFO:root:FL Epoch: 286 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :194
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 194 is 0.856906
INFO:root:FL Epoch: 286 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1064
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458452
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441955
INFO:root:FL Epoch: 286 Norm Difference for worker 1064 is 0.859989
INFO:root:FL Epoch: 286 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1377
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700995
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463931
INFO:root:FL Epoch: 286 Norm Difference for worker 1377 is 0.945853
INFO:root:FL Epoch: 286 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :475
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655197
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404059
INFO:root:FL Epoch: 286 Norm Difference for worker 475 is 0.888167
INFO:root:FL Epoch: 286 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1341
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385269
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462670
INFO:root:FL Epoch: 286 Norm Difference for worker 1341 is 0.927486
INFO:root:FL Epoch: 286 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 800
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.5277723810252022 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:1.9969687263170879                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [496, 164, 1683, 89, 347, 553, 1095, 151, 977, 515]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 287 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :496
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434296
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554726
INFO:root:FL Epoch: 287 Norm Difference for worker 496 is 0.87773
INFO:root:FL Epoch: 287 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :164
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437257
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 164 is 0.92371
INFO:root:FL Epoch: 287 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1683
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535573
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580722
INFO:root:FL Epoch: 287 Norm Difference for worker 1683 is 0.89316
INFO:root:FL Epoch: 287 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :89
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551751
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 89 is 0.923475
INFO:root:FL Epoch: 287 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :347
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648125
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588413
INFO:root:FL Epoch: 287 Norm Difference for worker 347 is 0.887655
INFO:root:FL Epoch: 287 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :553
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439538
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244661
INFO:root:FL Epoch: 287 Norm Difference for worker 553 is 0.808343
INFO:root:FL Epoch: 287 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1095
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521634
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447674
INFO:root:FL Epoch: 287 Norm Difference for worker 1095 is 0.937586
INFO:root:FL Epoch: 287 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :151
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397140
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 151 is 0.890121
INFO:root:FL Epoch: 287 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :977
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571696
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488605
INFO:root:FL Epoch: 287 Norm Difference for worker 977 is 1.047289
INFO:root:FL Epoch: 287 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :515
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482803
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458446
INFO:root:FL Epoch: 287 Norm Difference for worker 515 is 0.873338
INFO:root:FL Epoch: 287 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 553
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.5539934898124022 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:2.5286370515823364                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [1736, 1596, 1067, 1537, 767, 1925, 195, 178, 1724, 404]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :1736
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753288
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379088
INFO:root:FL Epoch: 288 Norm Difference for worker 1736 is 1.222218
INFO:root:FL Epoch: 288 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1596
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784887
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540662
INFO:root:FL Epoch: 288 Norm Difference for worker 1596 is 1.200976
INFO:root:FL Epoch: 288 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1067
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735713
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497476
INFO:root:FL Epoch: 288 Norm Difference for worker 1067 is 1.241246
INFO:root:FL Epoch: 288 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1537
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.910679
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466040
INFO:root:FL Epoch: 288 Norm Difference for worker 1537 is 1.381717
INFO:root:FL Epoch: 288 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :767
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872606
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564410
INFO:root:FL Epoch: 288 Norm Difference for worker 767 is 1.230596
INFO:root:FL Epoch: 288 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1925
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758942
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.883037
INFO:root:FL Epoch: 288 Norm Difference for worker 1925 is 1.296085
INFO:root:FL Epoch: 288 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :195
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 195 is 1.234043
INFO:root:FL Epoch: 288 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :178
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.254532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 178 is 1.170305
INFO:root:FL Epoch: 288 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1724
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530741
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293812
INFO:root:FL Epoch: 288 Norm Difference for worker 1724 is 1.253046
INFO:root:FL Epoch: 288 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :404
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309885
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435536
INFO:root:FL Epoch: 288 Norm Difference for worker 404 is 1.130618
INFO:root:FL Epoch: 288 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 404
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.5259637394372154 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:2.34810463587443                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [932, 1877, 1889, 791, 852, 1436, 585, 960, 1510, 1492]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :932
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471345
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610674
INFO:root:FL Epoch: 289 Norm Difference for worker 932 is 1.123154
INFO:root:FL Epoch: 289 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1877
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494946
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472412
INFO:root:FL Epoch: 289 Norm Difference for worker 1877 is 1.027125
INFO:root:FL Epoch: 289 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1889
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841505
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607067
INFO:root:FL Epoch: 289 Norm Difference for worker 1889 is 1.087839
INFO:root:FL Epoch: 289 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :791
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539006
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617849
INFO:root:FL Epoch: 289 Norm Difference for worker 791 is 0.991043
INFO:root:FL Epoch: 289 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :852
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519125
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371383
INFO:root:FL Epoch: 289 Norm Difference for worker 852 is 1.146221
INFO:root:FL Epoch: 289 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1436
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671726
INFO:root:Worker: 1436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365408
INFO:root:FL Epoch: 289 Norm Difference for worker 1436 is 0.970887
INFO:root:FL Epoch: 289 Done on worker:1436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :585
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469759
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592476
INFO:root:FL Epoch: 289 Norm Difference for worker 585 is 1.112901
INFO:root:FL Epoch: 289 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :960
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431736
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459939
INFO:root:FL Epoch: 289 Norm Difference for worker 960 is 1.044056
INFO:root:FL Epoch: 289 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1510
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497209
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426282
INFO:root:FL Epoch: 289 Norm Difference for worker 1510 is 1.164618
INFO:root:FL Epoch: 289 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1492
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707976
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325304
INFO:root:FL Epoch: 289 Norm Difference for worker 1492 is 1.175987
INFO:root:FL Epoch: 289 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1436
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.5197293039630441 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:2.2480464776357016                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [443, 843, 215, 450, 1198, 856, 1108, 523, 365, 1475]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :443
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838732
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474713
INFO:root:FL Epoch: 290 Norm Difference for worker 443 is 1.005637
INFO:root:FL Epoch: 290 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :843
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451405
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686552
INFO:root:FL Epoch: 290 Norm Difference for worker 843 is 1.03271
INFO:root:FL Epoch: 290 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :215
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 215 is 1.054681
INFO:root:FL Epoch: 290 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :450
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.910370
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567092
INFO:root:FL Epoch: 290 Norm Difference for worker 450 is 0.977848
INFO:root:FL Epoch: 290 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1198
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545851
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679584
INFO:root:FL Epoch: 290 Norm Difference for worker 1198 is 1.087582
INFO:root:FL Epoch: 290 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :856
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681918
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.810969
INFO:root:FL Epoch: 290 Norm Difference for worker 856 is 1.157403
INFO:root:FL Epoch: 290 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1108
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522450
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424522
INFO:root:FL Epoch: 290 Norm Difference for worker 1108 is 1.058883
INFO:root:FL Epoch: 290 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :523
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631564
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746191
INFO:root:FL Epoch: 290 Norm Difference for worker 523 is 1.131292
INFO:root:FL Epoch: 290 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :365
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438662
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345523
INFO:root:FL Epoch: 290 Norm Difference for worker 365 is 1.009977
INFO:root:FL Epoch: 290 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1475
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543637
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500919
INFO:root:FL Epoch: 290 Norm Difference for worker 1475 is 1.125777
INFO:root:FL Epoch: 290 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 365
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.5299498351181254 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:2.0489672223726907                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [786, 228, 1294, 447, 313, 1601, 1675, 1647, 629, 1546]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 291 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :786
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484624
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584895
INFO:root:FL Epoch: 291 Norm Difference for worker 786 is 0.886595
INFO:root:FL Epoch: 291 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :228
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 228 is 0.870294
INFO:root:FL Epoch: 291 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1294
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445939
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661198
INFO:root:FL Epoch: 291 Norm Difference for worker 1294 is 0.917544
INFO:root:FL Epoch: 291 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :447
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781616
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542671
INFO:root:FL Epoch: 291 Norm Difference for worker 447 is 0.891787
INFO:root:FL Epoch: 291 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :313
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414135
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 313 is 0.946228
INFO:root:FL Epoch: 291 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1601
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414123
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492984
INFO:root:FL Epoch: 291 Norm Difference for worker 1601 is 0.873863
INFO:root:FL Epoch: 291 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1675
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412718
INFO:root:Worker: 1675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757901
INFO:root:FL Epoch: 291 Norm Difference for worker 1675 is 0.852319
INFO:root:FL Epoch: 291 Done on worker:1675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1647
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930395
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643236
INFO:root:FL Epoch: 291 Norm Difference for worker 1647 is 0.952946
INFO:root:FL Epoch: 291 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :629
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488300
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550544
INFO:root:FL Epoch: 291 Norm Difference for worker 629 is 0.899965
INFO:root:FL Epoch: 291 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1546
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527260
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503115
INFO:root:FL Epoch: 291 Norm Difference for worker 1546 is 0.856517
INFO:root:FL Epoch: 291 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1675
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.5164019535569584 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:1.8191379110018413                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1904, 161, 197, 27, 1628, 1695, 390, 1468, 1703, 46]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 292 Num points on workers: [200 201 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1904
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397170
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429297
INFO:root:FL Epoch: 292 Norm Difference for worker 1904 is 0.85867
INFO:root:FL Epoch: 292 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :161
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479922
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 161 is 0.829039
INFO:root:FL Epoch: 292 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :197
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 197 is 0.880588
INFO:root:FL Epoch: 292 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :27
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468660
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 27 is 0.81039
INFO:root:FL Epoch: 292 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1628
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436578
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432791
INFO:root:FL Epoch: 292 Norm Difference for worker 1628 is 0.788016
INFO:root:FL Epoch: 292 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1695
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644828
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598081
INFO:root:FL Epoch: 292 Norm Difference for worker 1695 is 0.89358
INFO:root:FL Epoch: 292 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :390
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319674
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424145
INFO:root:FL Epoch: 292 Norm Difference for worker 390 is 0.930024
INFO:root:FL Epoch: 292 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1468
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596417
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527808
INFO:root:FL Epoch: 292 Norm Difference for worker 1468 is 0.924806
INFO:root:FL Epoch: 292 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1703
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623858
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596748
INFO:root:FL Epoch: 292 Norm Difference for worker 1703 is 0.896194
INFO:root:FL Epoch: 292 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :46
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588429
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 46 is 0.828319
INFO:root:FL Epoch: 292 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1628
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.5214451095637154 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:1.5688576102256775                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [990, 1027, 778, 820, 897, 1470, 1412, 1850, 280, 1630]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :990
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750000
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507868
INFO:root:FL Epoch: 293 Norm Difference for worker 990 is 0.79728
INFO:root:FL Epoch: 293 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1027
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391538
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426312
INFO:root:FL Epoch: 293 Norm Difference for worker 1027 is 0.819777
INFO:root:FL Epoch: 293 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :778
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487425
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463728
INFO:root:FL Epoch: 293 Norm Difference for worker 778 is 0.890378
INFO:root:FL Epoch: 293 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :820
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444817
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552676
INFO:root:FL Epoch: 293 Norm Difference for worker 820 is 0.799095
INFO:root:FL Epoch: 293 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :897
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586309
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555454
INFO:root:FL Epoch: 293 Norm Difference for worker 897 is 0.849527
INFO:root:FL Epoch: 293 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1470
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416072
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510162
INFO:root:FL Epoch: 293 Norm Difference for worker 1470 is 0.792834
INFO:root:FL Epoch: 293 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1412
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482262
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460872
INFO:root:FL Epoch: 293 Norm Difference for worker 1412 is 0.822486
INFO:root:FL Epoch: 293 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1850
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737401
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529766
INFO:root:FL Epoch: 293 Norm Difference for worker 1850 is 0.743948
INFO:root:FL Epoch: 293 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :280
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 280 is 0.77555
INFO:root:FL Epoch: 293 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1630
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595464
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605412
INFO:root:FL Epoch: 293 Norm Difference for worker 1630 is 0.904727
INFO:root:FL Epoch: 293 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1850
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.5263072637950673 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:1.984112282594045                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [1609, 257, 589, 765, 1723, 1247, 1937, 1922, 1288, 430]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 294 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :1609
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703122
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435420
INFO:root:FL Epoch: 294 Norm Difference for worker 1609 is 0.887144
INFO:root:FL Epoch: 294 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :257
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 257 is 0.911623
INFO:root:FL Epoch: 294 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :589
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582066
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335991
INFO:root:FL Epoch: 294 Norm Difference for worker 589 is 0.925129
INFO:root:FL Epoch: 294 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :765
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560131
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392718
INFO:root:FL Epoch: 294 Norm Difference for worker 765 is 0.845264
INFO:root:FL Epoch: 294 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1723
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393532
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512758
INFO:root:FL Epoch: 294 Norm Difference for worker 1723 is 0.88539
INFO:root:FL Epoch: 294 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1247
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432553
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412384
INFO:root:FL Epoch: 294 Norm Difference for worker 1247 is 0.872869
INFO:root:FL Epoch: 294 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1937
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394434
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337456
INFO:root:FL Epoch: 294 Norm Difference for worker 1937 is 0.91752
INFO:root:FL Epoch: 294 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1922
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396631
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315667
INFO:root:FL Epoch: 294 Norm Difference for worker 1922 is 0.850465
INFO:root:FL Epoch: 294 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1288
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1288 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441851
INFO:root:Worker: 1288 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361852
INFO:root:FL Epoch: 294 Norm Difference for worker 1288 is 0.82219
INFO:root:FL Epoch: 294 Done on worker:1288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :430
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465910
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502740
INFO:root:FL Epoch: 294 Norm Difference for worker 430 is 0.929342
INFO:root:FL Epoch: 294 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1288
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.517864374553456 and Test Accuracy:75.0 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:1.8203657865524292                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [1771, 483, 777, 1098, 1768, 202, 1516, 1063, 1641, 1039]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :1771
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661597
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457017
INFO:root:FL Epoch: 295 Norm Difference for worker 1771 is 0.85354
INFO:root:FL Epoch: 295 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :483
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597498
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484001
INFO:root:FL Epoch: 295 Norm Difference for worker 483 is 0.862142
INFO:root:FL Epoch: 295 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :777
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405237
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459711
INFO:root:FL Epoch: 295 Norm Difference for worker 777 is 0.833328
INFO:root:FL Epoch: 295 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1098
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597962
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289162
INFO:root:FL Epoch: 295 Norm Difference for worker 1098 is 0.803685
INFO:root:FL Epoch: 295 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1768
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608881
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586322
INFO:root:FL Epoch: 295 Norm Difference for worker 1768 is 0.802726
INFO:root:FL Epoch: 295 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :202
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.802994
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 202 is 0.830207
INFO:root:FL Epoch: 295 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1516
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554706
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439810
INFO:root:FL Epoch: 295 Norm Difference for worker 1516 is 0.796301
INFO:root:FL Epoch: 295 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1063
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701370
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543663
INFO:root:FL Epoch: 295 Norm Difference for worker 1063 is 0.851981
INFO:root:FL Epoch: 295 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1641
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776209
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434652
INFO:root:FL Epoch: 295 Norm Difference for worker 1641 is 0.781679
INFO:root:FL Epoch: 295 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1039
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698408
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502365
INFO:root:FL Epoch: 295 Norm Difference for worker 1039 is 0.791869
INFO:root:FL Epoch: 295 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1516
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.5357190598459804 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:1.914511541525523                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [555, 461, 928, 344, 62, 991, 1165, 641, 167, 1617]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :555
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526448
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443682
INFO:root:FL Epoch: 296 Norm Difference for worker 555 is 0.819523
INFO:root:FL Epoch: 296 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :461
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451458
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541764
INFO:root:FL Epoch: 296 Norm Difference for worker 461 is 0.804787
INFO:root:FL Epoch: 296 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :928
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475096
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294339
INFO:root:FL Epoch: 296 Norm Difference for worker 928 is 0.76664
INFO:root:FL Epoch: 296 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :344
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465613
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543087
INFO:root:FL Epoch: 296 Norm Difference for worker 344 is 0.815948
INFO:root:FL Epoch: 296 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :62
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 62 is 0.735937
INFO:root:FL Epoch: 296 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :991
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606895
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500323
INFO:root:FL Epoch: 296 Norm Difference for worker 991 is 0.784445
INFO:root:FL Epoch: 296 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1165
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578223
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452290
INFO:root:FL Epoch: 296 Norm Difference for worker 1165 is 0.806923
INFO:root:FL Epoch: 296 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :641
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569544
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564326
INFO:root:FL Epoch: 296 Norm Difference for worker 641 is 0.841743
INFO:root:FL Epoch: 296 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :167
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 167 is 0.748624
INFO:root:FL Epoch: 296 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1617
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448980
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692406
INFO:root:FL Epoch: 296 Norm Difference for worker 1617 is 0.758547
INFO:root:FL Epoch: 296 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 62
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.5406492142116323 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:2.0632768273353577                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [966, 887, 1424, 986, 300, 1827, 1841, 977, 881, 1102]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :966
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375779
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594310
INFO:root:FL Epoch: 297 Norm Difference for worker 966 is 0.880104
INFO:root:FL Epoch: 297 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :887
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432581
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476750
INFO:root:FL Epoch: 297 Norm Difference for worker 887 is 0.858882
INFO:root:FL Epoch: 297 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1424
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560666
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397093
INFO:root:FL Epoch: 297 Norm Difference for worker 1424 is 0.98072
INFO:root:FL Epoch: 297 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :986
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665591
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528479
INFO:root:FL Epoch: 297 Norm Difference for worker 986 is 0.912794
INFO:root:FL Epoch: 297 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :300
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 300 is 0.824972
INFO:root:FL Epoch: 297 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1827
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649722
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588114
INFO:root:FL Epoch: 297 Norm Difference for worker 1827 is 0.880229
INFO:root:FL Epoch: 297 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1841
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394016
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540012
INFO:root:FL Epoch: 297 Norm Difference for worker 1841 is 0.866491
INFO:root:FL Epoch: 297 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :977
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549271
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572746
INFO:root:FL Epoch: 297 Norm Difference for worker 977 is 0.994009
INFO:root:FL Epoch: 297 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :881
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363177
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265915
INFO:root:FL Epoch: 297 Norm Difference for worker 881 is 0.781459
INFO:root:FL Epoch: 297 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1102
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521840
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513695
INFO:root:FL Epoch: 297 Norm Difference for worker 1102 is 0.922026
INFO:root:FL Epoch: 297 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.5252815081792719 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:2.002505044142405                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [343, 606, 373, 1158, 1563, 612, 534, 253, 1299, 646]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 298 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :343
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475135
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468530
INFO:root:FL Epoch: 298 Norm Difference for worker 343 is 0.836023
INFO:root:FL Epoch: 298 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :606
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443420
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411430
INFO:root:FL Epoch: 298 Norm Difference for worker 606 is 0.879958
INFO:root:FL Epoch: 298 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :373
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670849
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470394
INFO:root:FL Epoch: 298 Norm Difference for worker 373 is 0.931249
INFO:root:FL Epoch: 298 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1158
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695661
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314057
INFO:root:FL Epoch: 298 Norm Difference for worker 1158 is 0.764305
INFO:root:FL Epoch: 298 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1563
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760108
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660230
INFO:root:FL Epoch: 298 Norm Difference for worker 1563 is 0.95428
INFO:root:FL Epoch: 298 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :612
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527017
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.784837
INFO:root:FL Epoch: 298 Norm Difference for worker 612 is 0.875553
INFO:root:FL Epoch: 298 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :534
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323870
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621488
INFO:root:FL Epoch: 298 Norm Difference for worker 534 is 0.923647
INFO:root:FL Epoch: 298 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :253
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 253 is 0.873801
INFO:root:FL Epoch: 298 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1299
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628811
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505406
INFO:root:FL Epoch: 298 Norm Difference for worker 1299 is 0.842786
INFO:root:FL Epoch: 298 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :646
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572269
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442189
INFO:root:FL Epoch: 298 Norm Difference for worker 646 is 0.801541
INFO:root:FL Epoch: 298 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1158
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.5209368800415712 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:1.8788134853045146                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [367, 258, 428, 1570, 177, 392, 1200, 1933, 163, 1260]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 299 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :367
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494466
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443206
INFO:root:FL Epoch: 299 Norm Difference for worker 367 is 0.947706
INFO:root:FL Epoch: 299 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :258
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591615
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441315
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 258 is 0.912504
INFO:root:FL Epoch: 299 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :428
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544120
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464261
INFO:root:FL Epoch: 299 Norm Difference for worker 428 is 0.927021
INFO:root:FL Epoch: 299 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1570
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820662
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342230
INFO:root:FL Epoch: 299 Norm Difference for worker 1570 is 0.856794
INFO:root:FL Epoch: 299 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :177
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 177 is 0.986276
INFO:root:FL Epoch: 299 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :392
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532609
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611864
INFO:root:FL Epoch: 299 Norm Difference for worker 392 is 0.922446
INFO:root:FL Epoch: 299 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1200
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704191
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621882
INFO:root:FL Epoch: 299 Norm Difference for worker 1200 is 0.891975
INFO:root:FL Epoch: 299 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1933
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813399
INFO:root:Worker: 1933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663510
INFO:root:FL Epoch: 299 Norm Difference for worker 1933 is 0.890203
INFO:root:FL Epoch: 299 Done on worker:1933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :163
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 163 is 0.940795
INFO:root:FL Epoch: 299 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1260
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720941
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487263
INFO:root:FL Epoch: 299 Norm Difference for worker 1260 is 0.872311
INFO:root:FL Epoch: 299 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1570
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.5369714077781228 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:2.006275216738383                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1099, 1825, 1025, 582, 379, 729, 685, 810, 1419, 1696]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1099
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360091
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558737
INFO:root:FL Epoch: 300 Norm Difference for worker 1099 is 0.814763
INFO:root:FL Epoch: 300 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1825
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521056
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350294
INFO:root:FL Epoch: 300 Norm Difference for worker 1825 is 0.821769
INFO:root:FL Epoch: 300 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1025
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634804
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423936
INFO:root:FL Epoch: 300 Norm Difference for worker 1025 is 0.799746
INFO:root:FL Epoch: 300 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :582
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648261
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616221
INFO:root:FL Epoch: 300 Norm Difference for worker 582 is 0.85102
INFO:root:FL Epoch: 300 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :379
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680809
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686899
INFO:root:FL Epoch: 300 Norm Difference for worker 379 is 0.830332
INFO:root:FL Epoch: 300 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :729
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428498
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434638
INFO:root:FL Epoch: 300 Norm Difference for worker 729 is 0.797712
INFO:root:FL Epoch: 300 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :685
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382326
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511888
INFO:root:FL Epoch: 300 Norm Difference for worker 685 is 0.772366
INFO:root:FL Epoch: 300 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :810
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502996
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453542
INFO:root:FL Epoch: 300 Norm Difference for worker 810 is 0.864844
INFO:root:FL Epoch: 300 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1419
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510941
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508472
INFO:root:FL Epoch: 300 Norm Difference for worker 1419 is 0.746265
INFO:root:FL Epoch: 300 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1696
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410467
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279918
INFO:root:FL Epoch: 300 Norm Difference for worker 1696 is 0.792937
INFO:root:FL Epoch: 300 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1419
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.5281693777617287 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:2.195279896259308                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [1480, 1911, 180, 284, 1537, 949, 1287, 1424, 1602, 1772]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :1480
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391917
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517721
INFO:root:FL Epoch: 301 Norm Difference for worker 1480 is 0.884945
INFO:root:FL Epoch: 301 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1911
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366373
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359055
INFO:root:FL Epoch: 301 Norm Difference for worker 1911 is 0.880577
INFO:root:FL Epoch: 301 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :180
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 180 is 0.799755
INFO:root:FL Epoch: 301 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :284
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655647
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.621767
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 284 is 0.935041
INFO:root:FL Epoch: 301 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1537
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413148
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472787
INFO:root:FL Epoch: 301 Norm Difference for worker 1537 is 0.987416
INFO:root:FL Epoch: 301 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :949
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683078
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432521
INFO:root:FL Epoch: 301 Norm Difference for worker 949 is 1.060021
INFO:root:FL Epoch: 301 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1287
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521724
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628746
INFO:root:FL Epoch: 301 Norm Difference for worker 1287 is 0.876984
INFO:root:FL Epoch: 301 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1424
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488259
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594398
INFO:root:FL Epoch: 301 Norm Difference for worker 1424 is 0.975424
INFO:root:FL Epoch: 301 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1602
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635116
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455936
INFO:root:FL Epoch: 301 Norm Difference for worker 1602 is 0.981861
INFO:root:FL Epoch: 301 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1772
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617906
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548878
INFO:root:FL Epoch: 301 Norm Difference for worker 1772 is 0.827067
INFO:root:FL Epoch: 301 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1772
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.5527738122379079 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:2.204089403152466                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [1767, 1463, 574, 485, 563, 1168, 253, 1626, 1549, 1816]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :1767
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642567
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358581
INFO:root:FL Epoch: 302 Norm Difference for worker 1767 is 0.803483
INFO:root:FL Epoch: 302 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1463
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703002
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639282
INFO:root:FL Epoch: 302 Norm Difference for worker 1463 is 0.864628
INFO:root:FL Epoch: 302 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :574
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493944
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519059
INFO:root:FL Epoch: 302 Norm Difference for worker 574 is 0.834159
INFO:root:FL Epoch: 302 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :485
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599868
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417111
INFO:root:FL Epoch: 302 Norm Difference for worker 485 is 0.816746
INFO:root:FL Epoch: 302 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :563
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686487
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527419
INFO:root:FL Epoch: 302 Norm Difference for worker 563 is 0.942422
INFO:root:FL Epoch: 302 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1168
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632226
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522900
INFO:root:FL Epoch: 302 Norm Difference for worker 1168 is 0.812864
INFO:root:FL Epoch: 302 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :253
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446628
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 253 is 0.885823
INFO:root:FL Epoch: 302 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1626
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589867
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558220
INFO:root:FL Epoch: 302 Norm Difference for worker 1626 is 0.9122
INFO:root:FL Epoch: 302 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1549
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574242
INFO:root:Worker: 1549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360234
INFO:root:FL Epoch: 302 Norm Difference for worker 1549 is 0.752607
INFO:root:FL Epoch: 302 Done on worker:1549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1816
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520350
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431514
INFO:root:FL Epoch: 302 Norm Difference for worker 1816 is 0.849138
INFO:root:FL Epoch: 302 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1549
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.5143414525424733 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:1.9985439777374268                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1642, 403, 1876, 812, 1218, 1754, 773, 518, 1321, 379]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1642
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416970
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516675
INFO:root:FL Epoch: 303 Norm Difference for worker 1642 is 0.806192
INFO:root:FL Epoch: 303 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :403
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702309
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639812
INFO:root:FL Epoch: 303 Norm Difference for worker 403 is 0.872307
INFO:root:FL Epoch: 303 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1876
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483299
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446286
INFO:root:FL Epoch: 303 Norm Difference for worker 1876 is 0.85446
INFO:root:FL Epoch: 303 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :812
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575709
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469527
INFO:root:FL Epoch: 303 Norm Difference for worker 812 is 0.80571
INFO:root:FL Epoch: 303 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1218
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720543
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645840
INFO:root:FL Epoch: 303 Norm Difference for worker 1218 is 0.833636
INFO:root:FL Epoch: 303 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1754
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661103
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569454
INFO:root:FL Epoch: 303 Norm Difference for worker 1754 is 0.819873
INFO:root:FL Epoch: 303 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :773
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633251
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491231
INFO:root:FL Epoch: 303 Norm Difference for worker 773 is 0.813919
INFO:root:FL Epoch: 303 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :518
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416355
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640278
INFO:root:FL Epoch: 303 Norm Difference for worker 518 is 0.892663
INFO:root:FL Epoch: 303 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1321
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327652
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359227
INFO:root:FL Epoch: 303 Norm Difference for worker 1321 is 0.998022
INFO:root:FL Epoch: 303 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :379
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505518
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414584
INFO:root:FL Epoch: 303 Norm Difference for worker 379 is 0.865962
INFO:root:FL Epoch: 303 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1642
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.5341454831992879 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:2.008907973766327                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [1007, 1050, 1266, 473, 644, 750, 1239, 632, 1312, 547]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 304 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :1007
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605376
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412023
INFO:root:FL Epoch: 304 Norm Difference for worker 1007 is 0.79147
INFO:root:FL Epoch: 304 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1050
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557920
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330071
INFO:root:FL Epoch: 304 Norm Difference for worker 1050 is 0.757729
INFO:root:FL Epoch: 304 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1266
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742455
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626522
INFO:root:FL Epoch: 304 Norm Difference for worker 1266 is 0.741145
INFO:root:FL Epoch: 304 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :473
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535073
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409145
INFO:root:FL Epoch: 304 Norm Difference for worker 473 is 0.795182
INFO:root:FL Epoch: 304 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :644
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589401
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573060
INFO:root:FL Epoch: 304 Norm Difference for worker 644 is 0.800258
INFO:root:FL Epoch: 304 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :750
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642874
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626206
INFO:root:FL Epoch: 304 Norm Difference for worker 750 is 0.763937
INFO:root:FL Epoch: 304 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1239
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733139
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556913
INFO:root:FL Epoch: 304 Norm Difference for worker 1239 is 0.814244
INFO:root:FL Epoch: 304 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :632
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516155
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496616
INFO:root:FL Epoch: 304 Norm Difference for worker 632 is 0.747996
INFO:root:FL Epoch: 304 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1312
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431778
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521474
INFO:root:FL Epoch: 304 Norm Difference for worker 1312 is 0.751719
INFO:root:FL Epoch: 304 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :547
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432057
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670424
INFO:root:FL Epoch: 304 Norm Difference for worker 547 is 0.766157
INFO:root:FL Epoch: 304 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1266
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.5122308923917658 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:1.6310647527376811                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [1315, 1631, 814, 1670, 1268, 763, 1632, 1915, 307, 524]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 305 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :1315
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636309
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498637
INFO:root:FL Epoch: 305 Norm Difference for worker 1315 is 0.816309
INFO:root:FL Epoch: 305 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1631
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600270
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633588
INFO:root:FL Epoch: 305 Norm Difference for worker 1631 is 0.831113
INFO:root:FL Epoch: 305 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :814
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493445
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478296
INFO:root:FL Epoch: 305 Norm Difference for worker 814 is 0.767924
INFO:root:FL Epoch: 305 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1670
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472369
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440573
INFO:root:FL Epoch: 305 Norm Difference for worker 1670 is 0.772692
INFO:root:FL Epoch: 305 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1268
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669095
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492525
INFO:root:FL Epoch: 305 Norm Difference for worker 1268 is 0.757083
INFO:root:FL Epoch: 305 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :763
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494135
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571864
INFO:root:FL Epoch: 305 Norm Difference for worker 763 is 0.710934
INFO:root:FL Epoch: 305 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1632
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374256
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501917
INFO:root:FL Epoch: 305 Norm Difference for worker 1632 is 0.758239
INFO:root:FL Epoch: 305 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1915
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508134
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645178
INFO:root:FL Epoch: 305 Norm Difference for worker 1915 is 0.728276
INFO:root:FL Epoch: 305 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :307
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.638710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 307 is 0.766811
INFO:root:FL Epoch: 305 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :524
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500822
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436076
INFO:root:FL Epoch: 305 Norm Difference for worker 524 is 0.736321
INFO:root:FL Epoch: 305 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 524
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.5470153636792127 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:1.9817798137664795                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [1111, 270, 1182, 430, 1015, 1773, 1788, 821, 1632, 611]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 306 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :1111
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431793
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377081
INFO:root:FL Epoch: 306 Norm Difference for worker 1111 is 0.895281
INFO:root:FL Epoch: 306 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :270
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631469
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 270 is 0.920085
INFO:root:FL Epoch: 306 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1182
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602431
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619856
INFO:root:FL Epoch: 306 Norm Difference for worker 1182 is 1.283178
INFO:root:FL Epoch: 306 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :430
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433111
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399123
INFO:root:FL Epoch: 306 Norm Difference for worker 430 is 0.949644
INFO:root:FL Epoch: 306 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1015
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588603
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557750
INFO:root:FL Epoch: 306 Norm Difference for worker 1015 is 0.995363
INFO:root:FL Epoch: 306 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1773
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590706
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467797
INFO:root:FL Epoch: 306 Norm Difference for worker 1773 is 1.196502
INFO:root:FL Epoch: 306 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1788
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493053
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608520
INFO:root:FL Epoch: 306 Norm Difference for worker 1788 is 0.916585
INFO:root:FL Epoch: 306 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :821
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583520
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432799
INFO:root:FL Epoch: 306 Norm Difference for worker 821 is 1.133711
INFO:root:FL Epoch: 306 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1632
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521131
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377234
INFO:root:FL Epoch: 306 Norm Difference for worker 1632 is 1.104599
INFO:root:FL Epoch: 306 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :611
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474164
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617163
INFO:root:FL Epoch: 306 Norm Difference for worker 611 is 0.888788
INFO:root:FL Epoch: 306 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1015
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.5152296476504382 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:1.8262187639872234                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [617, 1831, 1802, 1731, 504, 15, 101, 1887, 622, 1565]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :617
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361553
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519789
INFO:root:FL Epoch: 307 Norm Difference for worker 617 is 0.824166
INFO:root:FL Epoch: 307 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1831
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387981
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444031
INFO:root:FL Epoch: 307 Norm Difference for worker 1831 is 0.762925
INFO:root:FL Epoch: 307 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1802
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710524
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500079
INFO:root:FL Epoch: 307 Norm Difference for worker 1802 is 0.857219
INFO:root:FL Epoch: 307 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1731
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521401
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543228
INFO:root:FL Epoch: 307 Norm Difference for worker 1731 is 0.785715
INFO:root:FL Epoch: 307 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :504
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504934
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473200
INFO:root:FL Epoch: 307 Norm Difference for worker 504 is 0.803663
INFO:root:FL Epoch: 307 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :15
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429017
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 15 is 0.815901
INFO:root:FL Epoch: 307 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :101
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 101 is 0.806211
INFO:root:FL Epoch: 307 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1887
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644253
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534477
INFO:root:FL Epoch: 307 Norm Difference for worker 1887 is 0.743018
INFO:root:FL Epoch: 307 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :622
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582680
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695092
INFO:root:FL Epoch: 307 Norm Difference for worker 622 is 0.737051
INFO:root:FL Epoch: 307 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1565
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413495
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465510
INFO:root:FL Epoch: 307 Norm Difference for worker 1565 is 0.843311
INFO:root:FL Epoch: 307 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 622
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.5154232733389911 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:1.8035744229952495                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [264, 701, 1169, 1646, 1126, 1913, 301, 783, 1919, 1787]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 308 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :264
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387875
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 264 is 0.831143
INFO:root:FL Epoch: 308 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :701
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592230
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601962
INFO:root:FL Epoch: 308 Norm Difference for worker 701 is 0.804592
INFO:root:FL Epoch: 308 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1169
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467128
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586601
INFO:root:FL Epoch: 308 Norm Difference for worker 1169 is 0.774851
INFO:root:FL Epoch: 308 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1646
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663812
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387952
INFO:root:FL Epoch: 308 Norm Difference for worker 1646 is 0.828394
INFO:root:FL Epoch: 308 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1126
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676096
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570928
INFO:root:FL Epoch: 308 Norm Difference for worker 1126 is 0.826993
INFO:root:FL Epoch: 308 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1913
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636638
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476313
INFO:root:FL Epoch: 308 Norm Difference for worker 1913 is 0.776252
INFO:root:FL Epoch: 308 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :301
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 301 is 0.774231
INFO:root:FL Epoch: 308 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :783
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608982
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762152
INFO:root:FL Epoch: 308 Norm Difference for worker 783 is 0.752746
INFO:root:FL Epoch: 308 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1919
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768686
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504696
INFO:root:FL Epoch: 308 Norm Difference for worker 1919 is 0.795999
INFO:root:FL Epoch: 308 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1787
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545845
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394066
INFO:root:FL Epoch: 308 Norm Difference for worker 1787 is 0.722403
INFO:root:FL Epoch: 308 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1787
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.5030012060614193 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:1.6630873084068298                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [586, 333, 1284, 1892, 1023, 1930, 1531, 1133, 468, 1461]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 309 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :586
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385212
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352717
INFO:root:FL Epoch: 309 Norm Difference for worker 586 is 0.793908
INFO:root:FL Epoch: 309 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :333
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 333 is 0.736061
INFO:root:FL Epoch: 309 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1284
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584977
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325861
INFO:root:FL Epoch: 309 Norm Difference for worker 1284 is 0.741612
INFO:root:FL Epoch: 309 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1892
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386980
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531590
INFO:root:FL Epoch: 309 Norm Difference for worker 1892 is 0.782742
INFO:root:FL Epoch: 309 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1023
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758399
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399300
INFO:root:FL Epoch: 309 Norm Difference for worker 1023 is 0.728037
INFO:root:FL Epoch: 309 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1930
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646233
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645137
INFO:root:FL Epoch: 309 Norm Difference for worker 1930 is 0.746284
INFO:root:FL Epoch: 309 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1531
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746653
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528290
INFO:root:FL Epoch: 309 Norm Difference for worker 1531 is 0.771779
INFO:root:FL Epoch: 309 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1133
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696043
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463046
INFO:root:FL Epoch: 309 Norm Difference for worker 1133 is 0.803285
INFO:root:FL Epoch: 309 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :468
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713052
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505710
INFO:root:FL Epoch: 309 Norm Difference for worker 468 is 0.743567
INFO:root:FL Epoch: 309 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1461
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409417
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335627
INFO:root:FL Epoch: 309 Norm Difference for worker 1461 is 0.744698
INFO:root:FL Epoch: 309 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.5009267838562236 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:1.5958473483721416                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [384, 1035, 1157, 21, 1257, 355, 414, 1755, 1497, 278]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 310 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :384
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415102
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624726
INFO:root:FL Epoch: 310 Norm Difference for worker 384 is 0.839745
INFO:root:FL Epoch: 310 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1035
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470882
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412350
INFO:root:FL Epoch: 310 Norm Difference for worker 1035 is 0.76648
INFO:root:FL Epoch: 310 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1157
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717973
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719852
INFO:root:FL Epoch: 310 Norm Difference for worker 1157 is 0.756052
INFO:root:FL Epoch: 310 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :21
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 21 is 0.741788
INFO:root:FL Epoch: 310 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1257
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453511
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569086
INFO:root:FL Epoch: 310 Norm Difference for worker 1257 is 0.699036
INFO:root:FL Epoch: 310 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :355
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527202
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606159
INFO:root:FL Epoch: 310 Norm Difference for worker 355 is 0.766784
INFO:root:FL Epoch: 310 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :414
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657536
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472092
INFO:root:FL Epoch: 310 Norm Difference for worker 414 is 0.711954
INFO:root:FL Epoch: 310 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1755
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672526
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457847
INFO:root:FL Epoch: 310 Norm Difference for worker 1755 is 0.746865
INFO:root:FL Epoch: 310 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1497
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726276
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599012
INFO:root:FL Epoch: 310 Norm Difference for worker 1497 is 0.675631
INFO:root:FL Epoch: 310 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :278
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 278 is 0.770029
INFO:root:FL Epoch: 310 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1497
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.5012250893256244 and Test Accuracy:75.0 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:1.4839819073677063                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [279, 1498, 1783, 1672, 1438, 1370, 206, 1254, 652, 1474]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 311 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :279
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542076
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 279 is 0.711972
INFO:root:FL Epoch: 311 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1498
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511454
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630024
INFO:root:FL Epoch: 311 Norm Difference for worker 1498 is 0.736742
INFO:root:FL Epoch: 311 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1783
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727464
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451525
INFO:root:FL Epoch: 311 Norm Difference for worker 1783 is 0.784346
INFO:root:FL Epoch: 311 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1672
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684715
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435976
INFO:root:FL Epoch: 311 Norm Difference for worker 1672 is 0.728757
INFO:root:FL Epoch: 311 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1438
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731320
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736434
INFO:root:FL Epoch: 311 Norm Difference for worker 1438 is 0.737487
INFO:root:FL Epoch: 311 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1370
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443266
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392564
INFO:root:FL Epoch: 311 Norm Difference for worker 1370 is 0.742521
INFO:root:FL Epoch: 311 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :206
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 206 is 0.748689
INFO:root:FL Epoch: 311 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1254
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569199
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437245
INFO:root:FL Epoch: 311 Norm Difference for worker 1254 is 0.750722
INFO:root:FL Epoch: 311 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :652
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380533
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431172
INFO:root:FL Epoch: 311 Norm Difference for worker 652 is 0.730755
INFO:root:FL Epoch: 311 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1474
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552289
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416881
INFO:root:FL Epoch: 311 Norm Difference for worker 1474 is 0.752099
INFO:root:FL Epoch: 311 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 206
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.5011083921965431 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:1.9217292070388794                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [982, 979, 1737, 384, 187, 839, 1148, 1678, 1856, 1388]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :982
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634986
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509463
INFO:root:FL Epoch: 312 Norm Difference for worker 982 is 0.917196
INFO:root:FL Epoch: 312 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :979
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733142
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610153
INFO:root:FL Epoch: 312 Norm Difference for worker 979 is 0.973659
INFO:root:FL Epoch: 312 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1737
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554216
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346624
INFO:root:FL Epoch: 312 Norm Difference for worker 1737 is 0.885043
INFO:root:FL Epoch: 312 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :384
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520426
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317238
INFO:root:FL Epoch: 312 Norm Difference for worker 384 is 0.875241
INFO:root:FL Epoch: 312 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :187
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 187 is 0.913508
INFO:root:FL Epoch: 312 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :839
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681059
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328050
INFO:root:FL Epoch: 312 Norm Difference for worker 839 is 0.935642
INFO:root:FL Epoch: 312 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1148
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636110
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714921
INFO:root:FL Epoch: 312 Norm Difference for worker 1148 is 0.904831
INFO:root:FL Epoch: 312 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1678
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409289
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367574
INFO:root:FL Epoch: 312 Norm Difference for worker 1678 is 0.863707
INFO:root:FL Epoch: 312 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1856
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618448
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322157
INFO:root:FL Epoch: 312 Norm Difference for worker 1856 is 0.980611
INFO:root:FL Epoch: 312 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1388
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701834
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345600
INFO:root:FL Epoch: 312 Norm Difference for worker 1388 is 0.871991
INFO:root:FL Epoch: 312 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1678
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.5188063698656419 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:2.3647015492121377                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [416, 953, 410, 382, 11, 1222, 1158, 1523, 1490, 1844]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :416
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654886
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452617
INFO:root:FL Epoch: 313 Norm Difference for worker 416 is 0.914498
INFO:root:FL Epoch: 313 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :953
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481629
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505896
INFO:root:FL Epoch: 313 Norm Difference for worker 953 is 0.895276
INFO:root:FL Epoch: 313 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :410
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290099
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555330
INFO:root:FL Epoch: 313 Norm Difference for worker 410 is 0.815486
INFO:root:FL Epoch: 313 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :382
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651827
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324510
INFO:root:FL Epoch: 313 Norm Difference for worker 382 is 0.923838
INFO:root:FL Epoch: 313 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :11
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 11 is 0.841839
INFO:root:FL Epoch: 313 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1222
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405256
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393867
INFO:root:FL Epoch: 313 Norm Difference for worker 1222 is 0.921215
INFO:root:FL Epoch: 313 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1158
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.276560
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254100
INFO:root:FL Epoch: 313 Norm Difference for worker 1158 is 0.785247
INFO:root:FL Epoch: 313 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1523
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651601
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348659
INFO:root:FL Epoch: 313 Norm Difference for worker 1523 is 0.900795
INFO:root:FL Epoch: 313 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1490
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684266
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584797
INFO:root:FL Epoch: 313 Norm Difference for worker 1490 is 0.882733
INFO:root:FL Epoch: 313 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1844
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397532
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334423
INFO:root:FL Epoch: 313 Norm Difference for worker 1844 is 0.912425
INFO:root:FL Epoch: 313 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1158
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.5170280810664681 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:2.2275734742482505                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [755, 561, 563, 245, 1771, 1681, 1886, 67, 939, 413]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :755
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840524
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265798
INFO:root:FL Epoch: 314 Norm Difference for worker 755 is 1.067804
INFO:root:FL Epoch: 314 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :561
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558629
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579496
INFO:root:FL Epoch: 314 Norm Difference for worker 561 is 1.114761
INFO:root:FL Epoch: 314 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :563
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742420
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513705
INFO:root:FL Epoch: 314 Norm Difference for worker 563 is 0.992569
INFO:root:FL Epoch: 314 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :245
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 245 is 1.137182
INFO:root:FL Epoch: 314 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1771
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 1.021639
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573987
INFO:root:FL Epoch: 314 Norm Difference for worker 1771 is 1.057416
INFO:root:FL Epoch: 314 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1681
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348092
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513943
INFO:root:FL Epoch: 314 Norm Difference for worker 1681 is 1.076854
INFO:root:FL Epoch: 314 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1886
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662518
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486817
INFO:root:FL Epoch: 314 Norm Difference for worker 1886 is 1.084739
INFO:root:FL Epoch: 314 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :67
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 67 is 1.063612
INFO:root:FL Epoch: 314 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :939
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559913
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585134
INFO:root:FL Epoch: 314 Norm Difference for worker 939 is 1.086678
INFO:root:FL Epoch: 314 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :413
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612038
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447317
INFO:root:FL Epoch: 314 Norm Difference for worker 413 is 1.026631
INFO:root:FL Epoch: 314 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 67
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.5221579443005955 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:2.2848483324050903                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [850, 1, 1181, 1907, 244, 750, 377, 1376, 1206, 1204]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 315 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :850
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749102
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427865
INFO:root:FL Epoch: 315 Norm Difference for worker 850 is 0.914721
INFO:root:FL Epoch: 315 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 1 is 0.875433
INFO:root:FL Epoch: 315 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1181
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507304
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576523
INFO:root:FL Epoch: 315 Norm Difference for worker 1181 is 0.842477
INFO:root:FL Epoch: 315 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1907
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419298
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428567
INFO:root:FL Epoch: 315 Norm Difference for worker 1907 is 0.89346
INFO:root:FL Epoch: 315 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :244
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392215
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 244 is 0.855512
INFO:root:FL Epoch: 315 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :750
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397764
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674810
INFO:root:FL Epoch: 315 Norm Difference for worker 750 is 0.90561
INFO:root:FL Epoch: 315 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :377
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571038
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374818
INFO:root:FL Epoch: 315 Norm Difference for worker 377 is 0.964415
INFO:root:FL Epoch: 315 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1376
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420849
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356684
INFO:root:FL Epoch: 315 Norm Difference for worker 1376 is 0.96289
INFO:root:FL Epoch: 315 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1206
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333351
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397048
INFO:root:FL Epoch: 315 Norm Difference for worker 1206 is 0.897203
INFO:root:FL Epoch: 315 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1204
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458280
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528202
INFO:root:FL Epoch: 315 Norm Difference for worker 1204 is 0.902496
INFO:root:FL Epoch: 315 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.5135517996900222 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:1.5685003995895386                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [642, 705, 1671, 1601, 865, 146, 1614, 1418, 1861, 1813]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :642
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490809
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587809
INFO:root:FL Epoch: 316 Norm Difference for worker 642 is 0.857412
INFO:root:FL Epoch: 316 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :705
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461002
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341834
INFO:root:FL Epoch: 316 Norm Difference for worker 705 is 0.785734
INFO:root:FL Epoch: 316 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1671
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582373
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384765
INFO:root:FL Epoch: 316 Norm Difference for worker 1671 is 0.724377
INFO:root:FL Epoch: 316 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1601
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488669
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465167
INFO:root:FL Epoch: 316 Norm Difference for worker 1601 is 0.761219
INFO:root:FL Epoch: 316 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :865
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543807
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587073
INFO:root:FL Epoch: 316 Norm Difference for worker 865 is 0.818154
INFO:root:FL Epoch: 316 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :146
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541912
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511618
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 146 is 0.878555
INFO:root:FL Epoch: 316 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1614
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439840
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339674
INFO:root:FL Epoch: 316 Norm Difference for worker 1614 is 0.814781
INFO:root:FL Epoch: 316 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1418
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559158
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277537
INFO:root:FL Epoch: 316 Norm Difference for worker 1418 is 0.752264
INFO:root:FL Epoch: 316 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1861
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425599
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454634
INFO:root:FL Epoch: 316 Norm Difference for worker 1861 is 0.786726
INFO:root:FL Epoch: 316 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1813
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616488
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465921
INFO:root:FL Epoch: 316 Norm Difference for worker 1813 is 0.812473
INFO:root:FL Epoch: 316 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1671
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.5069808714530047 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:1.8214612007141113                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [1399, 719, 1885, 529, 1390, 810, 186, 1778, 1932, 962]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :1399
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436363
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321657
INFO:root:FL Epoch: 317 Norm Difference for worker 1399 is 0.788117
INFO:root:FL Epoch: 317 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :719
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794478
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661384
INFO:root:FL Epoch: 317 Norm Difference for worker 719 is 0.7532
INFO:root:FL Epoch: 317 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1885
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525875
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596856
INFO:root:FL Epoch: 317 Norm Difference for worker 1885 is 0.785234
INFO:root:FL Epoch: 317 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :529
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628441
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437428
INFO:root:FL Epoch: 317 Norm Difference for worker 529 is 0.793774
INFO:root:FL Epoch: 317 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1390
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571537
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298065
INFO:root:FL Epoch: 317 Norm Difference for worker 1390 is 0.740017
INFO:root:FL Epoch: 317 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :810
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499148
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575361
INFO:root:FL Epoch: 317 Norm Difference for worker 810 is 0.833399
INFO:root:FL Epoch: 317 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :186
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507133
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 186 is 0.840349
INFO:root:FL Epoch: 317 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1778
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587595
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584371
INFO:root:FL Epoch: 317 Norm Difference for worker 1778 is 0.803775
INFO:root:FL Epoch: 317 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1932
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393641
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324058
INFO:root:FL Epoch: 317 Norm Difference for worker 1932 is 0.821226
INFO:root:FL Epoch: 317 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :962
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680971
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507316
INFO:root:FL Epoch: 317 Norm Difference for worker 962 is 0.799674
INFO:root:FL Epoch: 317 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1390
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.4975009280092576 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:1.94430673122406                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [19, 428, 1021, 929, 390, 658, 1834, 1315, 2, 994]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :19
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491061
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 19 is 0.771785
INFO:root:FL Epoch: 318 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :428
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480788
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452627
INFO:root:FL Epoch: 318 Norm Difference for worker 428 is 0.839172
INFO:root:FL Epoch: 318 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1021
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710443
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685243
INFO:root:FL Epoch: 318 Norm Difference for worker 1021 is 0.823178
INFO:root:FL Epoch: 318 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :929
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602785
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402199
INFO:root:FL Epoch: 318 Norm Difference for worker 929 is 0.770893
INFO:root:FL Epoch: 318 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :390
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608024
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662758
INFO:root:FL Epoch: 318 Norm Difference for worker 390 is 0.833402
INFO:root:FL Epoch: 318 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :658
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533138
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285775
INFO:root:FL Epoch: 318 Norm Difference for worker 658 is 0.860764
INFO:root:FL Epoch: 318 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1834
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799254
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523688
INFO:root:FL Epoch: 318 Norm Difference for worker 1834 is 0.893868
INFO:root:FL Epoch: 318 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1315
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531275
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464384
INFO:root:FL Epoch: 318 Norm Difference for worker 1315 is 0.880172
INFO:root:FL Epoch: 318 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :2
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 2 is 0.786997
INFO:root:FL Epoch: 318 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :994
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432236
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598516
INFO:root:FL Epoch: 318 Norm Difference for worker 994 is 0.807225
INFO:root:FL Epoch: 318 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.49478473032222076 and Test Accuracy:75.0 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:2.172986388206482                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1904, 1871, 1222, 1549, 567, 189, 1181, 1516, 504, 114]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1904
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480610
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606490
INFO:root:FL Epoch: 319 Norm Difference for worker 1904 is 0.861246
INFO:root:FL Epoch: 319 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1871
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390061
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434786
INFO:root:FL Epoch: 319 Norm Difference for worker 1871 is 0.879933
INFO:root:FL Epoch: 319 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1222
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643947
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496311
INFO:root:FL Epoch: 319 Norm Difference for worker 1222 is 0.898979
INFO:root:FL Epoch: 319 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1549
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489169
INFO:root:Worker: 1549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448048
INFO:root:FL Epoch: 319 Norm Difference for worker 1549 is 0.80781
INFO:root:FL Epoch: 319 Done on worker:1549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :567
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613124
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367813
INFO:root:FL Epoch: 319 Norm Difference for worker 567 is 0.785958
INFO:root:FL Epoch: 319 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :189
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 189 is 0.91294
INFO:root:FL Epoch: 319 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1181
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349933
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361699
INFO:root:FL Epoch: 319 Norm Difference for worker 1181 is 0.902579
INFO:root:FL Epoch: 319 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1516
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508039
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344512
INFO:root:FL Epoch: 319 Norm Difference for worker 1516 is 0.724889
INFO:root:FL Epoch: 319 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :504
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537416
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346751
INFO:root:FL Epoch: 319 Norm Difference for worker 504 is 0.839736
INFO:root:FL Epoch: 319 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :114
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.869383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409912
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 114 is 0.926802
INFO:root:FL Epoch: 319 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1516
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.5037163671325234 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:2.2674534718195596                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [888, 1173, 29, 1189, 1094, 947, 1607, 226, 1855, 300]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 320 Num points on workers: [200 200 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :888
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872851
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534193
INFO:root:FL Epoch: 320 Norm Difference for worker 888 is 0.924284
INFO:root:FL Epoch: 320 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1173
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574253
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384637
INFO:root:FL Epoch: 320 Norm Difference for worker 1173 is 0.826148
INFO:root:FL Epoch: 320 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :29
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 29 is 0.937145
INFO:root:FL Epoch: 320 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1189
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423782
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517810
INFO:root:FL Epoch: 320 Norm Difference for worker 1189 is 0.902809
INFO:root:FL Epoch: 320 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1094
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621400
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656321
INFO:root:FL Epoch: 320 Norm Difference for worker 1094 is 0.951826
INFO:root:FL Epoch: 320 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :947
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499429
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516818
INFO:root:FL Epoch: 320 Norm Difference for worker 947 is 0.877078
INFO:root:FL Epoch: 320 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1607
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592430
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313846
INFO:root:FL Epoch: 320 Norm Difference for worker 1607 is 0.834257
INFO:root:FL Epoch: 320 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :226
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501498
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 226 is 0.872019
INFO:root:FL Epoch: 320 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1855
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427381
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491396
INFO:root:FL Epoch: 320 Norm Difference for worker 1855 is 0.929954
INFO:root:FL Epoch: 320 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :300
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.861908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 300 is 0.873985
INFO:root:FL Epoch: 320 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1173
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.5041168437284582 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:2.315208911895752                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [1083, 618, 1577, 463, 941, 1276, 456, 528, 669, 472]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :1083
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398643
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523596
INFO:root:FL Epoch: 321 Norm Difference for worker 1083 is 0.90984
INFO:root:FL Epoch: 321 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :618
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576731
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513598
INFO:root:FL Epoch: 321 Norm Difference for worker 618 is 1.014922
INFO:root:FL Epoch: 321 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1577
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591323
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.820464
INFO:root:FL Epoch: 321 Norm Difference for worker 1577 is 0.9612
INFO:root:FL Epoch: 321 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :463
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858428
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450762
INFO:root:FL Epoch: 321 Norm Difference for worker 463 is 0.967718
INFO:root:FL Epoch: 321 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :941
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624485
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473957
INFO:root:FL Epoch: 321 Norm Difference for worker 941 is 0.902748
INFO:root:FL Epoch: 321 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1276
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555452
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362027
INFO:root:FL Epoch: 321 Norm Difference for worker 1276 is 0.977088
INFO:root:FL Epoch: 321 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :456
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598840
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421298
INFO:root:FL Epoch: 321 Norm Difference for worker 456 is 0.916489
INFO:root:FL Epoch: 321 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :528
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701625
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434413
INFO:root:FL Epoch: 321 Norm Difference for worker 528 is 0.980307
INFO:root:FL Epoch: 321 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :669
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744518
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405977
INFO:root:FL Epoch: 321 Norm Difference for worker 669 is 0.884088
INFO:root:FL Epoch: 321 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :472
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342578
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498912
INFO:root:FL Epoch: 321 Norm Difference for worker 472 is 0.925885
INFO:root:FL Epoch: 321 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 472
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.5216412439065821 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:1.9722630381584167                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [1793, 574, 1225, 619, 1620, 90, 1916, 721, 251, 105]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :1793
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507988
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502617
INFO:root:FL Epoch: 322 Norm Difference for worker 1793 is 0.823567
INFO:root:FL Epoch: 322 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :574
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499764
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464452
INFO:root:FL Epoch: 322 Norm Difference for worker 574 is 0.812399
INFO:root:FL Epoch: 322 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1225
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871583
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533758
INFO:root:FL Epoch: 322 Norm Difference for worker 1225 is 0.795322
INFO:root:FL Epoch: 322 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :619
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907688
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586714
INFO:root:FL Epoch: 322 Norm Difference for worker 619 is 0.796123
INFO:root:FL Epoch: 322 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1620
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480220
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516900
INFO:root:FL Epoch: 322 Norm Difference for worker 1620 is 0.828009
INFO:root:FL Epoch: 322 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :90
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657552
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372750
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 90 is 0.845766
INFO:root:FL Epoch: 322 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1916
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499933
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393701
INFO:root:FL Epoch: 322 Norm Difference for worker 1916 is 0.813778
INFO:root:FL Epoch: 322 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :721
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627229
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582010
INFO:root:FL Epoch: 322 Norm Difference for worker 721 is 0.83892
INFO:root:FL Epoch: 322 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :251
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 251 is 0.815169
INFO:root:FL Epoch: 322 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :105
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627104
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 105 is 0.863577
INFO:root:FL Epoch: 322 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 619
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.49498208305414987 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:1.8401906887690227                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [218, 473, 1303, 1742, 670, 450, 1853, 1333, 1321, 1547]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 323 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :218
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 218 is 0.793451
INFO:root:FL Epoch: 323 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :473
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544643
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449480
INFO:root:FL Epoch: 323 Norm Difference for worker 473 is 0.793794
INFO:root:FL Epoch: 323 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1303
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544312
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374886
INFO:root:FL Epoch: 323 Norm Difference for worker 1303 is 0.808906
INFO:root:FL Epoch: 323 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1742
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460360
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396750
INFO:root:FL Epoch: 323 Norm Difference for worker 1742 is 0.8347
INFO:root:FL Epoch: 323 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :670
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817508
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536150
INFO:root:FL Epoch: 323 Norm Difference for worker 670 is 0.846734
INFO:root:FL Epoch: 323 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :450
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493062
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587641
INFO:root:FL Epoch: 323 Norm Difference for worker 450 is 0.77759
INFO:root:FL Epoch: 323 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1853
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658295
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432699
INFO:root:FL Epoch: 323 Norm Difference for worker 1853 is 0.912784
INFO:root:FL Epoch: 323 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1333
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601897
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702057
INFO:root:FL Epoch: 323 Norm Difference for worker 1333 is 0.810135
INFO:root:FL Epoch: 323 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1321
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442997
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357385
INFO:root:FL Epoch: 323 Norm Difference for worker 1321 is 0.80421
INFO:root:FL Epoch: 323 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1547
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477520
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506602
INFO:root:FL Epoch: 323 Norm Difference for worker 1547 is 0.849971
INFO:root:FL Epoch: 323 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1303
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.534012100275825 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:2.36802347501119                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1318, 1635, 1854, 1121, 882, 265, 1649, 509, 856, 954]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1318
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298565
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452902
INFO:root:FL Epoch: 324 Norm Difference for worker 1318 is 0.86013
INFO:root:FL Epoch: 324 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1635
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658516
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495757
INFO:root:FL Epoch: 324 Norm Difference for worker 1635 is 0.784275
INFO:root:FL Epoch: 324 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1854
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594556
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522540
INFO:root:FL Epoch: 324 Norm Difference for worker 1854 is 0.882951
INFO:root:FL Epoch: 324 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1121
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468289
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430423
INFO:root:FL Epoch: 324 Norm Difference for worker 1121 is 0.832905
INFO:root:FL Epoch: 324 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :882
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503207
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289991
INFO:root:FL Epoch: 324 Norm Difference for worker 882 is 0.772599
INFO:root:FL Epoch: 324 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :265
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479806
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 324 Norm Difference for worker 265 is 0.914507
INFO:root:FL Epoch: 324 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1649
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620210
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449948
INFO:root:FL Epoch: 324 Norm Difference for worker 1649 is 0.851761
INFO:root:FL Epoch: 324 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :509
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742384
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392830
INFO:root:FL Epoch: 324 Norm Difference for worker 509 is 0.907978
INFO:root:FL Epoch: 324 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :856
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599073
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686878
INFO:root:FL Epoch: 324 Norm Difference for worker 856 is 1.020043
INFO:root:FL Epoch: 324 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :954
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499199
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407522
INFO:root:FL Epoch: 324 Norm Difference for worker 954 is 0.838701
INFO:root:FL Epoch: 324 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 882
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.5021805587936851 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:2.0101610819498696                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [254, 1178, 1522, 1098, 492, 1636, 1511, 1163, 207, 939]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 325 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :254
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 254 is 0.912058
INFO:root:FL Epoch: 325 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1178
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532967
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410064
INFO:root:FL Epoch: 325 Norm Difference for worker 1178 is 0.857833
INFO:root:FL Epoch: 325 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1522
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619358
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428560
INFO:root:FL Epoch: 325 Norm Difference for worker 1522 is 0.849561
INFO:root:FL Epoch: 325 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1098
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575707
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420043
INFO:root:FL Epoch: 325 Norm Difference for worker 1098 is 0.820965
INFO:root:FL Epoch: 325 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :492
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460569
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261098
INFO:root:FL Epoch: 325 Norm Difference for worker 492 is 0.802799
INFO:root:FL Epoch: 325 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1636
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479871
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539285
INFO:root:FL Epoch: 325 Norm Difference for worker 1636 is 0.906344
INFO:root:FL Epoch: 325 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1511
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611904
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383823
INFO:root:FL Epoch: 325 Norm Difference for worker 1511 is 0.850941
INFO:root:FL Epoch: 325 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1163
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702218
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509383
INFO:root:FL Epoch: 325 Norm Difference for worker 1163 is 0.835947
INFO:root:FL Epoch: 325 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :207
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.746538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 207 is 0.847816
INFO:root:FL Epoch: 325 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :939
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498218
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600266
INFO:root:FL Epoch: 325 Norm Difference for worker 939 is 0.863773
INFO:root:FL Epoch: 325 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1098
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.5198739451520583 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:2.1612796783447266                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [353, 1765, 603, 1802, 1867, 884, 641, 1212, 1420, 1713]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :353
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445997
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321667
INFO:root:FL Epoch: 326 Norm Difference for worker 353 is 0.82181
INFO:root:FL Epoch: 326 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1765
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397580
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506050
INFO:root:FL Epoch: 326 Norm Difference for worker 1765 is 0.81082
INFO:root:FL Epoch: 326 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :603
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771851
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684399
INFO:root:FL Epoch: 326 Norm Difference for worker 603 is 0.856798
INFO:root:FL Epoch: 326 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1802
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765311
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368781
INFO:root:FL Epoch: 326 Norm Difference for worker 1802 is 0.853673
INFO:root:FL Epoch: 326 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1867
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530916
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386363
INFO:root:FL Epoch: 326 Norm Difference for worker 1867 is 0.823336
INFO:root:FL Epoch: 326 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :884
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585626
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489557
INFO:root:FL Epoch: 326 Norm Difference for worker 884 is 0.898505
INFO:root:FL Epoch: 326 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :641
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518102
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691901
INFO:root:FL Epoch: 326 Norm Difference for worker 641 is 0.929608
INFO:root:FL Epoch: 326 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1212
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466889
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303510
INFO:root:FL Epoch: 326 Norm Difference for worker 1212 is 0.820169
INFO:root:FL Epoch: 326 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1420
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537408
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632549
INFO:root:FL Epoch: 326 Norm Difference for worker 1420 is 0.861621
INFO:root:FL Epoch: 326 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1713
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481196
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380830
INFO:root:FL Epoch: 326 Norm Difference for worker 1713 is 0.824236
INFO:root:FL Epoch: 326 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1765
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.5163382975494161 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:1.7693854570388794                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [811, 131, 253, 1227, 930, 971, 668, 1491, 182, 1472]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 327 Num points on workers: [200 201 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :811
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545145
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646093
INFO:root:FL Epoch: 327 Norm Difference for worker 811 is 0.897175
INFO:root:FL Epoch: 327 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :131
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 131 is 0.8578
INFO:root:FL Epoch: 327 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :253
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482941
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 253 is 0.856539
INFO:root:FL Epoch: 327 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1227
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749767
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446397
INFO:root:FL Epoch: 327 Norm Difference for worker 1227 is 0.914378
INFO:root:FL Epoch: 327 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :930
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181960
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480963
INFO:root:FL Epoch: 327 Norm Difference for worker 930 is 0.793654
INFO:root:FL Epoch: 327 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :971
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472670
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403795
INFO:root:FL Epoch: 327 Norm Difference for worker 971 is 0.877418
INFO:root:FL Epoch: 327 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :668
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757032
INFO:root:Worker: 668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747690
INFO:root:FL Epoch: 327 Norm Difference for worker 668 is 0.981534
INFO:root:FL Epoch: 327 Done on worker:668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1491
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546963
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385595
INFO:root:FL Epoch: 327 Norm Difference for worker 1491 is 0.87971
INFO:root:FL Epoch: 327 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :182
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 182 is 1.042817
INFO:root:FL Epoch: 327 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1472
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404987
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551351
INFO:root:FL Epoch: 327 Norm Difference for worker 1472 is 0.899379
INFO:root:FL Epoch: 327 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 930
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.5156849096803104 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:2.1023887395858765                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [342, 1865, 475, 379, 621, 50, 835, 1034, 1405, 84]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 328 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :342
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607503
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571240
INFO:root:FL Epoch: 328 Norm Difference for worker 342 is 0.925425
INFO:root:FL Epoch: 328 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1865
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604480
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432931
INFO:root:FL Epoch: 328 Norm Difference for worker 1865 is 0.831175
INFO:root:FL Epoch: 328 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :475
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459765
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589536
INFO:root:FL Epoch: 328 Norm Difference for worker 475 is 0.892139
INFO:root:FL Epoch: 328 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :379
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630246
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448889
INFO:root:FL Epoch: 328 Norm Difference for worker 379 is 0.86109
INFO:root:FL Epoch: 328 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :621
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638084
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499013
INFO:root:FL Epoch: 328 Norm Difference for worker 621 is 0.870255
INFO:root:FL Epoch: 328 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :50
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346722
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 50 is 0.881969
INFO:root:FL Epoch: 328 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :835
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425031
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281684
INFO:root:FL Epoch: 328 Norm Difference for worker 835 is 0.831358
INFO:root:FL Epoch: 328 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1034
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738076
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377884
INFO:root:FL Epoch: 328 Norm Difference for worker 1034 is 0.863533
INFO:root:FL Epoch: 328 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1405
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611769
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556024
INFO:root:FL Epoch: 328 Norm Difference for worker 1405 is 0.853343
INFO:root:FL Epoch: 328 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :84
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389416
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 84 is 0.842448
INFO:root:FL Epoch: 328 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1865
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.505858814015108 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:1.7257466713587444                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [929, 132, 409, 711, 475, 1409, 1598, 289, 386, 34]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 329 Num points on workers: [200 201 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :929
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413888
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586225
INFO:root:FL Epoch: 329 Norm Difference for worker 929 is 0.769559
INFO:root:FL Epoch: 329 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :132
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 132 is 0.755724
INFO:root:FL Epoch: 329 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :409
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435477
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345968
INFO:root:FL Epoch: 329 Norm Difference for worker 409 is 0.771746
INFO:root:FL Epoch: 329 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :711
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489172
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429334
INFO:root:FL Epoch: 329 Norm Difference for worker 711 is 0.725492
INFO:root:FL Epoch: 329 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :475
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510493
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447416
INFO:root:FL Epoch: 329 Norm Difference for worker 475 is 0.761154
INFO:root:FL Epoch: 329 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1409
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558602
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421360
INFO:root:FL Epoch: 329 Norm Difference for worker 1409 is 0.746909
INFO:root:FL Epoch: 329 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1598
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375396
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368630
INFO:root:FL Epoch: 329 Norm Difference for worker 1598 is 0.764765
INFO:root:FL Epoch: 329 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :289
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554609
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312676
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 289 is 0.744587
INFO:root:FL Epoch: 329 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :386
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530592
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437352
INFO:root:FL Epoch: 329 Norm Difference for worker 386 is 0.78708
INFO:root:FL Epoch: 329 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :34
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 34 is 0.778229
INFO:root:FL Epoch: 329 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.49099360494052663 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:1.940574010213216                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [1707, 1902, 922, 1552, 554, 1445, 763, 861, 1372, 638]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :1707
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369570
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713559
INFO:root:FL Epoch: 330 Norm Difference for worker 1707 is 0.880414
INFO:root:FL Epoch: 330 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1902
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778939
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296615
INFO:root:FL Epoch: 330 Norm Difference for worker 1902 is 0.930757
INFO:root:FL Epoch: 330 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :922
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402984
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453728
INFO:root:FL Epoch: 330 Norm Difference for worker 922 is 0.88014
INFO:root:FL Epoch: 330 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1552
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356179
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470183
INFO:root:FL Epoch: 330 Norm Difference for worker 1552 is 0.911053
INFO:root:FL Epoch: 330 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :554
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486083
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373011
INFO:root:FL Epoch: 330 Norm Difference for worker 554 is 0.843646
INFO:root:FL Epoch: 330 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1445
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445366
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464672
INFO:root:FL Epoch: 330 Norm Difference for worker 1445 is 0.914806
INFO:root:FL Epoch: 330 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :763
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500306
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602140
INFO:root:FL Epoch: 330 Norm Difference for worker 763 is 0.868657
INFO:root:FL Epoch: 330 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :861
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575523
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694152
INFO:root:FL Epoch: 330 Norm Difference for worker 861 is 0.944454
INFO:root:FL Epoch: 330 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1372
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548449
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517370
INFO:root:FL Epoch: 330 Norm Difference for worker 1372 is 0.919912
INFO:root:FL Epoch: 330 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :638
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439883
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512441
INFO:root:FL Epoch: 330 Norm Difference for worker 638 is 0.829158
INFO:root:FL Epoch: 330 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 554
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.4867008345968583 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:1.6706292629241943                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [297, 1896, 411, 346, 1830, 1852, 72, 1291, 1661, 238]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 331 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :297
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 297 is 0.824318
INFO:root:FL Epoch: 331 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1896
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590008
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497358
INFO:root:FL Epoch: 331 Norm Difference for worker 1896 is 0.83936
INFO:root:FL Epoch: 331 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :411
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286862
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390887
INFO:root:FL Epoch: 331 Norm Difference for worker 411 is 0.795776
INFO:root:FL Epoch: 331 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :346
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394312
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400986
INFO:root:FL Epoch: 331 Norm Difference for worker 346 is 0.805769
INFO:root:FL Epoch: 331 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1830
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466036
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320907
INFO:root:FL Epoch: 331 Norm Difference for worker 1830 is 0.817035
INFO:root:FL Epoch: 331 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1852
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447219
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623800
INFO:root:FL Epoch: 331 Norm Difference for worker 1852 is 0.782579
INFO:root:FL Epoch: 331 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :72
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 72 is 0.798644
INFO:root:FL Epoch: 331 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1291
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373734
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431523
INFO:root:FL Epoch: 331 Norm Difference for worker 1291 is 0.780663
INFO:root:FL Epoch: 331 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1661
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400379
INFO:root:Worker: 1661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659849
INFO:root:FL Epoch: 331 Norm Difference for worker 1661 is 0.803959
INFO:root:FL Epoch: 331 Done on worker:1661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :238
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 238 is 0.732656
INFO:root:FL Epoch: 331 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 238
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.4815973516772775 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:1.6798476378122966                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1556, 46, 1138, 1808, 1072, 868, 395, 329, 1284, 1682]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 332 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1556
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357796
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334588
INFO:root:FL Epoch: 332 Norm Difference for worker 1556 is 0.815911
INFO:root:FL Epoch: 332 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :46
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407455
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 46 is 0.826509
INFO:root:FL Epoch: 332 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1138
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749324
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692402
INFO:root:FL Epoch: 332 Norm Difference for worker 1138 is 0.890224
INFO:root:FL Epoch: 332 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1808
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850991
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482908
INFO:root:FL Epoch: 332 Norm Difference for worker 1808 is 0.830289
INFO:root:FL Epoch: 332 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1072
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694540
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401174
INFO:root:FL Epoch: 332 Norm Difference for worker 1072 is 0.806701
INFO:root:FL Epoch: 332 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :868
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326808
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415559
INFO:root:FL Epoch: 332 Norm Difference for worker 868 is 0.883636
INFO:root:FL Epoch: 332 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :395
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699961
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476892
INFO:root:FL Epoch: 332 Norm Difference for worker 395 is 0.81414
INFO:root:FL Epoch: 332 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :329
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729704
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 329 is 0.763558
INFO:root:FL Epoch: 332 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1284
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665027
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323198
INFO:root:FL Epoch: 332 Norm Difference for worker 1284 is 0.736365
INFO:root:FL Epoch: 332 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1682
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649209
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329612
INFO:root:FL Epoch: 332 Norm Difference for worker 1682 is 0.739052
INFO:root:FL Epoch: 332 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1284
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.49095574547262755 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:2.057141820589701                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [557, 730, 633, 293, 1591, 209, 1900, 958, 1186, 1926]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :557
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436159
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478022
INFO:root:FL Epoch: 333 Norm Difference for worker 557 is 0.836774
INFO:root:FL Epoch: 333 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :730
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448022
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277872
INFO:root:FL Epoch: 333 Norm Difference for worker 730 is 0.896851
INFO:root:FL Epoch: 333 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :633
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333067
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656070
INFO:root:FL Epoch: 333 Norm Difference for worker 633 is 0.863084
INFO:root:FL Epoch: 333 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :293
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 293 is 0.881313
INFO:root:FL Epoch: 333 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1591
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351447
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519816
INFO:root:FL Epoch: 333 Norm Difference for worker 1591 is 0.845207
INFO:root:FL Epoch: 333 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :209
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442869
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 209 is 0.776931
INFO:root:FL Epoch: 333 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1900
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573245
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495086
INFO:root:FL Epoch: 333 Norm Difference for worker 1900 is 0.874985
INFO:root:FL Epoch: 333 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :958
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624810
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441221
INFO:root:FL Epoch: 333 Norm Difference for worker 958 is 0.910965
INFO:root:FL Epoch: 333 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1186
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458745
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545783
INFO:root:FL Epoch: 333 Norm Difference for worker 1186 is 0.916583
INFO:root:FL Epoch: 333 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1926
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497794
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487270
INFO:root:FL Epoch: 333 Norm Difference for worker 1926 is 0.869458
INFO:root:FL Epoch: 333 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 209
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.4782096866299124 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:1.7966065605481465                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1197, 468, 155, 1301, 322, 566, 1738, 369, 1568, 47]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1197
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447701
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630101
INFO:root:FL Epoch: 334 Norm Difference for worker 1197 is 0.818149
INFO:root:FL Epoch: 334 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :468
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496439
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.775409
INFO:root:FL Epoch: 334 Norm Difference for worker 468 is 0.730375
INFO:root:FL Epoch: 334 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :155
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429218
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 155 is 0.857675
INFO:root:FL Epoch: 334 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1301
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.956376
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500460
INFO:root:FL Epoch: 334 Norm Difference for worker 1301 is 0.90912
INFO:root:FL Epoch: 334 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :322
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.807901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 322 is 0.855919
INFO:root:FL Epoch: 334 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :566
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793753
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387638
INFO:root:FL Epoch: 334 Norm Difference for worker 566 is 0.790548
INFO:root:FL Epoch: 334 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1738
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663824
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629832
INFO:root:FL Epoch: 334 Norm Difference for worker 1738 is 0.852979
INFO:root:FL Epoch: 334 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :369
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969477
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636690
INFO:root:FL Epoch: 334 Norm Difference for worker 369 is 0.822315
INFO:root:FL Epoch: 334 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1568
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603739
INFO:root:Worker: 1568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588020
INFO:root:FL Epoch: 334 Norm Difference for worker 1568 is 0.82903
INFO:root:FL Epoch: 334 Done on worker:1568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :47
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 47 is 0.892854
INFO:root:FL Epoch: 334 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 468
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.48005320219432607 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:1.8376792271931965                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [9, 811, 1180, 499, 1843, 1918, 329, 169, 1622, 778]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 335 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :9
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 9 is 0.830832
INFO:root:FL Epoch: 335 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :811
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369453
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463152
INFO:root:FL Epoch: 335 Norm Difference for worker 811 is 0.792083
INFO:root:FL Epoch: 335 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1180
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308217
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647045
INFO:root:FL Epoch: 335 Norm Difference for worker 1180 is 0.775012
INFO:root:FL Epoch: 335 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :499
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454726
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425329
INFO:root:FL Epoch: 335 Norm Difference for worker 499 is 0.898153
INFO:root:FL Epoch: 335 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1843
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519536
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279259
INFO:root:FL Epoch: 335 Norm Difference for worker 1843 is 0.768448
INFO:root:FL Epoch: 335 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1918
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512112
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527712
INFO:root:FL Epoch: 335 Norm Difference for worker 1918 is 0.797961
INFO:root:FL Epoch: 335 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :329
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 329 is 0.807395
INFO:root:FL Epoch: 335 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :169
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 169 is 0.827755
INFO:root:FL Epoch: 335 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1622
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619405
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256029
INFO:root:FL Epoch: 335 Norm Difference for worker 1622 is 0.809271
INFO:root:FL Epoch: 335 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :778
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498819
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721869
INFO:root:FL Epoch: 335 Norm Difference for worker 778 is 0.943101
INFO:root:FL Epoch: 335 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.5037360173814437 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:2.216357946395874                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [295, 1128, 471, 1188, 180, 157, 1900, 212, 688, 377]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 336 Num points on workers: [201 200 200 200 201 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :295
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777944
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 295 is 0.892695
INFO:root:FL Epoch: 336 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1128
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589786
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548096
INFO:root:FL Epoch: 336 Norm Difference for worker 1128 is 0.891885
INFO:root:FL Epoch: 336 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :471
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746877
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495934
INFO:root:FL Epoch: 336 Norm Difference for worker 471 is 0.934204
INFO:root:FL Epoch: 336 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1188
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319875
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459453
INFO:root:FL Epoch: 336 Norm Difference for worker 1188 is 0.966098
INFO:root:FL Epoch: 336 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :180
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 180 is 0.84807
INFO:root:FL Epoch: 336 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :157
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 157 is 0.839905
INFO:root:FL Epoch: 336 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1900
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653472
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508071
INFO:root:FL Epoch: 336 Norm Difference for worker 1900 is 0.919668
INFO:root:FL Epoch: 336 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :212
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513461
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483976
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 212 is 1.04166
INFO:root:FL Epoch: 336 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :688
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359759
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574390
INFO:root:FL Epoch: 336 Norm Difference for worker 688 is 0.894158
INFO:root:FL Epoch: 336 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :377
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537711
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589765
INFO:root:FL Epoch: 336 Norm Difference for worker 377 is 0.981415
INFO:root:FL Epoch: 336 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 157
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.5303186861907735 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:2.1370434562365213                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [1764, 1480, 1583, 620, 33, 1504, 1466, 955, 148, 1589]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 337 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :1764
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660433
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570635
INFO:root:FL Epoch: 337 Norm Difference for worker 1764 is 0.820341
INFO:root:FL Epoch: 337 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1480
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532689
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498908
INFO:root:FL Epoch: 337 Norm Difference for worker 1480 is 0.767094
INFO:root:FL Epoch: 337 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1583
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453557
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381899
INFO:root:FL Epoch: 337 Norm Difference for worker 1583 is 0.743747
INFO:root:FL Epoch: 337 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :620
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643996
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400001
INFO:root:FL Epoch: 337 Norm Difference for worker 620 is 0.788656
INFO:root:FL Epoch: 337 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :33
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 33 is 0.798189
INFO:root:FL Epoch: 337 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1504
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681210
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478115
INFO:root:FL Epoch: 337 Norm Difference for worker 1504 is 0.810464
INFO:root:FL Epoch: 337 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1466
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516723
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438512
INFO:root:FL Epoch: 337 Norm Difference for worker 1466 is 0.825591
INFO:root:FL Epoch: 337 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :955
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809827
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536513
INFO:root:FL Epoch: 337 Norm Difference for worker 955 is 0.804045
INFO:root:FL Epoch: 337 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :148
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679929
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 148 is 0.815049
INFO:root:FL Epoch: 337 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1589
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535775
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464485
INFO:root:FL Epoch: 337 Norm Difference for worker 1589 is 0.881186
INFO:root:FL Epoch: 337 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.4977540549109964 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:1.921696623166402                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [1122, 909, 1618, 206, 475, 3, 1246, 686, 1017, 384]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :1122
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638861
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543301
INFO:root:FL Epoch: 338 Norm Difference for worker 1122 is 0.837599
INFO:root:FL Epoch: 338 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :909
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508238
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499692
INFO:root:FL Epoch: 338 Norm Difference for worker 909 is 0.796714
INFO:root:FL Epoch: 338 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1618
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478433
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363413
INFO:root:FL Epoch: 338 Norm Difference for worker 1618 is 0.828054
INFO:root:FL Epoch: 338 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :206
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 206 is 0.755147
INFO:root:FL Epoch: 338 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :475
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443269
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396260
INFO:root:FL Epoch: 338 Norm Difference for worker 475 is 0.851649
INFO:root:FL Epoch: 338 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :3
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.277620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 3 is 0.878408
INFO:root:FL Epoch: 338 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1246
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519319
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376636
INFO:root:FL Epoch: 338 Norm Difference for worker 1246 is 0.821187
INFO:root:FL Epoch: 338 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :686
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694308
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432786
INFO:root:FL Epoch: 338 Norm Difference for worker 686 is 0.909075
INFO:root:FL Epoch: 338 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1017
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363498
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568196
INFO:root:FL Epoch: 338 Norm Difference for worker 1017 is 0.880645
INFO:root:FL Epoch: 338 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :384
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463328
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394007
INFO:root:FL Epoch: 338 Norm Difference for worker 384 is 0.861642
INFO:root:FL Epoch: 338 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 909
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.5007119827410754 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:1.8307666778564453                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [908, 448, 1852, 1909, 65, 1445, 1431, 154, 1276, 695]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 339 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :908
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389853
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438060
INFO:root:FL Epoch: 339 Norm Difference for worker 908 is 0.719545
INFO:root:FL Epoch: 339 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :448
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612989
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512796
INFO:root:FL Epoch: 339 Norm Difference for worker 448 is 0.662529
INFO:root:FL Epoch: 339 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1852
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466136
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644891
INFO:root:FL Epoch: 339 Norm Difference for worker 1852 is 0.674882
INFO:root:FL Epoch: 339 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1909
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439921
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418710
INFO:root:FL Epoch: 339 Norm Difference for worker 1909 is 0.771336
INFO:root:FL Epoch: 339 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :65
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655485
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 65 is 0.724297
INFO:root:FL Epoch: 339 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1445
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659163
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371286
INFO:root:FL Epoch: 339 Norm Difference for worker 1445 is 0.809078
INFO:root:FL Epoch: 339 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1431
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581862
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555732
INFO:root:FL Epoch: 339 Norm Difference for worker 1431 is 0.718506
INFO:root:FL Epoch: 339 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :154
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 154 is 0.837094
INFO:root:FL Epoch: 339 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1276
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429113
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435846
INFO:root:FL Epoch: 339 Norm Difference for worker 1276 is 0.77233
INFO:root:FL Epoch: 339 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :695
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530995
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537831
INFO:root:FL Epoch: 339 Norm Difference for worker 695 is 0.739064
INFO:root:FL Epoch: 339 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 448
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.49607546539867625 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:1.7287918329238892                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [1561, 1597, 913, 27, 1446, 1096, 654, 751, 1286, 265]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 340 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :1561
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426839
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470626
INFO:root:FL Epoch: 340 Norm Difference for worker 1561 is 0.746516
INFO:root:FL Epoch: 340 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1597
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453050
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396678
INFO:root:FL Epoch: 340 Norm Difference for worker 1597 is 0.701198
INFO:root:FL Epoch: 340 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :913
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632781
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496588
INFO:root:FL Epoch: 340 Norm Difference for worker 913 is 0.811641
INFO:root:FL Epoch: 340 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :27
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 27 is 0.742971
INFO:root:FL Epoch: 340 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1446
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353384
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406972
INFO:root:FL Epoch: 340 Norm Difference for worker 1446 is 0.705466
INFO:root:FL Epoch: 340 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1096
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453116
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460730
INFO:root:FL Epoch: 340 Norm Difference for worker 1096 is 0.762991
INFO:root:FL Epoch: 340 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :654
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576671
INFO:root:Worker: 654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502027
INFO:root:FL Epoch: 340 Norm Difference for worker 654 is 0.686709
INFO:root:FL Epoch: 340 Done on worker:654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :751
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494124
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500106
INFO:root:FL Epoch: 340 Norm Difference for worker 751 is 0.71488
INFO:root:FL Epoch: 340 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1286
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.919895
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526981
INFO:root:FL Epoch: 340 Norm Difference for worker 1286 is 0.728429
INFO:root:FL Epoch: 340 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :265
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 265 is 0.791592
INFO:root:FL Epoch: 340 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1597
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.4976133002954371 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:2.0240665872891745                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [738, 532, 119, 967, 1830, 1431, 1437, 1925, 1696, 714]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :738
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528683
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583799
INFO:root:FL Epoch: 341 Norm Difference for worker 738 is 0.779945
INFO:root:FL Epoch: 341 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :532
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360655
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625281
INFO:root:FL Epoch: 341 Norm Difference for worker 532 is 0.831032
INFO:root:FL Epoch: 341 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :119
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.347556
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 341 Norm Difference for worker 119 is 0.799429
INFO:root:FL Epoch: 341 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :967
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456203
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739161
INFO:root:FL Epoch: 341 Norm Difference for worker 967 is 0.84068
INFO:root:FL Epoch: 341 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1830
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593383
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469370
INFO:root:FL Epoch: 341 Norm Difference for worker 1830 is 0.783859
INFO:root:FL Epoch: 341 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1431
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387215
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236716
INFO:root:FL Epoch: 341 Norm Difference for worker 1431 is 0.738119
INFO:root:FL Epoch: 341 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1437
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816890
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571031
INFO:root:FL Epoch: 341 Norm Difference for worker 1437 is 0.85725
INFO:root:FL Epoch: 341 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1925
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436920
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440774
INFO:root:FL Epoch: 341 Norm Difference for worker 1925 is 0.847304
INFO:root:FL Epoch: 341 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1696
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421413
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492413
INFO:root:FL Epoch: 341 Norm Difference for worker 1696 is 0.772059
INFO:root:FL Epoch: 341 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :714
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487838
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332221
INFO:root:FL Epoch: 341 Norm Difference for worker 714 is 0.808029
INFO:root:FL Epoch: 341 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1431
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.49598969431484446 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:1.876481533050537                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1491, 279, 1255, 1928, 1817, 391, 698, 1547, 1563, 1586]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 342 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1491
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380761
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394946
INFO:root:FL Epoch: 342 Norm Difference for worker 1491 is 0.728876
INFO:root:FL Epoch: 342 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :279
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 279 is 0.734706
INFO:root:FL Epoch: 342 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1255
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572895
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434420
INFO:root:FL Epoch: 342 Norm Difference for worker 1255 is 0.778731
INFO:root:FL Epoch: 342 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1928
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538341
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340850
INFO:root:FL Epoch: 342 Norm Difference for worker 1928 is 0.763439
INFO:root:FL Epoch: 342 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1817
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598000
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504525
INFO:root:FL Epoch: 342 Norm Difference for worker 1817 is 0.772644
INFO:root:FL Epoch: 342 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :391
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566958
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363648
INFO:root:FL Epoch: 342 Norm Difference for worker 391 is 0.803677
INFO:root:FL Epoch: 342 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :698
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762780
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720255
INFO:root:FL Epoch: 342 Norm Difference for worker 698 is 0.757643
INFO:root:FL Epoch: 342 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1547
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441630
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604535
INFO:root:FL Epoch: 342 Norm Difference for worker 1547 is 0.761478
INFO:root:FL Epoch: 342 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1563
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606598
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509571
INFO:root:FL Epoch: 342 Norm Difference for worker 1563 is 0.790175
INFO:root:FL Epoch: 342 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1586
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682118
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730010
INFO:root:FL Epoch: 342 Norm Difference for worker 1586 is 0.830904
INFO:root:FL Epoch: 342 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1491
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.4889941162922803 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:1.9101912180582683                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [1930, 1546, 1015, 1029, 1283, 430, 856, 1567, 600, 1680]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :1930
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576298
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632717
INFO:root:FL Epoch: 343 Norm Difference for worker 1930 is 0.859948
INFO:root:FL Epoch: 343 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1546
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648474
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480042
INFO:root:FL Epoch: 343 Norm Difference for worker 1546 is 0.869576
INFO:root:FL Epoch: 343 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1015
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394644
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408923
INFO:root:FL Epoch: 343 Norm Difference for worker 1015 is 0.760188
INFO:root:FL Epoch: 343 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1029
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381122
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430361
INFO:root:FL Epoch: 343 Norm Difference for worker 1029 is 0.84384
INFO:root:FL Epoch: 343 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1283
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631409
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451390
INFO:root:FL Epoch: 343 Norm Difference for worker 1283 is 0.828936
INFO:root:FL Epoch: 343 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :430
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485481
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397543
INFO:root:FL Epoch: 343 Norm Difference for worker 430 is 0.947681
INFO:root:FL Epoch: 343 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :856
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781406
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522650
INFO:root:FL Epoch: 343 Norm Difference for worker 856 is 0.938568
INFO:root:FL Epoch: 343 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1567
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669957
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201019
INFO:root:FL Epoch: 343 Norm Difference for worker 1567 is 0.873258
INFO:root:FL Epoch: 343 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :600
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893246
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644520
INFO:root:FL Epoch: 343 Norm Difference for worker 600 is 0.798166
INFO:root:FL Epoch: 343 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1680
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622550
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470785
INFO:root:FL Epoch: 343 Norm Difference for worker 1680 is 0.915151
INFO:root:FL Epoch: 343 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.49877026677131653 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:1.6995714108149211                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1893, 1353, 966, 1904, 1719, 1249, 798, 1776, 1787, 900]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1893
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530024
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555268
INFO:root:FL Epoch: 344 Norm Difference for worker 1893 is 0.851233
INFO:root:FL Epoch: 344 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1353
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699930
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578748
INFO:root:FL Epoch: 344 Norm Difference for worker 1353 is 0.831026
INFO:root:FL Epoch: 344 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :966
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506542
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640823
INFO:root:FL Epoch: 344 Norm Difference for worker 966 is 0.935233
INFO:root:FL Epoch: 344 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1904
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532132
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574854
INFO:root:FL Epoch: 344 Norm Difference for worker 1904 is 0.85044
INFO:root:FL Epoch: 344 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1719
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387900
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525583
INFO:root:FL Epoch: 344 Norm Difference for worker 1719 is 0.858546
INFO:root:FL Epoch: 344 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1249
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663540
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516348
INFO:root:FL Epoch: 344 Norm Difference for worker 1249 is 0.924289
INFO:root:FL Epoch: 344 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :798
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522347
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336669
INFO:root:FL Epoch: 344 Norm Difference for worker 798 is 0.853642
INFO:root:FL Epoch: 344 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1776
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715798
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508353
INFO:root:FL Epoch: 344 Norm Difference for worker 1776 is 0.821528
INFO:root:FL Epoch: 344 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1787
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309468
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295244
INFO:root:FL Epoch: 344 Norm Difference for worker 1787 is 0.813738
INFO:root:FL Epoch: 344 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :900
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502492
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443450
INFO:root:FL Epoch: 344 Norm Difference for worker 900 is 0.834786
INFO:root:FL Epoch: 344 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1787
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.5037123315474566 and Test Accuracy:75.0 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:2.314227342605591                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [1316, 1061, 593, 1398, 1374, 820, 1202, 125, 1748, 1414]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 345 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :1316
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399120
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468661
INFO:root:FL Epoch: 345 Norm Difference for worker 1316 is 0.881256
INFO:root:FL Epoch: 345 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1061
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440313
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255620
INFO:root:FL Epoch: 345 Norm Difference for worker 1061 is 0.804196
INFO:root:FL Epoch: 345 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :593
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437288
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.797394
INFO:root:FL Epoch: 345 Norm Difference for worker 593 is 0.927401
INFO:root:FL Epoch: 345 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1398
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416026
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524738
INFO:root:FL Epoch: 345 Norm Difference for worker 1398 is 0.884911
INFO:root:FL Epoch: 345 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1374
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461813
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372929
INFO:root:FL Epoch: 345 Norm Difference for worker 1374 is 0.83111
INFO:root:FL Epoch: 345 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :820
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573377
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444435
INFO:root:FL Epoch: 345 Norm Difference for worker 820 is 0.824277
INFO:root:FL Epoch: 345 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1202
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679618
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566678
INFO:root:FL Epoch: 345 Norm Difference for worker 1202 is 0.894436
INFO:root:FL Epoch: 345 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :125
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 125 is 0.83751
INFO:root:FL Epoch: 345 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1748
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675611
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.832686
INFO:root:FL Epoch: 345 Norm Difference for worker 1748 is 0.936823
INFO:root:FL Epoch: 345 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1414
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274527
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354601
INFO:root:FL Epoch: 345 Norm Difference for worker 1414 is 0.8777
INFO:root:FL Epoch: 345 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.4906211810953477 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:2.0585890213648477                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [1089, 260, 226, 1670, 553, 1838, 850, 914, 704, 264]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 346 Num points on workers: [200 201 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :1089
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642892
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622368
INFO:root:FL Epoch: 346 Norm Difference for worker 1089 is 0.82929
INFO:root:FL Epoch: 346 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :260
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602756
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 260 is 0.85798
INFO:root:FL Epoch: 346 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :226
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 226 is 0.895215
INFO:root:FL Epoch: 346 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1670
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504512
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300802
INFO:root:FL Epoch: 346 Norm Difference for worker 1670 is 0.899826
INFO:root:FL Epoch: 346 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :553
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366685
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396167
INFO:root:FL Epoch: 346 Norm Difference for worker 553 is 0.768235
INFO:root:FL Epoch: 346 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1838
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439561
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438424
INFO:root:FL Epoch: 346 Norm Difference for worker 1838 is 0.850934
INFO:root:FL Epoch: 346 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :850
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636046
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519372
INFO:root:FL Epoch: 346 Norm Difference for worker 850 is 0.985292
INFO:root:FL Epoch: 346 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :914
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677425
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491777
INFO:root:FL Epoch: 346 Norm Difference for worker 914 is 0.85663
INFO:root:FL Epoch: 346 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :704
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409114
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449279
INFO:root:FL Epoch: 346 Norm Difference for worker 704 is 0.911828
INFO:root:FL Epoch: 346 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :264
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.778832
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 264 is 0.957666
INFO:root:FL Epoch: 346 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 346 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 346 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.4807475437136257 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:1.5754218498865764                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [16, 590, 683, 495, 665, 1121, 1307, 364, 1665, 1226]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :16
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550678
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 16 is 0.713981
INFO:root:FL Epoch: 347 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :590
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472014
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532828
INFO:root:FL Epoch: 347 Norm Difference for worker 590 is 0.733519
INFO:root:FL Epoch: 347 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :683
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441607
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430057
INFO:root:FL Epoch: 347 Norm Difference for worker 683 is 0.812485
INFO:root:FL Epoch: 347 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :495
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638481
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430819
INFO:root:FL Epoch: 347 Norm Difference for worker 495 is 0.722998
INFO:root:FL Epoch: 347 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :665
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581200
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472980
INFO:root:FL Epoch: 347 Norm Difference for worker 665 is 0.690206
INFO:root:FL Epoch: 347 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1121
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419718
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556531
INFO:root:FL Epoch: 347 Norm Difference for worker 1121 is 0.72663
INFO:root:FL Epoch: 347 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1307
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469262
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372021
INFO:root:FL Epoch: 347 Norm Difference for worker 1307 is 0.771934
INFO:root:FL Epoch: 347 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :364
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544265
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550966
INFO:root:FL Epoch: 347 Norm Difference for worker 364 is 0.772378
INFO:root:FL Epoch: 347 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1665
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413600
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437007
INFO:root:FL Epoch: 347 Norm Difference for worker 1665 is 0.712307
INFO:root:FL Epoch: 347 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1226
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450140
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369663
INFO:root:FL Epoch: 347 Norm Difference for worker 1226 is 0.737633
INFO:root:FL Epoch: 347 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 665
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.4907234328634599 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:1.7705960869789124                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1554, 1707, 1750, 683, 532, 1635, 1215, 813, 634, 145]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1554
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409372
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292670
INFO:root:FL Epoch: 348 Norm Difference for worker 1554 is 0.718327
INFO:root:FL Epoch: 348 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1707
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664298
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528502
INFO:root:FL Epoch: 348 Norm Difference for worker 1707 is 0.72908
INFO:root:FL Epoch: 348 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1750
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478240
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617603
INFO:root:FL Epoch: 348 Norm Difference for worker 1750 is 0.642406
INFO:root:FL Epoch: 348 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :683
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585153
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528296
INFO:root:FL Epoch: 348 Norm Difference for worker 683 is 0.691985
INFO:root:FL Epoch: 348 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :532
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694427
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393487
INFO:root:FL Epoch: 348 Norm Difference for worker 532 is 0.726084
INFO:root:FL Epoch: 348 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1635
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374265
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453350
INFO:root:FL Epoch: 348 Norm Difference for worker 1635 is 0.677727
INFO:root:FL Epoch: 348 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1215
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653455
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418731
INFO:root:FL Epoch: 348 Norm Difference for worker 1215 is 0.670129
INFO:root:FL Epoch: 348 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :813
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654098
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353001
INFO:root:FL Epoch: 348 Norm Difference for worker 813 is 0.750565
INFO:root:FL Epoch: 348 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :634
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621430
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595784
INFO:root:FL Epoch: 348 Norm Difference for worker 634 is 0.648481
INFO:root:FL Epoch: 348 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :145
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455390
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 145 is 0.659699
INFO:root:FL Epoch: 348 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.4701487527174108 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:1.9580477277437847                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [894, 1732, 1860, 399, 1547, 911, 1946, 938, 475, 572]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :894
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505761
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590452
INFO:root:FL Epoch: 349 Norm Difference for worker 894 is 0.832531
INFO:root:FL Epoch: 349 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1732
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423393
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454491
INFO:root:FL Epoch: 349 Norm Difference for worker 1732 is 0.742188
INFO:root:FL Epoch: 349 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1860
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331704
INFO:root:Worker: 1860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297269
INFO:root:FL Epoch: 349 Norm Difference for worker 1860 is 0.829128
INFO:root:FL Epoch: 349 Done on worker:1860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :399
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577362
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480819
INFO:root:FL Epoch: 349 Norm Difference for worker 399 is 0.849526
INFO:root:FL Epoch: 349 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1547
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697047
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356178
INFO:root:FL Epoch: 349 Norm Difference for worker 1547 is 0.824903
INFO:root:FL Epoch: 349 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :911
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494376
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376616
INFO:root:FL Epoch: 349 Norm Difference for worker 911 is 0.872991
INFO:root:FL Epoch: 349 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1946
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470215
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504184
INFO:root:FL Epoch: 349 Norm Difference for worker 1946 is 0.770852
INFO:root:FL Epoch: 349 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :938
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798070
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527257
INFO:root:FL Epoch: 349 Norm Difference for worker 938 is 0.837457
INFO:root:FL Epoch: 349 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :475
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595446
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549111
INFO:root:FL Epoch: 349 Norm Difference for worker 475 is 0.843461
INFO:root:FL Epoch: 349 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :572
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498117
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447846
INFO:root:FL Epoch: 349 Norm Difference for worker 572 is 0.873806
INFO:root:FL Epoch: 349 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1732
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.46708517039523406 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:2.251743276913961                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1380, 266, 743, 960, 1577, 612, 9, 477, 26, 144]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 350 Num points on workers: [200 201 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1380
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673949
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510186
INFO:root:FL Epoch: 350 Norm Difference for worker 1380 is 0.907623
INFO:root:FL Epoch: 350 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :266
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 266 is 0.896572
INFO:root:FL Epoch: 350 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :743
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445452
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466705
INFO:root:FL Epoch: 350 Norm Difference for worker 743 is 0.83277
INFO:root:FL Epoch: 350 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :960
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438228
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451066
INFO:root:FL Epoch: 350 Norm Difference for worker 960 is 0.853055
INFO:root:FL Epoch: 350 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1577
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575598
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790263
INFO:root:FL Epoch: 350 Norm Difference for worker 1577 is 0.900092
INFO:root:FL Epoch: 350 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :612
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451178
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399317
INFO:root:FL Epoch: 350 Norm Difference for worker 612 is 0.891108
INFO:root:FL Epoch: 350 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :9
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 9 is 0.881864
INFO:root:FL Epoch: 350 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :477
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440163
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396048
INFO:root:FL Epoch: 350 Norm Difference for worker 477 is 0.752517
INFO:root:FL Epoch: 350 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :26
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 26 is 0.858483
INFO:root:FL Epoch: 350 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :144
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 144 is 0.883477
INFO:root:FL Epoch: 350 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.46261342483408313 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:2.3109185695648193                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [1898, 565, 883, 716, 340, 1644, 366, 1235, 1822, 1743]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :1898
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566434
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422693
INFO:root:FL Epoch: 351 Norm Difference for worker 1898 is 0.929413
INFO:root:FL Epoch: 351 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :565
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522709
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368595
INFO:root:FL Epoch: 351 Norm Difference for worker 565 is 0.835044
INFO:root:FL Epoch: 351 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :883
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615020
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313064
INFO:root:FL Epoch: 351 Norm Difference for worker 883 is 1.025973
INFO:root:FL Epoch: 351 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :716
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672766
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412407
INFO:root:FL Epoch: 351 Norm Difference for worker 716 is 0.911977
INFO:root:FL Epoch: 351 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :340
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459384
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385378
INFO:root:FL Epoch: 351 Norm Difference for worker 340 is 0.911585
INFO:root:FL Epoch: 351 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1644
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657896
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395959
INFO:root:FL Epoch: 351 Norm Difference for worker 1644 is 0.882326
INFO:root:FL Epoch: 351 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :366
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497164
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435198
INFO:root:FL Epoch: 351 Norm Difference for worker 366 is 0.894169
INFO:root:FL Epoch: 351 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1235
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612854
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408971
INFO:root:FL Epoch: 351 Norm Difference for worker 1235 is 0.91164
INFO:root:FL Epoch: 351 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1822
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530710
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457530
INFO:root:FL Epoch: 351 Norm Difference for worker 1822 is 0.906097
INFO:root:FL Epoch: 351 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1743
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598222
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368231
INFO:root:FL Epoch: 351 Norm Difference for worker 1743 is 0.949089
INFO:root:FL Epoch: 351 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 565
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.46672898005036745 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:2.0329476396242776                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [864, 1056, 110, 1920, 1157, 447, 1477, 987, 392, 1391]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :864
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433440
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465468
INFO:root:FL Epoch: 352 Norm Difference for worker 864 is 0.829203
INFO:root:FL Epoch: 352 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1056
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439588
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422336
INFO:root:FL Epoch: 352 Norm Difference for worker 1056 is 0.814389
INFO:root:FL Epoch: 352 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :110
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686535
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 110 is 0.930896
INFO:root:FL Epoch: 352 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1920
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729193
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665571
INFO:root:FL Epoch: 352 Norm Difference for worker 1920 is 0.846773
INFO:root:FL Epoch: 352 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1157
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676462
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310594
INFO:root:FL Epoch: 352 Norm Difference for worker 1157 is 0.874951
INFO:root:FL Epoch: 352 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :447
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567319
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703717
INFO:root:FL Epoch: 352 Norm Difference for worker 447 is 0.839723
INFO:root:FL Epoch: 352 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1477
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545161
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455486
INFO:root:FL Epoch: 352 Norm Difference for worker 1477 is 0.811611
INFO:root:FL Epoch: 352 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :987
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632837
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477676
INFO:root:FL Epoch: 352 Norm Difference for worker 987 is 0.845994
INFO:root:FL Epoch: 352 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :392
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692665
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462628
INFO:root:FL Epoch: 352 Norm Difference for worker 392 is 0.855128
INFO:root:FL Epoch: 352 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1391
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519245
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311556
INFO:root:FL Epoch: 352 Norm Difference for worker 1391 is 0.844086
INFO:root:FL Epoch: 352 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1477
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.4773675746777478 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:1.9861483176549275                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1295, 1788, 499, 101, 250, 623, 1837, 1435, 901, 752]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1295
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521824
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359200
INFO:root:FL Epoch: 353 Norm Difference for worker 1295 is 0.689034
INFO:root:FL Epoch: 353 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1788
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743202
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391929
INFO:root:FL Epoch: 353 Norm Difference for worker 1788 is 0.772458
INFO:root:FL Epoch: 353 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :499
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364349
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244038
INFO:root:FL Epoch: 353 Norm Difference for worker 499 is 0.715596
INFO:root:FL Epoch: 353 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :101
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643049
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 101 is 0.767009
INFO:root:FL Epoch: 353 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :250
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 250 is 0.758067
INFO:root:FL Epoch: 353 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :623
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459680
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579387
INFO:root:FL Epoch: 353 Norm Difference for worker 623 is 0.752158
INFO:root:FL Epoch: 353 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1837
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765722
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522868
INFO:root:FL Epoch: 353 Norm Difference for worker 1837 is 0.762017
INFO:root:FL Epoch: 353 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1435
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395698
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474240
INFO:root:FL Epoch: 353 Norm Difference for worker 1435 is 0.768329
INFO:root:FL Epoch: 353 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :901
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211722
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389022
INFO:root:FL Epoch: 353 Norm Difference for worker 901 is 0.758086
INFO:root:FL Epoch: 353 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :752
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386428
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508057
INFO:root:FL Epoch: 353 Norm Difference for worker 752 is 0.761003
INFO:root:FL Epoch: 353 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.48311275243759155 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:2.362196445465088                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [963, 851, 1261, 1221, 616, 1249, 1513, 247, 1843, 1375]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :963
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.996621
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522432
INFO:root:FL Epoch: 354 Norm Difference for worker 963 is 0.97461
INFO:root:FL Epoch: 354 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :851
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559352
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333404
INFO:root:FL Epoch: 354 Norm Difference for worker 851 is 0.843461
INFO:root:FL Epoch: 354 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1261
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478222
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442457
INFO:root:FL Epoch: 354 Norm Difference for worker 1261 is 0.938148
INFO:root:FL Epoch: 354 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1221
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477489
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412246
INFO:root:FL Epoch: 354 Norm Difference for worker 1221 is 0.920074
INFO:root:FL Epoch: 354 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :616
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546771
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485413
INFO:root:FL Epoch: 354 Norm Difference for worker 616 is 0.892924
INFO:root:FL Epoch: 354 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1249
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715836
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664587
INFO:root:FL Epoch: 354 Norm Difference for worker 1249 is 1.019499
INFO:root:FL Epoch: 354 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1513
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574505
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361083
INFO:root:FL Epoch: 354 Norm Difference for worker 1513 is 0.939588
INFO:root:FL Epoch: 354 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :247
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 247 is 1.031063
INFO:root:FL Epoch: 354 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1843
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557073
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548212
INFO:root:FL Epoch: 354 Norm Difference for worker 1843 is 1.066309
INFO:root:FL Epoch: 354 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1375
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521984
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508562
INFO:root:FL Epoch: 354 Norm Difference for worker 1375 is 0.948783
INFO:root:FL Epoch: 354 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 851
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.4697649969774134 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:2.156957467397054                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [1467, 1794, 640, 825, 1881, 1422, 1517, 338, 1330, 286]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 355 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :1467
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597103
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359149
INFO:root:FL Epoch: 355 Norm Difference for worker 1467 is 0.898836
INFO:root:FL Epoch: 355 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1794
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652603
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607529
INFO:root:FL Epoch: 355 Norm Difference for worker 1794 is 0.958646
INFO:root:FL Epoch: 355 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :640
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347043
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651750
INFO:root:FL Epoch: 355 Norm Difference for worker 640 is 0.805541
INFO:root:FL Epoch: 355 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :825
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420774
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325148
INFO:root:FL Epoch: 355 Norm Difference for worker 825 is 0.796551
INFO:root:FL Epoch: 355 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1881
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336030
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369416
INFO:root:FL Epoch: 355 Norm Difference for worker 1881 is 0.804109
INFO:root:FL Epoch: 355 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1422
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417979
INFO:root:Worker: 1422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353927
INFO:root:FL Epoch: 355 Norm Difference for worker 1422 is 0.903149
INFO:root:FL Epoch: 355 Done on worker:1422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1517
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533778
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437973
INFO:root:FL Epoch: 355 Norm Difference for worker 1517 is 0.883947
INFO:root:FL Epoch: 355 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :338
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 338 is 0.793648
INFO:root:FL Epoch: 355 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1330
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394838
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425909
INFO:root:FL Epoch: 355 Norm Difference for worker 1330 is 0.948547
INFO:root:FL Epoch: 355 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :286
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 286 is 0.832844
INFO:root:FL Epoch: 355 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 338
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.47212470279020424 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:2.238473812739054                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [1239, 283, 50, 1176, 973, 1784, 1394, 177, 977, 1615]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 356 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :1239
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648586
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490934
INFO:root:FL Epoch: 356 Norm Difference for worker 1239 is 0.998502
INFO:root:FL Epoch: 356 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :283
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 283 is 0.915395
INFO:root:FL Epoch: 356 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :50
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 50 is 0.829835
INFO:root:FL Epoch: 356 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1176
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608772
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615427
INFO:root:FL Epoch: 356 Norm Difference for worker 1176 is 0.857405
INFO:root:FL Epoch: 356 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :973
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656681
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550713
INFO:root:FL Epoch: 356 Norm Difference for worker 973 is 0.868352
INFO:root:FL Epoch: 356 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1784
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548018
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535939
INFO:root:FL Epoch: 356 Norm Difference for worker 1784 is 0.886426
INFO:root:FL Epoch: 356 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1394
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474240
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639725
INFO:root:FL Epoch: 356 Norm Difference for worker 1394 is 0.95515
INFO:root:FL Epoch: 356 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :177
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 177 is 0.926135
INFO:root:FL Epoch: 356 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :977
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597681
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493792
INFO:root:FL Epoch: 356 Norm Difference for worker 977 is 0.855839
INFO:root:FL Epoch: 356 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1615
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508606
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426957
INFO:root:FL Epoch: 356 Norm Difference for worker 1615 is 0.856799
INFO:root:FL Epoch: 356 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 50
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.47588029503822327 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:2.1069470246632895                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1740, 912, 969, 385, 1622, 182, 1226, 94, 1741, 545]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1740
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584848
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281405
INFO:root:FL Epoch: 357 Norm Difference for worker 1740 is 0.82532
INFO:root:FL Epoch: 357 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :912
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625682
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402312
INFO:root:FL Epoch: 357 Norm Difference for worker 912 is 0.815845
INFO:root:FL Epoch: 357 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :969
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312771
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459212
INFO:root:FL Epoch: 357 Norm Difference for worker 969 is 0.864708
INFO:root:FL Epoch: 357 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :385
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729289
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686181
INFO:root:FL Epoch: 357 Norm Difference for worker 385 is 0.861292
INFO:root:FL Epoch: 357 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1622
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766216
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401888
INFO:root:FL Epoch: 357 Norm Difference for worker 1622 is 0.822722
INFO:root:FL Epoch: 357 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :182
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.907405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 182 is 0.96862
INFO:root:FL Epoch: 357 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1226
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573692
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497269
INFO:root:FL Epoch: 357 Norm Difference for worker 1226 is 0.906046
INFO:root:FL Epoch: 357 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :94
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 94 is 0.884338
INFO:root:FL Epoch: 357 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1741
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699399
INFO:root:Worker: 1741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361626
INFO:root:FL Epoch: 357 Norm Difference for worker 1741 is 0.788765
INFO:root:FL Epoch: 357 Done on worker:1741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :545
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540157
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396044
INFO:root:FL Epoch: 357 Norm Difference for worker 545 is 0.861113
INFO:root:FL Epoch: 357 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1741
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 357 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 357 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.47186289815341725 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:2.230392356713613                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1028, 732, 1046, 332, 92, 312, 11, 1373, 561, 186]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.09975062 0.09975062 0.09975062 0.10024938 0.10024938 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 358 Num points on workers: [200 200 200 201 201 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1028
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488777
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548423
INFO:root:FL Epoch: 358 Norm Difference for worker 1028 is 0.802769
INFO:root:FL Epoch: 358 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :732
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582012
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396823
INFO:root:FL Epoch: 358 Norm Difference for worker 732 is 0.848085
INFO:root:FL Epoch: 358 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1046
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368979
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463335
INFO:root:FL Epoch: 358 Norm Difference for worker 1046 is 0.910551
INFO:root:FL Epoch: 358 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :332
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675669
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 332 is 0.874572
INFO:root:FL Epoch: 358 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :92
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392184
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 92 is 0.896456
INFO:root:FL Epoch: 358 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :312
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474491
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 312 is 0.907504
INFO:root:FL Epoch: 358 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :11
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 11 is 0.782675
INFO:root:FL Epoch: 358 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1373
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553705
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480911
INFO:root:FL Epoch: 358 Norm Difference for worker 1373 is 0.907527
INFO:root:FL Epoch: 358 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :561
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548740
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489788
INFO:root:FL Epoch: 358 Norm Difference for worker 561 is 0.963153
INFO:root:FL Epoch: 358 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :186
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 186 is 0.874455
INFO:root:FL Epoch: 358 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1028
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.4748921867679147 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:1.8807247479756672                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [1316, 1382, 530, 1653, 1041, 377, 282, 544, 187, 354]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :1316
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550166
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468745
INFO:root:FL Epoch: 359 Norm Difference for worker 1316 is 0.745998
INFO:root:FL Epoch: 359 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1382
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563737
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509792
INFO:root:FL Epoch: 359 Norm Difference for worker 1382 is 0.749045
INFO:root:FL Epoch: 359 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :530
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673753
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587715
INFO:root:FL Epoch: 359 Norm Difference for worker 530 is 0.811717
INFO:root:FL Epoch: 359 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1653
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317015
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456540
INFO:root:FL Epoch: 359 Norm Difference for worker 1653 is 0.738178
INFO:root:FL Epoch: 359 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1041
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596097
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438015
INFO:root:FL Epoch: 359 Norm Difference for worker 1041 is 0.822258
INFO:root:FL Epoch: 359 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :377
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535659
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442985
INFO:root:FL Epoch: 359 Norm Difference for worker 377 is 0.794301
INFO:root:FL Epoch: 359 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :282
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653390
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 282 is 0.740736
INFO:root:FL Epoch: 359 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :544
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602507
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504675
INFO:root:FL Epoch: 359 Norm Difference for worker 544 is 0.722326
INFO:root:FL Epoch: 359 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :187
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 187 is 0.732046
INFO:root:FL Epoch: 359 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :354
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455534
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264722
INFO:root:FL Epoch: 359 Norm Difference for worker 354 is 0.775066
INFO:root:FL Epoch: 359 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 282
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 359 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 359 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.4727431851274827 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:1.8177295724550884                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [401, 830, 331, 202, 1302, 989, 1147, 1706, 674, 39]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :401
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455473
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475558
INFO:root:FL Epoch: 360 Norm Difference for worker 401 is 0.762181
INFO:root:FL Epoch: 360 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :830
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653953
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616266
INFO:root:FL Epoch: 360 Norm Difference for worker 830 is 0.757726
INFO:root:FL Epoch: 360 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :331
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646497
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 331 is 0.753123
INFO:root:FL Epoch: 360 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :202
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 202 is 0.771004
INFO:root:FL Epoch: 360 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1302
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514780
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521157
INFO:root:FL Epoch: 360 Norm Difference for worker 1302 is 0.818827
INFO:root:FL Epoch: 360 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :989
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652099
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726937
INFO:root:FL Epoch: 360 Norm Difference for worker 989 is 0.764326
INFO:root:FL Epoch: 360 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1147
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427636
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515720
INFO:root:FL Epoch: 360 Norm Difference for worker 1147 is 1.095383
INFO:root:FL Epoch: 360 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1706
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487759
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431706
INFO:root:FL Epoch: 360 Norm Difference for worker 1706 is 0.729054
INFO:root:FL Epoch: 360 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :674
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341512
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429327
INFO:root:FL Epoch: 360 Norm Difference for worker 674 is 0.824038
INFO:root:FL Epoch: 360 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :39
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 39 is 0.733206
INFO:root:FL Epoch: 360 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.49592123838031993 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:1.911740243434906                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [1298, 476, 197, 1208, 850, 687, 123, 1636, 829, 206]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :1298
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586630
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515192
INFO:root:FL Epoch: 361 Norm Difference for worker 1298 is 0.743915
INFO:root:FL Epoch: 361 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :476
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476802
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594557
INFO:root:FL Epoch: 361 Norm Difference for worker 476 is 0.706863
INFO:root:FL Epoch: 361 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :197
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 197 is 0.72366
INFO:root:FL Epoch: 361 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1208
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493772
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479224
INFO:root:FL Epoch: 361 Norm Difference for worker 1208 is 0.723044
INFO:root:FL Epoch: 361 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :850
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555723
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595657
INFO:root:FL Epoch: 361 Norm Difference for worker 850 is 0.747209
INFO:root:FL Epoch: 361 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :687
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380450
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229368
INFO:root:FL Epoch: 361 Norm Difference for worker 687 is 0.764304
INFO:root:FL Epoch: 361 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :123
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 123 is 0.736436
INFO:root:FL Epoch: 361 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1636
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450781
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496342
INFO:root:FL Epoch: 361 Norm Difference for worker 1636 is 0.757464
INFO:root:FL Epoch: 361 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :829
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684944
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564546
INFO:root:FL Epoch: 361 Norm Difference for worker 829 is 0.73828
INFO:root:FL Epoch: 361 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :206
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 206 is 0.748699
INFO:root:FL Epoch: 361 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 206
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.48963068863924814 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:2.121009965737661                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [1632, 837, 997, 1938, 1419, 1085, 1820, 1553, 957, 1827]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :1632
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397337
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383296
INFO:root:FL Epoch: 362 Norm Difference for worker 1632 is 0.923346
INFO:root:FL Epoch: 362 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :837
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271329
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618936
INFO:root:FL Epoch: 362 Norm Difference for worker 837 is 0.977736
INFO:root:FL Epoch: 362 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :997
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500342
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525329
INFO:root:FL Epoch: 362 Norm Difference for worker 997 is 0.877901
INFO:root:FL Epoch: 362 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1938
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561263
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566653
INFO:root:FL Epoch: 362 Norm Difference for worker 1938 is 0.906216
INFO:root:FL Epoch: 362 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1419
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398827
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507944
INFO:root:FL Epoch: 362 Norm Difference for worker 1419 is 0.787317
INFO:root:FL Epoch: 362 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1085
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578821
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458582
INFO:root:FL Epoch: 362 Norm Difference for worker 1085 is 0.866522
INFO:root:FL Epoch: 362 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1820
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358779
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243035
INFO:root:FL Epoch: 362 Norm Difference for worker 1820 is 0.91113
INFO:root:FL Epoch: 362 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1553
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534778
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537486
INFO:root:FL Epoch: 362 Norm Difference for worker 1553 is 0.945375
INFO:root:FL Epoch: 362 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :957
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535915
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666234
INFO:root:FL Epoch: 362 Norm Difference for worker 957 is 0.906676
INFO:root:FL Epoch: 362 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1827
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552355
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243690
INFO:root:FL Epoch: 362 Norm Difference for worker 1827 is 0.930041
INFO:root:FL Epoch: 362 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1419
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.5202840478981242 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:2.7481160163879395                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [721, 143, 446, 1940, 1755, 1652, 716, 238, 1740, 787]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 363 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :721
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810754
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556345
INFO:root:FL Epoch: 363 Norm Difference for worker 721 is 0.984537
INFO:root:FL Epoch: 363 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :143
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 143 is 0.991964
INFO:root:FL Epoch: 363 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :446
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437091
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490431
INFO:root:FL Epoch: 363 Norm Difference for worker 446 is 0.932325
INFO:root:FL Epoch: 363 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1940
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626364
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317918
INFO:root:FL Epoch: 363 Norm Difference for worker 1940 is 0.899991
INFO:root:FL Epoch: 363 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1755
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481502
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463138
INFO:root:FL Epoch: 363 Norm Difference for worker 1755 is 1.050546
INFO:root:FL Epoch: 363 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1652
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516689
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651613
INFO:root:FL Epoch: 363 Norm Difference for worker 1652 is 0.926746
INFO:root:FL Epoch: 363 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :716
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336088
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431939
INFO:root:FL Epoch: 363 Norm Difference for worker 716 is 0.93314
INFO:root:FL Epoch: 363 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :238
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.287187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446318
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 238 is 0.92467
INFO:root:FL Epoch: 363 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1740
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398314
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285742
INFO:root:FL Epoch: 363 Norm Difference for worker 1740 is 0.855503
INFO:root:FL Epoch: 363 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :787
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621699
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585768
INFO:root:FL Epoch: 363 Norm Difference for worker 787 is 0.98631
INFO:root:FL Epoch: 363 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1740
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.47696218595785256 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:2.3003596464792886                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [429, 1891, 1834, 1485, 886, 415, 1345, 1908, 1628, 1083]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 364 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :429
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506977
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553441
INFO:root:FL Epoch: 364 Norm Difference for worker 429 is 0.849566
INFO:root:FL Epoch: 364 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1891
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578679
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546136
INFO:root:FL Epoch: 364 Norm Difference for worker 1891 is 0.915211
INFO:root:FL Epoch: 364 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1834
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422004
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311728
INFO:root:FL Epoch: 364 Norm Difference for worker 1834 is 0.868078
INFO:root:FL Epoch: 364 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1485
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570116
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580273
INFO:root:FL Epoch: 364 Norm Difference for worker 1485 is 0.790343
INFO:root:FL Epoch: 364 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :886
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641552
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620013
INFO:root:FL Epoch: 364 Norm Difference for worker 886 is 0.890903
INFO:root:FL Epoch: 364 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :415
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378374
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269673
INFO:root:FL Epoch: 364 Norm Difference for worker 415 is 0.88695
INFO:root:FL Epoch: 364 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1345
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598157
INFO:root:Worker: 1345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580783
INFO:root:FL Epoch: 364 Norm Difference for worker 1345 is 0.859564
INFO:root:FL Epoch: 364 Done on worker:1345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1908
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533987
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208715
INFO:root:FL Epoch: 364 Norm Difference for worker 1908 is 0.866352
INFO:root:FL Epoch: 364 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1628
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526864
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367989
INFO:root:FL Epoch: 364 Norm Difference for worker 1628 is 0.858091
INFO:root:FL Epoch: 364 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1083
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549958
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374640
INFO:root:FL Epoch: 364 Norm Difference for worker 1083 is 0.836332
INFO:root:FL Epoch: 364 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1485
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.4610771904973423 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:2.2146346171696982                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [527, 1272, 1752, 1273, 1653, 1464, 1934, 1714, 1339, 1667]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 365 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :527
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514882
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371277
INFO:root:FL Epoch: 365 Norm Difference for worker 527 is 0.816987
INFO:root:FL Epoch: 365 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1272
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528583
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400288
INFO:root:FL Epoch: 365 Norm Difference for worker 1272 is 0.791581
INFO:root:FL Epoch: 365 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1752
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417715
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364979
INFO:root:FL Epoch: 365 Norm Difference for worker 1752 is 0.826832
INFO:root:FL Epoch: 365 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1273
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.207021
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348749
INFO:root:FL Epoch: 365 Norm Difference for worker 1273 is 0.77646
INFO:root:FL Epoch: 365 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1653
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249474
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430118
INFO:root:FL Epoch: 365 Norm Difference for worker 1653 is 0.793473
INFO:root:FL Epoch: 365 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1464
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698317
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541804
INFO:root:FL Epoch: 365 Norm Difference for worker 1464 is 0.7836
INFO:root:FL Epoch: 365 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1934
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543005
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446651
INFO:root:FL Epoch: 365 Norm Difference for worker 1934 is 0.800883
INFO:root:FL Epoch: 365 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1714
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448199
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391108
INFO:root:FL Epoch: 365 Norm Difference for worker 1714 is 0.818656
INFO:root:FL Epoch: 365 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1339
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554405
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475718
INFO:root:FL Epoch: 365 Norm Difference for worker 1339 is 0.835233
INFO:root:FL Epoch: 365 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1667
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759987
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588209
INFO:root:FL Epoch: 365 Norm Difference for worker 1667 is 0.889381
INFO:root:FL Epoch: 365 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 365 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 365 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.4613396218594383 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:2.2114388147989907                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1199, 734, 75, 909, 1692, 1177, 1671, 1141, 281, 1918]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1199
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483612
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680663
INFO:root:FL Epoch: 366 Norm Difference for worker 1199 is 0.893939
INFO:root:FL Epoch: 366 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :734
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559396
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513302
INFO:root:FL Epoch: 366 Norm Difference for worker 734 is 0.806207
INFO:root:FL Epoch: 366 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :75
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457963
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 75 is 0.885741
INFO:root:FL Epoch: 366 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :909
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413314
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563702
INFO:root:FL Epoch: 366 Norm Difference for worker 909 is 0.760955
INFO:root:FL Epoch: 366 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1692
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459501
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712351
INFO:root:FL Epoch: 366 Norm Difference for worker 1692 is 0.930812
INFO:root:FL Epoch: 366 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1177
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461884
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439462
INFO:root:FL Epoch: 366 Norm Difference for worker 1177 is 0.818991
INFO:root:FL Epoch: 366 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1671
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442176
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614562
INFO:root:FL Epoch: 366 Norm Difference for worker 1671 is 0.792062
INFO:root:FL Epoch: 366 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1141
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368081
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437045
INFO:root:FL Epoch: 366 Norm Difference for worker 1141 is 0.866217
INFO:root:FL Epoch: 366 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :281
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.295334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 281 is 0.773976
INFO:root:FL Epoch: 366 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1918
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500118
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306807
INFO:root:FL Epoch: 366 Norm Difference for worker 1918 is 0.814538
INFO:root:FL Epoch: 366 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 281
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.47136377849999594 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:2.2123236854871116                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [751, 1632, 316, 260, 367, 1083, 646, 339, 102, 1255]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 367 Num points on workers: [200 200 201 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :751
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487841
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496560
INFO:root:FL Epoch: 367 Norm Difference for worker 751 is 0.79874
INFO:root:FL Epoch: 367 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1632
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396625
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345423
INFO:root:FL Epoch: 367 Norm Difference for worker 1632 is 0.879066
INFO:root:FL Epoch: 367 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :316
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 316 is 0.785443
INFO:root:FL Epoch: 367 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :260
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 260 is 0.821787
INFO:root:FL Epoch: 367 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :367
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572471
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676877
INFO:root:FL Epoch: 367 Norm Difference for worker 367 is 0.823448
INFO:root:FL Epoch: 367 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1083
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286770
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683881
INFO:root:FL Epoch: 367 Norm Difference for worker 1083 is 0.808771
INFO:root:FL Epoch: 367 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :646
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565396
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402826
INFO:root:FL Epoch: 367 Norm Difference for worker 646 is 0.785783
INFO:root:FL Epoch: 367 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :339
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.353887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 339 is 0.785403
INFO:root:FL Epoch: 367 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :102
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 102 is 0.867773
INFO:root:FL Epoch: 367 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1255
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496887
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558403
INFO:root:FL Epoch: 367 Norm Difference for worker 1255 is 0.843023
INFO:root:FL Epoch: 367 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 316
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.5093098037383136 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:2.4846178690592446                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [1056, 1141, 937, 1651, 564, 322, 52, 1484, 156, 295]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 368 Num points on workers: [200 200 200 200 200 201 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :1056
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480879
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325621
INFO:root:FL Epoch: 368 Norm Difference for worker 1056 is 1.01849
INFO:root:FL Epoch: 368 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1141
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547457
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404876
INFO:root:FL Epoch: 368 Norm Difference for worker 1141 is 0.817373
INFO:root:FL Epoch: 368 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :937
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520240
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478051
INFO:root:FL Epoch: 368 Norm Difference for worker 937 is 0.835101
INFO:root:FL Epoch: 368 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1651
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677948
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433525
INFO:root:FL Epoch: 368 Norm Difference for worker 1651 is 0.874742
INFO:root:FL Epoch: 368 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :564
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511902
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452027
INFO:root:FL Epoch: 368 Norm Difference for worker 564 is 0.807108
INFO:root:FL Epoch: 368 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :322
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 322 is 0.879436
INFO:root:FL Epoch: 368 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :52
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 52 is 0.815877
INFO:root:FL Epoch: 368 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1484
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568055
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731484
INFO:root:FL Epoch: 368 Norm Difference for worker 1484 is 0.859502
INFO:root:FL Epoch: 368 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :156
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 156 is 0.813144
INFO:root:FL Epoch: 368 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :295
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.399682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 295 is 0.836003
INFO:root:FL Epoch: 368 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 52
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.4662533963427824 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:1.9177319010098774                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [1806, 968, 1291, 812, 907, 963, 78, 762, 1607, 763]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :1806
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472530
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312452
INFO:root:FL Epoch: 369 Norm Difference for worker 1806 is 0.976183
INFO:root:FL Epoch: 369 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :968
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486880
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436412
INFO:root:FL Epoch: 369 Norm Difference for worker 968 is 0.794021
INFO:root:FL Epoch: 369 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1291
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510000
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489197
INFO:root:FL Epoch: 369 Norm Difference for worker 1291 is 0.740671
INFO:root:FL Epoch: 369 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :812
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630717
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551980
INFO:root:FL Epoch: 369 Norm Difference for worker 812 is 0.746067
INFO:root:FL Epoch: 369 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :907
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566694
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513370
INFO:root:FL Epoch: 369 Norm Difference for worker 907 is 0.753613
INFO:root:FL Epoch: 369 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :963
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578639
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347545
INFO:root:FL Epoch: 369 Norm Difference for worker 963 is 0.785441
INFO:root:FL Epoch: 369 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :78
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484909
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 78 is 0.743591
INFO:root:FL Epoch: 369 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :762
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753448
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479558
INFO:root:FL Epoch: 369 Norm Difference for worker 762 is 0.765329
INFO:root:FL Epoch: 369 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1607
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524721
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390765
INFO:root:FL Epoch: 369 Norm Difference for worker 1607 is 0.766039
INFO:root:FL Epoch: 369 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :763
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373335
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565671
INFO:root:FL Epoch: 369 Norm Difference for worker 763 is 0.771655
INFO:root:FL Epoch: 369 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.49073875826947827 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:1.8651570081710815                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [1925, 1192, 1339, 856, 347, 1101, 1760, 1269, 760, 1326]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 370 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :1925
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556197
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588085
INFO:root:FL Epoch: 370 Norm Difference for worker 1925 is 0.728437
INFO:root:FL Epoch: 370 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1192
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660031
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519805
INFO:root:FL Epoch: 370 Norm Difference for worker 1192 is 0.710106
INFO:root:FL Epoch: 370 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1339
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484739
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570291
INFO:root:FL Epoch: 370 Norm Difference for worker 1339 is 0.701631
INFO:root:FL Epoch: 370 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :856
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 1.028934
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625254
INFO:root:FL Epoch: 370 Norm Difference for worker 856 is 0.74767
INFO:root:FL Epoch: 370 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :347
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513539
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619497
INFO:root:FL Epoch: 370 Norm Difference for worker 347 is 0.6795
INFO:root:FL Epoch: 370 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1101
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676818
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605054
INFO:root:FL Epoch: 370 Norm Difference for worker 1101 is 0.688182
INFO:root:FL Epoch: 370 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1760
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437377
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566190
INFO:root:FL Epoch: 370 Norm Difference for worker 1760 is 0.727611
INFO:root:FL Epoch: 370 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1269
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656666
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458984
INFO:root:FL Epoch: 370 Norm Difference for worker 1269 is 0.727165
INFO:root:FL Epoch: 370 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :760
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616739
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449330
INFO:root:FL Epoch: 370 Norm Difference for worker 760 is 0.698367
INFO:root:FL Epoch: 370 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1326
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850245
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520201
INFO:root:FL Epoch: 370 Norm Difference for worker 1326 is 0.662791
INFO:root:FL Epoch: 370 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1326
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.4939203928498661 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:1.593298316001892                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [1852, 1064, 1192, 204, 1284, 286, 996, 959, 826, 516]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :1852
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540844
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495783
INFO:root:FL Epoch: 371 Norm Difference for worker 1852 is 0.640467
INFO:root:FL Epoch: 371 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1064
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601681
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591536
INFO:root:FL Epoch: 371 Norm Difference for worker 1064 is 0.692332
INFO:root:FL Epoch: 371 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1192
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606270
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455214
INFO:root:FL Epoch: 371 Norm Difference for worker 1192 is 0.695017
INFO:root:FL Epoch: 371 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :204
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 371 Norm Difference for worker 204 is 0.656483
INFO:root:FL Epoch: 371 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1284
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498990
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406016
INFO:root:FL Epoch: 371 Norm Difference for worker 1284 is 0.645318
INFO:root:FL Epoch: 371 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :286
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424370
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 371 Norm Difference for worker 286 is 0.64001
INFO:root:FL Epoch: 371 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :996
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544864
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431956
INFO:root:FL Epoch: 371 Norm Difference for worker 996 is 0.668679
INFO:root:FL Epoch: 371 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :959
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393488
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544828
INFO:root:FL Epoch: 371 Norm Difference for worker 959 is 0.649434
INFO:root:FL Epoch: 371 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :826
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692470
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507151
INFO:root:FL Epoch: 371 Norm Difference for worker 826 is 0.655603
INFO:root:FL Epoch: 371 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :516
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518771
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378456
INFO:root:FL Epoch: 371 Norm Difference for worker 516 is 0.666293
INFO:root:FL Epoch: 371 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1852
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.48926644114887013 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:2.1000881592432656                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [147, 45, 1469, 773, 1943, 1226, 1798, 1935, 1041, 605]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 372 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :147
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.835336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 147 is 0.744184
INFO:root:FL Epoch: 372 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :45
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.295981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 45 is 0.716737
INFO:root:FL Epoch: 372 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1469
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356219
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397184
INFO:root:FL Epoch: 372 Norm Difference for worker 1469 is 0.724737
INFO:root:FL Epoch: 372 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :773
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569359
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483564
INFO:root:FL Epoch: 372 Norm Difference for worker 773 is 0.716448
INFO:root:FL Epoch: 372 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1943
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688870
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359036
INFO:root:FL Epoch: 372 Norm Difference for worker 1943 is 0.754522
INFO:root:FL Epoch: 372 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1226
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642791
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421460
INFO:root:FL Epoch: 372 Norm Difference for worker 1226 is 0.710952
INFO:root:FL Epoch: 372 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1798
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691353
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387922
INFO:root:FL Epoch: 372 Norm Difference for worker 1798 is 0.808842
INFO:root:FL Epoch: 372 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1935
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601633
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524942
INFO:root:FL Epoch: 372 Norm Difference for worker 1935 is 0.778672
INFO:root:FL Epoch: 372 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1041
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457727
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659193
INFO:root:FL Epoch: 372 Norm Difference for worker 1041 is 0.731829
INFO:root:FL Epoch: 372 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :605
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367458
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400519
INFO:root:FL Epoch: 372 Norm Difference for worker 605 is 0.882393
INFO:root:FL Epoch: 372 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1226
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.4827202576048234 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:1.859557310740153                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [384, 1095, 877, 1714, 1830, 353, 272, 231, 1568, 830]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :384
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590250
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400786
INFO:root:FL Epoch: 373 Norm Difference for worker 384 is 0.742229
INFO:root:FL Epoch: 373 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1095
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742506
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533567
INFO:root:FL Epoch: 373 Norm Difference for worker 1095 is 0.662363
INFO:root:FL Epoch: 373 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :877
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469084
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364657
INFO:root:FL Epoch: 373 Norm Difference for worker 877 is 0.665253
INFO:root:FL Epoch: 373 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1714
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494879
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528874
INFO:root:FL Epoch: 373 Norm Difference for worker 1714 is 0.707008
INFO:root:FL Epoch: 373 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1830
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568954
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454445
INFO:root:FL Epoch: 373 Norm Difference for worker 1830 is 0.683195
INFO:root:FL Epoch: 373 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :353
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598573
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589631
INFO:root:FL Epoch: 373 Norm Difference for worker 353 is 0.745233
INFO:root:FL Epoch: 373 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :272
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365021
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 272 is 0.65633
INFO:root:FL Epoch: 373 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :231
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 231 is 0.678421
INFO:root:FL Epoch: 373 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1568
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585766
INFO:root:Worker: 1568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557056
INFO:root:FL Epoch: 373 Norm Difference for worker 1568 is 0.678671
INFO:root:FL Epoch: 373 Done on worker:1568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :830
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361795
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462861
INFO:root:FL Epoch: 373 Norm Difference for worker 830 is 0.783764
INFO:root:FL Epoch: 373 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.48110954025212455 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:2.32282022635142                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [860, 522, 386, 810, 536, 165, 75, 1401, 445, 480]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :860
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781983
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616475
INFO:root:FL Epoch: 374 Norm Difference for worker 860 is 0.880507
INFO:root:FL Epoch: 374 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :522
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427492
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583001
INFO:root:FL Epoch: 374 Norm Difference for worker 522 is 0.807991
INFO:root:FL Epoch: 374 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :386
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653992
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218655
INFO:root:FL Epoch: 374 Norm Difference for worker 386 is 0.794663
INFO:root:FL Epoch: 374 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :810
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413112
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590211
INFO:root:FL Epoch: 374 Norm Difference for worker 810 is 0.948192
INFO:root:FL Epoch: 374 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :536
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636405
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353154
INFO:root:FL Epoch: 374 Norm Difference for worker 536 is 0.785407
INFO:root:FL Epoch: 374 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :165
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 165 is 0.779897
INFO:root:FL Epoch: 374 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :75
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.298617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595867
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 75 is 0.735358
INFO:root:FL Epoch: 374 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1401
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390732
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488043
INFO:root:FL Epoch: 374 Norm Difference for worker 1401 is 0.817302
INFO:root:FL Epoch: 374 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :445
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527890
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653918
INFO:root:FL Epoch: 374 Norm Difference for worker 445 is 0.817466
INFO:root:FL Epoch: 374 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :480
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798373
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349902
INFO:root:FL Epoch: 374 Norm Difference for worker 480 is 0.832062
INFO:root:FL Epoch: 374 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 75
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.5109960033613092 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:2.5800570249557495                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [1152, 140, 218, 1719, 979, 1902, 1482, 774, 1691, 1050]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 375 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :1152
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418893
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588315
INFO:root:FL Epoch: 375 Norm Difference for worker 1152 is 0.980735
INFO:root:FL Epoch: 375 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :140
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597372
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 140 is 0.942393
INFO:root:FL Epoch: 375 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :218
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407960
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 218 is 0.826074
INFO:root:FL Epoch: 375 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1719
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449359
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424319
INFO:root:FL Epoch: 375 Norm Difference for worker 1719 is 0.888559
INFO:root:FL Epoch: 375 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :979
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578810
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449173
INFO:root:FL Epoch: 375 Norm Difference for worker 979 is 1.05715
INFO:root:FL Epoch: 375 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1902
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654264
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571229
INFO:root:FL Epoch: 375 Norm Difference for worker 1902 is 0.907425
INFO:root:FL Epoch: 375 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1482
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823973
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332292
INFO:root:FL Epoch: 375 Norm Difference for worker 1482 is 0.88096
INFO:root:FL Epoch: 375 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :774
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526518
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447451
INFO:root:FL Epoch: 375 Norm Difference for worker 774 is 0.833549
INFO:root:FL Epoch: 375 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1691
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389985
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273685
INFO:root:FL Epoch: 375 Norm Difference for worker 1691 is 0.89853
INFO:root:FL Epoch: 375 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1050
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393149
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476579
INFO:root:FL Epoch: 375 Norm Difference for worker 1050 is 0.902637
INFO:root:FL Epoch: 375 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.49545297201941996 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:2.116923709710439                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1073, 759, 1757, 1939, 968, 1916, 1885, 436, 482, 988]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 376 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1073
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570813
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502432
INFO:root:FL Epoch: 376 Norm Difference for worker 1073 is 0.843898
INFO:root:FL Epoch: 376 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :759
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272300
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402820
INFO:root:FL Epoch: 376 Norm Difference for worker 759 is 0.799855
INFO:root:FL Epoch: 376 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1757
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592174
INFO:root:Worker: 1757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467300
INFO:root:FL Epoch: 376 Norm Difference for worker 1757 is 0.822033
INFO:root:FL Epoch: 376 Done on worker:1757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1939
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631008
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.857338
INFO:root:FL Epoch: 376 Norm Difference for worker 1939 is 0.891701
INFO:root:FL Epoch: 376 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :968
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487597
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427826
INFO:root:FL Epoch: 376 Norm Difference for worker 968 is 0.811197
INFO:root:FL Epoch: 376 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1916
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588962
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486706
INFO:root:FL Epoch: 376 Norm Difference for worker 1916 is 0.820672
INFO:root:FL Epoch: 376 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1885
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603146
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516104
INFO:root:FL Epoch: 376 Norm Difference for worker 1885 is 0.750084
INFO:root:FL Epoch: 376 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :436
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482973
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384350
INFO:root:FL Epoch: 376 Norm Difference for worker 436 is 0.781385
INFO:root:FL Epoch: 376 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :482
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422127
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432073
INFO:root:FL Epoch: 376 Norm Difference for worker 482 is 0.770884
INFO:root:FL Epoch: 376 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :988
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609931
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317371
INFO:root:FL Epoch: 376 Norm Difference for worker 988 is 0.802307
INFO:root:FL Epoch: 376 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1885
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.4881789877134211 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:1.9797474940617878                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [416, 741, 1801, 405, 1272, 242, 139, 39, 1668, 672]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [200 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :416
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748357
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562471
INFO:root:FL Epoch: 377 Norm Difference for worker 416 is 0.76653
INFO:root:FL Epoch: 377 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :741
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799213
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407716
INFO:root:FL Epoch: 377 Norm Difference for worker 741 is 0.775023
INFO:root:FL Epoch: 377 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1801
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689132
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575333
INFO:root:FL Epoch: 377 Norm Difference for worker 1801 is 0.786699
INFO:root:FL Epoch: 377 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :405
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441826
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476620
INFO:root:FL Epoch: 377 Norm Difference for worker 405 is 0.728055
INFO:root:FL Epoch: 377 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1272
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505969
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437500
INFO:root:FL Epoch: 377 Norm Difference for worker 1272 is 0.747364
INFO:root:FL Epoch: 377 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :242
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 242 is 0.719157
INFO:root:FL Epoch: 377 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :139
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 139 is 0.754692
INFO:root:FL Epoch: 377 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :39
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 39 is 0.712689
INFO:root:FL Epoch: 377 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1668
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543493
INFO:root:Worker: 1668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273419
INFO:root:FL Epoch: 377 Norm Difference for worker 1668 is 0.78815
INFO:root:FL Epoch: 377 Done on worker:1668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :672
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364679
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496716
INFO:root:FL Epoch: 377 Norm Difference for worker 672 is 0.738532
INFO:root:FL Epoch: 377 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 39
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.49981854242437024 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:2.2611606121063232                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1813, 1674, 1542, 1523, 1490, 33, 560, 180, 282, 695]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1813
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653696
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342312
INFO:root:FL Epoch: 378 Norm Difference for worker 1813 is 0.84371
INFO:root:FL Epoch: 378 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1674
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379465
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468338
INFO:root:FL Epoch: 378 Norm Difference for worker 1674 is 1.02945
INFO:root:FL Epoch: 378 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1542
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310000
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419105
INFO:root:FL Epoch: 378 Norm Difference for worker 1542 is 0.835693
INFO:root:FL Epoch: 378 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1523
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439515
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424637
INFO:root:FL Epoch: 378 Norm Difference for worker 1523 is 0.773639
INFO:root:FL Epoch: 378 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1490
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416789
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387015
INFO:root:FL Epoch: 378 Norm Difference for worker 1490 is 0.790858
INFO:root:FL Epoch: 378 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :33
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531437
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 33 is 0.823021
INFO:root:FL Epoch: 378 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :560
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491083
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487025
INFO:root:FL Epoch: 378 Norm Difference for worker 560 is 0.82605
INFO:root:FL Epoch: 378 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :180
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363375
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 180 is 0.770707
INFO:root:FL Epoch: 378 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :282
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302517
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 282 is 0.995123
INFO:root:FL Epoch: 378 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :695
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829384
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334331
INFO:root:FL Epoch: 378 Norm Difference for worker 695 is 0.804805
INFO:root:FL Epoch: 378 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1523
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.5117774728466483 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:2.196902632713318                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1628, 717, 126, 1262, 1254, 1906, 770, 1202, 1420, 193]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1628
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478819
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.791679
INFO:root:FL Epoch: 379 Norm Difference for worker 1628 is 1.193426
INFO:root:FL Epoch: 379 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :717
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655703
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514829
INFO:root:FL Epoch: 379 Norm Difference for worker 717 is 0.79122
INFO:root:FL Epoch: 379 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :126
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.318668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 126 is 0.75196
INFO:root:FL Epoch: 379 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1262
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660281
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369898
INFO:root:FL Epoch: 379 Norm Difference for worker 1262 is 0.766337
INFO:root:FL Epoch: 379 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1254
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434516
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452272
INFO:root:FL Epoch: 379 Norm Difference for worker 1254 is 0.777639
INFO:root:FL Epoch: 379 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1906
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761036
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573368
INFO:root:FL Epoch: 379 Norm Difference for worker 1906 is 0.793276
INFO:root:FL Epoch: 379 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :770
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489703
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419578
INFO:root:FL Epoch: 379 Norm Difference for worker 770 is 0.793783
INFO:root:FL Epoch: 379 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1202
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650458
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510185
INFO:root:FL Epoch: 379 Norm Difference for worker 1202 is 0.817883
INFO:root:FL Epoch: 379 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1420
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510241
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631057
INFO:root:FL Epoch: 379 Norm Difference for worker 1420 is 0.819908
INFO:root:FL Epoch: 379 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :193
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.878397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 193 is 0.800112
INFO:root:FL Epoch: 379 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 126
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.49839935407919045 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:1.6588466962178547                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [546, 1682, 1362, 1117, 1124, 743, 671, 160, 1014, 1260]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :546
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587877
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423405
INFO:root:FL Epoch: 380 Norm Difference for worker 546 is 0.744172
INFO:root:FL Epoch: 380 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1682
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509815
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271103
INFO:root:FL Epoch: 380 Norm Difference for worker 1682 is 0.642488
INFO:root:FL Epoch: 380 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1362
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476944
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501702
INFO:root:FL Epoch: 380 Norm Difference for worker 1362 is 0.650906
INFO:root:FL Epoch: 380 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1117
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507032
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580739
INFO:root:FL Epoch: 380 Norm Difference for worker 1117 is 0.701067
INFO:root:FL Epoch: 380 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1124
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538331
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764492
INFO:root:FL Epoch: 380 Norm Difference for worker 1124 is 0.689
INFO:root:FL Epoch: 380 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :743
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380890
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428711
INFO:root:FL Epoch: 380 Norm Difference for worker 743 is 0.6592
INFO:root:FL Epoch: 380 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :671
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470892
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383135
INFO:root:FL Epoch: 380 Norm Difference for worker 671 is 0.806112
INFO:root:FL Epoch: 380 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :160
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 160 is 0.693657
INFO:root:FL Epoch: 380 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1014
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638658
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547980
INFO:root:FL Epoch: 380 Norm Difference for worker 1014 is 0.703383
INFO:root:FL Epoch: 380 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1260
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520521
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637641
INFO:root:FL Epoch: 380 Norm Difference for worker 1260 is 0.715988
INFO:root:FL Epoch: 380 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1682
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.532756928135367 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:1.8612457116444905                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [42, 1663, 1071, 1394, 1484, 908, 145, 47, 422, 1602]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 381 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :42
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.288549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 42 is 0.705776
INFO:root:FL Epoch: 381 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1663
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547462
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495769
INFO:root:FL Epoch: 381 Norm Difference for worker 1663 is 1.228288
INFO:root:FL Epoch: 381 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1071
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211903
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375245
INFO:root:FL Epoch: 381 Norm Difference for worker 1071 is 0.770113
INFO:root:FL Epoch: 381 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1394
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608354
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462649
INFO:root:FL Epoch: 381 Norm Difference for worker 1394 is 0.783356
INFO:root:FL Epoch: 381 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1484
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593664
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370744
INFO:root:FL Epoch: 381 Norm Difference for worker 1484 is 1.213322
INFO:root:FL Epoch: 381 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :908
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444291
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653392
INFO:root:FL Epoch: 381 Norm Difference for worker 908 is 1.06453
INFO:root:FL Epoch: 381 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :145
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.329364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 145 is 0.709764
INFO:root:FL Epoch: 381 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :47
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418347
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 47 is 0.779022
INFO:root:FL Epoch: 381 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :422
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685814
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516717
INFO:root:FL Epoch: 381 Norm Difference for worker 422 is 1.192809
INFO:root:FL Epoch: 381 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1602
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537901
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671251
INFO:root:FL Epoch: 381 Norm Difference for worker 1602 is 1.046612
INFO:root:FL Epoch: 381 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.4956549248274635 and Test Accuracy:75.0 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:2.2303245464960733                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [1376, 1049, 976, 1651, 827, 833, 1399, 104, 1647, 1715]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 382 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :1376
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682411
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743639
INFO:root:FL Epoch: 382 Norm Difference for worker 1376 is 0.885118
INFO:root:FL Epoch: 382 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1049
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597611
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412949
INFO:root:FL Epoch: 382 Norm Difference for worker 1049 is 0.760398
INFO:root:FL Epoch: 382 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :976
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554796
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442388
INFO:root:FL Epoch: 382 Norm Difference for worker 976 is 0.860048
INFO:root:FL Epoch: 382 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1651
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369342
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671734
INFO:root:FL Epoch: 382 Norm Difference for worker 1651 is 0.854425
INFO:root:FL Epoch: 382 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :827
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738396
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659128
INFO:root:FL Epoch: 382 Norm Difference for worker 827 is 0.900601
INFO:root:FL Epoch: 382 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :833
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612145
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599327
INFO:root:FL Epoch: 382 Norm Difference for worker 833 is 0.894705
INFO:root:FL Epoch: 382 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1399
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596501
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317389
INFO:root:FL Epoch: 382 Norm Difference for worker 1399 is 0.856133
INFO:root:FL Epoch: 382 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :104
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.450018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 104 is 0.936204
INFO:root:FL Epoch: 382 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1647
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581517
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638687
INFO:root:FL Epoch: 382 Norm Difference for worker 1647 is 0.976039
INFO:root:FL Epoch: 382 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1715
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645790
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579652
INFO:root:FL Epoch: 382 Norm Difference for worker 1715 is 0.940703
INFO:root:FL Epoch: 382 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.49292609796804543 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:2.2511077721913657                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [967, 645, 116, 1847, 1597, 982, 430, 765, 624, 1488]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :967
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588336
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502212
INFO:root:FL Epoch: 383 Norm Difference for worker 967 is 0.957145
INFO:root:FL Epoch: 383 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :645
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408460
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421836
INFO:root:FL Epoch: 383 Norm Difference for worker 645 is 0.959183
INFO:root:FL Epoch: 383 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :116
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.294062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431955
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 116 is 0.876328
INFO:root:FL Epoch: 383 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1847
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442352
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597546
INFO:root:FL Epoch: 383 Norm Difference for worker 1847 is 0.886839
INFO:root:FL Epoch: 383 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1597
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364320
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396075
INFO:root:FL Epoch: 383 Norm Difference for worker 1597 is 0.771827
INFO:root:FL Epoch: 383 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :982
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529938
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515256
INFO:root:FL Epoch: 383 Norm Difference for worker 982 is 0.897262
INFO:root:FL Epoch: 383 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :430
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675528
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469666
INFO:root:FL Epoch: 383 Norm Difference for worker 430 is 0.875591
INFO:root:FL Epoch: 383 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :765
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652114
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332096
INFO:root:FL Epoch: 383 Norm Difference for worker 765 is 0.911502
INFO:root:FL Epoch: 383 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :624
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403624
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511692
INFO:root:FL Epoch: 383 Norm Difference for worker 624 is 0.883394
INFO:root:FL Epoch: 383 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1488
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832939
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579631
INFO:root:FL Epoch: 383 Norm Difference for worker 1488 is 0.903242
INFO:root:FL Epoch: 383 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1597
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.4945525553296594 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:2.2600585222244263                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [1506, 168, 726, 1861, 1707, 805, 541, 1524, 164, 1044]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 384 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :1506
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495378
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331583
INFO:root:FL Epoch: 384 Norm Difference for worker 1506 is 0.845776
INFO:root:FL Epoch: 384 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :168
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 168 is 0.954103
INFO:root:FL Epoch: 384 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :726
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402259
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410403
INFO:root:FL Epoch: 384 Norm Difference for worker 726 is 0.958993
INFO:root:FL Epoch: 384 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1861
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324505
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596970
INFO:root:FL Epoch: 384 Norm Difference for worker 1861 is 0.861085
INFO:root:FL Epoch: 384 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1707
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520010
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413395
INFO:root:FL Epoch: 384 Norm Difference for worker 1707 is 0.912647
INFO:root:FL Epoch: 384 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :805
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581709
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587845
INFO:root:FL Epoch: 384 Norm Difference for worker 805 is 0.928155
INFO:root:FL Epoch: 384 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :541
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714682
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534038
INFO:root:FL Epoch: 384 Norm Difference for worker 541 is 0.902907
INFO:root:FL Epoch: 384 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1524
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557402
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599716
INFO:root:FL Epoch: 384 Norm Difference for worker 1524 is 0.9849
INFO:root:FL Epoch: 384 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :164
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 164 is 0.881659
INFO:root:FL Epoch: 384 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1044
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586940
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578740
INFO:root:FL Epoch: 384 Norm Difference for worker 1044 is 0.887693
INFO:root:FL Epoch: 384 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.48900090859216805 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:2.33780304590861                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [528, 235, 961, 958, 853, 1027, 1040, 1392, 1696, 1267]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 385 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :528
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470815
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474628
INFO:root:FL Epoch: 385 Norm Difference for worker 528 is 0.924887
INFO:root:FL Epoch: 385 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :235
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 235 is 0.956898
INFO:root:FL Epoch: 385 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :961
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505691
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372725
INFO:root:FL Epoch: 385 Norm Difference for worker 961 is 0.879672
INFO:root:FL Epoch: 385 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :958
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465974
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367567
INFO:root:FL Epoch: 385 Norm Difference for worker 958 is 0.925169
INFO:root:FL Epoch: 385 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :853
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487204
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400139
INFO:root:FL Epoch: 385 Norm Difference for worker 853 is 0.935681
INFO:root:FL Epoch: 385 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1027
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615558
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597651
INFO:root:FL Epoch: 385 Norm Difference for worker 1027 is 0.901718
INFO:root:FL Epoch: 385 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1040
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427052
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512621
INFO:root:FL Epoch: 385 Norm Difference for worker 1040 is 0.9101
INFO:root:FL Epoch: 385 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1392
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396813
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243052
INFO:root:FL Epoch: 385 Norm Difference for worker 1392 is 0.829615
INFO:root:FL Epoch: 385 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1696
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239508
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686904
INFO:root:FL Epoch: 385 Norm Difference for worker 1696 is 0.84981
INFO:root:FL Epoch: 385 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1267
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523268
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671178
INFO:root:FL Epoch: 385 Norm Difference for worker 1267 is 0.846778
INFO:root:FL Epoch: 385 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1267
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.4889235321213217 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:1.9633965889612834                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [1609, 73, 1498, 543, 1861, 1559, 1126, 467, 1271, 1286]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :1609
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370917
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533530
INFO:root:FL Epoch: 386 Norm Difference for worker 1609 is 0.767082
INFO:root:FL Epoch: 386 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :73
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 73 is 0.799827
INFO:root:FL Epoch: 386 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1498
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581250
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459951
INFO:root:FL Epoch: 386 Norm Difference for worker 1498 is 0.730444
INFO:root:FL Epoch: 386 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :543
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708554
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327711
INFO:root:FL Epoch: 386 Norm Difference for worker 543 is 0.752877
INFO:root:FL Epoch: 386 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1861
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680471
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574834
INFO:root:FL Epoch: 386 Norm Difference for worker 1861 is 0.690776
INFO:root:FL Epoch: 386 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1559
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590715
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244406
INFO:root:FL Epoch: 386 Norm Difference for worker 1559 is 0.699961
INFO:root:FL Epoch: 386 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1126
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447431
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564842
INFO:root:FL Epoch: 386 Norm Difference for worker 1126 is 0.795569
INFO:root:FL Epoch: 386 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :467
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565074
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366499
INFO:root:FL Epoch: 386 Norm Difference for worker 467 is 0.782746
INFO:root:FL Epoch: 386 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1271
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645396
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575869
INFO:root:FL Epoch: 386 Norm Difference for worker 1271 is 0.7564
INFO:root:FL Epoch: 386 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1286
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734441
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524816
INFO:root:FL Epoch: 386 Norm Difference for worker 1286 is 0.792711
INFO:root:FL Epoch: 386 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1861
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.49600664131781635 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:1.9760154684384663                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [549, 1673, 500, 72, 653, 1716, 11, 387, 396, 158]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 387 Num points on workers: [200 200 200 201 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :549
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343037
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642488
INFO:root:FL Epoch: 387 Norm Difference for worker 549 is 0.770576
INFO:root:FL Epoch: 387 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1673
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684946
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412273
INFO:root:FL Epoch: 387 Norm Difference for worker 1673 is 0.718968
INFO:root:FL Epoch: 387 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :500
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381014
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617839
INFO:root:FL Epoch: 387 Norm Difference for worker 500 is 0.737219
INFO:root:FL Epoch: 387 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :72
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 72 is 0.770344
INFO:root:FL Epoch: 387 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :653
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681078
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456888
INFO:root:FL Epoch: 387 Norm Difference for worker 653 is 0.706001
INFO:root:FL Epoch: 387 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1716
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455402
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322061
INFO:root:FL Epoch: 387 Norm Difference for worker 1716 is 0.766675
INFO:root:FL Epoch: 387 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :11
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 11 is 0.695515
INFO:root:FL Epoch: 387 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :387
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838280
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346883
INFO:root:FL Epoch: 387 Norm Difference for worker 387 is 0.751379
INFO:root:FL Epoch: 387 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :396
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543406
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457132
INFO:root:FL Epoch: 387 Norm Difference for worker 396 is 0.728455
INFO:root:FL Epoch: 387 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :158
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.874361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 158 is 0.770788
INFO:root:FL Epoch: 387 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 11
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 387 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 387 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.4795439462451374 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:2.0106629927953086                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [1665, 1125, 1765, 790, 1839, 1239, 380, 115, 470, 66]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 388 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :1665
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244572
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377191
INFO:root:FL Epoch: 388 Norm Difference for worker 1665 is 0.726408
INFO:root:FL Epoch: 388 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1125
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589057
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546894
INFO:root:FL Epoch: 388 Norm Difference for worker 1125 is 0.733274
INFO:root:FL Epoch: 388 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1765
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409549
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370612
INFO:root:FL Epoch: 388 Norm Difference for worker 1765 is 0.754195
INFO:root:FL Epoch: 388 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :790
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767507
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661840
INFO:root:FL Epoch: 388 Norm Difference for worker 790 is 0.832935
INFO:root:FL Epoch: 388 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1839
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478430
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471798
INFO:root:FL Epoch: 388 Norm Difference for worker 1839 is 0.784774
INFO:root:FL Epoch: 388 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1239
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925783
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536903
INFO:root:FL Epoch: 388 Norm Difference for worker 1239 is 0.814435
INFO:root:FL Epoch: 388 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :380
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788654
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602593
INFO:root:FL Epoch: 388 Norm Difference for worker 380 is 0.785615
INFO:root:FL Epoch: 388 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :115
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.405260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 115 is 0.729678
INFO:root:FL Epoch: 388 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :470
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685889
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666402
INFO:root:FL Epoch: 388 Norm Difference for worker 470 is 0.792636
INFO:root:FL Epoch: 388 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :66
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.180802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 66 is 0.812797
INFO:root:FL Epoch: 388 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1125
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.4724276889772976 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:1.62137367328008                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [1606, 93, 1407, 1135, 1858, 138, 1653, 1773, 776, 1529]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 389 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :1606
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438625
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418741
INFO:root:FL Epoch: 389 Norm Difference for worker 1606 is 0.709886
INFO:root:FL Epoch: 389 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :93
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 93 is 0.658432
INFO:root:FL Epoch: 389 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1407
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528059
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491096
INFO:root:FL Epoch: 389 Norm Difference for worker 1407 is 0.685039
INFO:root:FL Epoch: 389 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1135
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519099
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662308
INFO:root:FL Epoch: 389 Norm Difference for worker 1135 is 0.730335
INFO:root:FL Epoch: 389 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1858
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414063
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482565
INFO:root:FL Epoch: 389 Norm Difference for worker 1858 is 0.736388
INFO:root:FL Epoch: 389 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :138
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510737
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 138 is 0.687518
INFO:root:FL Epoch: 389 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1653
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397906
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353836
INFO:root:FL Epoch: 389 Norm Difference for worker 1653 is 0.715531
INFO:root:FL Epoch: 389 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1773
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468431
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651194
INFO:root:FL Epoch: 389 Norm Difference for worker 1773 is 0.718743
INFO:root:FL Epoch: 389 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :776
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353093
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475510
INFO:root:FL Epoch: 389 Norm Difference for worker 776 is 0.695295
INFO:root:FL Epoch: 389 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1529
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378224
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622139
INFO:root:FL Epoch: 389 Norm Difference for worker 1529 is 0.687463
INFO:root:FL Epoch: 389 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 93
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.4749320377321804 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:1.768980046113332                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [1287, 140, 41, 524, 516, 1671, 1251, 1472, 1931, 518]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 390 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :1287
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356443
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643136
INFO:root:FL Epoch: 390 Norm Difference for worker 1287 is 0.747277
INFO:root:FL Epoch: 390 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :140
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503628
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 140 is 0.726665
INFO:root:FL Epoch: 390 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :41
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 41 is 0.729668
INFO:root:FL Epoch: 390 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :524
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522685
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424989
INFO:root:FL Epoch: 390 Norm Difference for worker 524 is 0.680179
INFO:root:FL Epoch: 390 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :516
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674786
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404463
INFO:root:FL Epoch: 390 Norm Difference for worker 516 is 0.720522
INFO:root:FL Epoch: 390 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1671
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357085
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436106
INFO:root:FL Epoch: 390 Norm Difference for worker 1671 is 0.720859
INFO:root:FL Epoch: 390 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1251
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814796
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346229
INFO:root:FL Epoch: 390 Norm Difference for worker 1251 is 0.765415
INFO:root:FL Epoch: 390 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1472
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720131
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509800
INFO:root:FL Epoch: 390 Norm Difference for worker 1472 is 0.750682
INFO:root:FL Epoch: 390 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1931
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449384
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580078
INFO:root:FL Epoch: 390 Norm Difference for worker 1931 is 0.755947
INFO:root:FL Epoch: 390 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :518
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469360
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548867
INFO:root:FL Epoch: 390 Norm Difference for worker 518 is 0.750327
INFO:root:FL Epoch: 390 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 524
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.4665815304307377 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:1.9933412472407024                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [657, 588, 658, 1478, 1297, 840, 642, 148, 1140, 457]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :657
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608017
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577782
INFO:root:FL Epoch: 391 Norm Difference for worker 657 is 0.840799
INFO:root:FL Epoch: 391 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :588
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611465
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465871
INFO:root:FL Epoch: 391 Norm Difference for worker 588 is 0.874093
INFO:root:FL Epoch: 391 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :658
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373485
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475740
INFO:root:FL Epoch: 391 Norm Difference for worker 658 is 0.847133
INFO:root:FL Epoch: 391 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1478
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452205
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356717
INFO:root:FL Epoch: 391 Norm Difference for worker 1478 is 0.802288
INFO:root:FL Epoch: 391 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1297
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701571
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459167
INFO:root:FL Epoch: 391 Norm Difference for worker 1297 is 0.85733
INFO:root:FL Epoch: 391 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :840
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424176
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521378
INFO:root:FL Epoch: 391 Norm Difference for worker 840 is 0.784018
INFO:root:FL Epoch: 391 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :642
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633979
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399345
INFO:root:FL Epoch: 391 Norm Difference for worker 642 is 0.811149
INFO:root:FL Epoch: 391 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :148
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.398887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403227
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 148 is 0.817541
INFO:root:FL Epoch: 391 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1140
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639806
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447701
INFO:root:FL Epoch: 391 Norm Difference for worker 1140 is 0.798966
INFO:root:FL Epoch: 391 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :457
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657919
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417480
INFO:root:FL Epoch: 391 Norm Difference for worker 457 is 0.817541
INFO:root:FL Epoch: 391 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1140
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.4755973368883133 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:1.9807002345720928                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [309, 906, 1151, 497, 188, 535, 589, 443, 1660, 75]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 392 Num points on workers: [201 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :309
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474329
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572864
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 309 is 0.738378
INFO:root:FL Epoch: 392 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :906
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320668
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338257
INFO:root:FL Epoch: 392 Norm Difference for worker 906 is 0.699573
INFO:root:FL Epoch: 392 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1151
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579307
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338484
INFO:root:FL Epoch: 392 Norm Difference for worker 1151 is 0.677647
INFO:root:FL Epoch: 392 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :497
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475651
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430866
INFO:root:FL Epoch: 392 Norm Difference for worker 497 is 0.682391
INFO:root:FL Epoch: 392 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :188
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 188 is 0.713694
INFO:root:FL Epoch: 392 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :535
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481400
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414457
INFO:root:FL Epoch: 392 Norm Difference for worker 535 is 0.734548
INFO:root:FL Epoch: 392 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :589
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579492
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709950
INFO:root:FL Epoch: 392 Norm Difference for worker 589 is 0.737149
INFO:root:FL Epoch: 392 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :443
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355782
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501487
INFO:root:FL Epoch: 392 Norm Difference for worker 443 is 0.743237
INFO:root:FL Epoch: 392 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1660
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609938
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486949
INFO:root:FL Epoch: 392 Norm Difference for worker 1660 is 0.749968
INFO:root:FL Epoch: 392 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :75
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.285150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 75 is 0.696187
INFO:root:FL Epoch: 392 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.4889126533971113 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:2.137670914332072                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [15, 1711, 222, 1761, 1183, 1408, 1510, 976, 1069, 478]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 393 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :15
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.292212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 15 is 0.743731
INFO:root:FL Epoch: 393 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1711
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622897
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429469
INFO:root:FL Epoch: 393 Norm Difference for worker 1711 is 0.732958
INFO:root:FL Epoch: 393 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :222
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 222 is 0.73434
INFO:root:FL Epoch: 393 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1761
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503559
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458718
INFO:root:FL Epoch: 393 Norm Difference for worker 1761 is 0.744754
INFO:root:FL Epoch: 393 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1183
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420332
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457694
INFO:root:FL Epoch: 393 Norm Difference for worker 1183 is 0.763045
INFO:root:FL Epoch: 393 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1408
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595106
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475893
INFO:root:FL Epoch: 393 Norm Difference for worker 1408 is 0.757166
INFO:root:FL Epoch: 393 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1510
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472506
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529856
INFO:root:FL Epoch: 393 Norm Difference for worker 1510 is 0.787417
INFO:root:FL Epoch: 393 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :976
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481150
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591179
INFO:root:FL Epoch: 393 Norm Difference for worker 976 is 0.764266
INFO:root:FL Epoch: 393 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1069
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832153
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465265
INFO:root:FL Epoch: 393 Norm Difference for worker 1069 is 0.780621
INFO:root:FL Epoch: 393 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :478
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709501
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429626
INFO:root:FL Epoch: 393 Norm Difference for worker 478 is 0.793788
INFO:root:FL Epoch: 393 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1183
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.47987665148342357 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:1.519987682501475                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [163, 1068, 1533, 112, 1607, 233, 108, 1054, 1778, 1238]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 394 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :163
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 163 is 0.756709
INFO:root:FL Epoch: 394 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1068
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430291
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507343
INFO:root:FL Epoch: 394 Norm Difference for worker 1068 is 0.709684
INFO:root:FL Epoch: 394 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1533
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694613
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421125
INFO:root:FL Epoch: 394 Norm Difference for worker 1533 is 0.705165
INFO:root:FL Epoch: 394 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :112
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.746763
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 112 is 0.671905
INFO:root:FL Epoch: 394 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1607
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499303
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460306
INFO:root:FL Epoch: 394 Norm Difference for worker 1607 is 0.727039
INFO:root:FL Epoch: 394 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :233
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 233 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 233 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 233 is 0.70341
INFO:root:FL Epoch: 394 Done on worker:233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :108
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 108 is 0.652427
INFO:root:FL Epoch: 394 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1054
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473792
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451959
INFO:root:FL Epoch: 394 Norm Difference for worker 1054 is 0.681644
INFO:root:FL Epoch: 394 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1778
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415034
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351210
INFO:root:FL Epoch: 394 Norm Difference for worker 1778 is 0.725914
INFO:root:FL Epoch: 394 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1238
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484166
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430952
INFO:root:FL Epoch: 394 Norm Difference for worker 1238 is 0.744993
INFO:root:FL Epoch: 394 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 112
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.47479549050331116 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:1.9382689396540325                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [1066, 51, 146, 1140, 1089, 1305, 1752, 547, 1937, 1028]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 395 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :1066
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561362
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260112
INFO:root:FL Epoch: 395 Norm Difference for worker 1066 is 0.698242
INFO:root:FL Epoch: 395 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :51
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 51 is 0.75483
INFO:root:FL Epoch: 395 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :146
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 146 is 0.647963
INFO:root:FL Epoch: 395 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1140
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374859
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466015
INFO:root:FL Epoch: 395 Norm Difference for worker 1140 is 0.646263
INFO:root:FL Epoch: 395 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1089
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358948
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608668
INFO:root:FL Epoch: 395 Norm Difference for worker 1089 is 0.620701
INFO:root:FL Epoch: 395 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1305
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482678
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496171
INFO:root:FL Epoch: 395 Norm Difference for worker 1305 is 0.747127
INFO:root:FL Epoch: 395 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1752
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629383
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439184
INFO:root:FL Epoch: 395 Norm Difference for worker 1752 is 0.726719
INFO:root:FL Epoch: 395 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :547
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653769
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540751
INFO:root:FL Epoch: 395 Norm Difference for worker 547 is 0.675429
INFO:root:FL Epoch: 395 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1937
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462852
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510847
INFO:root:FL Epoch: 395 Norm Difference for worker 1937 is 0.73501
INFO:root:FL Epoch: 395 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1028
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599436
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425407
INFO:root:FL Epoch: 395 Norm Difference for worker 1028 is 0.684171
INFO:root:FL Epoch: 395 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.4589877636993633 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:1.7561747431755066                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [1402, 112, 1319, 954, 1339, 963, 928, 1031, 1261, 1888]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :1402
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555962
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541718
INFO:root:FL Epoch: 396 Norm Difference for worker 1402 is 0.763901
INFO:root:FL Epoch: 396 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :112
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500843
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 112 is 0.636278
INFO:root:FL Epoch: 396 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1319
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692247
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.823745
INFO:root:FL Epoch: 396 Norm Difference for worker 1319 is 0.754313
INFO:root:FL Epoch: 396 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :954
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506158
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407591
INFO:root:FL Epoch: 396 Norm Difference for worker 954 is 0.749133
INFO:root:FL Epoch: 396 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1339
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695618
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402102
INFO:root:FL Epoch: 396 Norm Difference for worker 1339 is 0.747987
INFO:root:FL Epoch: 396 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :963
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466581
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649339
INFO:root:FL Epoch: 396 Norm Difference for worker 963 is 0.785294
INFO:root:FL Epoch: 396 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :928
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395681
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480709
INFO:root:FL Epoch: 396 Norm Difference for worker 928 is 0.665654
INFO:root:FL Epoch: 396 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1031
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511297
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536503
INFO:root:FL Epoch: 396 Norm Difference for worker 1031 is 0.754499
INFO:root:FL Epoch: 396 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1261
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540540
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.809317
INFO:root:FL Epoch: 396 Norm Difference for worker 1261 is 0.72682
INFO:root:FL Epoch: 396 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1888
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495540
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403000
INFO:root:FL Epoch: 396 Norm Difference for worker 1888 is 0.73183
INFO:root:FL Epoch: 396 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 112
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 396 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 396 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.4422752269927193 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:2.3733471234639487                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [1000, 626, 1566, 6, 608, 1932, 940, 68, 1742, 783]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :1000
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638680
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414787
INFO:root:FL Epoch: 397 Norm Difference for worker 1000 is 0.82738
INFO:root:FL Epoch: 397 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :626
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330685
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405790
INFO:root:FL Epoch: 397 Norm Difference for worker 626 is 0.777948
INFO:root:FL Epoch: 397 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1566
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321365
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365638
INFO:root:FL Epoch: 397 Norm Difference for worker 1566 is 0.751736
INFO:root:FL Epoch: 397 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :6
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 6 is 0.780372
INFO:root:FL Epoch: 397 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :608
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663287
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461653
INFO:root:FL Epoch: 397 Norm Difference for worker 608 is 0.853825
INFO:root:FL Epoch: 397 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1932
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339404
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498057
INFO:root:FL Epoch: 397 Norm Difference for worker 1932 is 0.829337
INFO:root:FL Epoch: 397 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :940
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295470
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289899
INFO:root:FL Epoch: 397 Norm Difference for worker 940 is 0.837034
INFO:root:FL Epoch: 397 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :68
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341924
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 68 is 0.804071
INFO:root:FL Epoch: 397 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1742
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591426
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527244
INFO:root:FL Epoch: 397 Norm Difference for worker 1742 is 0.886655
INFO:root:FL Epoch: 397 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :783
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496933
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433989
INFO:root:FL Epoch: 397 Norm Difference for worker 783 is 0.910975
INFO:root:FL Epoch: 397 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.4667689511004616 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:1.79397718111674                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1815, 279, 666, 1121, 1755, 734, 464, 1096, 1764, 936]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 398 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1815
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427990
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546135
INFO:root:FL Epoch: 398 Norm Difference for worker 1815 is 0.791215
INFO:root:FL Epoch: 398 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :279
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431874
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 279 is 0.735924
INFO:root:FL Epoch: 398 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :666
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345487
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438077
INFO:root:FL Epoch: 398 Norm Difference for worker 666 is 0.745238
INFO:root:FL Epoch: 398 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1121
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496665
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395824
INFO:root:FL Epoch: 398 Norm Difference for worker 1121 is 0.713941
INFO:root:FL Epoch: 398 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1755
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287950
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317188
INFO:root:FL Epoch: 398 Norm Difference for worker 1755 is 0.743957
INFO:root:FL Epoch: 398 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :734
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484923
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360906
INFO:root:FL Epoch: 398 Norm Difference for worker 734 is 0.695713
INFO:root:FL Epoch: 398 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :464
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513884
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515642
INFO:root:FL Epoch: 398 Norm Difference for worker 464 is 0.700873
INFO:root:FL Epoch: 398 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1096
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575365
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472456
INFO:root:FL Epoch: 398 Norm Difference for worker 1096 is 0.746372
INFO:root:FL Epoch: 398 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1764
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859571
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487558
INFO:root:FL Epoch: 398 Norm Difference for worker 1764 is 0.830602
INFO:root:FL Epoch: 398 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :936
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666156
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742015
INFO:root:FL Epoch: 398 Norm Difference for worker 936 is 0.765531
INFO:root:FL Epoch: 398 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 464
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.45915276338072386 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:2.153672456741333                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [465, 1626, 299, 363, 1601, 505, 1227, 1758, 1774, 487]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 399 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :465
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439369
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563144
INFO:root:FL Epoch: 399 Norm Difference for worker 465 is 0.803283
INFO:root:FL Epoch: 399 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1626
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483106
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475638
INFO:root:FL Epoch: 399 Norm Difference for worker 1626 is 0.821029
INFO:root:FL Epoch: 399 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :299
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 299 is 0.736298
INFO:root:FL Epoch: 399 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :363
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631289
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679662
INFO:root:FL Epoch: 399 Norm Difference for worker 363 is 0.890426
INFO:root:FL Epoch: 399 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1601
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405416
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455889
INFO:root:FL Epoch: 399 Norm Difference for worker 1601 is 0.724617
INFO:root:FL Epoch: 399 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :505
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331486
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575189
INFO:root:FL Epoch: 399 Norm Difference for worker 505 is 0.837731
INFO:root:FL Epoch: 399 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1227
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551160
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436810
INFO:root:FL Epoch: 399 Norm Difference for worker 1227 is 0.772898
INFO:root:FL Epoch: 399 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1758
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664240
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610306
INFO:root:FL Epoch: 399 Norm Difference for worker 1758 is 0.787834
INFO:root:FL Epoch: 399 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1774
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436643
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568077
INFO:root:FL Epoch: 399 Norm Difference for worker 1774 is 0.738054
INFO:root:FL Epoch: 399 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :487
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694931
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638114
INFO:root:FL Epoch: 399 Norm Difference for worker 487 is 0.776538
INFO:root:FL Epoch: 399 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1601
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.4505888959940742 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:2.141941487789154                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [618, 643, 1936, 576, 1256, 403, 351, 468, 263, 1841]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :618
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410919
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531313
INFO:root:FL Epoch: 400 Norm Difference for worker 618 is 0.828088
INFO:root:FL Epoch: 400 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :643
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564960
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463257
INFO:root:FL Epoch: 400 Norm Difference for worker 643 is 0.805632
INFO:root:FL Epoch: 400 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1936
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824783
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318067
INFO:root:FL Epoch: 400 Norm Difference for worker 1936 is 0.727714
INFO:root:FL Epoch: 400 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :576
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393425
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546076
INFO:root:FL Epoch: 400 Norm Difference for worker 576 is 0.793312
INFO:root:FL Epoch: 400 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1256
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617072
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421886
INFO:root:FL Epoch: 400 Norm Difference for worker 1256 is 0.750655
INFO:root:FL Epoch: 400 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :403
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674037
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353704
INFO:root:FL Epoch: 400 Norm Difference for worker 403 is 0.85672
INFO:root:FL Epoch: 400 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :351
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686787
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465301
INFO:root:FL Epoch: 400 Norm Difference for worker 351 is 0.779534
INFO:root:FL Epoch: 400 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :468
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481977
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279927
INFO:root:FL Epoch: 400 Norm Difference for worker 468 is 0.737263
INFO:root:FL Epoch: 400 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :263
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 263 is 0.781803
INFO:root:FL Epoch: 400 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1841
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413282
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487033
INFO:root:FL Epoch: 400 Norm Difference for worker 1841 is 0.794662
INFO:root:FL Epoch: 400 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1936
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.45124305171125073 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:2.1756306091944375                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [714, 1571, 405, 1487, 410, 926, 1010, 626, 800, 768]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :714
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711760
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599881
INFO:root:FL Epoch: 401 Norm Difference for worker 714 is 0.812434
INFO:root:FL Epoch: 401 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1571
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507851
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415899
INFO:root:FL Epoch: 401 Norm Difference for worker 1571 is 0.76487
INFO:root:FL Epoch: 401 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :405
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530649
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407681
INFO:root:FL Epoch: 401 Norm Difference for worker 405 is 0.75708
INFO:root:FL Epoch: 401 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1487
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390951
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520941
INFO:root:FL Epoch: 401 Norm Difference for worker 1487 is 0.763665
INFO:root:FL Epoch: 401 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :410
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551829
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441058
INFO:root:FL Epoch: 401 Norm Difference for worker 410 is 0.669153
INFO:root:FL Epoch: 401 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :926
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545893
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429743
INFO:root:FL Epoch: 401 Norm Difference for worker 926 is 0.697242
INFO:root:FL Epoch: 401 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1010
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402358
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313805
INFO:root:FL Epoch: 401 Norm Difference for worker 1010 is 0.775102
INFO:root:FL Epoch: 401 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :626
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297329
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462151
INFO:root:FL Epoch: 401 Norm Difference for worker 626 is 0.710969
INFO:root:FL Epoch: 401 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :800
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481572
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556641
INFO:root:FL Epoch: 401 Norm Difference for worker 800 is 0.733806
INFO:root:FL Epoch: 401 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :768
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686214
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254016
INFO:root:FL Epoch: 401 Norm Difference for worker 768 is 0.754785
INFO:root:FL Epoch: 401 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 401 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 401 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.4548296437543981 and Test Accuracy:80.88235294117646 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:2.66066312789917                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [659, 1820, 1570, 929, 1453, 1575, 18, 1677, 1205, 1463]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :659
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751228
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301692
INFO:root:FL Epoch: 402 Norm Difference for worker 659 is 0.865074
INFO:root:FL Epoch: 402 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1820
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527311
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631617
INFO:root:FL Epoch: 402 Norm Difference for worker 1820 is 0.894933
INFO:root:FL Epoch: 402 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1570
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517600
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289025
INFO:root:FL Epoch: 402 Norm Difference for worker 1570 is 0.843926
INFO:root:FL Epoch: 402 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :929
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497858
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620498
INFO:root:FL Epoch: 402 Norm Difference for worker 929 is 0.916286
INFO:root:FL Epoch: 402 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1453
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651207
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359871
INFO:root:FL Epoch: 402 Norm Difference for worker 1453 is 0.881518
INFO:root:FL Epoch: 402 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1575
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579023
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447361
INFO:root:FL Epoch: 402 Norm Difference for worker 1575 is 0.858737
INFO:root:FL Epoch: 402 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :18
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.257211
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 18 is 0.852759
INFO:root:FL Epoch: 402 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1677
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500422
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737357
INFO:root:FL Epoch: 402 Norm Difference for worker 1677 is 0.857918
INFO:root:FL Epoch: 402 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1205
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581155
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708873
INFO:root:FL Epoch: 402 Norm Difference for worker 1205 is 0.925848
INFO:root:FL Epoch: 402 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1463
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829747
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608336
INFO:root:FL Epoch: 402 Norm Difference for worker 1463 is 0.940293
INFO:root:FL Epoch: 402 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.4516802605460672 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:2.006791909535726                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1859, 1132, 1780, 1797, 1240, 363, 594, 1358, 1023, 1607]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1859
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716777
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554941
INFO:root:FL Epoch: 403 Norm Difference for worker 1859 is 0.731969
INFO:root:FL Epoch: 403 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1132
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671253
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337381
INFO:root:FL Epoch: 403 Norm Difference for worker 1132 is 0.684521
INFO:root:FL Epoch: 403 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1780
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415094
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618609
INFO:root:FL Epoch: 403 Norm Difference for worker 1780 is 0.715277
INFO:root:FL Epoch: 403 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1797
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376951
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504210
INFO:root:FL Epoch: 403 Norm Difference for worker 1797 is 0.721743
INFO:root:FL Epoch: 403 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1240
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452639
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530510
INFO:root:FL Epoch: 403 Norm Difference for worker 1240 is 0.781619
INFO:root:FL Epoch: 403 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :363
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653314
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519655
INFO:root:FL Epoch: 403 Norm Difference for worker 363 is 0.791017
INFO:root:FL Epoch: 403 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :594
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509866
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592801
INFO:root:FL Epoch: 403 Norm Difference for worker 594 is 0.787641
INFO:root:FL Epoch: 403 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1358
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471689
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456446
INFO:root:FL Epoch: 403 Norm Difference for worker 1358 is 0.687017
INFO:root:FL Epoch: 403 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1023
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556795
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376660
INFO:root:FL Epoch: 403 Norm Difference for worker 1023 is 0.689003
INFO:root:FL Epoch: 403 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1607
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380140
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436155
INFO:root:FL Epoch: 403 Norm Difference for worker 1607 is 0.737456
INFO:root:FL Epoch: 403 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1132
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.4857879193390117 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:2.231861392656962                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [53, 123, 381, 848, 395, 1829, 475, 718, 683, 1358]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 404 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :53
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 53 is 0.692375
INFO:root:FL Epoch: 404 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :123
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 123 is 0.712573
INFO:root:FL Epoch: 404 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :381
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451331
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330632
INFO:root:FL Epoch: 404 Norm Difference for worker 381 is 0.666682
INFO:root:FL Epoch: 404 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :848
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367402
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736822
INFO:root:FL Epoch: 404 Norm Difference for worker 848 is 0.795663
INFO:root:FL Epoch: 404 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :395
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656356
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426804
INFO:root:FL Epoch: 404 Norm Difference for worker 395 is 0.671417
INFO:root:FL Epoch: 404 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1829
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360046
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373033
INFO:root:FL Epoch: 404 Norm Difference for worker 1829 is 0.74685
INFO:root:FL Epoch: 404 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :475
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545461
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472582
INFO:root:FL Epoch: 404 Norm Difference for worker 475 is 0.697218
INFO:root:FL Epoch: 404 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :718
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563560
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528728
INFO:root:FL Epoch: 404 Norm Difference for worker 718 is 0.73174
INFO:root:FL Epoch: 404 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :683
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546011
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600212
INFO:root:FL Epoch: 404 Norm Difference for worker 683 is 0.751098
INFO:root:FL Epoch: 404 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1358
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477247
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769765
INFO:root:FL Epoch: 404 Norm Difference for worker 1358 is 0.782888
INFO:root:FL Epoch: 404 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 381
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.47839511142057534 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:2.015318969885508                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1195, 736, 83, 847, 1702, 1608, 1475, 98, 318, 41]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 201 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1195
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763921
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498676
INFO:root:FL Epoch: 405 Norm Difference for worker 1195 is 0.770881
INFO:root:FL Epoch: 405 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :736
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395218
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293029
INFO:root:FL Epoch: 405 Norm Difference for worker 736 is 0.766728
INFO:root:FL Epoch: 405 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :83
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 83 is 0.774935
INFO:root:FL Epoch: 405 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :847
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337477
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365788
INFO:root:FL Epoch: 405 Norm Difference for worker 847 is 0.863296
INFO:root:FL Epoch: 405 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1702
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678309
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473027
INFO:root:FL Epoch: 405 Norm Difference for worker 1702 is 0.783713
INFO:root:FL Epoch: 405 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1608
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647393
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659935
INFO:root:FL Epoch: 405 Norm Difference for worker 1608 is 0.869974
INFO:root:FL Epoch: 405 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1475
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668524
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273708
INFO:root:FL Epoch: 405 Norm Difference for worker 1475 is 0.846493
INFO:root:FL Epoch: 405 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :98
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446586
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 98 is 0.920846
INFO:root:FL Epoch: 405 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :318
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 318 is 0.845531
INFO:root:FL Epoch: 405 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :41
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600932
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 41 is 0.767039
INFO:root:FL Epoch: 405 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1702
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.49285318921594057 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:2.4427815278371177                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [1386, 1827, 1286, 299, 1481, 1930, 1502, 1216, 613, 535]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 406 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :1386
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514289
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326312
INFO:root:FL Epoch: 406 Norm Difference for worker 1386 is 0.809366
INFO:root:FL Epoch: 406 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1827
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475457
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470955
INFO:root:FL Epoch: 406 Norm Difference for worker 1827 is 0.813424
INFO:root:FL Epoch: 406 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1286
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534503
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658730
INFO:root:FL Epoch: 406 Norm Difference for worker 1286 is 0.863367
INFO:root:FL Epoch: 406 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :299
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418021
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 299 is 0.692165
INFO:root:FL Epoch: 406 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1481
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805008
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509982
INFO:root:FL Epoch: 406 Norm Difference for worker 1481 is 0.928375
INFO:root:FL Epoch: 406 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1930
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533539
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435782
INFO:root:FL Epoch: 406 Norm Difference for worker 1930 is 0.854562
INFO:root:FL Epoch: 406 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1502
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803959
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250772
INFO:root:FL Epoch: 406 Norm Difference for worker 1502 is 0.77252
INFO:root:FL Epoch: 406 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1216
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779228
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428200
INFO:root:FL Epoch: 406 Norm Difference for worker 1216 is 0.872906
INFO:root:FL Epoch: 406 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :613
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589341
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501355
INFO:root:FL Epoch: 406 Norm Difference for worker 613 is 0.846119
INFO:root:FL Epoch: 406 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :535
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380014
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434093
INFO:root:FL Epoch: 406 Norm Difference for worker 535 is 0.835317
INFO:root:FL Epoch: 406 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 299
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.5050227869959438 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:2.6912867625554404                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1924, 670, 1936, 599, 801, 477, 1643, 376, 508, 360]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1924
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800647
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667163
INFO:root:FL Epoch: 407 Norm Difference for worker 1924 is 0.832347
INFO:root:FL Epoch: 407 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :670
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669677
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291247
INFO:root:FL Epoch: 407 Norm Difference for worker 670 is 0.834651
INFO:root:FL Epoch: 407 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1936
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452147
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253427
INFO:root:FL Epoch: 407 Norm Difference for worker 1936 is 0.720656
INFO:root:FL Epoch: 407 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :599
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382477
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529814
INFO:root:FL Epoch: 407 Norm Difference for worker 599 is 0.85927
INFO:root:FL Epoch: 407 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :801
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467353
INFO:root:Worker: 801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527223
INFO:root:FL Epoch: 407 Norm Difference for worker 801 is 0.798807
INFO:root:FL Epoch: 407 Done on worker:801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :477
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500213
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395736
INFO:root:FL Epoch: 407 Norm Difference for worker 477 is 0.778833
INFO:root:FL Epoch: 407 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1643
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812367
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560088
INFO:root:FL Epoch: 407 Norm Difference for worker 1643 is 0.932604
INFO:root:FL Epoch: 407 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :376
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505448
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456638
INFO:root:FL Epoch: 407 Norm Difference for worker 376 is 0.983174
INFO:root:FL Epoch: 407 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :508
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375835
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310401
INFO:root:FL Epoch: 407 Norm Difference for worker 508 is 0.782433
INFO:root:FL Epoch: 407 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :360
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536555
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337823
INFO:root:FL Epoch: 407 Norm Difference for worker 360 is 0.904326
INFO:root:FL Epoch: 407 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1936
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.47178901907275705 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:2.4000312089920044                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [892, 1676, 413, 1578, 1261, 1657, 1701, 168, 1462, 1213]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :892
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461306
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420593
INFO:root:FL Epoch: 408 Norm Difference for worker 892 is 0.812292
INFO:root:FL Epoch: 408 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1676
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498516
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526987
INFO:root:FL Epoch: 408 Norm Difference for worker 1676 is 0.907619
INFO:root:FL Epoch: 408 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :413
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653224
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436251
INFO:root:FL Epoch: 408 Norm Difference for worker 413 is 0.894076
INFO:root:FL Epoch: 408 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1578
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415540
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769944
INFO:root:FL Epoch: 408 Norm Difference for worker 1578 is 0.868806
INFO:root:FL Epoch: 408 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1261
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345191
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526811
INFO:root:FL Epoch: 408 Norm Difference for worker 1261 is 0.909962
INFO:root:FL Epoch: 408 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1657
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510081
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371272
INFO:root:FL Epoch: 408 Norm Difference for worker 1657 is 0.873254
INFO:root:FL Epoch: 408 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1701
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441824
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423023
INFO:root:FL Epoch: 408 Norm Difference for worker 1701 is 0.857933
INFO:root:FL Epoch: 408 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :168
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462174
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 168 is 0.931899
INFO:root:FL Epoch: 408 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1462
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452690
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343715
INFO:root:FL Epoch: 408 Norm Difference for worker 1462 is 0.822347
INFO:root:FL Epoch: 408 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1213
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1213 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727657
INFO:root:Worker: 1213 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470657
INFO:root:FL Epoch: 408 Norm Difference for worker 1213 is 0.841241
INFO:root:FL Epoch: 408 Done on worker:1213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1213
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.48257212428485646 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:2.3520979086558023                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [508, 889, 1784, 1811, 912, 236, 1941, 1504, 1116, 48]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :508
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386002
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409331
INFO:root:FL Epoch: 409 Norm Difference for worker 508 is 0.706992
INFO:root:FL Epoch: 409 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :889
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822855
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437423
INFO:root:FL Epoch: 409 Norm Difference for worker 889 is 0.766828
INFO:root:FL Epoch: 409 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1784
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461046
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614502
INFO:root:FL Epoch: 409 Norm Difference for worker 1784 is 0.888898
INFO:root:FL Epoch: 409 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1811
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407614
INFO:root:Worker: 1811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500090
INFO:root:FL Epoch: 409 Norm Difference for worker 1811 is 0.812276
INFO:root:FL Epoch: 409 Done on worker:1811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :912
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594477
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354503
INFO:root:FL Epoch: 409 Norm Difference for worker 912 is 0.714583
INFO:root:FL Epoch: 409 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :236
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729550
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 236 is 0.816035
INFO:root:FL Epoch: 409 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1941
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521456
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335119
INFO:root:FL Epoch: 409 Norm Difference for worker 1941 is 0.775547
INFO:root:FL Epoch: 409 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1504
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502242
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596235
INFO:root:FL Epoch: 409 Norm Difference for worker 1504 is 0.777728
INFO:root:FL Epoch: 409 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1116
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1116 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692273
INFO:root:Worker: 1116 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403645
INFO:root:FL Epoch: 409 Norm Difference for worker 1116 is 0.821575
INFO:root:FL Epoch: 409 Done on worker:1116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :48
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 48 is 0.759613
INFO:root:FL Epoch: 409 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 508
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.4736757234615438 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:2.528877337773641                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [1144, 1641, 1526, 510, 1002, 1752, 733, 1458, 990, 1924]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :1144
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589987
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404589
INFO:root:FL Epoch: 410 Norm Difference for worker 1144 is 0.826601
INFO:root:FL Epoch: 410 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1641
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507759
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498558
INFO:root:FL Epoch: 410 Norm Difference for worker 1641 is 1.28063
INFO:root:FL Epoch: 410 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1526
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588078
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390488
INFO:root:FL Epoch: 410 Norm Difference for worker 1526 is 0.888657
INFO:root:FL Epoch: 410 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :510
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667966
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382544
INFO:root:FL Epoch: 410 Norm Difference for worker 510 is 0.829971
INFO:root:FL Epoch: 410 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1002
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443893
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384099
INFO:root:FL Epoch: 410 Norm Difference for worker 1002 is 0.831819
INFO:root:FL Epoch: 410 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1752
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219818
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450105
INFO:root:FL Epoch: 410 Norm Difference for worker 1752 is 0.856155
INFO:root:FL Epoch: 410 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :733
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332990
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405655
INFO:root:FL Epoch: 410 Norm Difference for worker 733 is 0.803681
INFO:root:FL Epoch: 410 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1458
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384199
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525691
INFO:root:FL Epoch: 410 Norm Difference for worker 1458 is 0.783925
INFO:root:FL Epoch: 410 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :990
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586255
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.814658
INFO:root:FL Epoch: 410 Norm Difference for worker 990 is 1.117507
INFO:root:FL Epoch: 410 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1924
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561285
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468747
INFO:root:FL Epoch: 410 Norm Difference for worker 1924 is 0.81372
INFO:root:FL Epoch: 410 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1458
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.48045466401997733 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:2.1894107659657798                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [473, 871, 501, 320, 1221, 172, 1734, 1232, 1445, 662]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :473
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476657
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505880
INFO:root:FL Epoch: 411 Norm Difference for worker 473 is 0.777259
INFO:root:FL Epoch: 411 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :871
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.169620
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427094
INFO:root:FL Epoch: 411 Norm Difference for worker 871 is 0.734177
INFO:root:FL Epoch: 411 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :501
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464307
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604322
INFO:root:FL Epoch: 411 Norm Difference for worker 501 is 0.714794
INFO:root:FL Epoch: 411 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :320
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 320 is 0.753377
INFO:root:FL Epoch: 411 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1221
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565207
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562889
INFO:root:FL Epoch: 411 Norm Difference for worker 1221 is 0.754564
INFO:root:FL Epoch: 411 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :172
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.352534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 172 is 0.75084
INFO:root:FL Epoch: 411 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1734
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366898
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279029
INFO:root:FL Epoch: 411 Norm Difference for worker 1734 is 0.69113
INFO:root:FL Epoch: 411 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1232
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594022
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320871
INFO:root:FL Epoch: 411 Norm Difference for worker 1232 is 0.73706
INFO:root:FL Epoch: 411 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1445
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776655
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627586
INFO:root:FL Epoch: 411 Norm Difference for worker 1445 is 0.888998
INFO:root:FL Epoch: 411 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :662
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742157
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604674
INFO:root:FL Epoch: 411 Norm Difference for worker 662 is 0.721741
INFO:root:FL Epoch: 411 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1734
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.48378244831281547 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:2.443133314450582                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1462, 1758, 356, 342, 1500, 1463, 1849, 1403, 1560, 144]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 412 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1462
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491050
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356747
INFO:root:FL Epoch: 412 Norm Difference for worker 1462 is 0.820456
INFO:root:FL Epoch: 412 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1758
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538996
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363598
INFO:root:FL Epoch: 412 Norm Difference for worker 1758 is 0.838187
INFO:root:FL Epoch: 412 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :356
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601232
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300258
INFO:root:FL Epoch: 412 Norm Difference for worker 356 is 0.809662
INFO:root:FL Epoch: 412 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :342
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610002
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668017
INFO:root:FL Epoch: 412 Norm Difference for worker 342 is 0.996662
INFO:root:FL Epoch: 412 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1500
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896437
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431274
INFO:root:FL Epoch: 412 Norm Difference for worker 1500 is 0.912706
INFO:root:FL Epoch: 412 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1463
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619282
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621239
INFO:root:FL Epoch: 412 Norm Difference for worker 1463 is 0.955919
INFO:root:FL Epoch: 412 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1849
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341969
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436036
INFO:root:FL Epoch: 412 Norm Difference for worker 1849 is 0.784413
INFO:root:FL Epoch: 412 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1403
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521706
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631043
INFO:root:FL Epoch: 412 Norm Difference for worker 1403 is 0.937678
INFO:root:FL Epoch: 412 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1560
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437153
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405646
INFO:root:FL Epoch: 412 Norm Difference for worker 1560 is 0.872121
INFO:root:FL Epoch: 412 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :144
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 144 is 0.910887
INFO:root:FL Epoch: 412 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1849
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.4761395506999072 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:2.2843345403671265                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [458, 701, 47, 968, 1028, 873, 671, 1800, 898, 1690]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 413 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :458
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545961
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654973
INFO:root:FL Epoch: 413 Norm Difference for worker 458 is 0.849759
INFO:root:FL Epoch: 413 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :701
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567330
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434317
INFO:root:FL Epoch: 413 Norm Difference for worker 701 is 0.834303
INFO:root:FL Epoch: 413 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :47
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461229
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 47 is 0.820681
INFO:root:FL Epoch: 413 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :968
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380610
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422239
INFO:root:FL Epoch: 413 Norm Difference for worker 968 is 0.891096
INFO:root:FL Epoch: 413 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1028
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652511
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438174
INFO:root:FL Epoch: 413 Norm Difference for worker 1028 is 0.783803
INFO:root:FL Epoch: 413 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :873
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568278
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444834
INFO:root:FL Epoch: 413 Norm Difference for worker 873 is 1.01058
INFO:root:FL Epoch: 413 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :671
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370646
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429559
INFO:root:FL Epoch: 413 Norm Difference for worker 671 is 0.962158
INFO:root:FL Epoch: 413 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1800
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768117
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367269
INFO:root:FL Epoch: 413 Norm Difference for worker 1800 is 0.793941
INFO:root:FL Epoch: 413 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :898
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795317
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507052
INFO:root:FL Epoch: 413 Norm Difference for worker 898 is 0.868046
INFO:root:FL Epoch: 413 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1690
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405899
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495925
INFO:root:FL Epoch: 413 Norm Difference for worker 1690 is 0.842421
INFO:root:FL Epoch: 413 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1028
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.481256390319151 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:2.013912479082743                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [958, 917, 904, 1754, 1352, 584, 1737, 661, 983, 712]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :958
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579595
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.882231
INFO:root:FL Epoch: 414 Norm Difference for worker 958 is 0.798959
INFO:root:FL Epoch: 414 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :917
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485562
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378528
INFO:root:FL Epoch: 414 Norm Difference for worker 917 is 0.803491
INFO:root:FL Epoch: 414 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :904
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611965
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382769
INFO:root:FL Epoch: 414 Norm Difference for worker 904 is 0.667654
INFO:root:FL Epoch: 414 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1754
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885600
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644021
INFO:root:FL Epoch: 414 Norm Difference for worker 1754 is 0.725187
INFO:root:FL Epoch: 414 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1352
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596717
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640682
INFO:root:FL Epoch: 414 Norm Difference for worker 1352 is 0.800726
INFO:root:FL Epoch: 414 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :584
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308663
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389796
INFO:root:FL Epoch: 414 Norm Difference for worker 584 is 0.735458
INFO:root:FL Epoch: 414 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1737
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611351
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326361
INFO:root:FL Epoch: 414 Norm Difference for worker 1737 is 0.781055
INFO:root:FL Epoch: 414 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :661
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787982
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585174
INFO:root:FL Epoch: 414 Norm Difference for worker 661 is 0.727295
INFO:root:FL Epoch: 414 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :983
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755021
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671691
INFO:root:FL Epoch: 414 Norm Difference for worker 983 is 0.754711
INFO:root:FL Epoch: 414 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :712
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422507
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384674
INFO:root:FL Epoch: 414 Norm Difference for worker 712 is 0.771519
INFO:root:FL Epoch: 414 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 904
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.49788667699869943 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:1.6090556184450786                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [693, 1178, 1626, 1519, 496, 294, 945, 458, 1024, 906]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 415 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :693
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394630
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391522
INFO:root:FL Epoch: 415 Norm Difference for worker 693 is 0.763574
INFO:root:FL Epoch: 415 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1178
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451371
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440128
INFO:root:FL Epoch: 415 Norm Difference for worker 1178 is 0.693632
INFO:root:FL Epoch: 415 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1626
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687419
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549575
INFO:root:FL Epoch: 415 Norm Difference for worker 1626 is 0.754756
INFO:root:FL Epoch: 415 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1519
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596390
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490423
INFO:root:FL Epoch: 415 Norm Difference for worker 1519 is 0.655289
INFO:root:FL Epoch: 415 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :496
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473338
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536611
INFO:root:FL Epoch: 415 Norm Difference for worker 496 is 0.743493
INFO:root:FL Epoch: 415 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :294
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.801218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 294 is 0.77553
INFO:root:FL Epoch: 415 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :945
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568666
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255142
INFO:root:FL Epoch: 415 Norm Difference for worker 945 is 0.748343
INFO:root:FL Epoch: 415 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :458
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694585
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495361
INFO:root:FL Epoch: 415 Norm Difference for worker 458 is 0.771388
INFO:root:FL Epoch: 415 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1024
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658895
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605241
INFO:root:FL Epoch: 415 Norm Difference for worker 1024 is 0.673197
INFO:root:FL Epoch: 415 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :906
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464281
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622247
INFO:root:FL Epoch: 415 Norm Difference for worker 906 is 0.78843
INFO:root:FL Epoch: 415 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1024
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.49909848150085 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:1.5582791964213054                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [795, 1153, 28, 1418, 45, 615, 448, 1541, 319, 423]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 416 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :795
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584625
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355567
INFO:root:FL Epoch: 416 Norm Difference for worker 795 is 0.650456
INFO:root:FL Epoch: 416 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1153
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671534
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674539
INFO:root:FL Epoch: 416 Norm Difference for worker 1153 is 0.677859
INFO:root:FL Epoch: 416 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :28
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532713
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 28 is 0.597897
INFO:root:FL Epoch: 416 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1418
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544591
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438630
INFO:root:FL Epoch: 416 Norm Difference for worker 1418 is 0.620863
INFO:root:FL Epoch: 416 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :45
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515342
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 45 is 0.634884
INFO:root:FL Epoch: 416 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :615
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476409
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693198
INFO:root:FL Epoch: 416 Norm Difference for worker 615 is 0.641537
INFO:root:FL Epoch: 416 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :448
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373813
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326418
INFO:root:FL Epoch: 416 Norm Difference for worker 448 is 0.582374
INFO:root:FL Epoch: 416 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1541
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567167
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553624
INFO:root:FL Epoch: 416 Norm Difference for worker 1541 is 0.66969
INFO:root:FL Epoch: 416 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :319
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490017
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 319 is 0.62118
INFO:root:FL Epoch: 416 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :423
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476555
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463652
INFO:root:FL Epoch: 416 Norm Difference for worker 423 is 0.672304
INFO:root:FL Epoch: 416 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 448
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.491491461501402 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:1.7858462532361348                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1339, 327, 564, 662, 1584, 331, 1534, 717, 1510, 1557]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 417 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1339
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562617
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701022
INFO:root:FL Epoch: 417 Norm Difference for worker 1339 is 0.787777
INFO:root:FL Epoch: 417 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :327
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 327 is 0.738265
INFO:root:FL Epoch: 417 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :564
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734851
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391647
INFO:root:FL Epoch: 417 Norm Difference for worker 564 is 0.679112
INFO:root:FL Epoch: 417 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :662
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441102
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406712
INFO:root:FL Epoch: 417 Norm Difference for worker 662 is 0.695908
INFO:root:FL Epoch: 417 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1584
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426933
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730590
INFO:root:FL Epoch: 417 Norm Difference for worker 1584 is 0.798786
INFO:root:FL Epoch: 417 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :331
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689993
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 331 is 0.711735
INFO:root:FL Epoch: 417 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1534
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576178
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311037
INFO:root:FL Epoch: 417 Norm Difference for worker 1534 is 0.718058
INFO:root:FL Epoch: 417 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :717
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799983
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371380
INFO:root:FL Epoch: 417 Norm Difference for worker 717 is 0.665519
INFO:root:FL Epoch: 417 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1510
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505805
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655719
INFO:root:FL Epoch: 417 Norm Difference for worker 1510 is 0.740707
INFO:root:FL Epoch: 417 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1557
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315402
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458066
INFO:root:FL Epoch: 417 Norm Difference for worker 1557 is 0.653174
INFO:root:FL Epoch: 417 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.4892827833400053 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:2.2287195920944214                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [725, 1930, 264, 1432, 1116, 1221, 632, 1900, 1107, 1893]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :725
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438708
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350860
INFO:root:FL Epoch: 418 Norm Difference for worker 725 is 0.922257
INFO:root:FL Epoch: 418 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1930
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.868405
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443310
INFO:root:FL Epoch: 418 Norm Difference for worker 1930 is 0.862828
INFO:root:FL Epoch: 418 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :264
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 264 is 0.945834
INFO:root:FL Epoch: 418 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1432
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382891
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495520
INFO:root:FL Epoch: 418 Norm Difference for worker 1432 is 0.983851
INFO:root:FL Epoch: 418 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1116
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1116 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649116
INFO:root:Worker: 1116 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447989
INFO:root:FL Epoch: 418 Norm Difference for worker 1116 is 0.98537
INFO:root:FL Epoch: 418 Done on worker:1116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1221
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462884
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595909
INFO:root:FL Epoch: 418 Norm Difference for worker 1221 is 0.881198
INFO:root:FL Epoch: 418 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :632
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630498
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399267
INFO:root:FL Epoch: 418 Norm Difference for worker 632 is 0.821824
INFO:root:FL Epoch: 418 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1900
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362472
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574197
INFO:root:FL Epoch: 418 Norm Difference for worker 1900 is 0.869822
INFO:root:FL Epoch: 418 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1107
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612046
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430770
INFO:root:FL Epoch: 418 Norm Difference for worker 1107 is 0.852555
INFO:root:FL Epoch: 418 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1893
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396683
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533150
INFO:root:FL Epoch: 418 Norm Difference for worker 1893 is 0.926325
INFO:root:FL Epoch: 418 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 632
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.49805805788320656 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:1.9865976373354595                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [688, 717, 85, 1544, 170, 279, 777, 1409, 213, 1063]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 201 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :688
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813281
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535024
INFO:root:FL Epoch: 419 Norm Difference for worker 688 is 0.846431
INFO:root:FL Epoch: 419 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :717
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252527
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518073
INFO:root:FL Epoch: 419 Norm Difference for worker 717 is 0.775347
INFO:root:FL Epoch: 419 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :85
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 85 is 0.896015
INFO:root:FL Epoch: 419 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1544
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539681
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487174
INFO:root:FL Epoch: 419 Norm Difference for worker 1544 is 0.884892
INFO:root:FL Epoch: 419 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :170
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698761
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 170 is 0.742078
INFO:root:FL Epoch: 419 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :279
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440797
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 279 is 0.72105
INFO:root:FL Epoch: 419 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :777
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725380
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299039
INFO:root:FL Epoch: 419 Norm Difference for worker 777 is 0.80249
INFO:root:FL Epoch: 419 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1409
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548207
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701335
INFO:root:FL Epoch: 419 Norm Difference for worker 1409 is 0.782326
INFO:root:FL Epoch: 419 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :213
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652392
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 213 is 0.855573
INFO:root:FL Epoch: 419 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1063
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493802
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479839
INFO:root:FL Epoch: 419 Norm Difference for worker 1063 is 0.83183
INFO:root:FL Epoch: 419 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 717
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.5268405746011173 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:2.0061293244361877                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [838, 625, 1737, 1136, 713, 789, 1211, 1594, 1202, 335]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 420 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :838
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841345
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471764
INFO:root:FL Epoch: 420 Norm Difference for worker 838 is 0.683349
INFO:root:FL Epoch: 420 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :625
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559765
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597035
INFO:root:FL Epoch: 420 Norm Difference for worker 625 is 0.682105
INFO:root:FL Epoch: 420 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1737
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470205
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560727
INFO:root:FL Epoch: 420 Norm Difference for worker 1737 is 0.7327
INFO:root:FL Epoch: 420 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1136
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495408
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487955
INFO:root:FL Epoch: 420 Norm Difference for worker 1136 is 0.729153
INFO:root:FL Epoch: 420 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :713
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595318
INFO:root:Worker: 713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431726
INFO:root:FL Epoch: 420 Norm Difference for worker 713 is 0.730954
INFO:root:FL Epoch: 420 Done on worker:713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :789
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260340
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510258
INFO:root:FL Epoch: 420 Norm Difference for worker 789 is 0.673648
INFO:root:FL Epoch: 420 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1211
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1211 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445705
INFO:root:Worker: 1211 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565518
INFO:root:FL Epoch: 420 Norm Difference for worker 1211 is 0.676725
INFO:root:FL Epoch: 420 Done on worker:1211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1594
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493936
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459412
INFO:root:FL Epoch: 420 Norm Difference for worker 1594 is 0.613036
INFO:root:FL Epoch: 420 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1202
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491156
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678485
INFO:root:FL Epoch: 420 Norm Difference for worker 1202 is 0.660765
INFO:root:FL Epoch: 420 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :335
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626105
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 335 is 0.718748
INFO:root:FL Epoch: 420 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.507500864127103 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:2.071280539035797                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [92, 277, 841, 8, 1604, 1232, 156, 1579, 1933, 870]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 421 Num points on workers: [201 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :92
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 92 is 0.776335
INFO:root:FL Epoch: 421 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :277
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.761042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 277 is 0.696458
INFO:root:FL Epoch: 421 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :841
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533537
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483797
INFO:root:FL Epoch: 421 Norm Difference for worker 841 is 0.726422
INFO:root:FL Epoch: 421 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :8
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 8 is 0.671198
INFO:root:FL Epoch: 421 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1604
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305709
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449877
INFO:root:FL Epoch: 421 Norm Difference for worker 1604 is 0.734723
INFO:root:FL Epoch: 421 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1232
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642955
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449545
INFO:root:FL Epoch: 421 Norm Difference for worker 1232 is 0.687661
INFO:root:FL Epoch: 421 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :156
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 156 is 0.754763
INFO:root:FL Epoch: 421 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1579
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758360
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300976
INFO:root:FL Epoch: 421 Norm Difference for worker 1579 is 0.694549
INFO:root:FL Epoch: 421 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1933
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339962
INFO:root:Worker: 1933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725678
INFO:root:FL Epoch: 421 Norm Difference for worker 1933 is 0.707395
INFO:root:FL Epoch: 421 Done on worker:1933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :870
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573463
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626199
INFO:root:FL Epoch: 421 Norm Difference for worker 870 is 0.741151
INFO:root:FL Epoch: 421 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.5096830743200639 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:1.8446720838546753                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [813, 725, 1510, 1152, 1854, 743, 1200, 1675, 1244, 1431]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 422 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :813
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340374
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432513
INFO:root:FL Epoch: 422 Norm Difference for worker 813 is 0.779704
INFO:root:FL Epoch: 422 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :725
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666305
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393520
INFO:root:FL Epoch: 422 Norm Difference for worker 725 is 0.830382
INFO:root:FL Epoch: 422 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1510
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503254
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431494
INFO:root:FL Epoch: 422 Norm Difference for worker 1510 is 0.777848
INFO:root:FL Epoch: 422 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1152
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607513
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492256
INFO:root:FL Epoch: 422 Norm Difference for worker 1152 is 0.865157
INFO:root:FL Epoch: 422 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1854
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401176
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618392
INFO:root:FL Epoch: 422 Norm Difference for worker 1854 is 0.872144
INFO:root:FL Epoch: 422 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :743
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504547
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328123
INFO:root:FL Epoch: 422 Norm Difference for worker 743 is 0.75571
INFO:root:FL Epoch: 422 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1200
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293872
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515646
INFO:root:FL Epoch: 422 Norm Difference for worker 1200 is 0.779549
INFO:root:FL Epoch: 422 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1675
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291962
INFO:root:Worker: 1675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189150
INFO:root:FL Epoch: 422 Norm Difference for worker 1675 is 0.732742
INFO:root:FL Epoch: 422 Done on worker:1675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1244
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624075
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395958
INFO:root:FL Epoch: 422 Norm Difference for worker 1244 is 0.743163
INFO:root:FL Epoch: 422 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1431
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326356
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361991
INFO:root:FL Epoch: 422 Norm Difference for worker 1431 is 0.699587
INFO:root:FL Epoch: 422 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1431
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.5213941020124099 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:2.481534242630005                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [56, 107, 1920, 505, 1640, 829, 730, 1087, 252, 1568]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 423 Num points on workers: [201 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :56
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 56 is 0.857988
INFO:root:FL Epoch: 423 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :107
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.804563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 107 is 0.790328
INFO:root:FL Epoch: 423 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1920
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714151
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674951
INFO:root:FL Epoch: 423 Norm Difference for worker 1920 is 0.837014
INFO:root:FL Epoch: 423 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :505
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477130
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517298
INFO:root:FL Epoch: 423 Norm Difference for worker 505 is 0.839539
INFO:root:FL Epoch: 423 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1640
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704802
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599437
INFO:root:FL Epoch: 423 Norm Difference for worker 1640 is 0.79802
INFO:root:FL Epoch: 423 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :829
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778219
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759711
INFO:root:FL Epoch: 423 Norm Difference for worker 829 is 0.900006
INFO:root:FL Epoch: 423 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :730
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435870
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384087
INFO:root:FL Epoch: 423 Norm Difference for worker 730 is 0.799297
INFO:root:FL Epoch: 423 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1087
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612972
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489969
INFO:root:FL Epoch: 423 Norm Difference for worker 1087 is 0.787784
INFO:root:FL Epoch: 423 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :252
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581980
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 252 is 0.82595
INFO:root:FL Epoch: 423 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1568
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646362
INFO:root:Worker: 1568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562370
INFO:root:FL Epoch: 423 Norm Difference for worker 1568 is 0.814455
INFO:root:FL Epoch: 423 Done on worker:1568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 107
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.512731160311138 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:1.903286079565684                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [718, 362, 222, 1111, 1052, 306, 1346, 73, 404, 1233]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :718
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593105
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437124
INFO:root:FL Epoch: 424 Norm Difference for worker 718 is 0.73938
INFO:root:FL Epoch: 424 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :362
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295656
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419300
INFO:root:FL Epoch: 424 Norm Difference for worker 362 is 0.782693
INFO:root:FL Epoch: 424 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :222
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 222 is 0.709085
INFO:root:FL Epoch: 424 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1111
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476075
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311437
INFO:root:FL Epoch: 424 Norm Difference for worker 1111 is 0.704225
INFO:root:FL Epoch: 424 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1052
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406336
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363349
INFO:root:FL Epoch: 424 Norm Difference for worker 1052 is 0.673866
INFO:root:FL Epoch: 424 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :306
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 306 is 0.72498
INFO:root:FL Epoch: 424 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1346
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634086
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451669
INFO:root:FL Epoch: 424 Norm Difference for worker 1346 is 0.675851
INFO:root:FL Epoch: 424 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :73
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.933697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 73 is 0.821345
INFO:root:FL Epoch: 424 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :404
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341151
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661188
INFO:root:FL Epoch: 424 Norm Difference for worker 404 is 0.742361
INFO:root:FL Epoch: 424 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1233
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680971
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602619
INFO:root:FL Epoch: 424 Norm Difference for worker 1233 is 0.818087
INFO:root:FL Epoch: 424 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.5168044391800376 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:2.246416370073954                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [354, 1295, 1711, 1931, 1635, 1104, 1248, 226, 1462, 1023]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 425 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :354
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403091
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571027
INFO:root:FL Epoch: 425 Norm Difference for worker 354 is 0.812807
INFO:root:FL Epoch: 425 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1295
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483523
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147641
INFO:root:FL Epoch: 425 Norm Difference for worker 1295 is 0.665849
INFO:root:FL Epoch: 425 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1711
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694243
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299362
INFO:root:FL Epoch: 425 Norm Difference for worker 1711 is 0.791819
INFO:root:FL Epoch: 425 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1931
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667955
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589297
INFO:root:FL Epoch: 425 Norm Difference for worker 1931 is 0.822944
INFO:root:FL Epoch: 425 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1635
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551901
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408440
INFO:root:FL Epoch: 425 Norm Difference for worker 1635 is 0.755999
INFO:root:FL Epoch: 425 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1104
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597756
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492751
INFO:root:FL Epoch: 425 Norm Difference for worker 1104 is 0.868697
INFO:root:FL Epoch: 425 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1248
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366269
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501028
INFO:root:FL Epoch: 425 Norm Difference for worker 1248 is 0.850341
INFO:root:FL Epoch: 425 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :226
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523026
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 226 is 0.88105
INFO:root:FL Epoch: 425 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1462
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355210
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355424
INFO:root:FL Epoch: 425 Norm Difference for worker 1462 is 0.796787
INFO:root:FL Epoch: 425 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1023
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496604
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526509
INFO:root:FL Epoch: 425 Norm Difference for worker 1023 is 0.78251
INFO:root:FL Epoch: 425 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.5239485563600764 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:2.376634160677592                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [541, 301, 1747, 1242, 641, 1776, 1297, 359, 1763, 587]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 426 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :541
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900529
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233333
INFO:root:FL Epoch: 426 Norm Difference for worker 541 is 0.840788
INFO:root:FL Epoch: 426 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :301
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.420732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 301 is 0.853271
INFO:root:FL Epoch: 426 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1747
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366041
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628523
INFO:root:FL Epoch: 426 Norm Difference for worker 1747 is 0.984687
INFO:root:FL Epoch: 426 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1242
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763771
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451690
INFO:root:FL Epoch: 426 Norm Difference for worker 1242 is 0.890646
INFO:root:FL Epoch: 426 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :641
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841407
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467552
INFO:root:FL Epoch: 426 Norm Difference for worker 641 is 0.962241
INFO:root:FL Epoch: 426 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1776
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601581
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436748
INFO:root:FL Epoch: 426 Norm Difference for worker 1776 is 0.864591
INFO:root:FL Epoch: 426 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1297
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770111
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357313
INFO:root:FL Epoch: 426 Norm Difference for worker 1297 is 0.952084
INFO:root:FL Epoch: 426 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :359
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536421
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286581
INFO:root:FL Epoch: 426 Norm Difference for worker 359 is 0.784357
INFO:root:FL Epoch: 426 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1763
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872938
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450628
INFO:root:FL Epoch: 426 Norm Difference for worker 1763 is 0.86255
INFO:root:FL Epoch: 426 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :587
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930944
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521247
INFO:root:FL Epoch: 426 Norm Difference for worker 587 is 0.947077
INFO:root:FL Epoch: 426 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 359
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.5151747640441445 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:2.026267170906067                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [1596, 1762, 1202, 383, 334, 1278, 1695, 1531, 1478, 1369]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :1596
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502484
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447310
INFO:root:FL Epoch: 427 Norm Difference for worker 1596 is 0.852203
INFO:root:FL Epoch: 427 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1762
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394735
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653260
INFO:root:FL Epoch: 427 Norm Difference for worker 1762 is 0.797842
INFO:root:FL Epoch: 427 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1202
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361411
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474779
INFO:root:FL Epoch: 427 Norm Difference for worker 1202 is 0.861919
INFO:root:FL Epoch: 427 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :383
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557407
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259318
INFO:root:FL Epoch: 427 Norm Difference for worker 383 is 0.867688
INFO:root:FL Epoch: 427 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :334
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467103
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 334 is 0.782876
INFO:root:FL Epoch: 427 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1278
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364491
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365392
INFO:root:FL Epoch: 427 Norm Difference for worker 1278 is 0.751544
INFO:root:FL Epoch: 427 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1695
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646418
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575494
INFO:root:FL Epoch: 427 Norm Difference for worker 1695 is 0.892969
INFO:root:FL Epoch: 427 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1531
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378942
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519028
INFO:root:FL Epoch: 427 Norm Difference for worker 1531 is 0.83676
INFO:root:FL Epoch: 427 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1478
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597928
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292864
INFO:root:FL Epoch: 427 Norm Difference for worker 1478 is 0.776024
INFO:root:FL Epoch: 427 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1369
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728087
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529461
INFO:root:FL Epoch: 427 Norm Difference for worker 1369 is 0.873548
INFO:root:FL Epoch: 427 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.5291537432109609 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:2.1920785506566367                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [168, 1521, 1532, 891, 1036, 344, 1475, 700, 1591, 915]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 428 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :168
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519003
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 168 is 0.911525
INFO:root:FL Epoch: 428 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1521
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727236
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424132
INFO:root:FL Epoch: 428 Norm Difference for worker 1521 is 0.831131
INFO:root:FL Epoch: 428 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1532
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814055
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737486
INFO:root:FL Epoch: 428 Norm Difference for worker 1532 is 0.859749
INFO:root:FL Epoch: 428 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :891
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720679
INFO:root:Worker: 891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416413
INFO:root:FL Epoch: 428 Norm Difference for worker 891 is 0.913162
INFO:root:FL Epoch: 428 Done on worker:891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1036
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373225
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451917
INFO:root:FL Epoch: 428 Norm Difference for worker 1036 is 0.952788
INFO:root:FL Epoch: 428 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :344
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468024
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393032
INFO:root:FL Epoch: 428 Norm Difference for worker 344 is 0.960002
INFO:root:FL Epoch: 428 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1475
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521788
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417491
INFO:root:FL Epoch: 428 Norm Difference for worker 1475 is 0.846024
INFO:root:FL Epoch: 428 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :700
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641644
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337392
INFO:root:FL Epoch: 428 Norm Difference for worker 700 is 0.862442
INFO:root:FL Epoch: 428 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1591
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358397
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270849
INFO:root:FL Epoch: 428 Norm Difference for worker 1591 is 0.806698
INFO:root:FL Epoch: 428 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :915
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501689
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370416
INFO:root:FL Epoch: 428 Norm Difference for worker 915 is 0.915705
INFO:root:FL Epoch: 428 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1591
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.5159449016346651 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:1.8798398971557617                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [911, 867, 484, 366, 656, 907, 1116, 943, 1350, 1853]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :911
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611539
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314325
INFO:root:FL Epoch: 429 Norm Difference for worker 911 is 0.86017
INFO:root:FL Epoch: 429 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :867
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434368
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443065
INFO:root:FL Epoch: 429 Norm Difference for worker 867 is 0.814316
INFO:root:FL Epoch: 429 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :484
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603053
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512782
INFO:root:FL Epoch: 429 Norm Difference for worker 484 is 0.82472
INFO:root:FL Epoch: 429 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :366
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540400
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423820
INFO:root:FL Epoch: 429 Norm Difference for worker 366 is 0.805361
INFO:root:FL Epoch: 429 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :656
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754596
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576274
INFO:root:FL Epoch: 429 Norm Difference for worker 656 is 0.854266
INFO:root:FL Epoch: 429 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :907
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567712
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323405
INFO:root:FL Epoch: 429 Norm Difference for worker 907 is 0.787153
INFO:root:FL Epoch: 429 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1116
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1116 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498560
INFO:root:Worker: 1116 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447827
INFO:root:FL Epoch: 429 Norm Difference for worker 1116 is 0.89297
INFO:root:FL Epoch: 429 Done on worker:1116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :943
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537435
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507263
INFO:root:FL Epoch: 429 Norm Difference for worker 943 is 0.842371
INFO:root:FL Epoch: 429 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1350
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495724
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373020
INFO:root:FL Epoch: 429 Norm Difference for worker 1350 is 0.819702
INFO:root:FL Epoch: 429 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1853
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844623
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429481
INFO:root:FL Epoch: 429 Norm Difference for worker 1853 is 0.908156
INFO:root:FL Epoch: 429 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 366
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.5030558056691113 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:1.588518460591634                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [1626, 88, 452, 1916, 1402, 353, 151, 1132, 932, 1593]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 430 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :1626
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367564
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498944
INFO:root:FL Epoch: 430 Norm Difference for worker 1626 is 0.759794
INFO:root:FL Epoch: 430 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :88
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505097
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451860
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 88 is 0.696444
INFO:root:FL Epoch: 430 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :452
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583460
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485373
INFO:root:FL Epoch: 430 Norm Difference for worker 452 is 0.730568
INFO:root:FL Epoch: 430 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1916
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513412
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605929
INFO:root:FL Epoch: 430 Norm Difference for worker 1916 is 0.751546
INFO:root:FL Epoch: 430 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1402
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345412
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361574
INFO:root:FL Epoch: 430 Norm Difference for worker 1402 is 0.752699
INFO:root:FL Epoch: 430 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :353
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624807
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325379
INFO:root:FL Epoch: 430 Norm Difference for worker 353 is 0.736608
INFO:root:FL Epoch: 430 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :151
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602143
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 151 is 0.727533
INFO:root:FL Epoch: 430 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1132
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376062
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330761
INFO:root:FL Epoch: 430 Norm Difference for worker 1132 is 0.656985
INFO:root:FL Epoch: 430 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :932
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381073
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415334
INFO:root:FL Epoch: 430 Norm Difference for worker 932 is 0.67175
INFO:root:FL Epoch: 430 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1593
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513421
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455120
INFO:root:FL Epoch: 430 Norm Difference for worker 1593 is 0.643908
INFO:root:FL Epoch: 430 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.5291357373490053 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:2.117935280005137                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [1143, 234, 297, 1059, 1676, 1700, 819, 1636, 1368, 261]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 431 Num points on workers: [200 201 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :1143
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744721
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443173
INFO:root:FL Epoch: 431 Norm Difference for worker 1143 is 0.790702
INFO:root:FL Epoch: 431 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :234
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600807
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 234 is 0.830251
INFO:root:FL Epoch: 431 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :297
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 297 is 0.754607
INFO:root:FL Epoch: 431 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1059
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432931
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337929
INFO:root:FL Epoch: 431 Norm Difference for worker 1059 is 0.750984
INFO:root:FL Epoch: 431 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1676
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724418
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360621
INFO:root:FL Epoch: 431 Norm Difference for worker 1676 is 0.783549
INFO:root:FL Epoch: 431 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1700
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646246
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394775
INFO:root:FL Epoch: 431 Norm Difference for worker 1700 is 0.737433
INFO:root:FL Epoch: 431 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :819
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503799
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402790
INFO:root:FL Epoch: 431 Norm Difference for worker 819 is 0.728143
INFO:root:FL Epoch: 431 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1636
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519548
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497770
INFO:root:FL Epoch: 431 Norm Difference for worker 1636 is 0.86206
INFO:root:FL Epoch: 431 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1368
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330258
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317347
INFO:root:FL Epoch: 431 Norm Difference for worker 1368 is 0.735412
INFO:root:FL Epoch: 431 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :261
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 261 is 0.78081
INFO:root:FL Epoch: 431 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1368
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.5161479360917035 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:2.0284676750501                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1603, 1834, 969, 1178, 766, 602, 1411, 257, 272, 33]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 432 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1603
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615380
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232039
INFO:root:FL Epoch: 432 Norm Difference for worker 1603 is 0.689195
INFO:root:FL Epoch: 432 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1834
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562721
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469107
INFO:root:FL Epoch: 432 Norm Difference for worker 1834 is 0.817264
INFO:root:FL Epoch: 432 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :969
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480415
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378696
INFO:root:FL Epoch: 432 Norm Difference for worker 969 is 0.733787
INFO:root:FL Epoch: 432 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1178
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396648
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400622
INFO:root:FL Epoch: 432 Norm Difference for worker 1178 is 0.795569
INFO:root:FL Epoch: 432 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :766
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458767
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381216
INFO:root:FL Epoch: 432 Norm Difference for worker 766 is 0.779929
INFO:root:FL Epoch: 432 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :602
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597906
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480546
INFO:root:FL Epoch: 432 Norm Difference for worker 602 is 0.809388
INFO:root:FL Epoch: 432 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1411
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444079
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544711
INFO:root:FL Epoch: 432 Norm Difference for worker 1411 is 0.810997
INFO:root:FL Epoch: 432 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :257
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 257 is 0.844892
INFO:root:FL Epoch: 432 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :272
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.238520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 272 is 0.666987
INFO:root:FL Epoch: 432 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :33
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711829
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 33 is 0.882498
INFO:root:FL Epoch: 432 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.5455182580386891 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:2.424514333407084                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [592, 79, 1470, 1812, 1471, 719, 588, 1106, 1084, 570]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 433 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :592
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419180
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524635
INFO:root:FL Epoch: 433 Norm Difference for worker 592 is 0.9211
INFO:root:FL Epoch: 433 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :79
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 79 is 0.85614
INFO:root:FL Epoch: 433 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1470
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490882
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373107
INFO:root:FL Epoch: 433 Norm Difference for worker 1470 is 0.865991
INFO:root:FL Epoch: 433 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1812
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356751
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348648
INFO:root:FL Epoch: 433 Norm Difference for worker 1812 is 0.947161
INFO:root:FL Epoch: 433 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1471
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505495
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319181
INFO:root:FL Epoch: 433 Norm Difference for worker 1471 is 0.914073
INFO:root:FL Epoch: 433 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :719
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563841
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397107
INFO:root:FL Epoch: 433 Norm Difference for worker 719 is 0.96668
INFO:root:FL Epoch: 433 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :588
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626818
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416213
INFO:root:FL Epoch: 433 Norm Difference for worker 588 is 0.933339
INFO:root:FL Epoch: 433 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1106
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554322
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426978
INFO:root:FL Epoch: 433 Norm Difference for worker 1106 is 0.816924
INFO:root:FL Epoch: 433 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1084
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341859
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413523
INFO:root:FL Epoch: 433 Norm Difference for worker 1084 is 0.874586
INFO:root:FL Epoch: 433 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :570
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616349
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.174450
INFO:root:FL Epoch: 433 Norm Difference for worker 570 is 0.775943
INFO:root:FL Epoch: 433 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.5090350894366994 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:2.046768287817637                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1463, 382, 171, 386, 120, 1791, 1601, 627, 1217, 1337]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1463
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614554
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576168
INFO:root:FL Epoch: 434 Norm Difference for worker 1463 is 0.94873
INFO:root:FL Epoch: 434 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :382
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454763
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502304
INFO:root:FL Epoch: 434 Norm Difference for worker 382 is 0.861671
INFO:root:FL Epoch: 434 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :171
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.778826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 171 is 0.878711
INFO:root:FL Epoch: 434 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :386
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591964
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353292
INFO:root:FL Epoch: 434 Norm Difference for worker 386 is 0.786318
INFO:root:FL Epoch: 434 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :120
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 120 is 0.883103
INFO:root:FL Epoch: 434 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1791
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438727
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672039
INFO:root:FL Epoch: 434 Norm Difference for worker 1791 is 0.95009
INFO:root:FL Epoch: 434 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1601
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447920
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387350
INFO:root:FL Epoch: 434 Norm Difference for worker 1601 is 0.711012
INFO:root:FL Epoch: 434 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :627
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721870
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557262
INFO:root:FL Epoch: 434 Norm Difference for worker 627 is 0.837702
INFO:root:FL Epoch: 434 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1217
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530871
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463085
INFO:root:FL Epoch: 434 Norm Difference for worker 1217 is 0.90797
INFO:root:FL Epoch: 434 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1337
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568016
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510994
INFO:root:FL Epoch: 434 Norm Difference for worker 1337 is 0.786362
INFO:root:FL Epoch: 434 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1601
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.5027815068469328 and Test Accuracy:75.0 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:2.373328526814779                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [16, 919, 1363, 1254, 548, 1776, 536, 893, 1787, 531]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 435 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :16
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364887
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 16 is 0.853979
INFO:root:FL Epoch: 435 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :919
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517230
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603344
INFO:root:FL Epoch: 435 Norm Difference for worker 919 is 0.922691
INFO:root:FL Epoch: 435 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1363
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502841
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351540
INFO:root:FL Epoch: 435 Norm Difference for worker 1363 is 0.884705
INFO:root:FL Epoch: 435 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1254
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565574
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482663
INFO:root:FL Epoch: 435 Norm Difference for worker 1254 is 0.807145
INFO:root:FL Epoch: 435 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :548
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605756
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436078
INFO:root:FL Epoch: 435 Norm Difference for worker 548 is 0.847827
INFO:root:FL Epoch: 435 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1776
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543727
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631981
INFO:root:FL Epoch: 435 Norm Difference for worker 1776 is 0.823659
INFO:root:FL Epoch: 435 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :536
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424321
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332328
INFO:root:FL Epoch: 435 Norm Difference for worker 536 is 0.856589
INFO:root:FL Epoch: 435 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :893
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452307
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323812
INFO:root:FL Epoch: 435 Norm Difference for worker 893 is 0.827187
INFO:root:FL Epoch: 435 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1787
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416942
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398628
INFO:root:FL Epoch: 435 Norm Difference for worker 1787 is 0.780128
INFO:root:FL Epoch: 435 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :531
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418090
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285273
INFO:root:FL Epoch: 435 Norm Difference for worker 531 is 0.896529
INFO:root:FL Epoch: 435 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1787
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.4945416774819879 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:2.3729223012924194                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1576, 1187, 284, 1355, 1562, 339, 223, 1434, 1163, 544]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 436 Num points on workers: [200 200 201 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1576
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517982
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678018
INFO:root:FL Epoch: 436 Norm Difference for worker 1576 is 0.828085
INFO:root:FL Epoch: 436 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1187
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521215
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.857042
INFO:root:FL Epoch: 436 Norm Difference for worker 1187 is 0.821513
INFO:root:FL Epoch: 436 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :284
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496171
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 284 is 0.933518
INFO:root:FL Epoch: 436 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1355
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449975
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504875
INFO:root:FL Epoch: 436 Norm Difference for worker 1355 is 0.962941
INFO:root:FL Epoch: 436 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1562
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603155
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553883
INFO:root:FL Epoch: 436 Norm Difference for worker 1562 is 0.85385
INFO:root:FL Epoch: 436 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :339
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 339 is 0.901681
INFO:root:FL Epoch: 436 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :223
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542088
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 223 is 0.916246
INFO:root:FL Epoch: 436 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1434
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424499
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690499
INFO:root:FL Epoch: 436 Norm Difference for worker 1434 is 0.936823
INFO:root:FL Epoch: 436 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1163
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624934
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388348
INFO:root:FL Epoch: 436 Norm Difference for worker 1163 is 0.89714
INFO:root:FL Epoch: 436 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :544
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730067
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224334
INFO:root:FL Epoch: 436 Norm Difference for worker 544 is 0.864797
INFO:root:FL Epoch: 436 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1187
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.5209780624684166 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:2.623177091280619                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [1503, 1500, 1540, 55, 34, 494, 1389, 1226, 777, 1885]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 437 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :1503
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535215
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366324
INFO:root:FL Epoch: 437 Norm Difference for worker 1503 is 0.808932
INFO:root:FL Epoch: 437 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1500
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452384
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624657
INFO:root:FL Epoch: 437 Norm Difference for worker 1500 is 0.850136
INFO:root:FL Epoch: 437 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1540
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446427
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538020
INFO:root:FL Epoch: 437 Norm Difference for worker 1540 is 0.928006
INFO:root:FL Epoch: 437 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :55
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397915
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 55 is 0.735045
INFO:root:FL Epoch: 437 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :34
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 34 is 0.801849
INFO:root:FL Epoch: 437 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :494
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636390
INFO:root:Worker: 494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352294
INFO:root:FL Epoch: 437 Norm Difference for worker 494 is 0.765044
INFO:root:FL Epoch: 437 Done on worker:494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1389
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493594
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444391
INFO:root:FL Epoch: 437 Norm Difference for worker 1389 is 0.84437
INFO:root:FL Epoch: 437 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1226
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449121
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362708
INFO:root:FL Epoch: 437 Norm Difference for worker 1226 is 0.735268
INFO:root:FL Epoch: 437 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :777
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545201
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503617
INFO:root:FL Epoch: 437 Norm Difference for worker 777 is 0.859596
INFO:root:FL Epoch: 437 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1885
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415544
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.806981
INFO:root:FL Epoch: 437 Norm Difference for worker 1885 is 0.721492
INFO:root:FL Epoch: 437 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1885
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.5011142974390703 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:2.3032206296920776                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [1006, 97, 735, 196, 505, 1393, 1255, 773, 1426, 1288]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 438 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :1006
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395382
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484256
INFO:root:FL Epoch: 438 Norm Difference for worker 1006 is 0.780518
INFO:root:FL Epoch: 438 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :97
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 97 is 0.746229
INFO:root:FL Epoch: 438 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :735
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417592
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480678
INFO:root:FL Epoch: 438 Norm Difference for worker 735 is 0.752735
INFO:root:FL Epoch: 438 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :196
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 196 is 0.717385
INFO:root:FL Epoch: 438 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :505
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509147
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497588
INFO:root:FL Epoch: 438 Norm Difference for worker 505 is 0.721177
INFO:root:FL Epoch: 438 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1393
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570686
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386343
INFO:root:FL Epoch: 438 Norm Difference for worker 1393 is 0.774559
INFO:root:FL Epoch: 438 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1255
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543632
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524461
INFO:root:FL Epoch: 438 Norm Difference for worker 1255 is 0.762937
INFO:root:FL Epoch: 438 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :773
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515273
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307863
INFO:root:FL Epoch: 438 Norm Difference for worker 773 is 0.716958
INFO:root:FL Epoch: 438 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1426
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385679
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474505
INFO:root:FL Epoch: 438 Norm Difference for worker 1426 is 0.75663
INFO:root:FL Epoch: 438 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1288
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1288 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387740
INFO:root:Worker: 1288 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419862
INFO:root:FL Epoch: 438 Norm Difference for worker 1288 is 0.710597
INFO:root:FL Epoch: 438 Done on worker:1288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1288
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.49875766915433545 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:1.9836491743723552                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1429, 1179, 135, 620, 745, 869, 1739, 870, 493, 1407]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1429
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398896
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553241
INFO:root:FL Epoch: 439 Norm Difference for worker 1429 is 0.77651
INFO:root:FL Epoch: 439 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1179
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258111
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231946
INFO:root:FL Epoch: 439 Norm Difference for worker 1179 is 0.750451
INFO:root:FL Epoch: 439 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :135
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 135 is 0.748241
INFO:root:FL Epoch: 439 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :620
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283732
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227739
INFO:root:FL Epoch: 439 Norm Difference for worker 620 is 0.72389
INFO:root:FL Epoch: 439 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :745
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446509
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408476
INFO:root:FL Epoch: 439 Norm Difference for worker 745 is 0.83607
INFO:root:FL Epoch: 439 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :869
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397861
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486164
INFO:root:FL Epoch: 439 Norm Difference for worker 869 is 0.82564
INFO:root:FL Epoch: 439 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1739
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706788
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379868
INFO:root:FL Epoch: 439 Norm Difference for worker 1739 is 0.778483
INFO:root:FL Epoch: 439 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :870
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651595
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540109
INFO:root:FL Epoch: 439 Norm Difference for worker 870 is 0.872791
INFO:root:FL Epoch: 439 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :493
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412762
INFO:root:Worker: 493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533782
INFO:root:FL Epoch: 439 Norm Difference for worker 493 is 0.885148
INFO:root:FL Epoch: 439 Done on worker:493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1407
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475148
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526522
INFO:root:FL Epoch: 439 Norm Difference for worker 1407 is 0.781878
INFO:root:FL Epoch: 439 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1739
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.5127325916991514 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:2.462843100229899                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1320, 695, 213, 1645, 1093, 1696, 465, 986, 139, 978]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1320
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526729
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387918
INFO:root:FL Epoch: 440 Norm Difference for worker 1320 is 0.787434
INFO:root:FL Epoch: 440 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :695
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452559
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425139
INFO:root:FL Epoch: 440 Norm Difference for worker 695 is 0.803778
INFO:root:FL Epoch: 440 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :213
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 213 is 0.82853
INFO:root:FL Epoch: 440 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1645
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454856
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387224
INFO:root:FL Epoch: 440 Norm Difference for worker 1645 is 0.833561
INFO:root:FL Epoch: 440 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1093
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629697
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501364
INFO:root:FL Epoch: 440 Norm Difference for worker 1093 is 0.763316
INFO:root:FL Epoch: 440 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1696
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394485
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461565
INFO:root:FL Epoch: 440 Norm Difference for worker 1696 is 0.739872
INFO:root:FL Epoch: 440 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :465
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472591
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.804561
INFO:root:FL Epoch: 440 Norm Difference for worker 465 is 0.817728
INFO:root:FL Epoch: 440 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :986
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563685
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509200
INFO:root:FL Epoch: 440 Norm Difference for worker 986 is 0.878894
INFO:root:FL Epoch: 440 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :139
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 139 is 0.767015
INFO:root:FL Epoch: 440 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :978
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418728
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304500
INFO:root:FL Epoch: 440 Norm Difference for worker 978 is 0.798559
INFO:root:FL Epoch: 440 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1696
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.4945472847012913 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:2.213019589583079                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [774, 507, 41, 984, 267, 80, 1078, 1686, 1711, 526]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :774
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474211
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275410
INFO:root:FL Epoch: 441 Norm Difference for worker 774 is 0.792848
INFO:root:FL Epoch: 441 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :507
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.922233
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359525
INFO:root:FL Epoch: 441 Norm Difference for worker 507 is 0.881319
INFO:root:FL Epoch: 441 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :41
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 41 is 0.844485
INFO:root:FL Epoch: 441 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :984
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516279
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169375
INFO:root:FL Epoch: 441 Norm Difference for worker 984 is 0.713001
INFO:root:FL Epoch: 441 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :267
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346381
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 267 is 0.766478
INFO:root:FL Epoch: 441 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :80
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 80 is 0.811629
INFO:root:FL Epoch: 441 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1078
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547099
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361361
INFO:root:FL Epoch: 441 Norm Difference for worker 1078 is 0.858606
INFO:root:FL Epoch: 441 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1686
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380751
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343449
INFO:root:FL Epoch: 441 Norm Difference for worker 1686 is 0.797232
INFO:root:FL Epoch: 441 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1711
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533229
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522005
INFO:root:FL Epoch: 441 Norm Difference for worker 1711 is 0.879521
INFO:root:FL Epoch: 441 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :526
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552258
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301793
INFO:root:FL Epoch: 441 Norm Difference for worker 526 is 0.854792
INFO:root:FL Epoch: 441 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 984
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.5000656483804479 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:2.1557859977086387                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [403, 1526, 900, 1312, 382, 1705, 724, 1375, 1382, 623]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :403
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711171
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414581
INFO:root:FL Epoch: 442 Norm Difference for worker 403 is 0.990578
INFO:root:FL Epoch: 442 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1526
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526916
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594028
INFO:root:FL Epoch: 442 Norm Difference for worker 1526 is 0.887859
INFO:root:FL Epoch: 442 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :900
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602079
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478760
INFO:root:FL Epoch: 442 Norm Difference for worker 900 is 0.853302
INFO:root:FL Epoch: 442 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1312
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522934
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411028
INFO:root:FL Epoch: 442 Norm Difference for worker 1312 is 0.843324
INFO:root:FL Epoch: 442 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :382
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794082
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394348
INFO:root:FL Epoch: 442 Norm Difference for worker 382 is 0.862678
INFO:root:FL Epoch: 442 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1705
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474315
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293853
INFO:root:FL Epoch: 442 Norm Difference for worker 1705 is 0.865516
INFO:root:FL Epoch: 442 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :724
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461269
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378851
INFO:root:FL Epoch: 442 Norm Difference for worker 724 is 0.89735
INFO:root:FL Epoch: 442 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1375
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545516
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553715
INFO:root:FL Epoch: 442 Norm Difference for worker 1375 is 0.831279
INFO:root:FL Epoch: 442 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1382
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779876
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421964
INFO:root:FL Epoch: 442 Norm Difference for worker 1382 is 0.827611
INFO:root:FL Epoch: 442 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :623
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512735
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.816636
INFO:root:FL Epoch: 442 Norm Difference for worker 623 is 0.897077
INFO:root:FL Epoch: 442 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1382
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.49454119275597963 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:2.0271727045377097                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1755, 1335, 1409, 1852, 205, 1907, 1781, 767, 1602, 1178]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1755
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440209
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376452
INFO:root:FL Epoch: 443 Norm Difference for worker 1755 is 0.702465
INFO:root:FL Epoch: 443 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1335
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804977
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407425
INFO:root:FL Epoch: 443 Norm Difference for worker 1335 is 0.734225
INFO:root:FL Epoch: 443 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1409
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382147
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311820
INFO:root:FL Epoch: 443 Norm Difference for worker 1409 is 0.71736
INFO:root:FL Epoch: 443 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1852
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339001
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325370
INFO:root:FL Epoch: 443 Norm Difference for worker 1852 is 0.683133
INFO:root:FL Epoch: 443 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :205
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 205 is 0.712713
INFO:root:FL Epoch: 443 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1907
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428775
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667854
INFO:root:FL Epoch: 443 Norm Difference for worker 1907 is 0.757672
INFO:root:FL Epoch: 443 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1781
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525697
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552951
INFO:root:FL Epoch: 443 Norm Difference for worker 1781 is 0.785343
INFO:root:FL Epoch: 443 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :767
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568469
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392886
INFO:root:FL Epoch: 443 Norm Difference for worker 767 is 0.731897
INFO:root:FL Epoch: 443 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1602
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497266
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317361
INFO:root:FL Epoch: 443 Norm Difference for worker 1602 is 0.747527
INFO:root:FL Epoch: 443 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1178
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326966
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355465
INFO:root:FL Epoch: 443 Norm Difference for worker 1178 is 0.724124
INFO:root:FL Epoch: 443 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1755
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.49020783340229707 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:1.9240220387776692                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [1741, 1167, 231, 1344, 1645, 463, 1897, 293, 1200, 1914]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :1741
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304823
INFO:root:Worker: 1741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290374
INFO:root:FL Epoch: 444 Norm Difference for worker 1741 is 0.727231
INFO:root:FL Epoch: 444 Done on worker:1741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1167
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381174
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613311
INFO:root:FL Epoch: 444 Norm Difference for worker 1167 is 0.737368
INFO:root:FL Epoch: 444 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :231
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570832
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 231 is 0.782342
INFO:root:FL Epoch: 444 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1344
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548408
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383550
INFO:root:FL Epoch: 444 Norm Difference for worker 1344 is 0.818404
INFO:root:FL Epoch: 444 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1645
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415804
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592339
INFO:root:FL Epoch: 444 Norm Difference for worker 1645 is 0.773034
INFO:root:FL Epoch: 444 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :463
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656146
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564891
INFO:root:FL Epoch: 444 Norm Difference for worker 463 is 0.800919
INFO:root:FL Epoch: 444 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1897
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280490
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630145
INFO:root:FL Epoch: 444 Norm Difference for worker 1897 is 0.768654
INFO:root:FL Epoch: 444 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :293
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.290813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.212075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 293 is 0.76001
INFO:root:FL Epoch: 444 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1200
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551818
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421648
INFO:root:FL Epoch: 444 Norm Difference for worker 1200 is 0.818034
INFO:root:FL Epoch: 444 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1914
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352968
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458169
INFO:root:FL Epoch: 444 Norm Difference for worker 1914 is 0.735784
INFO:root:FL Epoch: 444 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1741
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.4938366588424234 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:2.4654382864634194                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [1905, 224, 1527, 1917, 541, 1443, 1053, 472, 1329, 364]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 445 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :1905
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268968
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359481
INFO:root:FL Epoch: 445 Norm Difference for worker 1905 is 0.655753
INFO:root:FL Epoch: 445 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :224
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 224 is 0.74512
INFO:root:FL Epoch: 445 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1527
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681693
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310799
INFO:root:FL Epoch: 445 Norm Difference for worker 1527 is 0.799218
INFO:root:FL Epoch: 445 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1917
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748131
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338794
INFO:root:FL Epoch: 445 Norm Difference for worker 1917 is 0.867641
INFO:root:FL Epoch: 445 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :541
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510021
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427261
INFO:root:FL Epoch: 445 Norm Difference for worker 541 is 0.781233
INFO:root:FL Epoch: 445 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1443
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595549
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523907
INFO:root:FL Epoch: 445 Norm Difference for worker 1443 is 0.815228
INFO:root:FL Epoch: 445 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1053
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410112
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653153
INFO:root:FL Epoch: 445 Norm Difference for worker 1053 is 0.723139
INFO:root:FL Epoch: 445 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :472
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521308
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372592
INFO:root:FL Epoch: 445 Norm Difference for worker 472 is 0.864345
INFO:root:FL Epoch: 445 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1329
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589552
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313911
INFO:root:FL Epoch: 445 Norm Difference for worker 1329 is 0.854877
INFO:root:FL Epoch: 445 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :364
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555062
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539305
INFO:root:FL Epoch: 445 Norm Difference for worker 364 is 0.834114
INFO:root:FL Epoch: 445 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.4938833958962384 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:2.525968392690023                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [1006, 1245, 312, 1414, 354, 540, 1316, 142, 1573, 1621]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :1006
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511366
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767000
INFO:root:FL Epoch: 446 Norm Difference for worker 1006 is 0.951022
INFO:root:FL Epoch: 446 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1245
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584276
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606175
INFO:root:FL Epoch: 446 Norm Difference for worker 1245 is 0.74984
INFO:root:FL Epoch: 446 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :312
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 312 is 0.831195
INFO:root:FL Epoch: 446 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1414
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393840
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327209
INFO:root:FL Epoch: 446 Norm Difference for worker 1414 is 0.841653
INFO:root:FL Epoch: 446 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :354
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630785
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491238
INFO:root:FL Epoch: 446 Norm Difference for worker 354 is 0.853083
INFO:root:FL Epoch: 446 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :540
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701972
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580445
INFO:root:FL Epoch: 446 Norm Difference for worker 540 is 0.866921
INFO:root:FL Epoch: 446 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1316
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565009
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453333
INFO:root:FL Epoch: 446 Norm Difference for worker 1316 is 0.774549
INFO:root:FL Epoch: 446 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :142
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 142 is 0.849475
INFO:root:FL Epoch: 446 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1573
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700318
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444153
INFO:root:FL Epoch: 446 Norm Difference for worker 1573 is 0.82052
INFO:root:FL Epoch: 446 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1621
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439798
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437268
INFO:root:FL Epoch: 446 Norm Difference for worker 1621 is 0.814765
INFO:root:FL Epoch: 446 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1245
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.4709779357208925 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:2.088441570599874                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [1086, 1772, 789, 1483, 1141, 1340, 1456, 280, 1332, 1172]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 447 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :1086
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667613
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348487
INFO:root:FL Epoch: 447 Norm Difference for worker 1086 is 0.662992
INFO:root:FL Epoch: 447 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1772
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488972
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291202
INFO:root:FL Epoch: 447 Norm Difference for worker 1772 is 0.80759
INFO:root:FL Epoch: 447 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :789
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481344
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338446
INFO:root:FL Epoch: 447 Norm Difference for worker 789 is 0.748477
INFO:root:FL Epoch: 447 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1483
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462834
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333980
INFO:root:FL Epoch: 447 Norm Difference for worker 1483 is 0.791034
INFO:root:FL Epoch: 447 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1141
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392947
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511711
INFO:root:FL Epoch: 447 Norm Difference for worker 1141 is 0.77516
INFO:root:FL Epoch: 447 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1340
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608223
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544994
INFO:root:FL Epoch: 447 Norm Difference for worker 1340 is 0.847001
INFO:root:FL Epoch: 447 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1456
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551948
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579427
INFO:root:FL Epoch: 447 Norm Difference for worker 1456 is 0.830997
INFO:root:FL Epoch: 447 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :280
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 280 is 0.793534
INFO:root:FL Epoch: 447 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1332
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470833
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475069
INFO:root:FL Epoch: 447 Norm Difference for worker 1332 is 0.822487
INFO:root:FL Epoch: 447 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1172
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553949
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654586
INFO:root:FL Epoch: 447 Norm Difference for worker 1172 is 0.763345
INFO:root:FL Epoch: 447 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.4954700803055483 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:2.3207938273747764                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [932, 477, 1445, 109, 1870, 840, 712, 1917, 1502, 1856]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :932
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551994
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551975
INFO:root:FL Epoch: 448 Norm Difference for worker 932 is 0.782203
INFO:root:FL Epoch: 448 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :477
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363690
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271423
INFO:root:FL Epoch: 448 Norm Difference for worker 477 is 0.666674
INFO:root:FL Epoch: 448 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1445
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527335
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.752611
INFO:root:FL Epoch: 448 Norm Difference for worker 1445 is 0.869815
INFO:root:FL Epoch: 448 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :109
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.366925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 109 is 0.828016
INFO:root:FL Epoch: 448 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1870
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561684
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514180
INFO:root:FL Epoch: 448 Norm Difference for worker 1870 is 0.839288
INFO:root:FL Epoch: 448 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :840
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.198677
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621394
INFO:root:FL Epoch: 448 Norm Difference for worker 840 is 0.769181
INFO:root:FL Epoch: 448 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :712
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337162
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418182
INFO:root:FL Epoch: 448 Norm Difference for worker 712 is 0.739366
INFO:root:FL Epoch: 448 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1917
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562907
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461977
INFO:root:FL Epoch: 448 Norm Difference for worker 1917 is 0.840969
INFO:root:FL Epoch: 448 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1502
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296149
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591469
INFO:root:FL Epoch: 448 Norm Difference for worker 1502 is 0.748279
INFO:root:FL Epoch: 448 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1856
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560486
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517348
INFO:root:FL Epoch: 448 Norm Difference for worker 1856 is 0.786564
INFO:root:FL Epoch: 448 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.4899803829543731 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:2.450551191965739                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [460, 631, 1198, 813, 1018, 1088, 408, 1783, 371, 65]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :460
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399350
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584419
INFO:root:FL Epoch: 449 Norm Difference for worker 460 is 0.86183
INFO:root:FL Epoch: 449 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :631
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619766
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376684
INFO:root:FL Epoch: 449 Norm Difference for worker 631 is 0.82773
INFO:root:FL Epoch: 449 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1198
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555553
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668238
INFO:root:FL Epoch: 449 Norm Difference for worker 1198 is 0.815014
INFO:root:FL Epoch: 449 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :813
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506056
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489953
INFO:root:FL Epoch: 449 Norm Difference for worker 813 is 0.829216
INFO:root:FL Epoch: 449 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1018
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458248
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464366
INFO:root:FL Epoch: 449 Norm Difference for worker 1018 is 0.82087
INFO:root:FL Epoch: 449 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1088
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598840
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322292
INFO:root:FL Epoch: 449 Norm Difference for worker 1088 is 0.819401
INFO:root:FL Epoch: 449 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :408
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593030
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231797
INFO:root:FL Epoch: 449 Norm Difference for worker 408 is 0.78076
INFO:root:FL Epoch: 449 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1783
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492286
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413824
INFO:root:FL Epoch: 449 Norm Difference for worker 1783 is 0.870615
INFO:root:FL Epoch: 449 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :371
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357508
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700292
INFO:root:FL Epoch: 449 Norm Difference for worker 371 is 0.82005
INFO:root:FL Epoch: 449 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :65
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.751411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 65 is 0.864445
INFO:root:FL Epoch: 449 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 408
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.4830593440462561 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:2.2348946730295816                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [1340, 1407, 893, 1126, 1022, 1441, 224, 255, 150, 1134]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :1340
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458805
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308090
INFO:root:FL Epoch: 450 Norm Difference for worker 1340 is 0.876822
INFO:root:FL Epoch: 450 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1407
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458889
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497302
INFO:root:FL Epoch: 450 Norm Difference for worker 1407 is 0.794158
INFO:root:FL Epoch: 450 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :893
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487479
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550388
INFO:root:FL Epoch: 450 Norm Difference for worker 893 is 0.791757
INFO:root:FL Epoch: 450 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1126
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604692
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604594
INFO:root:FL Epoch: 450 Norm Difference for worker 1126 is 0.879665
INFO:root:FL Epoch: 450 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1022
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779216
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450704
INFO:root:FL Epoch: 450 Norm Difference for worker 1022 is 0.778249
INFO:root:FL Epoch: 450 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1441
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461004
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370881
INFO:root:FL Epoch: 450 Norm Difference for worker 1441 is 0.819332
INFO:root:FL Epoch: 450 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :224
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.296772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 224 is 0.817798
INFO:root:FL Epoch: 450 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :255
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.567128
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 255 is 0.791444
INFO:root:FL Epoch: 450 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :150
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249452
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 150 is 0.808756
INFO:root:FL Epoch: 450 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1134
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501154
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410887
INFO:root:FL Epoch: 450 Norm Difference for worker 1134 is 0.854312
INFO:root:FL Epoch: 450 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.509201944750898 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:2.6423537731170654                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [1693, 294, 1464, 931, 828, 1821, 1652, 1404, 575, 1409]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 451 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :1693
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329715
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319548
INFO:root:FL Epoch: 451 Norm Difference for worker 1693 is 0.69338
INFO:root:FL Epoch: 451 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :294
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785962
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 294 is 0.937723
INFO:root:FL Epoch: 451 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1464
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511934
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355344
INFO:root:FL Epoch: 451 Norm Difference for worker 1464 is 0.745476
INFO:root:FL Epoch: 451 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :931
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614493
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519118
INFO:root:FL Epoch: 451 Norm Difference for worker 931 is 0.806917
INFO:root:FL Epoch: 451 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :828
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521772
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772069
INFO:root:FL Epoch: 451 Norm Difference for worker 828 is 0.865309
INFO:root:FL Epoch: 451 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1821
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395712
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487257
INFO:root:FL Epoch: 451 Norm Difference for worker 1821 is 0.829486
INFO:root:FL Epoch: 451 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1652
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364199
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570824
INFO:root:FL Epoch: 451 Norm Difference for worker 1652 is 0.799294
INFO:root:FL Epoch: 451 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1404
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438591
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369572
INFO:root:FL Epoch: 451 Norm Difference for worker 1404 is 0.780792
INFO:root:FL Epoch: 451 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :575
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 1.031307
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575386
INFO:root:FL Epoch: 451 Norm Difference for worker 575 is 0.883027
INFO:root:FL Epoch: 451 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1409
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602190
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395116
INFO:root:FL Epoch: 451 Norm Difference for worker 1409 is 0.792578
INFO:root:FL Epoch: 451 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.4857389006544562 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:2.277283231417338                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1728, 1638, 273, 803, 253, 437, 889, 358, 195, 806]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1728
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637592
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421919
INFO:root:FL Epoch: 452 Norm Difference for worker 1728 is 0.895351
INFO:root:FL Epoch: 452 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1638
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487228
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308345
INFO:root:FL Epoch: 452 Norm Difference for worker 1638 is 0.82915
INFO:root:FL Epoch: 452 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :273
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 273 is 0.794484
INFO:root:FL Epoch: 452 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :803
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.242004
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341695
INFO:root:FL Epoch: 452 Norm Difference for worker 803 is 0.750033
INFO:root:FL Epoch: 452 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :253
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419681
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 253 is 0.813917
INFO:root:FL Epoch: 452 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :437
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575749
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515738
INFO:root:FL Epoch: 452 Norm Difference for worker 437 is 0.77779
INFO:root:FL Epoch: 452 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :889
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707313
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385988
INFO:root:FL Epoch: 452 Norm Difference for worker 889 is 0.837913
INFO:root:FL Epoch: 452 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :358
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478730
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289797
INFO:root:FL Epoch: 452 Norm Difference for worker 358 is 0.802591
INFO:root:FL Epoch: 452 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :195
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456366
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 195 is 0.933324
INFO:root:FL Epoch: 452 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :806
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583363
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195756
INFO:root:FL Epoch: 452 Norm Difference for worker 806 is 0.846424
INFO:root:FL Epoch: 452 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 803
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.4869875530986225 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:2.3122318983078003                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1883, 896, 1393, 492, 1304, 1032, 1403, 926, 286, 1131]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 453 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1883
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330546
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496112
INFO:root:FL Epoch: 453 Norm Difference for worker 1883 is 0.841001
INFO:root:FL Epoch: 453 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :896
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526571
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270314
INFO:root:FL Epoch: 453 Norm Difference for worker 896 is 0.775753
INFO:root:FL Epoch: 453 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1393
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615843
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574695
INFO:root:FL Epoch: 453 Norm Difference for worker 1393 is 0.891141
INFO:root:FL Epoch: 453 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :492
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360428
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485140
INFO:root:FL Epoch: 453 Norm Difference for worker 492 is 0.845608
INFO:root:FL Epoch: 453 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1304
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377198
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545462
INFO:root:FL Epoch: 453 Norm Difference for worker 1304 is 0.798892
INFO:root:FL Epoch: 453 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1032
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356826
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199262
INFO:root:FL Epoch: 453 Norm Difference for worker 1032 is 0.749441
INFO:root:FL Epoch: 453 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1403
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529216
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682106
INFO:root:FL Epoch: 453 Norm Difference for worker 1403 is 0.850978
INFO:root:FL Epoch: 453 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :926
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542115
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246518
INFO:root:FL Epoch: 453 Norm Difference for worker 926 is 0.70697
INFO:root:FL Epoch: 453 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :286
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.800393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.385097
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 286 is 0.755727
INFO:root:FL Epoch: 453 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1131
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 1.066247
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439150
INFO:root:FL Epoch: 453 Norm Difference for worker 1131 is 0.9434
INFO:root:FL Epoch: 453 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.4841429187971003 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:2.53240438302358                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [753, 976, 1854, 219, 1694, 91, 1738, 1021, 173, 1810]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 454 Num points on workers: [200 200 200 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :753
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585517
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492261
INFO:root:FL Epoch: 454 Norm Difference for worker 753 is 0.935873
INFO:root:FL Epoch: 454 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :976
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619755
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372083
INFO:root:FL Epoch: 454 Norm Difference for worker 976 is 0.943898
INFO:root:FL Epoch: 454 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1854
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823713
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466154
INFO:root:FL Epoch: 454 Norm Difference for worker 1854 is 0.977127
INFO:root:FL Epoch: 454 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :219
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 219 is 0.966569
INFO:root:FL Epoch: 454 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1694
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569656
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450099
INFO:root:FL Epoch: 454 Norm Difference for worker 1694 is 0.906981
INFO:root:FL Epoch: 454 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :91
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.941554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 91 is 0.919501
INFO:root:FL Epoch: 454 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1738
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500344
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441883
INFO:root:FL Epoch: 454 Norm Difference for worker 1738 is 0.955429
INFO:root:FL Epoch: 454 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1021
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688032
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500719
INFO:root:FL Epoch: 454 Norm Difference for worker 1021 is 0.954641
INFO:root:FL Epoch: 454 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :173
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 173 is 0.946426
INFO:root:FL Epoch: 454 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1810
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444500
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386818
INFO:root:FL Epoch: 454 Norm Difference for worker 1810 is 0.844278
INFO:root:FL Epoch: 454 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.49345529167091146 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:2.65148917833964                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [107, 1286, 1022, 1930, 679, 1025, 136, 1609, 1080, 1625]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 455 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :107
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 107 is 0.876308
INFO:root:FL Epoch: 455 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1286
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427509
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374702
INFO:root:FL Epoch: 455 Norm Difference for worker 1286 is 0.927492
INFO:root:FL Epoch: 455 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1022
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269934
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237644
INFO:root:FL Epoch: 455 Norm Difference for worker 1022 is 0.617921
INFO:root:FL Epoch: 455 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1930
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500038
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339385
INFO:root:FL Epoch: 455 Norm Difference for worker 1930 is 0.936165
INFO:root:FL Epoch: 455 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :679
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546240
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363420
INFO:root:FL Epoch: 455 Norm Difference for worker 679 is 0.809235
INFO:root:FL Epoch: 455 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1025
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296157
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468832
INFO:root:FL Epoch: 455 Norm Difference for worker 1025 is 0.877192
INFO:root:FL Epoch: 455 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :136
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 136 is 0.919977
INFO:root:FL Epoch: 455 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1609
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 1.199487
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375748
INFO:root:FL Epoch: 455 Norm Difference for worker 1609 is 0.950481
INFO:root:FL Epoch: 455 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1080
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566022
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544745
INFO:root:FL Epoch: 455 Norm Difference for worker 1080 is 0.914449
INFO:root:FL Epoch: 455 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1625
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377156
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499652
INFO:root:FL Epoch: 455 Norm Difference for worker 1625 is 0.890039
INFO:root:FL Epoch: 455 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.5014142078511855 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:2.827125072479248                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1340, 1827, 1736, 1599, 487, 1680, 131, 1888, 1520, 1090]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1340
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568820
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232083
INFO:root:FL Epoch: 456 Norm Difference for worker 1340 is 0.967166
INFO:root:FL Epoch: 456 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1827
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820792
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562029
INFO:root:FL Epoch: 456 Norm Difference for worker 1827 is 0.988328
INFO:root:FL Epoch: 456 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1736
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008791
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380066
INFO:root:FL Epoch: 456 Norm Difference for worker 1736 is 1.018826
INFO:root:FL Epoch: 456 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1599
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804631
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226129
INFO:root:FL Epoch: 456 Norm Difference for worker 1599 is 0.9346
INFO:root:FL Epoch: 456 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :487
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722936
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648250
INFO:root:FL Epoch: 456 Norm Difference for worker 487 is 0.983173
INFO:root:FL Epoch: 456 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1680
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477298
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622670
INFO:root:FL Epoch: 456 Norm Difference for worker 1680 is 0.990293
INFO:root:FL Epoch: 456 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :131
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 131 is 0.986876
INFO:root:FL Epoch: 456 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1888
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826433
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.770918
INFO:root:FL Epoch: 456 Norm Difference for worker 1888 is 0.956391
INFO:root:FL Epoch: 456 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1520
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728375
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273757
INFO:root:FL Epoch: 456 Norm Difference for worker 1520 is 0.982294
INFO:root:FL Epoch: 456 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1090
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548211
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393097
INFO:root:FL Epoch: 456 Norm Difference for worker 1090 is 0.979189
INFO:root:FL Epoch: 456 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1888
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.489945154856233 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:2.091733455657959                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [192, 1777, 1554, 406, 1394, 1840, 815, 717, 1117, 585]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 457 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :192
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495609
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 192 is 0.797538
INFO:root:FL Epoch: 457 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1777
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634933
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189871
INFO:root:FL Epoch: 457 Norm Difference for worker 1777 is 0.881663
INFO:root:FL Epoch: 457 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1554
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382628
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342679
INFO:root:FL Epoch: 457 Norm Difference for worker 1554 is 0.69214
INFO:root:FL Epoch: 457 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :406
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755132
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354134
INFO:root:FL Epoch: 457 Norm Difference for worker 406 is 0.863379
INFO:root:FL Epoch: 457 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1394
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588422
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406317
INFO:root:FL Epoch: 457 Norm Difference for worker 1394 is 0.868384
INFO:root:FL Epoch: 457 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1840
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461575
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685391
INFO:root:FL Epoch: 457 Norm Difference for worker 1840 is 0.826151
INFO:root:FL Epoch: 457 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :815
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644255
INFO:root:Worker: 815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410169
INFO:root:FL Epoch: 457 Norm Difference for worker 815 is 0.858957
INFO:root:FL Epoch: 457 Done on worker:815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :717
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 1.049642
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291951
INFO:root:FL Epoch: 457 Norm Difference for worker 717 is 0.722465
INFO:root:FL Epoch: 457 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1117
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305550
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620081
INFO:root:FL Epoch: 457 Norm Difference for worker 1117 is 0.763909
INFO:root:FL Epoch: 457 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :585
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496914
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498936
INFO:root:FL Epoch: 457 Norm Difference for worker 585 is 0.787789
INFO:root:FL Epoch: 457 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 717
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.491181096609901 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:2.108097473780314                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [1531, 348, 1533, 1440, 1019, 106, 427, 1294, 810, 1924]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 458 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :1531
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740485
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284171
INFO:root:FL Epoch: 458 Norm Difference for worker 1531 is 0.731525
INFO:root:FL Epoch: 458 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :348
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604898
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526478
INFO:root:FL Epoch: 458 Norm Difference for worker 348 is 0.731815
INFO:root:FL Epoch: 458 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1533
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582896
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305159
INFO:root:FL Epoch: 458 Norm Difference for worker 1533 is 0.732769
INFO:root:FL Epoch: 458 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1440
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477319
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406476
INFO:root:FL Epoch: 458 Norm Difference for worker 1440 is 0.707799
INFO:root:FL Epoch: 458 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1019
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508854
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596545
INFO:root:FL Epoch: 458 Norm Difference for worker 1019 is 0.69866
INFO:root:FL Epoch: 458 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :106
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 106 is 0.761897
INFO:root:FL Epoch: 458 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :427
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546729
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550667
INFO:root:FL Epoch: 458 Norm Difference for worker 427 is 0.715647
INFO:root:FL Epoch: 458 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1294
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560291
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634697
INFO:root:FL Epoch: 458 Norm Difference for worker 1294 is 0.735236
INFO:root:FL Epoch: 458 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :810
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608102
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529592
INFO:root:FL Epoch: 458 Norm Difference for worker 810 is 0.926189
INFO:root:FL Epoch: 458 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1924
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515551
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366678
INFO:root:FL Epoch: 458 Norm Difference for worker 1924 is 0.72145
INFO:root:FL Epoch: 458 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1019
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.47141292691230774 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:2.005491554737091                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [102, 1895, 259, 115, 1648, 1779, 1309, 423, 1905, 302]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 459 Num points on workers: [201 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :102
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318285
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 102 is 0.705872
INFO:root:FL Epoch: 459 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1895
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669745
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463976
INFO:root:FL Epoch: 459 Norm Difference for worker 1895 is 0.695382
INFO:root:FL Epoch: 459 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :259
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 259 is 0.73551
INFO:root:FL Epoch: 459 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :115
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430304
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 115 is 0.645336
INFO:root:FL Epoch: 459 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1648
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423024
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418834
INFO:root:FL Epoch: 459 Norm Difference for worker 1648 is 0.66056
INFO:root:FL Epoch: 459 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1779
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544202
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519079
INFO:root:FL Epoch: 459 Norm Difference for worker 1779 is 0.752422
INFO:root:FL Epoch: 459 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1309
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478867
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397826
INFO:root:FL Epoch: 459 Norm Difference for worker 1309 is 0.588046
INFO:root:FL Epoch: 459 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :423
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519756
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307600
INFO:root:FL Epoch: 459 Norm Difference for worker 423 is 0.688567
INFO:root:FL Epoch: 459 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1905
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253213
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334632
INFO:root:FL Epoch: 459 Norm Difference for worker 1905 is 0.588953
INFO:root:FL Epoch: 459 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :302
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.364194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.320299
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 302 is 0.656437
INFO:root:FL Epoch: 459 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1309
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.4676398967995363 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:2.1529205242792764                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [1018, 340, 1745, 1464, 1399, 1052, 972, 1529, 603, 1126]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :1018
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549525
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373044
INFO:root:FL Epoch: 460 Norm Difference for worker 1018 is 0.716712
INFO:root:FL Epoch: 460 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :340
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438804
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513104
INFO:root:FL Epoch: 460 Norm Difference for worker 340 is 0.73362
INFO:root:FL Epoch: 460 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1745
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345788
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331409
INFO:root:FL Epoch: 460 Norm Difference for worker 1745 is 0.738978
INFO:root:FL Epoch: 460 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1464
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332076
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513401
INFO:root:FL Epoch: 460 Norm Difference for worker 1464 is 0.617802
INFO:root:FL Epoch: 460 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1399
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610344
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480181
INFO:root:FL Epoch: 460 Norm Difference for worker 1399 is 0.709134
INFO:root:FL Epoch: 460 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1052
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305077
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378465
INFO:root:FL Epoch: 460 Norm Difference for worker 1052 is 0.624427
INFO:root:FL Epoch: 460 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :972
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647144
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482417
INFO:root:FL Epoch: 460 Norm Difference for worker 972 is 0.779607
INFO:root:FL Epoch: 460 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1529
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563056
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368405
INFO:root:FL Epoch: 460 Norm Difference for worker 1529 is 0.700805
INFO:root:FL Epoch: 460 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :603
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567157
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587374
INFO:root:FL Epoch: 460 Norm Difference for worker 603 is 0.781364
INFO:root:FL Epoch: 460 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1126
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581587
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439916
INFO:root:FL Epoch: 460 Norm Difference for worker 1126 is 0.784758
INFO:root:FL Epoch: 460 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.4742428712985095 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:2.324489156405131                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [868, 1313, 1253, 1251, 1036, 1681, 104, 1628, 1047, 565]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :868
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524074
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463131
INFO:root:FL Epoch: 461 Norm Difference for worker 868 is 0.79494
INFO:root:FL Epoch: 461 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1313
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545429
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425701
INFO:root:FL Epoch: 461 Norm Difference for worker 1313 is 0.785179
INFO:root:FL Epoch: 461 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1253
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584935
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530457
INFO:root:FL Epoch: 461 Norm Difference for worker 1253 is 0.847419
INFO:root:FL Epoch: 461 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1251
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803321
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561409
INFO:root:FL Epoch: 461 Norm Difference for worker 1251 is 0.844468
INFO:root:FL Epoch: 461 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1036
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460634
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418930
INFO:root:FL Epoch: 461 Norm Difference for worker 1036 is 0.75812
INFO:root:FL Epoch: 461 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1681
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558396
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402523
INFO:root:FL Epoch: 461 Norm Difference for worker 1681 is 0.774547
INFO:root:FL Epoch: 461 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :104
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.320425
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.725538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 104 is 0.784247
INFO:root:FL Epoch: 461 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1628
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420104
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558404
INFO:root:FL Epoch: 461 Norm Difference for worker 1628 is 0.716036
INFO:root:FL Epoch: 461 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1047
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737002
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512032
INFO:root:FL Epoch: 461 Norm Difference for worker 1047 is 0.819315
INFO:root:FL Epoch: 461 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :565
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596662
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291797
INFO:root:FL Epoch: 461 Norm Difference for worker 565 is 0.72581
INFO:root:FL Epoch: 461 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 565
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.47126217887682076 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:2.058328866958618                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [415, 605, 719, 857, 70, 1527, 16, 186, 60, 1227]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 200 200 201 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :415
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895166
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481650
INFO:root:FL Epoch: 462 Norm Difference for worker 415 is 0.764081
INFO:root:FL Epoch: 462 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :605
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578299
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520052
INFO:root:FL Epoch: 462 Norm Difference for worker 605 is 0.826932
INFO:root:FL Epoch: 462 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :719
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638164
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441076
INFO:root:FL Epoch: 462 Norm Difference for worker 719 is 0.822451
INFO:root:FL Epoch: 462 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :857
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777785
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293310
INFO:root:FL Epoch: 462 Norm Difference for worker 857 is 0.808275
INFO:root:FL Epoch: 462 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :70
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 70 is 0.734958
INFO:root:FL Epoch: 462 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1527
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565882
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410854
INFO:root:FL Epoch: 462 Norm Difference for worker 1527 is 0.752018
INFO:root:FL Epoch: 462 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :16
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.805696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 16 is 0.759934
INFO:root:FL Epoch: 462 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :186
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 186 is 0.788541
INFO:root:FL Epoch: 462 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :60
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347410
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 60 is 0.78588
INFO:root:FL Epoch: 462 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1227
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502351
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569691
INFO:root:FL Epoch: 462 Norm Difference for worker 1227 is 0.808407
INFO:root:FL Epoch: 462 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.49150991615127115 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:2.4140509366989136                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [1209, 367, 1308, 1633, 371, 1398, 157, 1426, 9, 1816]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 463 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :1209
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424769
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447145
INFO:root:FL Epoch: 463 Norm Difference for worker 1209 is 0.780692
INFO:root:FL Epoch: 463 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :367
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573038
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350983
INFO:root:FL Epoch: 463 Norm Difference for worker 367 is 0.738689
INFO:root:FL Epoch: 463 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1308
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435728
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452342
INFO:root:FL Epoch: 463 Norm Difference for worker 1308 is 0.758703
INFO:root:FL Epoch: 463 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1633
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1633 Train Epoch: 0 [0/200 (0%)]	Loss: 1.014541
INFO:root:Worker: 1633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662377
INFO:root:FL Epoch: 463 Norm Difference for worker 1633 is 0.836482
INFO:root:FL Epoch: 463 Done on worker:1633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :371
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270260
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512091
INFO:root:FL Epoch: 463 Norm Difference for worker 371 is 0.73112
INFO:root:FL Epoch: 463 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1398
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585903
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384037
INFO:root:FL Epoch: 463 Norm Difference for worker 1398 is 0.732845
INFO:root:FL Epoch: 463 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :157
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458133
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 157 is 0.693467
INFO:root:FL Epoch: 463 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1426
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698299
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484231
INFO:root:FL Epoch: 463 Norm Difference for worker 1426 is 0.774667
INFO:root:FL Epoch: 463 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :9
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.738898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 9 is 0.784757
INFO:root:FL Epoch: 463 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1816
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537721
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407661
INFO:root:FL Epoch: 463 Norm Difference for worker 1816 is 0.744869
INFO:root:FL Epoch: 463 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 157
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.49883664793827953 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:2.4787511428197226                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [1500, 1518, 1575, 406, 524, 510, 1188, 184, 1756, 1321]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 464 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :1500
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339370
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573894
INFO:root:FL Epoch: 464 Norm Difference for worker 1500 is 0.78029
INFO:root:FL Epoch: 464 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1518
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691398
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648606
INFO:root:FL Epoch: 464 Norm Difference for worker 1518 is 0.72065
INFO:root:FL Epoch: 464 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1575
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416082
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445087
INFO:root:FL Epoch: 464 Norm Difference for worker 1575 is 0.766802
INFO:root:FL Epoch: 464 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :406
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561022
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724949
INFO:root:FL Epoch: 464 Norm Difference for worker 406 is 0.852813
INFO:root:FL Epoch: 464 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :524
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426886
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313515
INFO:root:FL Epoch: 464 Norm Difference for worker 524 is 0.670112
INFO:root:FL Epoch: 464 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :510
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284748
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278440
INFO:root:FL Epoch: 464 Norm Difference for worker 510 is 0.784548
INFO:root:FL Epoch: 464 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1188
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588617
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424813
INFO:root:FL Epoch: 464 Norm Difference for worker 1188 is 0.784984
INFO:root:FL Epoch: 464 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :184
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 184 is 0.691108
INFO:root:FL Epoch: 464 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1756
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572075
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491970
INFO:root:FL Epoch: 464 Norm Difference for worker 1756 is 0.805082
INFO:root:FL Epoch: 464 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1321
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596507
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485795
INFO:root:FL Epoch: 464 Norm Difference for worker 1321 is 0.899776
INFO:root:FL Epoch: 464 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 524
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.4752970197621514 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:2.178396681944529                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [1844, 257, 1248, 117, 1895, 590, 1706, 545, 453, 1743]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 465 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :1844
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339322
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404344
INFO:root:FL Epoch: 465 Norm Difference for worker 1844 is 0.74379
INFO:root:FL Epoch: 465 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :257
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 257 is 0.884401
INFO:root:FL Epoch: 465 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1248
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663785
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520695
INFO:root:FL Epoch: 465 Norm Difference for worker 1248 is 0.766441
INFO:root:FL Epoch: 465 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :117
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 117 is 0.745517
INFO:root:FL Epoch: 465 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1895
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652687
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705900
INFO:root:FL Epoch: 465 Norm Difference for worker 1895 is 0.816194
INFO:root:FL Epoch: 465 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :590
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652643
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544014
INFO:root:FL Epoch: 465 Norm Difference for worker 590 is 0.790976
INFO:root:FL Epoch: 465 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1706
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346575
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488333
INFO:root:FL Epoch: 465 Norm Difference for worker 1706 is 0.816042
INFO:root:FL Epoch: 465 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :545
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590860
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304682
INFO:root:FL Epoch: 465 Norm Difference for worker 545 is 0.809128
INFO:root:FL Epoch: 465 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :453
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821775
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221882
INFO:root:FL Epoch: 465 Norm Difference for worker 453 is 0.883703
INFO:root:FL Epoch: 465 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1743
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633323
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648725
INFO:root:FL Epoch: 465 Norm Difference for worker 1743 is 0.828608
INFO:root:FL Epoch: 465 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 590
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.47823502736933093 and Test Accuracy:75.0 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:2.1711915731430054                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1566, 950, 1113, 1234, 232, 1580, 1354, 404, 1908, 1062]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1566
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422049
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198678
INFO:root:FL Epoch: 466 Norm Difference for worker 1566 is 0.641785
INFO:root:FL Epoch: 466 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :950
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472394
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415195
INFO:root:FL Epoch: 466 Norm Difference for worker 950 is 0.656531
INFO:root:FL Epoch: 466 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1113
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722513
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648366
INFO:root:FL Epoch: 466 Norm Difference for worker 1113 is 0.726121
INFO:root:FL Epoch: 466 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1234
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796724
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646316
INFO:root:FL Epoch: 466 Norm Difference for worker 1234 is 0.721726
INFO:root:FL Epoch: 466 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :232
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.653681
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 232 is 0.744424
INFO:root:FL Epoch: 466 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1580
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327291
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362015
INFO:root:FL Epoch: 466 Norm Difference for worker 1580 is 0.69534
INFO:root:FL Epoch: 466 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1354
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404871
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482686
INFO:root:FL Epoch: 466 Norm Difference for worker 1354 is 0.651855
INFO:root:FL Epoch: 466 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :404
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464784
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342158
INFO:root:FL Epoch: 466 Norm Difference for worker 404 is 0.631664
INFO:root:FL Epoch: 466 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1908
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788019
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529540
INFO:root:FL Epoch: 466 Norm Difference for worker 1908 is 0.709607
INFO:root:FL Epoch: 466 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1062
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444940
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.886569
INFO:root:FL Epoch: 466 Norm Difference for worker 1062 is 0.750013
INFO:root:FL Epoch: 466 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.47365084991735573 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:1.7958101431528728                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1509, 198, 1101, 1583, 924, 400, 309, 1414, 908, 1640]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 467 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1509
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596237
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330828
INFO:root:FL Epoch: 467 Norm Difference for worker 1509 is 0.704176
INFO:root:FL Epoch: 467 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :198
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 198 is 0.776533
INFO:root:FL Epoch: 467 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1101
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664099
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503138
INFO:root:FL Epoch: 467 Norm Difference for worker 1101 is 0.768343
INFO:root:FL Epoch: 467 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1583
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571524
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401632
INFO:root:FL Epoch: 467 Norm Difference for worker 1583 is 0.765613
INFO:root:FL Epoch: 467 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :924
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708421
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427463
INFO:root:FL Epoch: 467 Norm Difference for worker 924 is 0.689341
INFO:root:FL Epoch: 467 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :400
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589040
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548512
INFO:root:FL Epoch: 467 Norm Difference for worker 400 is 0.728083
INFO:root:FL Epoch: 467 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :309
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 309 is 0.731542
INFO:root:FL Epoch: 467 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1414
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589705
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411428
INFO:root:FL Epoch: 467 Norm Difference for worker 1414 is 0.669355
INFO:root:FL Epoch: 467 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :908
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653329
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367056
INFO:root:FL Epoch: 467 Norm Difference for worker 908 is 0.665524
INFO:root:FL Epoch: 467 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1640
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535249
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387625
INFO:root:FL Epoch: 467 Norm Difference for worker 1640 is 0.749211
INFO:root:FL Epoch: 467 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1414
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.46679506494718437 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:1.9154259165128071                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1801, 175, 1432, 1594, 1908, 1554, 568, 373, 701, 1004]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 468 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1801
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580002
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370925
INFO:root:FL Epoch: 468 Norm Difference for worker 1801 is 0.769867
INFO:root:FL Epoch: 468 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :175
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.287937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 175 is 0.701773
INFO:root:FL Epoch: 468 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1432
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486746
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454302
INFO:root:FL Epoch: 468 Norm Difference for worker 1432 is 0.737803
INFO:root:FL Epoch: 468 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1594
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693948
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309124
INFO:root:FL Epoch: 468 Norm Difference for worker 1594 is 0.627984
INFO:root:FL Epoch: 468 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1908
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466078
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278967
INFO:root:FL Epoch: 468 Norm Difference for worker 1908 is 0.691074
INFO:root:FL Epoch: 468 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1554
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530552
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427506
INFO:root:FL Epoch: 468 Norm Difference for worker 1554 is 0.658862
INFO:root:FL Epoch: 468 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :568
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372887
INFO:root:Worker: 568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474402
INFO:root:FL Epoch: 468 Norm Difference for worker 568 is 0.712791
INFO:root:FL Epoch: 468 Done on worker:568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :373
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429172
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433340
INFO:root:FL Epoch: 468 Norm Difference for worker 373 is 0.714271
INFO:root:FL Epoch: 468 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :701
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331627
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522433
INFO:root:FL Epoch: 468 Norm Difference for worker 701 is 0.723972
INFO:root:FL Epoch: 468 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1004
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555022
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.970235
INFO:root:FL Epoch: 468 Norm Difference for worker 1004 is 0.71511
INFO:root:FL Epoch: 468 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.47353339721174803 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:2.247888525327047                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [1146, 1414, 292, 1435, 65, 326, 1129, 1916, 1239, 1630]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :1146
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471053
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675226
INFO:root:FL Epoch: 469 Norm Difference for worker 1146 is 0.75823
INFO:root:FL Epoch: 469 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1414
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291431
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398155
INFO:root:FL Epoch: 469 Norm Difference for worker 1414 is 0.630353
INFO:root:FL Epoch: 469 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :292
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 292 is 0.806108
INFO:root:FL Epoch: 469 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1435
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402096
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382930
INFO:root:FL Epoch: 469 Norm Difference for worker 1435 is 0.731858
INFO:root:FL Epoch: 469 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :65
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521048
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 65 is 0.701648
INFO:root:FL Epoch: 469 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :326
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 326 is 0.807497
INFO:root:FL Epoch: 469 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1129
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517448
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451360
INFO:root:FL Epoch: 469 Norm Difference for worker 1129 is 0.812381
INFO:root:FL Epoch: 469 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1916
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580916
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525787
INFO:root:FL Epoch: 469 Norm Difference for worker 1916 is 0.747804
INFO:root:FL Epoch: 469 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1239
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511172
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334801
INFO:root:FL Epoch: 469 Norm Difference for worker 1239 is 0.797993
INFO:root:FL Epoch: 469 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1630
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678114
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367393
INFO:root:FL Epoch: 469 Norm Difference for worker 1630 is 0.800288
INFO:root:FL Epoch: 469 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1414
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.47241677694460926 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:2.0360573728879294                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [1626, 633, 1053, 1213, 1201, 890, 213, 418, 1174, 249]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :1626
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752904
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508814
INFO:root:FL Epoch: 470 Norm Difference for worker 1626 is 0.813526
INFO:root:FL Epoch: 470 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :633
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821605
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361981
INFO:root:FL Epoch: 470 Norm Difference for worker 633 is 0.767627
INFO:root:FL Epoch: 470 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1053
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833252
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275805
INFO:root:FL Epoch: 470 Norm Difference for worker 1053 is 0.8235
INFO:root:FL Epoch: 470 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1213
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1213 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584713
INFO:root:Worker: 1213 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558939
INFO:root:FL Epoch: 470 Norm Difference for worker 1213 is 0.757107
INFO:root:FL Epoch: 470 Done on worker:1213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1201
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324049
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355458
INFO:root:FL Epoch: 470 Norm Difference for worker 1201 is 0.799511
INFO:root:FL Epoch: 470 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :890
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383594
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765280
INFO:root:FL Epoch: 470 Norm Difference for worker 890 is 0.90354
INFO:root:FL Epoch: 470 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :213
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 213 is 0.932285
INFO:root:FL Epoch: 470 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :418
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653983
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635704
INFO:root:FL Epoch: 470 Norm Difference for worker 418 is 0.843842
INFO:root:FL Epoch: 470 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1174
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848761
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549776
INFO:root:FL Epoch: 470 Norm Difference for worker 1174 is 0.835173
INFO:root:FL Epoch: 470 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :249
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.374935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 249 is 0.721278
INFO:root:FL Epoch: 470 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 633
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.4772057577091105 and Test Accuracy:75.0 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:2.202549715836843                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [1112, 725, 822, 1120, 683, 1849, 534, 57, 502, 1092]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :1112
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532473
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509337
INFO:root:FL Epoch: 471 Norm Difference for worker 1112 is 0.727147
INFO:root:FL Epoch: 471 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :725
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591944
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461450
INFO:root:FL Epoch: 471 Norm Difference for worker 725 is 0.752279
INFO:root:FL Epoch: 471 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :822
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503287
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425190
INFO:root:FL Epoch: 471 Norm Difference for worker 822 is 0.717227
INFO:root:FL Epoch: 471 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1120
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497531
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570471
INFO:root:FL Epoch: 471 Norm Difference for worker 1120 is 0.720785
INFO:root:FL Epoch: 471 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :683
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601943
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390060
INFO:root:FL Epoch: 471 Norm Difference for worker 683 is 0.680466
INFO:root:FL Epoch: 471 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1849
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353056
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312947
INFO:root:FL Epoch: 471 Norm Difference for worker 1849 is 0.646507
INFO:root:FL Epoch: 471 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :534
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591339
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551362
INFO:root:FL Epoch: 471 Norm Difference for worker 534 is 0.755523
INFO:root:FL Epoch: 471 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :57
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431640
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 57 is 0.714092
INFO:root:FL Epoch: 471 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :502
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553941
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563358
INFO:root:FL Epoch: 471 Norm Difference for worker 502 is 0.6781
INFO:root:FL Epoch: 471 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1092
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410376
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486504
INFO:root:FL Epoch: 471 Norm Difference for worker 1092 is 0.765673
INFO:root:FL Epoch: 471 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1849
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.46847062952378216 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:2.2859109242757163                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [197, 1625, 832, 481, 1053, 1700, 1515, 1061, 669, 968]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 472 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :197
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 197 is 0.804584
INFO:root:FL Epoch: 472 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1625
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664692
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589023
INFO:root:FL Epoch: 472 Norm Difference for worker 1625 is 0.768995
INFO:root:FL Epoch: 472 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :832
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759037
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629884
INFO:root:FL Epoch: 472 Norm Difference for worker 832 is 0.914198
INFO:root:FL Epoch: 472 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :481
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443032
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669678
INFO:root:FL Epoch: 472 Norm Difference for worker 481 is 0.835893
INFO:root:FL Epoch: 472 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1053
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307252
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557417
INFO:root:FL Epoch: 472 Norm Difference for worker 1053 is 0.782969
INFO:root:FL Epoch: 472 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1700
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391816
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367026
INFO:root:FL Epoch: 472 Norm Difference for worker 1700 is 0.793203
INFO:root:FL Epoch: 472 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1515
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466842
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448892
INFO:root:FL Epoch: 472 Norm Difference for worker 1515 is 0.834434
INFO:root:FL Epoch: 472 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1061
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431440
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281559
INFO:root:FL Epoch: 472 Norm Difference for worker 1061 is 0.658734
INFO:root:FL Epoch: 472 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :669
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432505
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679254
INFO:root:FL Epoch: 472 Norm Difference for worker 669 is 0.881195
INFO:root:FL Epoch: 472 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :968
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577247
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400755
INFO:root:FL Epoch: 472 Norm Difference for worker 968 is 0.804493
INFO:root:FL Epoch: 472 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.4696563350803712 and Test Accuracy:75.0 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:2.4265132745107016                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [1069, 122, 394, 1434, 1091, 1182, 990, 568, 544, 542]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 473 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :1069
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388709
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538054
INFO:root:FL Epoch: 473 Norm Difference for worker 1069 is 0.836465
INFO:root:FL Epoch: 473 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :122
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 473 Norm Difference for worker 122 is 0.762544
INFO:root:FL Epoch: 473 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :394
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421174
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463021
INFO:root:FL Epoch: 473 Norm Difference for worker 394 is 0.819346
INFO:root:FL Epoch: 473 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1434
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485946
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480745
INFO:root:FL Epoch: 473 Norm Difference for worker 1434 is 0.843648
INFO:root:FL Epoch: 473 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1091
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241352
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386203
INFO:root:FL Epoch: 473 Norm Difference for worker 1091 is 0.825209
INFO:root:FL Epoch: 473 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1182
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607248
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411443
INFO:root:FL Epoch: 473 Norm Difference for worker 1182 is 0.770963
INFO:root:FL Epoch: 473 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :990
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356116
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523567
INFO:root:FL Epoch: 473 Norm Difference for worker 990 is 0.901958
INFO:root:FL Epoch: 473 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :568
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544013
INFO:root:Worker: 568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449112
INFO:root:FL Epoch: 473 Norm Difference for worker 568 is 0.785896
INFO:root:FL Epoch: 473 Done on worker:568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :544
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562342
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428514
INFO:root:FL Epoch: 473 Norm Difference for worker 544 is 0.848527
INFO:root:FL Epoch: 473 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :542
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500119
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753504
INFO:root:FL Epoch: 473 Norm Difference for worker 542 is 0.739725
INFO:root:FL Epoch: 473 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 542
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.44723101661485787 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:1.934696654478709                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1465, 862, 486, 1115, 116, 1715, 1211, 250, 8, 395]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 201 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1465
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604324
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401726
INFO:root:FL Epoch: 474 Norm Difference for worker 1465 is 0.728694
INFO:root:FL Epoch: 474 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :862
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450189
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.844349
INFO:root:FL Epoch: 474 Norm Difference for worker 862 is 0.836465
INFO:root:FL Epoch: 474 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :486
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388080
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506487
INFO:root:FL Epoch: 474 Norm Difference for worker 486 is 0.707024
INFO:root:FL Epoch: 474 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1115
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635551
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413671
INFO:root:FL Epoch: 474 Norm Difference for worker 1115 is 0.686172
INFO:root:FL Epoch: 474 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :116
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423119
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 116 is 0.782566
INFO:root:FL Epoch: 474 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1715
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524428
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391863
INFO:root:FL Epoch: 474 Norm Difference for worker 1715 is 0.747191
INFO:root:FL Epoch: 474 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1211
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1211 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563272
INFO:root:Worker: 1211 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472564
INFO:root:FL Epoch: 474 Norm Difference for worker 1211 is 0.713864
INFO:root:FL Epoch: 474 Done on worker:1211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :250
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 250 is 0.750844
INFO:root:FL Epoch: 474 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :8
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 8 is 0.650723
INFO:root:FL Epoch: 474 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :395
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316935
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605524
INFO:root:FL Epoch: 474 Norm Difference for worker 395 is 0.759069
INFO:root:FL Epoch: 474 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.46378207031418295 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:1.6856075127919514                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1355, 1033, 405, 631, 933, 973, 1880, 1535, 288, 1831]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 475 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1355
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305458
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507823
INFO:root:FL Epoch: 475 Norm Difference for worker 1355 is 0.925353
INFO:root:FL Epoch: 475 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1033
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385831
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480473
INFO:root:FL Epoch: 475 Norm Difference for worker 1033 is 0.728671
INFO:root:FL Epoch: 475 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :405
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625549
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621733
INFO:root:FL Epoch: 475 Norm Difference for worker 405 is 0.796394
INFO:root:FL Epoch: 475 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :631
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457486
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624462
INFO:root:FL Epoch: 475 Norm Difference for worker 631 is 0.956227
INFO:root:FL Epoch: 475 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :933
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633476
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344377
INFO:root:FL Epoch: 475 Norm Difference for worker 933 is 0.84689
INFO:root:FL Epoch: 475 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :973
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339885
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497227
INFO:root:FL Epoch: 475 Norm Difference for worker 973 is 0.906837
INFO:root:FL Epoch: 475 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1880
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459801
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428534
INFO:root:FL Epoch: 475 Norm Difference for worker 1880 is 0.838607
INFO:root:FL Epoch: 475 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1535
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680014
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309575
INFO:root:FL Epoch: 475 Norm Difference for worker 1535 is 0.803841
INFO:root:FL Epoch: 475 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :288
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592006
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 288 is 0.848996
INFO:root:FL Epoch: 475 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1831
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363398
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397676
INFO:root:FL Epoch: 475 Norm Difference for worker 1831 is 0.805071
INFO:root:FL Epoch: 475 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1033
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.45550550783381744 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:2.0746448636054993                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [351, 135, 1608, 539, 612, 642, 123, 1128, 457, 27]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 476 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :351
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318619
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371420
INFO:root:FL Epoch: 476 Norm Difference for worker 351 is 0.74945
INFO:root:FL Epoch: 476 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :135
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 135 is 0.714402
INFO:root:FL Epoch: 476 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1608
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718952
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697233
INFO:root:FL Epoch: 476 Norm Difference for worker 1608 is 0.79544
INFO:root:FL Epoch: 476 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :539
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484156
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378149
INFO:root:FL Epoch: 476 Norm Difference for worker 539 is 0.762373
INFO:root:FL Epoch: 476 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :612
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.970361
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410263
INFO:root:FL Epoch: 476 Norm Difference for worker 612 is 0.795533
INFO:root:FL Epoch: 476 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :642
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760798
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541374
INFO:root:FL Epoch: 476 Norm Difference for worker 642 is 0.79526
INFO:root:FL Epoch: 476 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :123
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 123 is 0.784469
INFO:root:FL Epoch: 476 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1128
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356933
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512587
INFO:root:FL Epoch: 476 Norm Difference for worker 1128 is 0.792051
INFO:root:FL Epoch: 476 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :457
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.985633
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390791
INFO:root:FL Epoch: 476 Norm Difference for worker 457 is 0.776832
INFO:root:FL Epoch: 476 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :27
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495567
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 27 is 0.698163
INFO:root:FL Epoch: 476 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 27
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.4569943845272064 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:1.7722406387329102                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [525, 1441, 1694, 1174, 400, 418, 364, 781, 1589, 244]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 477 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :525
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591612
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604488
INFO:root:FL Epoch: 477 Norm Difference for worker 525 is 0.876003
INFO:root:FL Epoch: 477 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1441
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379156
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681945
INFO:root:FL Epoch: 477 Norm Difference for worker 1441 is 0.784291
INFO:root:FL Epoch: 477 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1694
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525111
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693041
INFO:root:FL Epoch: 477 Norm Difference for worker 1694 is 0.773971
INFO:root:FL Epoch: 477 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1174
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455637
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457587
INFO:root:FL Epoch: 477 Norm Difference for worker 1174 is 0.81901
INFO:root:FL Epoch: 477 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :400
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582848
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549378
INFO:root:FL Epoch: 477 Norm Difference for worker 400 is 0.743838
INFO:root:FL Epoch: 477 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :418
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523123
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465365
INFO:root:FL Epoch: 477 Norm Difference for worker 418 is 0.774127
INFO:root:FL Epoch: 477 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :364
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477508
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491976
INFO:root:FL Epoch: 477 Norm Difference for worker 364 is 0.780291
INFO:root:FL Epoch: 477 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :781
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682417
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466378
INFO:root:FL Epoch: 477 Norm Difference for worker 781 is 0.788853
INFO:root:FL Epoch: 477 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1589
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414007
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744789
INFO:root:FL Epoch: 477 Norm Difference for worker 1589 is 0.816204
INFO:root:FL Epoch: 477 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :244
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503776
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 244 is 0.737048
INFO:root:FL Epoch: 477 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 244
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.45656918252215667 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:1.8341098825136821                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [997, 1282, 284, 527, 1639, 469, 622, 1324, 1266, 728]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 478 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :997
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650813
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432337
INFO:root:FL Epoch: 478 Norm Difference for worker 997 is 0.71487
INFO:root:FL Epoch: 478 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1282
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593942
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552786
INFO:root:FL Epoch: 478 Norm Difference for worker 1282 is 0.740164
INFO:root:FL Epoch: 478 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :284
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 284 is 0.763873
INFO:root:FL Epoch: 478 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :527
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468038
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551469
INFO:root:FL Epoch: 478 Norm Difference for worker 527 is 0.714447
INFO:root:FL Epoch: 478 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1639
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569225
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496545
INFO:root:FL Epoch: 478 Norm Difference for worker 1639 is 0.699863
INFO:root:FL Epoch: 478 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :469
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547740
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599258
INFO:root:FL Epoch: 478 Norm Difference for worker 469 is 0.698975
INFO:root:FL Epoch: 478 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :622
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659101
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574344
INFO:root:FL Epoch: 478 Norm Difference for worker 622 is 0.723084
INFO:root:FL Epoch: 478 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1324
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550041
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368237
INFO:root:FL Epoch: 478 Norm Difference for worker 1324 is 0.747258
INFO:root:FL Epoch: 478 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1266
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565720
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486144
INFO:root:FL Epoch: 478 Norm Difference for worker 1266 is 0.700319
INFO:root:FL Epoch: 478 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :728
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404685
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664407
INFO:root:FL Epoch: 478 Norm Difference for worker 728 is 0.714251
INFO:root:FL Epoch: 478 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 469
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.48530933348571553 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:2.205682377020518                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [683, 1503, 202, 1165, 1946, 1742, 940, 525, 881, 105]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :683
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526728
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494555
INFO:root:FL Epoch: 479 Norm Difference for worker 683 is 0.715538
INFO:root:FL Epoch: 479 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1503
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499654
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432327
INFO:root:FL Epoch: 479 Norm Difference for worker 1503 is 0.748745
INFO:root:FL Epoch: 479 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :202
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567592
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 202 is 0.740815
INFO:root:FL Epoch: 479 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1165
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574222
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703046
INFO:root:FL Epoch: 479 Norm Difference for worker 1165 is 0.762172
INFO:root:FL Epoch: 479 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1946
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554939
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472870
INFO:root:FL Epoch: 479 Norm Difference for worker 1946 is 0.686801
INFO:root:FL Epoch: 479 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1742
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659561
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360358
INFO:root:FL Epoch: 479 Norm Difference for worker 1742 is 0.705785
INFO:root:FL Epoch: 479 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :940
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646914
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232841
INFO:root:FL Epoch: 479 Norm Difference for worker 940 is 0.667684
INFO:root:FL Epoch: 479 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :525
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559746
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361740
INFO:root:FL Epoch: 479 Norm Difference for worker 525 is 0.733938
INFO:root:FL Epoch: 479 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :881
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638631
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490658
INFO:root:FL Epoch: 479 Norm Difference for worker 881 is 0.623535
INFO:root:FL Epoch: 479 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :105
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 105 is 0.792049
INFO:root:FL Epoch: 479 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.45274120919844685 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:1.9693562388420105                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [1883, 864, 1369, 1815, 1184, 1661, 82, 1174, 1010, 462]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :1883
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589656
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519467
INFO:root:FL Epoch: 480 Norm Difference for worker 1883 is 0.808296
INFO:root:FL Epoch: 480 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :864
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619780
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549919
INFO:root:FL Epoch: 480 Norm Difference for worker 864 is 0.865359
INFO:root:FL Epoch: 480 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1369
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534894
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580561
INFO:root:FL Epoch: 480 Norm Difference for worker 1369 is 0.75968
INFO:root:FL Epoch: 480 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1815
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539291
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392563
INFO:root:FL Epoch: 480 Norm Difference for worker 1815 is 0.809861
INFO:root:FL Epoch: 480 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1184
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647712
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588061
INFO:root:FL Epoch: 480 Norm Difference for worker 1184 is 0.837724
INFO:root:FL Epoch: 480 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1661
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660717
INFO:root:Worker: 1661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579250
INFO:root:FL Epoch: 480 Norm Difference for worker 1661 is 0.796546
INFO:root:FL Epoch: 480 Done on worker:1661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :82
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646301
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 82 is 0.771695
INFO:root:FL Epoch: 480 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1174
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715158
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633915
INFO:root:FL Epoch: 480 Norm Difference for worker 1174 is 0.808517
INFO:root:FL Epoch: 480 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1010
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358910
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486948
INFO:root:FL Epoch: 480 Norm Difference for worker 1010 is 0.73556
INFO:root:FL Epoch: 480 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :462
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432825
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505029
INFO:root:FL Epoch: 480 Norm Difference for worker 462 is 0.815487
INFO:root:FL Epoch: 480 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.4689260037506328 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:2.0412116646766663                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [226, 1554, 53, 1169, 587, 459, 924, 1585, 52, 281]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 481 Num points on workers: [201 200 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :226
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 226 is 0.726257
INFO:root:FL Epoch: 481 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1554
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466245
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339563
INFO:root:FL Epoch: 481 Norm Difference for worker 1554 is 0.673623
INFO:root:FL Epoch: 481 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :53
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454763
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.269198
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 53 is 0.684
INFO:root:FL Epoch: 481 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1169
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306292
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450682
INFO:root:FL Epoch: 481 Norm Difference for worker 1169 is 0.671538
INFO:root:FL Epoch: 481 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :587
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686755
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364641
INFO:root:FL Epoch: 481 Norm Difference for worker 587 is 0.706444
INFO:root:FL Epoch: 481 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :459
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419932
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322966
INFO:root:FL Epoch: 481 Norm Difference for worker 459 is 0.65858
INFO:root:FL Epoch: 481 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :924
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776518
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529014
INFO:root:FL Epoch: 481 Norm Difference for worker 924 is 0.765902
INFO:root:FL Epoch: 481 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1585
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506483
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370277
INFO:root:FL Epoch: 481 Norm Difference for worker 1585 is 0.666477
INFO:root:FL Epoch: 481 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :52
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.367078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 52 is 0.73824
INFO:root:FL Epoch: 481 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :281
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 281 is 0.615069
INFO:root:FL Epoch: 481 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 281
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.45679571435732 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:1.6730443636576335                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [776, 1853, 1592, 1211, 917, 328, 708, 660, 1872, 426]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :776
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414889
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567626
INFO:root:FL Epoch: 482 Norm Difference for worker 776 is 0.658278
INFO:root:FL Epoch: 482 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1853
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419357
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474931
INFO:root:FL Epoch: 482 Norm Difference for worker 1853 is 0.70426
INFO:root:FL Epoch: 482 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1592
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555540
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736531
INFO:root:FL Epoch: 482 Norm Difference for worker 1592 is 0.752173
INFO:root:FL Epoch: 482 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1211
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1211 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570320
INFO:root:Worker: 1211 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336299
INFO:root:FL Epoch: 482 Norm Difference for worker 1211 is 0.619733
INFO:root:FL Epoch: 482 Done on worker:1211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :917
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703056
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480319
INFO:root:FL Epoch: 482 Norm Difference for worker 917 is 0.672095
INFO:root:FL Epoch: 482 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :328
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 328 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 328 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535922
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 328 is 0.721952
INFO:root:FL Epoch: 482 Done on worker:328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :708
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580098
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490394
INFO:root:FL Epoch: 482 Norm Difference for worker 708 is 0.648285
INFO:root:FL Epoch: 482 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :660
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512664
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409827
INFO:root:FL Epoch: 482 Norm Difference for worker 660 is 0.6549
INFO:root:FL Epoch: 482 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1872
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397407
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498249
INFO:root:FL Epoch: 482 Norm Difference for worker 1872 is 0.658597
INFO:root:FL Epoch: 482 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :426
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578415
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407530
INFO:root:FL Epoch: 482 Norm Difference for worker 426 is 0.632407
INFO:root:FL Epoch: 482 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1211
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.4518401570179883 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:1.6525215705235798                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [297, 160, 1880, 1871, 1390, 195, 1854, 406, 1605, 1873]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 483 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :297
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 297 is 0.705255
INFO:root:FL Epoch: 483 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :160
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.797391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 160 is 0.70048
INFO:root:FL Epoch: 483 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1880
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431539
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601121
INFO:root:FL Epoch: 483 Norm Difference for worker 1880 is 0.733381
INFO:root:FL Epoch: 483 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1871
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527964
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571774
INFO:root:FL Epoch: 483 Norm Difference for worker 1871 is 0.73669
INFO:root:FL Epoch: 483 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1390
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490942
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255851
INFO:root:FL Epoch: 483 Norm Difference for worker 1390 is 0.656804
INFO:root:FL Epoch: 483 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :195
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609083
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 195 is 0.684999
INFO:root:FL Epoch: 483 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1854
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656334
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470255
INFO:root:FL Epoch: 483 Norm Difference for worker 1854 is 0.811986
INFO:root:FL Epoch: 483 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :406
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648846
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.877590
INFO:root:FL Epoch: 483 Norm Difference for worker 406 is 0.740057
INFO:root:FL Epoch: 483 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1605
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630235
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700932
INFO:root:FL Epoch: 483 Norm Difference for worker 1605 is 0.69016
INFO:root:FL Epoch: 483 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1873
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448849
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341034
INFO:root:FL Epoch: 483 Norm Difference for worker 1873 is 0.682841
INFO:root:FL Epoch: 483 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1390
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.44786233849385204 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:1.8553579648335774                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [1054, 1339, 1759, 413, 1343, 1871, 757, 957, 1270, 626]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 484 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :1054
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569221
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477430
INFO:root:FL Epoch: 484 Norm Difference for worker 1054 is 0.733874
INFO:root:FL Epoch: 484 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1339
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853880
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500859
INFO:root:FL Epoch: 484 Norm Difference for worker 1339 is 0.712414
INFO:root:FL Epoch: 484 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1759
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409815
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634125
INFO:root:FL Epoch: 484 Norm Difference for worker 1759 is 0.703937
INFO:root:FL Epoch: 484 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :413
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783877
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515791
INFO:root:FL Epoch: 484 Norm Difference for worker 413 is 0.714412
INFO:root:FL Epoch: 484 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1343
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420955
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307036
INFO:root:FL Epoch: 484 Norm Difference for worker 1343 is 0.639084
INFO:root:FL Epoch: 484 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1871
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615051
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374866
INFO:root:FL Epoch: 484 Norm Difference for worker 1871 is 0.699673
INFO:root:FL Epoch: 484 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :757
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673271
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325690
INFO:root:FL Epoch: 484 Norm Difference for worker 757 is 0.671448
INFO:root:FL Epoch: 484 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :957
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447189
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424526
INFO:root:FL Epoch: 484 Norm Difference for worker 957 is 0.687961
INFO:root:FL Epoch: 484 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1270
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769377
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583943
INFO:root:FL Epoch: 484 Norm Difference for worker 1270 is 0.653068
INFO:root:FL Epoch: 484 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :626
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472840
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409660
INFO:root:FL Epoch: 484 Norm Difference for worker 626 is 0.668506
INFO:root:FL Epoch: 484 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.4492144093793981 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:2.1939337452252707                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [1946, 1921, 1204, 55, 19, 1741, 597, 338, 1656, 623]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 485 Num points on workers: [200 200 200 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :1946
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463547
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380081
INFO:root:FL Epoch: 485 Norm Difference for worker 1946 is 0.695599
INFO:root:FL Epoch: 485 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1921
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672872
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462850
INFO:root:FL Epoch: 485 Norm Difference for worker 1921 is 0.774344
INFO:root:FL Epoch: 485 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1204
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315328
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401945
INFO:root:FL Epoch: 485 Norm Difference for worker 1204 is 0.766766
INFO:root:FL Epoch: 485 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :55
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333493
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 55 is 0.659855
INFO:root:FL Epoch: 485 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :19
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252882
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 19 is 0.662868
INFO:root:FL Epoch: 485 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1741
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275388
INFO:root:Worker: 1741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405593
INFO:root:FL Epoch: 485 Norm Difference for worker 1741 is 0.630796
INFO:root:FL Epoch: 485 Done on worker:1741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :597
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566924
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389612
INFO:root:FL Epoch: 485 Norm Difference for worker 597 is 0.738348
INFO:root:FL Epoch: 485 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :338
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.197193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 338 is 0.642104
INFO:root:FL Epoch: 485 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1656
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548250
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588810
INFO:root:FL Epoch: 485 Norm Difference for worker 1656 is 0.680387
INFO:root:FL Epoch: 485 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :623
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833107
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696671
INFO:root:FL Epoch: 485 Norm Difference for worker 623 is 0.793093
INFO:root:FL Epoch: 485 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1741
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.43527329581625324 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:2.2980385224024453                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [854, 361, 1557, 334, 1942, 1872, 925, 510, 769, 1590]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :854
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.193787
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479470
INFO:root:FL Epoch: 486 Norm Difference for worker 854 is 0.795886
INFO:root:FL Epoch: 486 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :361
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507149
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675350
INFO:root:FL Epoch: 486 Norm Difference for worker 361 is 0.881553
INFO:root:FL Epoch: 486 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1557
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308193
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121887
INFO:root:FL Epoch: 486 Norm Difference for worker 1557 is 0.570751
INFO:root:FL Epoch: 486 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :334
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 334 is 0.77324
INFO:root:FL Epoch: 486 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1942
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629935
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424981
INFO:root:FL Epoch: 486 Norm Difference for worker 1942 is 0.823407
INFO:root:FL Epoch: 486 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1872
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662109
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413352
INFO:root:FL Epoch: 486 Norm Difference for worker 1872 is 0.788611
INFO:root:FL Epoch: 486 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :925
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532758
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232649
INFO:root:FL Epoch: 486 Norm Difference for worker 925 is 0.737297
INFO:root:FL Epoch: 486 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :510
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360583
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218889
INFO:root:FL Epoch: 486 Norm Difference for worker 510 is 0.805455
INFO:root:FL Epoch: 486 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :769
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723792
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431904
INFO:root:FL Epoch: 486 Norm Difference for worker 769 is 0.82383
INFO:root:FL Epoch: 486 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1590
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501857
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302303
INFO:root:FL Epoch: 486 Norm Difference for worker 1590 is 0.774212
INFO:root:FL Epoch: 486 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.4328828515375362 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:2.296250303586324                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1643, 1436, 738, 1035, 1146, 470, 1726, 96, 1725, 1356]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1643
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580235
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305407
INFO:root:FL Epoch: 487 Norm Difference for worker 1643 is 0.863952
INFO:root:FL Epoch: 487 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1436
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317787
INFO:root:Worker: 1436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353342
INFO:root:FL Epoch: 487 Norm Difference for worker 1436 is 0.803374
INFO:root:FL Epoch: 487 Done on worker:1436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :738
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524874
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463724
INFO:root:FL Epoch: 487 Norm Difference for worker 738 is 0.862911
INFO:root:FL Epoch: 487 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1035
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538579
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376390
INFO:root:FL Epoch: 487 Norm Difference for worker 1035 is 0.89367
INFO:root:FL Epoch: 487 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1146
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632556
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609864
INFO:root:FL Epoch: 487 Norm Difference for worker 1146 is 0.858897
INFO:root:FL Epoch: 487 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :470
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557340
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315539
INFO:root:FL Epoch: 487 Norm Difference for worker 470 is 0.858595
INFO:root:FL Epoch: 487 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1726
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576682
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690237
INFO:root:FL Epoch: 487 Norm Difference for worker 1726 is 0.915582
INFO:root:FL Epoch: 487 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :96
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.791604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626311
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 96 is 0.829513
INFO:root:FL Epoch: 487 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1725
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723854
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555734
INFO:root:FL Epoch: 487 Norm Difference for worker 1725 is 0.905473
INFO:root:FL Epoch: 487 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1356
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415395
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538878
INFO:root:FL Epoch: 487 Norm Difference for worker 1356 is 0.947447
INFO:root:FL Epoch: 487 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 96
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.4404993136139477 and Test Accuracy:80.88235294117646 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:1.9238061507542927                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [1918, 177, 73, 145, 116, 1140, 601, 211, 610, 1013]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.10024938 0.09975062
 0.09975062 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 488 Num points on workers: [200 201 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :1918
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311356
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274981
INFO:root:FL Epoch: 488 Norm Difference for worker 1918 is 0.685008
INFO:root:FL Epoch: 488 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :177
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 177 is 0.765283
INFO:root:FL Epoch: 488 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :73
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543456
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.244017
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 73 is 0.796983
INFO:root:FL Epoch: 488 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :145
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.216268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 145 is 0.574508
INFO:root:FL Epoch: 488 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :116
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 116 is 0.7573
INFO:root:FL Epoch: 488 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1140
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370053
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524527
INFO:root:FL Epoch: 488 Norm Difference for worker 1140 is 0.687114
INFO:root:FL Epoch: 488 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :601
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497983
INFO:root:Worker: 601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488079
INFO:root:FL Epoch: 488 Norm Difference for worker 601 is 0.684932
INFO:root:FL Epoch: 488 Done on worker:601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :211
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 211 is 0.693119
INFO:root:FL Epoch: 488 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :610
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563527
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288197
INFO:root:FL Epoch: 488 Norm Difference for worker 610 is 0.657381
INFO:root:FL Epoch: 488 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1013
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588399
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431803
INFO:root:FL Epoch: 488 Norm Difference for worker 1013 is 0.779577
INFO:root:FL Epoch: 488 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.4407224865520702 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:2.235339641571045                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [522, 1065, 1469, 68, 514, 629, 204, 1676, 1927, 237]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 200 201 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :522
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424163
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370279
INFO:root:FL Epoch: 489 Norm Difference for worker 522 is 0.755521
INFO:root:FL Epoch: 489 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1065
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365478
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439681
INFO:root:FL Epoch: 489 Norm Difference for worker 1065 is 0.874705
INFO:root:FL Epoch: 489 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1469
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709497
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.837493
INFO:root:FL Epoch: 489 Norm Difference for worker 1469 is 0.814768
INFO:root:FL Epoch: 489 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :68
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336452
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 68 is 0.8099
INFO:root:FL Epoch: 489 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :514
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522085
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297695
INFO:root:FL Epoch: 489 Norm Difference for worker 514 is 0.757541
INFO:root:FL Epoch: 489 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :629
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490397
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465592
INFO:root:FL Epoch: 489 Norm Difference for worker 629 is 0.803942
INFO:root:FL Epoch: 489 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :204
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 204 is 0.81311
INFO:root:FL Epoch: 489 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1676
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358075
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405981
INFO:root:FL Epoch: 489 Norm Difference for worker 1676 is 0.809802
INFO:root:FL Epoch: 489 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1927
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238676
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377809
INFO:root:FL Epoch: 489 Norm Difference for worker 1927 is 0.731775
INFO:root:FL Epoch: 489 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :237
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 237 is 0.804066
INFO:root:FL Epoch: 489 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1927
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.4466397087363636 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:2.2046389977137246                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [1584, 119, 876, 148, 1628, 1932, 1607, 1905, 1080, 1383]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 490 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :1584
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686442
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533387
INFO:root:FL Epoch: 490 Norm Difference for worker 1584 is 0.781726
INFO:root:FL Epoch: 490 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :119
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.273732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376830
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 119 is 0.768298
INFO:root:FL Epoch: 490 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :876
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682536
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387224
INFO:root:FL Epoch: 490 Norm Difference for worker 876 is 0.757655
INFO:root:FL Epoch: 490 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :148
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 148 is 0.817894
INFO:root:FL Epoch: 490 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1628
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455363
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173995
INFO:root:FL Epoch: 490 Norm Difference for worker 1628 is 0.718152
INFO:root:FL Epoch: 490 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1932
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467842
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585581
INFO:root:FL Epoch: 490 Norm Difference for worker 1932 is 0.810822
INFO:root:FL Epoch: 490 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1607
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270893
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454695
INFO:root:FL Epoch: 490 Norm Difference for worker 1607 is 0.78958
INFO:root:FL Epoch: 490 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1905
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488168
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361068
INFO:root:FL Epoch: 490 Norm Difference for worker 1905 is 0.605175
INFO:root:FL Epoch: 490 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1080
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601600
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572738
INFO:root:FL Epoch: 490 Norm Difference for worker 1080 is 0.877466
INFO:root:FL Epoch: 490 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1383
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630945
INFO:root:Worker: 1383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509920
INFO:root:FL Epoch: 490 Norm Difference for worker 1383 is 0.75234
INFO:root:FL Epoch: 490 Done on worker:1383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.45779532983022575 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:2.7279618183771768                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [928, 1722, 1300, 1623, 68, 1823, 1259, 1726, 638, 1375]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :928
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452308
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528226
INFO:root:FL Epoch: 491 Norm Difference for worker 928 is 0.755602
INFO:root:FL Epoch: 491 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1722
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554262
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531715
INFO:root:FL Epoch: 491 Norm Difference for worker 1722 is 0.82779
INFO:root:FL Epoch: 491 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1300
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519195
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493801
INFO:root:FL Epoch: 491 Norm Difference for worker 1300 is 0.823322
INFO:root:FL Epoch: 491 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1623
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 1.260284
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581876
INFO:root:FL Epoch: 491 Norm Difference for worker 1623 is 0.868888
INFO:root:FL Epoch: 491 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :68
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 68 is 0.829646
INFO:root:FL Epoch: 491 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1823
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377368
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435940
INFO:root:FL Epoch: 491 Norm Difference for worker 1823 is 0.90014
INFO:root:FL Epoch: 491 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1259
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486820
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409498
INFO:root:FL Epoch: 491 Norm Difference for worker 1259 is 0.825816
INFO:root:FL Epoch: 491 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1726
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512483
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422686
INFO:root:FL Epoch: 491 Norm Difference for worker 1726 is 0.880984
INFO:root:FL Epoch: 491 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :638
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644445
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447318
INFO:root:FL Epoch: 491 Norm Difference for worker 638 is 0.79937
INFO:root:FL Epoch: 491 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1375
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741273
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415336
INFO:root:FL Epoch: 491 Norm Difference for worker 1375 is 0.846587
INFO:root:FL Epoch: 491 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 928
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.4325705828035579 and Test Accuracy:80.29411764705883 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:2.363250414530436                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [1623, 1330, 169, 1279, 921, 269, 786, 598, 972, 642]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 492 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :1623
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446679
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339378
INFO:root:FL Epoch: 492 Norm Difference for worker 1623 is 0.854938
INFO:root:FL Epoch: 492 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1330
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636533
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522932
INFO:root:FL Epoch: 492 Norm Difference for worker 1330 is 0.927774
INFO:root:FL Epoch: 492 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :169
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546481
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 169 is 0.775869
INFO:root:FL Epoch: 492 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1279
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330619
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738215
INFO:root:FL Epoch: 492 Norm Difference for worker 1279 is 0.726482
INFO:root:FL Epoch: 492 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :921
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443952
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523579
INFO:root:FL Epoch: 492 Norm Difference for worker 921 is 0.80288
INFO:root:FL Epoch: 492 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :269
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308800
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 269 is 0.803298
INFO:root:FL Epoch: 492 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :786
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 1.056113
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360756
INFO:root:FL Epoch: 492 Norm Difference for worker 786 is 0.858963
INFO:root:FL Epoch: 492 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :598
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660997
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411181
INFO:root:FL Epoch: 492 Norm Difference for worker 598 is 0.748966
INFO:root:FL Epoch: 492 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :972
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.207241
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473380
INFO:root:FL Epoch: 492 Norm Difference for worker 972 is 0.842455
INFO:root:FL Epoch: 492 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :642
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612411
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603756
INFO:root:FL Epoch: 492 Norm Difference for worker 642 is 0.85284
INFO:root:FL Epoch: 492 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1279
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.4305559756124721 and Test Accuracy:80.58823529411765 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:2.1404823859532676                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [463, 1238, 1818, 1251, 609, 218, 1752, 1306, 1240, 738]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :463
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572052
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605978
INFO:root:FL Epoch: 493 Norm Difference for worker 463 is 0.766571
INFO:root:FL Epoch: 493 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1238
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600806
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623711
INFO:root:FL Epoch: 493 Norm Difference for worker 1238 is 0.758514
INFO:root:FL Epoch: 493 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1818
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411370
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485062
INFO:root:FL Epoch: 493 Norm Difference for worker 1818 is 0.683143
INFO:root:FL Epoch: 493 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1251
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511353
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493189
INFO:root:FL Epoch: 493 Norm Difference for worker 1251 is 0.780794
INFO:root:FL Epoch: 493 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :609
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340876
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404827
INFO:root:FL Epoch: 493 Norm Difference for worker 609 is 0.71964
INFO:root:FL Epoch: 493 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :218
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 218 is 0.692458
INFO:root:FL Epoch: 493 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1752
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462809
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335522
INFO:root:FL Epoch: 493 Norm Difference for worker 1752 is 0.692914
INFO:root:FL Epoch: 493 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1306
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564876
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.859690
INFO:root:FL Epoch: 493 Norm Difference for worker 1306 is 0.750621
INFO:root:FL Epoch: 493 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1240
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870240
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705164
INFO:root:FL Epoch: 493 Norm Difference for worker 1240 is 0.757411
INFO:root:FL Epoch: 493 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :738
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384049
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554591
INFO:root:FL Epoch: 493 Norm Difference for worker 738 is 0.699591
INFO:root:FL Epoch: 493 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1818
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.4366753206533544 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:2.2281526724497476                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [26, 1676, 270, 248, 1831, 598, 411, 390, 213, 573]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 494 Num points on workers: [201 200 201 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :26
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443493
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 26 is 0.739207
INFO:root:FL Epoch: 494 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1676
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587084
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478009
INFO:root:FL Epoch: 494 Norm Difference for worker 1676 is 0.67843
INFO:root:FL Epoch: 494 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :270
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562995
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 270 is 0.675575
INFO:root:FL Epoch: 494 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :248
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593375
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 248 is 0.663145
INFO:root:FL Epoch: 494 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1831
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436694
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479108
INFO:root:FL Epoch: 494 Norm Difference for worker 1831 is 0.670988
INFO:root:FL Epoch: 494 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :598
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552486
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500092
INFO:root:FL Epoch: 494 Norm Difference for worker 598 is 0.685623
INFO:root:FL Epoch: 494 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :411
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737301
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595357
INFO:root:FL Epoch: 494 Norm Difference for worker 411 is 0.759698
INFO:root:FL Epoch: 494 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :390
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624197
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.985764
INFO:root:FL Epoch: 494 Norm Difference for worker 390 is 0.738244
INFO:root:FL Epoch: 494 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :213
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 213 is 0.763038
INFO:root:FL Epoch: 494 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :573
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407820
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428820
INFO:root:FL Epoch: 494 Norm Difference for worker 573 is 0.725214
INFO:root:FL Epoch: 494 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 248
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.43685587977661805 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:2.397305488586426                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [1306, 649, 1928, 788, 155, 461, 1473, 792, 1736, 1855]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 495 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :1306
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422397
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383787
INFO:root:FL Epoch: 495 Norm Difference for worker 1306 is 0.75317
INFO:root:FL Epoch: 495 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :649
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532315
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471747
INFO:root:FL Epoch: 495 Norm Difference for worker 649 is 0.819212
INFO:root:FL Epoch: 495 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1928
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453729
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399218
INFO:root:FL Epoch: 495 Norm Difference for worker 1928 is 0.710808
INFO:root:FL Epoch: 495 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :788
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535144
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363499
INFO:root:FL Epoch: 495 Norm Difference for worker 788 is 0.740403
INFO:root:FL Epoch: 495 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :155
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 155 is 0.73694
INFO:root:FL Epoch: 495 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :461
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749145
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520028
INFO:root:FL Epoch: 495 Norm Difference for worker 461 is 0.652055
INFO:root:FL Epoch: 495 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1473
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666636
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479017
INFO:root:FL Epoch: 495 Norm Difference for worker 1473 is 0.835728
INFO:root:FL Epoch: 495 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :792
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404007
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448517
INFO:root:FL Epoch: 495 Norm Difference for worker 792 is 0.647905
INFO:root:FL Epoch: 495 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1736
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460851
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743981
INFO:root:FL Epoch: 495 Norm Difference for worker 1736 is 0.747197
INFO:root:FL Epoch: 495 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1855
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684124
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380044
INFO:root:FL Epoch: 495 Norm Difference for worker 1855 is 0.70954
INFO:root:FL Epoch: 495 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.45048729724743786 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:2.431784470876058                             and Backdoor Test Accuracy:1.6666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [297, 1684, 826, 732, 1321, 190, 239, 49, 1513, 1880]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 496 Num points on workers: [201 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :297
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461043
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 297 is 0.739524
INFO:root:FL Epoch: 496 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1684
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488862
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639107
INFO:root:FL Epoch: 496 Norm Difference for worker 1684 is 0.807234
INFO:root:FL Epoch: 496 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :826
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907481
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650354
INFO:root:FL Epoch: 496 Norm Difference for worker 826 is 0.813785
INFO:root:FL Epoch: 496 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :732
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465994
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492807
INFO:root:FL Epoch: 496 Norm Difference for worker 732 is 0.696665
INFO:root:FL Epoch: 496 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1321
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665030
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435695
INFO:root:FL Epoch: 496 Norm Difference for worker 1321 is 0.769675
INFO:root:FL Epoch: 496 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :190
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614982
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 190 is 0.765279
INFO:root:FL Epoch: 496 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :239
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387542
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 239 is 0.766958
INFO:root:FL Epoch: 496 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :49
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341179
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 49 is 0.759046
INFO:root:FL Epoch: 496 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1513
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545767
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503188
INFO:root:FL Epoch: 496 Norm Difference for worker 1513 is 0.68742
INFO:root:FL Epoch: 496 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1880
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620900
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695679
INFO:root:FL Epoch: 496 Norm Difference for worker 1880 is 0.73187
INFO:root:FL Epoch: 496 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 732
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.44006475017351265 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:1.8675539294878643                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [1128, 131, 606, 564, 913, 818, 618, 1195, 949, 1625]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 497 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :1128
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400269
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564433
INFO:root:FL Epoch: 497 Norm Difference for worker 1128 is 0.666513
INFO:root:FL Epoch: 497 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :131
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.738278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 131 is 0.673101
INFO:root:FL Epoch: 497 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :606
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472970
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347011
INFO:root:FL Epoch: 497 Norm Difference for worker 606 is 0.646268
INFO:root:FL Epoch: 497 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :564
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409659
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353996
INFO:root:FL Epoch: 497 Norm Difference for worker 564 is 0.704461
INFO:root:FL Epoch: 497 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :913
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623301
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458196
INFO:root:FL Epoch: 497 Norm Difference for worker 913 is 0.705982
INFO:root:FL Epoch: 497 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :818
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466183
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418859
INFO:root:FL Epoch: 497 Norm Difference for worker 818 is 0.649781
INFO:root:FL Epoch: 497 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :618
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363036
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274442
INFO:root:FL Epoch: 497 Norm Difference for worker 618 is 0.665979
INFO:root:FL Epoch: 497 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1195
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389190
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424555
INFO:root:FL Epoch: 497 Norm Difference for worker 1195 is 0.64112
INFO:root:FL Epoch: 497 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :949
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406901
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464954
INFO:root:FL Epoch: 497 Norm Difference for worker 949 is 0.642404
INFO:root:FL Epoch: 497 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1625
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509225
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344915
INFO:root:FL Epoch: 497 Norm Difference for worker 1625 is 0.641586
INFO:root:FL Epoch: 497 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 949
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.43919175337342653 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:1.8749282360076904                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [1000, 1033, 1128, 556, 1817, 987, 1171, 1083, 491, 1149]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :1000
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749582
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513767
INFO:root:FL Epoch: 498 Norm Difference for worker 1000 is 0.637634
INFO:root:FL Epoch: 498 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1033
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408155
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407628
INFO:root:FL Epoch: 498 Norm Difference for worker 1033 is 0.554442
INFO:root:FL Epoch: 498 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1128
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467336
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396144
INFO:root:FL Epoch: 498 Norm Difference for worker 1128 is 0.671779
INFO:root:FL Epoch: 498 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :556
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506906
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606117
INFO:root:FL Epoch: 498 Norm Difference for worker 556 is 0.700275
INFO:root:FL Epoch: 498 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1817
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610313
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386706
INFO:root:FL Epoch: 498 Norm Difference for worker 1817 is 0.654943
INFO:root:FL Epoch: 498 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :987
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494018
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506192
INFO:root:FL Epoch: 498 Norm Difference for worker 987 is 0.634784
INFO:root:FL Epoch: 498 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1171
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462109
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590451
INFO:root:FL Epoch: 498 Norm Difference for worker 1171 is 0.654852
INFO:root:FL Epoch: 498 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1083
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825083
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827983
INFO:root:FL Epoch: 498 Norm Difference for worker 1083 is 0.655046
INFO:root:FL Epoch: 498 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :491
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649074
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497568
INFO:root:FL Epoch: 498 Norm Difference for worker 491 is 0.679186
INFO:root:FL Epoch: 498 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1149
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519374
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568533
INFO:root:FL Epoch: 498 Norm Difference for worker 1149 is 0.697937
INFO:root:FL Epoch: 498 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1033
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.43133673685438495 and Test Accuracy:80.0 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:2.2626073360443115                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1665, 290, 987, 1493, 30, 1676, 1913, 45, 1817, 908]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 499 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1665
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509575
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263036
INFO:root:FL Epoch: 499 Norm Difference for worker 1665 is 0.679152
INFO:root:FL Epoch: 499 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :290
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.400448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 290 is 0.835153
INFO:root:FL Epoch: 499 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :987
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469653
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422172
INFO:root:FL Epoch: 499 Norm Difference for worker 987 is 0.737861
INFO:root:FL Epoch: 499 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1493
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658918
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517418
INFO:root:FL Epoch: 499 Norm Difference for worker 1493 is 0.760432
INFO:root:FL Epoch: 499 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :30
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 30 is 0.753607
INFO:root:FL Epoch: 499 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1676
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592174
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479575
INFO:root:FL Epoch: 499 Norm Difference for worker 1676 is 0.736832
INFO:root:FL Epoch: 499 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1913
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617596
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559446
INFO:root:FL Epoch: 499 Norm Difference for worker 1913 is 0.823721
INFO:root:FL Epoch: 499 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :45
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 45 is 0.764839
INFO:root:FL Epoch: 499 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1817
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370117
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596080
INFO:root:FL Epoch: 499 Norm Difference for worker 1817 is 0.734505
INFO:root:FL Epoch: 499 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :908
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368904
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408431
INFO:root:FL Epoch: 499 Norm Difference for worker 908 is 0.737461
INFO:root:FL Epoch: 499 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1665
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.43179309368133545 and Test Accuracy:80.0 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:2.0290876626968384                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [1112, 387, 679, 257, 1728, 477, 454, 313, 758, 456]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :1112
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499593
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648385
INFO:root:FL Epoch: 500 Norm Difference for worker 1112 is 0.681203
INFO:root:FL Epoch: 500 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :387
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691023
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357708
INFO:root:FL Epoch: 500 Norm Difference for worker 387 is 0.799426
INFO:root:FL Epoch: 500 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :679
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576015
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387744
INFO:root:FL Epoch: 500 Norm Difference for worker 679 is 0.640723
INFO:root:FL Epoch: 500 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :257
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584712
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395135
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 257 is 0.757817
INFO:root:FL Epoch: 500 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1728
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550803
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414186
INFO:root:FL Epoch: 500 Norm Difference for worker 1728 is 0.805242
INFO:root:FL Epoch: 500 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :477
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409596
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283229
INFO:root:FL Epoch: 500 Norm Difference for worker 477 is 0.580428
INFO:root:FL Epoch: 500 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :454
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521276
INFO:root:Worker: 454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429629
INFO:root:FL Epoch: 500 Norm Difference for worker 454 is 0.680476
INFO:root:FL Epoch: 500 Done on worker:454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :313
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471556
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 313 is 0.707752
INFO:root:FL Epoch: 500 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :758
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717118
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331443
INFO:root:FL Epoch: 500 Norm Difference for worker 758 is 0.70939
INFO:root:FL Epoch: 500 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :456
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633144
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542335
INFO:root:FL Epoch: 500 Norm Difference for worker 456 is 0.662931
INFO:root:FL Epoch: 500 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.4431120858472936 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:2.5143508513768515                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/noattack-krum-baseline//stats.csv ******
