INFO:root: noDefense: False
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [1606, 1878, 862, 1182, 1092, 730, 1171, 786, 594, 622]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :1606
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698303
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697776
INFO:root:FL Epoch: 1 Norm Difference for worker 1606 is 0.315865
INFO:root:FL Epoch: 1 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1878
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690026
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661391
INFO:root:FL Epoch: 1 Norm Difference for worker 1878 is 0.410548
INFO:root:FL Epoch: 1 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :862
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690099
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692415
INFO:root:FL Epoch: 1 Norm Difference for worker 862 is 0.311819
INFO:root:FL Epoch: 1 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1182
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691611
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693252
INFO:root:FL Epoch: 1 Norm Difference for worker 1182 is 0.307113
INFO:root:FL Epoch: 1 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1092
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692119
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685201
INFO:root:FL Epoch: 1 Norm Difference for worker 1092 is 0.296813
INFO:root:FL Epoch: 1 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :730
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694413
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682774
INFO:root:FL Epoch: 1 Norm Difference for worker 730 is 0.295464
INFO:root:FL Epoch: 1 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1171
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685938
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691727
INFO:root:FL Epoch: 1 Norm Difference for worker 1171 is 0.302236
INFO:root:FL Epoch: 1 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :786
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696200
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703516
INFO:root:FL Epoch: 1 Norm Difference for worker 786 is 0.28311
INFO:root:FL Epoch: 1 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :594
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693030
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675873
INFO:root:FL Epoch: 1 Norm Difference for worker 594 is 0.348142
INFO:root:FL Epoch: 1 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :622
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695827
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689992
INFO:root:FL Epoch: 1 Norm Difference for worker 622 is 0.364429
INFO:root:FL Epoch: 1 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1092
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 1 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 1 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6904877354117 and Test Accuracy:52.94117647058823 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6709586878617605                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1014, 541, 1235, 1385, 766, 1091, 1598, 274, 205, 157]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1014
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688270
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690192
INFO:root:FL Epoch: 2 Norm Difference for worker 1014 is 0.293343
INFO:root:FL Epoch: 2 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :541
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697292
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686423
INFO:root:FL Epoch: 2 Norm Difference for worker 541 is 0.283175
INFO:root:FL Epoch: 2 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1235
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699042
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679857
INFO:root:FL Epoch: 2 Norm Difference for worker 1235 is 0.355588
INFO:root:FL Epoch: 2 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1385
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683652
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702759
INFO:root:FL Epoch: 2 Norm Difference for worker 1385 is 0.295346
INFO:root:FL Epoch: 2 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :766
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695212
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680198
INFO:root:FL Epoch: 2 Norm Difference for worker 766 is 0.363824
INFO:root:FL Epoch: 2 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1091
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687731
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695188
INFO:root:FL Epoch: 2 Norm Difference for worker 1091 is 0.292763
INFO:root:FL Epoch: 2 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700485
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699368
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.34881
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :274
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 274 is 0.324434
INFO:root:FL Epoch: 2 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :205
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 205 is 0.332548
INFO:root:FL Epoch: 2 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :157
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 157 is 0.349797
INFO:root:FL Epoch: 2 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1091
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 2 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 2 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6873041286188013 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.6955914199352264                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [519, 894, 617, 1462, 1278, 1505, 427, 1685, 1714, 1913]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 3 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :519
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675287
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687964
INFO:root:FL Epoch: 3 Norm Difference for worker 519 is 0.325098
INFO:root:FL Epoch: 3 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :894
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693719
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688630
INFO:root:FL Epoch: 3 Norm Difference for worker 894 is 0.322266
INFO:root:FL Epoch: 3 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :617
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685023
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658362
INFO:root:FL Epoch: 3 Norm Difference for worker 617 is 0.434134
INFO:root:FL Epoch: 3 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1462
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680702
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715223
INFO:root:FL Epoch: 3 Norm Difference for worker 1462 is 0.418623
INFO:root:FL Epoch: 3 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689015
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657424
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.328717
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1505
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673720
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671090
INFO:root:FL Epoch: 3 Norm Difference for worker 1505 is 0.367225
INFO:root:FL Epoch: 3 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :427
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690807
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680410
INFO:root:FL Epoch: 3 Norm Difference for worker 427 is 0.318015
INFO:root:FL Epoch: 3 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1685
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681838
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692472
INFO:root:FL Epoch: 3 Norm Difference for worker 1685 is 0.3096
INFO:root:FL Epoch: 3 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1714
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689839
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665922
INFO:root:FL Epoch: 3 Norm Difference for worker 1714 is 0.394681
INFO:root:FL Epoch: 3 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1913
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697197
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680728
INFO:root:FL Epoch: 3 Norm Difference for worker 1913 is 0.367458
INFO:root:FL Epoch: 3 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6835638600237229 and Test Accuracy:55.88235294117647 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.7282120486100515                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [950, 1406, 1256, 1070, 1080, 1610, 532, 872, 619, 1157]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :950
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695574
INFO:root:FL Epoch: 4 Norm Difference for worker 950 is 0.420743
INFO:root:FL Epoch: 4 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1406
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680650
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684730
INFO:root:FL Epoch: 4 Norm Difference for worker 1406 is 0.435952
INFO:root:FL Epoch: 4 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1256
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680475
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694189
INFO:root:FL Epoch: 4 Norm Difference for worker 1256 is 0.41708
INFO:root:FL Epoch: 4 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1070
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678631
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704725
INFO:root:FL Epoch: 4 Norm Difference for worker 1070 is 0.412219
INFO:root:FL Epoch: 4 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1080
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694687
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681909
INFO:root:FL Epoch: 4 Norm Difference for worker 1080 is 0.386024
INFO:root:FL Epoch: 4 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1610
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702770
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694707
INFO:root:FL Epoch: 4 Norm Difference for worker 1610 is 0.365404
INFO:root:FL Epoch: 4 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :532
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671502
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679865
INFO:root:FL Epoch: 4 Norm Difference for worker 532 is 0.365387
INFO:root:FL Epoch: 4 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :872
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715083
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674203
INFO:root:FL Epoch: 4 Norm Difference for worker 872 is 0.359627
INFO:root:FL Epoch: 4 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :619
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682464
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690347
INFO:root:FL Epoch: 4 Norm Difference for worker 619 is 0.354653
INFO:root:FL Epoch: 4 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1157
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693386
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672336
INFO:root:FL Epoch: 4 Norm Difference for worker 1157 is 0.358723
INFO:root:FL Epoch: 4 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 872
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 4 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 4 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6808902270653668 and Test Accuracy:56.470588235294116 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.7152616580327352                             and Backdoor Test Accuracy:35.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [1195, 749, 491, 1167, 1623, 1225, 1025, 1361, 552, 1010]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 5 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :1195
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688112
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702013
INFO:root:FL Epoch: 5 Norm Difference for worker 1195 is 0.381491
INFO:root:FL Epoch: 5 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :749
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678915
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666216
INFO:root:FL Epoch: 5 Norm Difference for worker 749 is 0.419416
INFO:root:FL Epoch: 5 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :491
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668493
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607064
INFO:root:FL Epoch: 5 Norm Difference for worker 491 is 0.473453
INFO:root:FL Epoch: 5 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1167
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691964
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679230
INFO:root:FL Epoch: 5 Norm Difference for worker 1167 is 0.436478
INFO:root:FL Epoch: 5 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1623
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713713
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654386
INFO:root:FL Epoch: 5 Norm Difference for worker 1623 is 0.438007
INFO:root:FL Epoch: 5 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1225
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704647
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650474
INFO:root:FL Epoch: 5 Norm Difference for worker 1225 is 0.390061
INFO:root:FL Epoch: 5 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1025
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685034
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706514
INFO:root:FL Epoch: 5 Norm Difference for worker 1025 is 0.398544
INFO:root:FL Epoch: 5 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1361
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698796
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666910
INFO:root:FL Epoch: 5 Norm Difference for worker 1361 is 0.39831
INFO:root:FL Epoch: 5 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :552
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655898
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672479
INFO:root:FL Epoch: 5 Norm Difference for worker 552 is 0.382206
INFO:root:FL Epoch: 5 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1010
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685626
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661644
INFO:root:FL Epoch: 5 Norm Difference for worker 1010 is 0.401055
INFO:root:FL Epoch: 5 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1195
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 5 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 5 Saved Best Checkpoint at this epoch.
INFO:root:FL Epoch: 5 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 5 Saved Checkpoint at this epoch.
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6800960477660684 and Test Accuracy:57.94117647058823 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.67825119694074                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [31, 1357, 315, 1846, 246, 622, 809, 1763, 1350, 1677]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 6 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :31
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 31 is 0.463941
INFO:root:FL Epoch: 6 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1357
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672492
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630422
INFO:root:FL Epoch: 6 Norm Difference for worker 1357 is 0.429524
INFO:root:FL Epoch: 6 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :315
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 315 is 0.447597
INFO:root:FL Epoch: 6 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1846
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652520
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653338
INFO:root:FL Epoch: 6 Norm Difference for worker 1846 is 0.49554
INFO:root:FL Epoch: 6 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :246
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 246 is 0.416872
INFO:root:FL Epoch: 6 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :622
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690243
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671184
INFO:root:FL Epoch: 6 Norm Difference for worker 622 is 0.535324
INFO:root:FL Epoch: 6 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :809
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678840
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671494
INFO:root:FL Epoch: 6 Norm Difference for worker 809 is 0.439261
INFO:root:FL Epoch: 6 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1763
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677125
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684787
INFO:root:FL Epoch: 6 Norm Difference for worker 1763 is 0.422239
INFO:root:FL Epoch: 6 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1350
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678017
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676922
INFO:root:FL Epoch: 6 Norm Difference for worker 1350 is 0.429529
INFO:root:FL Epoch: 6 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1677
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689115
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712885
INFO:root:FL Epoch: 6 Norm Difference for worker 1677 is 0.389578
INFO:root:FL Epoch: 6 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 6 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 6 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6791893419097451 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7462107439835867                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [133, 1254, 1016, 294, 1554, 626, 129, 421, 349, 1823]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 7 Num points on workers: [201 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :133
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 133 is 0.592525
INFO:root:FL Epoch: 7 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1254
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672263
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708007
INFO:root:FL Epoch: 7 Norm Difference for worker 1254 is 0.430365
INFO:root:FL Epoch: 7 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1016
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685157
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677568
INFO:root:FL Epoch: 7 Norm Difference for worker 1016 is 0.586352
INFO:root:FL Epoch: 7 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :294
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 294 is 0.51755
INFO:root:FL Epoch: 7 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1554
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679752
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631606
INFO:root:FL Epoch: 7 Norm Difference for worker 1554 is 0.613193
INFO:root:FL Epoch: 7 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :626
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658054
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648782
INFO:root:FL Epoch: 7 Norm Difference for worker 626 is 0.470783
INFO:root:FL Epoch: 7 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :129
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.720801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 129 is 0.494063
INFO:root:FL Epoch: 7 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :421
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650343
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685247
INFO:root:FL Epoch: 7 Norm Difference for worker 421 is 0.544514
INFO:root:FL Epoch: 7 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :349
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678959
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674855
INFO:root:FL Epoch: 7 Norm Difference for worker 349 is 0.49836
INFO:root:FL Epoch: 7 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1823
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674082
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669515
INFO:root:FL Epoch: 7 Norm Difference for worker 1823 is 0.457305
INFO:root:FL Epoch: 7 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 129
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6845992593204274 and Test Accuracy:55.0 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.6052607893943787                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1491, 829, 387, 923, 162, 1926, 1235, 474, 1585, 270]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1491
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711151
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649916
INFO:root:FL Epoch: 8 Norm Difference for worker 1491 is 0.496732
INFO:root:FL Epoch: 8 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :829
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708140
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669169
INFO:root:FL Epoch: 8 Norm Difference for worker 829 is 0.590356
INFO:root:FL Epoch: 8 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :387
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710557
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615421
INFO:root:FL Epoch: 8 Norm Difference for worker 387 is 0.678799
INFO:root:FL Epoch: 8 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :923
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700215
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695126
INFO:root:FL Epoch: 8 Norm Difference for worker 923 is 0.504445
INFO:root:FL Epoch: 8 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :162
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 162 is 0.48697
INFO:root:FL Epoch: 8 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1926
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636471
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614123
INFO:root:FL Epoch: 8 Norm Difference for worker 1926 is 0.64234
INFO:root:FL Epoch: 8 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1235
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646957
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670595
INFO:root:FL Epoch: 8 Norm Difference for worker 1235 is 0.629064
INFO:root:FL Epoch: 8 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :474
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706656
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686926
INFO:root:FL Epoch: 8 Norm Difference for worker 474 is 0.504277
INFO:root:FL Epoch: 8 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1585
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737924
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666208
INFO:root:FL Epoch: 8 Norm Difference for worker 1585 is 0.618062
INFO:root:FL Epoch: 8 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :270
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 270 is 0.593042
INFO:root:FL Epoch: 8 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 474
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6763278947157019 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7813432713349661                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1241, 255, 1012, 1069, 1613, 633, 757, 656, 26, 342]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1241
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662751
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666862
INFO:root:FL Epoch: 9 Norm Difference for worker 1241 is 0.461566
INFO:root:FL Epoch: 9 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :255
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 255 is 0.516371
INFO:root:FL Epoch: 9 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1012
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631705
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662657
INFO:root:FL Epoch: 9 Norm Difference for worker 1012 is 0.525269
INFO:root:FL Epoch: 9 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1069
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706726
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723550
INFO:root:FL Epoch: 9 Norm Difference for worker 1069 is 0.548774
INFO:root:FL Epoch: 9 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1613
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672571
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666181
INFO:root:FL Epoch: 9 Norm Difference for worker 1613 is 0.537465
INFO:root:FL Epoch: 9 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :633
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701924
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680043
INFO:root:FL Epoch: 9 Norm Difference for worker 633 is 0.476103
INFO:root:FL Epoch: 9 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :757
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719564
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667822
INFO:root:FL Epoch: 9 Norm Difference for worker 757 is 0.480098
INFO:root:FL Epoch: 9 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :656
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650350
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689619
INFO:root:FL Epoch: 9 Norm Difference for worker 656 is 0.487723
INFO:root:FL Epoch: 9 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :26
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 26 is 0.491555
INFO:root:FL Epoch: 9 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :342
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664635
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704288
INFO:root:FL Epoch: 9 Norm Difference for worker 342 is 0.483693
INFO:root:FL Epoch: 9 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 342
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 9 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 9 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6707131967825049 and Test Accuracy:60.0 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.7327591677506765                             and Backdoor Test Accuracy:32.5 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [320, 1389, 1454, 771, 402, 1183, 714, 25, 534, 289]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :320
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 320 is 0.597565
INFO:root:FL Epoch: 10 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1389
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692398
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672887
INFO:root:FL Epoch: 10 Norm Difference for worker 1389 is 0.582813
INFO:root:FL Epoch: 10 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663377
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649196
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.575451
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :771
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674906
INFO:root:Worker: 771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659812
INFO:root:FL Epoch: 10 Norm Difference for worker 771 is 0.567872
INFO:root:FL Epoch: 10 Done on worker:771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :402
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682862
INFO:root:Worker: 402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645416
INFO:root:FL Epoch: 10 Norm Difference for worker 402 is 0.594518
INFO:root:FL Epoch: 10 Done on worker:402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1183
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660553
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667716
INFO:root:FL Epoch: 10 Norm Difference for worker 1183 is 0.601717
INFO:root:FL Epoch: 10 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :714
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719651
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719518
INFO:root:FL Epoch: 10 Norm Difference for worker 714 is 0.53675
INFO:root:FL Epoch: 10 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :25
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 25 is 0.548212
INFO:root:FL Epoch: 10 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :534
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678415
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670338
INFO:root:FL Epoch: 10 Norm Difference for worker 534 is 0.562953
INFO:root:FL Epoch: 10 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :289
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 289 is 0.537703
INFO:root:FL Epoch: 10 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 10 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 10 Saved Checkpoint at this epoch.
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6682054680936477 and Test Accuracy:58.529411764705884 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.813973863919576                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [897, 1516, 1771, 1392, 371, 1021, 1479, 1242, 95, 293]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :897
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677632
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712199
INFO:root:FL Epoch: 11 Norm Difference for worker 897 is 0.598732
INFO:root:FL Epoch: 11 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1516
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666731
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622793
INFO:root:FL Epoch: 11 Norm Difference for worker 1516 is 0.699413
INFO:root:FL Epoch: 11 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1771
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751801
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723804
INFO:root:FL Epoch: 11 Norm Difference for worker 1771 is 0.628153
INFO:root:FL Epoch: 11 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1392
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653414
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654344
INFO:root:FL Epoch: 11 Norm Difference for worker 1392 is 0.658027
INFO:root:FL Epoch: 11 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :371
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632979
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646524
INFO:root:FL Epoch: 11 Norm Difference for worker 371 is 0.625206
INFO:root:FL Epoch: 11 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1021
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671960
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569546
INFO:root:FL Epoch: 11 Norm Difference for worker 1021 is 0.684437
INFO:root:FL Epoch: 11 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1479
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679542
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557976
INFO:root:FL Epoch: 11 Norm Difference for worker 1479 is 0.750861
INFO:root:FL Epoch: 11 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1242
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643558
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657605
INFO:root:FL Epoch: 11 Norm Difference for worker 1242 is 0.694646
INFO:root:FL Epoch: 11 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :95
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 95 is 0.673073
INFO:root:FL Epoch: 11 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :293
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 293 is 0.637116
INFO:root:FL Epoch: 11 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 897
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 11 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 11 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6719137114637038 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.8112753828366598                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1404, 1927, 378, 123, 800, 838, 1754, 1772, 687, 1641]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1404
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671942
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597792
INFO:root:FL Epoch: 12 Norm Difference for worker 1404 is 0.766461
INFO:root:FL Epoch: 12 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1927
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656490
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628906
INFO:root:FL Epoch: 12 Norm Difference for worker 1927 is 0.65828
INFO:root:FL Epoch: 12 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :378
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663870
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669462
INFO:root:FL Epoch: 12 Norm Difference for worker 378 is 0.628879
INFO:root:FL Epoch: 12 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :123
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 123 is 0.68695
INFO:root:FL Epoch: 12 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :800
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685839
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684328
INFO:root:FL Epoch: 12 Norm Difference for worker 800 is 0.751732
INFO:root:FL Epoch: 12 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :838
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680380
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693271
INFO:root:FL Epoch: 12 Norm Difference for worker 838 is 0.685891
INFO:root:FL Epoch: 12 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1754
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596688
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599514
INFO:root:FL Epoch: 12 Norm Difference for worker 1754 is 0.750137
INFO:root:FL Epoch: 12 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1772
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651219
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614115
INFO:root:FL Epoch: 12 Norm Difference for worker 1772 is 0.631573
INFO:root:FL Epoch: 12 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :687
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701503
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630098
INFO:root:FL Epoch: 12 Norm Difference for worker 687 is 0.672358
INFO:root:FL Epoch: 12 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1641
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640392
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590563
INFO:root:FL Epoch: 12 Norm Difference for worker 1641 is 0.636346
INFO:root:FL Epoch: 12 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1641
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6726871097789091 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.7311789194742838                             and Backdoor Test Accuracy:38.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1902, 1208, 440, 230, 114, 200, 1579, 604, 1302, 1873]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1902
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686722
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645202
INFO:root:FL Epoch: 13 Norm Difference for worker 1902 is 0.722339
INFO:root:FL Epoch: 13 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1208
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680390
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587982
INFO:root:FL Epoch: 13 Norm Difference for worker 1208 is 0.754557
INFO:root:FL Epoch: 13 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :440
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637242
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652189
INFO:root:FL Epoch: 13 Norm Difference for worker 440 is 0.739878
INFO:root:FL Epoch: 13 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :230
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 230 is 0.688962
INFO:root:FL Epoch: 13 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :114
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 114 is 0.755093
INFO:root:FL Epoch: 13 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :200
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 200 is 0.798138
INFO:root:FL Epoch: 13 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1579
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596357
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608341
INFO:root:FL Epoch: 13 Norm Difference for worker 1579 is 0.695241
INFO:root:FL Epoch: 13 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :604
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606078
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619737
INFO:root:FL Epoch: 13 Norm Difference for worker 604 is 0.80969
INFO:root:FL Epoch: 13 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1302
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677368
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673337
INFO:root:FL Epoch: 13 Norm Difference for worker 1302 is 0.736704
INFO:root:FL Epoch: 13 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1873
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685032
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611976
INFO:root:FL Epoch: 13 Norm Difference for worker 1873 is 0.813488
INFO:root:FL Epoch: 13 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 230
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6704866079723134 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.8175317545731863                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1162, 1274, 407, 1924, 602, 198, 549, 1399, 1588, 744]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1162
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677940
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615812
INFO:root:FL Epoch: 14 Norm Difference for worker 1162 is 0.809902
INFO:root:FL Epoch: 14 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1274
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654778
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634431
INFO:root:FL Epoch: 14 Norm Difference for worker 1274 is 0.823429
INFO:root:FL Epoch: 14 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :407
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622072
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594373
INFO:root:FL Epoch: 14 Norm Difference for worker 407 is 0.8736
INFO:root:FL Epoch: 14 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1924
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720695
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579511
INFO:root:FL Epoch: 14 Norm Difference for worker 1924 is 0.905818
INFO:root:FL Epoch: 14 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :602
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730208
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605560
INFO:root:FL Epoch: 14 Norm Difference for worker 602 is 0.841605
INFO:root:FL Epoch: 14 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :198
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737050
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.653322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 198 is 0.920126
INFO:root:FL Epoch: 14 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :549
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649997
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630379
INFO:root:FL Epoch: 14 Norm Difference for worker 549 is 0.816945
INFO:root:FL Epoch: 14 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1399
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722531
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636317
INFO:root:FL Epoch: 14 Norm Difference for worker 1399 is 0.841151
INFO:root:FL Epoch: 14 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1588
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633115
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569951
INFO:root:FL Epoch: 14 Norm Difference for worker 1588 is 0.890999
INFO:root:FL Epoch: 14 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :744
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697813
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631804
INFO:root:FL Epoch: 14 Norm Difference for worker 744 is 0.879363
INFO:root:FL Epoch: 14 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6998817254515255 and Test Accuracy:57.35294117647059 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:1.3522136608759563                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [45, 447, 1156, 1595, 1797, 1888, 892, 546, 921, 350]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 15 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :45
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 45 is 1.026634
INFO:root:FL Epoch: 15 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :447
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633978
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649710
INFO:root:FL Epoch: 15 Norm Difference for worker 447 is 1.00034
INFO:root:FL Epoch: 15 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1156
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571511
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529522
INFO:root:FL Epoch: 15 Norm Difference for worker 1156 is 1.032402
INFO:root:FL Epoch: 15 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681016
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521322
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 1.057319
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1797
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796679
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634393
INFO:root:FL Epoch: 15 Norm Difference for worker 1797 is 1.096189
INFO:root:FL Epoch: 15 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1888
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725822
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530911
INFO:root:FL Epoch: 15 Norm Difference for worker 1888 is 0.947692
INFO:root:FL Epoch: 15 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :892
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772510
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713690
INFO:root:FL Epoch: 15 Norm Difference for worker 892 is 0.966548
INFO:root:FL Epoch: 15 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :546
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808317
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663428
INFO:root:FL Epoch: 15 Norm Difference for worker 546 is 1.052759
INFO:root:FL Epoch: 15 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :921
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754232
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600910
INFO:root:FL Epoch: 15 Norm Difference for worker 921 is 1.00998
INFO:root:FL Epoch: 15 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :350
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794829
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596585
INFO:root:FL Epoch: 15 Norm Difference for worker 350 is 0.967375
INFO:root:FL Epoch: 15 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1156
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6988154544549829 and Test Accuracy:52.05882352941177 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:1.0367930034796398                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [637, 325, 501, 1108, 837, 470, 272, 479, 803, 1605]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :637
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492239
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638770
INFO:root:FL Epoch: 16 Norm Difference for worker 637 is 1.09813
INFO:root:FL Epoch: 16 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :325
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 325 is 1.158363
INFO:root:FL Epoch: 16 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :501
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661383
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634180
INFO:root:FL Epoch: 16 Norm Difference for worker 501 is 1.168498
INFO:root:FL Epoch: 16 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1108
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640356
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618618
INFO:root:FL Epoch: 16 Norm Difference for worker 1108 is 1.145948
INFO:root:FL Epoch: 16 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :837
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567844
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588315
INFO:root:FL Epoch: 16 Norm Difference for worker 837 is 1.217614
INFO:root:FL Epoch: 16 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :470
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692161
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583198
INFO:root:FL Epoch: 16 Norm Difference for worker 470 is 1.112385
INFO:root:FL Epoch: 16 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :272
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 272 is 1.038993
INFO:root:FL Epoch: 16 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :479
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683212
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658787
INFO:root:FL Epoch: 16 Norm Difference for worker 479 is 1.092606
INFO:root:FL Epoch: 16 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :803
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669585
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671719
INFO:root:FL Epoch: 16 Norm Difference for worker 803 is 1.168002
INFO:root:FL Epoch: 16 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1605
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568547
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643678
INFO:root:FL Epoch: 16 Norm Difference for worker 1605 is 1.113759
INFO:root:FL Epoch: 16 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.68178110964158 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.1655728220939636                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [945, 1614, 175, 624, 1869, 206, 764, 212, 1274, 1148]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :945
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716685
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488955
INFO:root:FL Epoch: 17 Norm Difference for worker 945 is 1.101717
INFO:root:FL Epoch: 17 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1614
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615965
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563452
INFO:root:FL Epoch: 17 Norm Difference for worker 1614 is 1.091408
INFO:root:FL Epoch: 17 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :175
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 175 is 1.190746
INFO:root:FL Epoch: 17 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :624
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591441
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636493
INFO:root:FL Epoch: 17 Norm Difference for worker 624 is 1.121548
INFO:root:FL Epoch: 17 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1869
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595143
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592034
INFO:root:FL Epoch: 17 Norm Difference for worker 1869 is 1.174478
INFO:root:FL Epoch: 17 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :206
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 206 is 1.139373
INFO:root:FL Epoch: 17 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :764
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611141
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701008
INFO:root:FL Epoch: 17 Norm Difference for worker 764 is 1.111677
INFO:root:FL Epoch: 17 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :212
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 212 is 1.123011
INFO:root:FL Epoch: 17 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1274
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756994
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508844
INFO:root:FL Epoch: 17 Norm Difference for worker 1274 is 1.104117
INFO:root:FL Epoch: 17 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1148
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616658
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659731
INFO:root:FL Epoch: 17 Norm Difference for worker 1148 is 1.119778
INFO:root:FL Epoch: 17 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6869141880203696 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:1.2305590709050496                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [506, 101, 40, 1474, 1851, 588, 1914, 1565, 478, 1809]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 18 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :506
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518799
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728305
INFO:root:FL Epoch: 18 Norm Difference for worker 506 is 1.312562
INFO:root:FL Epoch: 18 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :101
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 101 is 1.349353
INFO:root:FL Epoch: 18 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :40
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 40 is 1.263682
INFO:root:FL Epoch: 18 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1474
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663678
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435316
INFO:root:FL Epoch: 18 Norm Difference for worker 1474 is 1.259095
INFO:root:FL Epoch: 18 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1851
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556966
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550792
INFO:root:FL Epoch: 18 Norm Difference for worker 1851 is 1.277118
INFO:root:FL Epoch: 18 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :588
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611225
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665715
INFO:root:FL Epoch: 18 Norm Difference for worker 588 is 1.312631
INFO:root:FL Epoch: 18 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1914
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724849
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462985
INFO:root:FL Epoch: 18 Norm Difference for worker 1914 is 1.352187
INFO:root:FL Epoch: 18 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1565
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706580
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550457
INFO:root:FL Epoch: 18 Norm Difference for worker 1565 is 1.322691
INFO:root:FL Epoch: 18 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :478
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563038
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704412
INFO:root:FL Epoch: 18 Norm Difference for worker 478 is 1.301789
INFO:root:FL Epoch: 18 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1809
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794257
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537521
INFO:root:FL Epoch: 18 Norm Difference for worker 1809 is 1.284581
INFO:root:FL Epoch: 18 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1809
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6582467538468978 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.1812270283699036                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [17, 321, 1662, 813, 1791, 1781, 1404, 1091, 1077, 1197]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 19 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :17
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 17 is 1.232167
INFO:root:FL Epoch: 19 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :321
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.724349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 321 is 1.173137
INFO:root:FL Epoch: 19 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1662
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482669
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580213
INFO:root:FL Epoch: 19 Norm Difference for worker 1662 is 1.112804
INFO:root:FL Epoch: 19 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :813
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589743
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641567
INFO:root:FL Epoch: 19 Norm Difference for worker 813 is 1.148392
INFO:root:FL Epoch: 19 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1791
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818920
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621850
INFO:root:FL Epoch: 19 Norm Difference for worker 1791 is 1.15174
INFO:root:FL Epoch: 19 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1781
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658205
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501497
INFO:root:FL Epoch: 19 Norm Difference for worker 1781 is 1.178345
INFO:root:FL Epoch: 19 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1404
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576222
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612663
INFO:root:FL Epoch: 19 Norm Difference for worker 1404 is 1.097948
INFO:root:FL Epoch: 19 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1091
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699778
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525933
INFO:root:FL Epoch: 19 Norm Difference for worker 1091 is 1.037611
INFO:root:FL Epoch: 19 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1077
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650781
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654781
INFO:root:FL Epoch: 19 Norm Difference for worker 1077 is 1.189651
INFO:root:FL Epoch: 19 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1197
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515537
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552535
INFO:root:FL Epoch: 19 Norm Difference for worker 1197 is 1.120344
INFO:root:FL Epoch: 19 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1091
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6630607142167932 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.0638479987780254                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [1500, 553, 1506, 437, 1362, 1482, 1583, 858, 1282, 333]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :1500
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646690
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699773
INFO:root:FL Epoch: 20 Norm Difference for worker 1500 is 1.100562
INFO:root:FL Epoch: 20 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :553
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633739
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613016
INFO:root:FL Epoch: 20 Norm Difference for worker 553 is 1.102366
INFO:root:FL Epoch: 20 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1506
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738802
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606678
INFO:root:FL Epoch: 20 Norm Difference for worker 1506 is 1.112451
INFO:root:FL Epoch: 20 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :437
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741891
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601944
INFO:root:FL Epoch: 20 Norm Difference for worker 437 is 1.092684
INFO:root:FL Epoch: 20 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1362
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749700
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617589
INFO:root:FL Epoch: 20 Norm Difference for worker 1362 is 1.065123
INFO:root:FL Epoch: 20 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1482
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596108
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561194
INFO:root:FL Epoch: 20 Norm Difference for worker 1482 is 1.076872
INFO:root:FL Epoch: 20 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1583
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770408
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693762
INFO:root:FL Epoch: 20 Norm Difference for worker 1583 is 1.089859
INFO:root:FL Epoch: 20 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :858
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615039
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561507
INFO:root:FL Epoch: 20 Norm Difference for worker 858 is 1.099634
INFO:root:FL Epoch: 20 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1282
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699880
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536877
INFO:root:FL Epoch: 20 Norm Difference for worker 1282 is 1.135699
INFO:root:FL Epoch: 20 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :333
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 333 is 1.089023
INFO:root:FL Epoch: 20 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 437
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6734892620759851 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.1722456216812134                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [1105, 510, 149, 375, 917, 72, 1368, 1094, 986, 1252]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :1105
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425889
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565566
INFO:root:FL Epoch: 21 Norm Difference for worker 1105 is 1.216561
INFO:root:FL Epoch: 21 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :510
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554092
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658112
INFO:root:FL Epoch: 21 Norm Difference for worker 510 is 1.153329
INFO:root:FL Epoch: 21 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :149
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 149 is 1.206697
INFO:root:FL Epoch: 21 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :375
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685135
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660988
INFO:root:FL Epoch: 21 Norm Difference for worker 375 is 1.179329
INFO:root:FL Epoch: 21 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :917
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603752
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513682
INFO:root:FL Epoch: 21 Norm Difference for worker 917 is 1.200159
INFO:root:FL Epoch: 21 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :72
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 72 is 1.218478
INFO:root:FL Epoch: 21 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1368
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705437
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515782
INFO:root:FL Epoch: 21 Norm Difference for worker 1368 is 1.132995
INFO:root:FL Epoch: 21 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1094
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579924
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.831385
INFO:root:FL Epoch: 21 Norm Difference for worker 1094 is 1.158562
INFO:root:FL Epoch: 21 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :986
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698543
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606855
INFO:root:FL Epoch: 21 Norm Difference for worker 986 is 1.258886
INFO:root:FL Epoch: 21 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1252
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713642
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475988
INFO:root:FL Epoch: 21 Norm Difference for worker 1252 is 1.222806
INFO:root:FL Epoch: 21 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1368
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 21 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 21 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6651132457396564 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:1.1216413378715515                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [31, 1403, 1071, 168, 46, 35, 710, 110, 61, 690]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.1001994 0.1001994 0.1001994 0.0997009
 0.1001994 0.1001994 0.0997009]
INFO:root:FL Epoch: 22 Num points on workers: [201 200 200 201 201 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :31
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 31 is 1.146361
INFO:root:FL Epoch: 22 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1403
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514729
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.779547
INFO:root:FL Epoch: 22 Norm Difference for worker 1403 is 1.183113
INFO:root:FL Epoch: 22 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1071
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814933
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611764
INFO:root:FL Epoch: 22 Norm Difference for worker 1071 is 1.172444
INFO:root:FL Epoch: 22 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :168
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 168 is 1.231277
INFO:root:FL Epoch: 22 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :46
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 46 is 1.161974
INFO:root:FL Epoch: 22 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :35
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678719
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593731
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 35 is 1.187359
INFO:root:FL Epoch: 22 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :710
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816998
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573991
INFO:root:FL Epoch: 22 Norm Difference for worker 710 is 1.137657
INFO:root:FL Epoch: 22 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :110
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.804764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 110 is 1.204944
INFO:root:FL Epoch: 22 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :61
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 61 is 1.188755
INFO:root:FL Epoch: 22 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :690
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553868
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470860
INFO:root:FL Epoch: 22 Norm Difference for worker 690 is 1.148998
INFO:root:FL Epoch: 22 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 110
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.7061292809598586 and Test Accuracy:54.411764705882355 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:1.2451602617899578                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1050, 1151, 805, 1810, 1401, 1243, 1774, 293, 441, 1596]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1050
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631793
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646671
INFO:root:FL Epoch: 23 Norm Difference for worker 1050 is 1.00361
INFO:root:FL Epoch: 23 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1151
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716501
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511945
INFO:root:FL Epoch: 23 Norm Difference for worker 1151 is 1.133224
INFO:root:FL Epoch: 23 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :805
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867749
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634730
INFO:root:FL Epoch: 23 Norm Difference for worker 805 is 1.045415
INFO:root:FL Epoch: 23 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1810
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666264
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577010
INFO:root:FL Epoch: 23 Norm Difference for worker 1810 is 1.129441
INFO:root:FL Epoch: 23 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1401
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633805
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662529
INFO:root:FL Epoch: 23 Norm Difference for worker 1401 is 1.054562
INFO:root:FL Epoch: 23 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1243
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742216
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542319
INFO:root:FL Epoch: 23 Norm Difference for worker 1243 is 0.979432
INFO:root:FL Epoch: 23 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1774
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777198
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573130
INFO:root:FL Epoch: 23 Norm Difference for worker 1774 is 1.018004
INFO:root:FL Epoch: 23 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :293
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 293 is 1.153535
INFO:root:FL Epoch: 23 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :441
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528746
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665739
INFO:root:FL Epoch: 23 Norm Difference for worker 441 is 1.035757
INFO:root:FL Epoch: 23 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1596
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801747
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617974
INFO:root:FL Epoch: 23 Norm Difference for worker 1596 is 1.052021
INFO:root:FL Epoch: 23 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1774
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6566479732008541 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:1.1240768035252888                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [743, 1858, 866, 1917, 103, 104, 5, 887, 1903, 694]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :743
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715041
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657932
INFO:root:FL Epoch: 24 Norm Difference for worker 743 is 1.028236
INFO:root:FL Epoch: 24 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809179
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507871
INFO:root:FL Epoch: 24 Norm Difference for worker 1858 is 1.044444
INFO:root:FL Epoch: 24 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :866
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659880
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573349
INFO:root:FL Epoch: 24 Norm Difference for worker 866 is 1.047595
INFO:root:FL Epoch: 24 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1917
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542063
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554824
INFO:root:FL Epoch: 24 Norm Difference for worker 1917 is 0.985833
INFO:root:FL Epoch: 24 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :103
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646874
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 103 is 1.051575
INFO:root:FL Epoch: 24 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :104
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 104 is 1.006737
INFO:root:FL Epoch: 24 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :5
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 5 is 0.998049
INFO:root:FL Epoch: 24 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :887
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604858
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667932
INFO:root:FL Epoch: 24 Norm Difference for worker 887 is 1.056084
INFO:root:FL Epoch: 24 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1903
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659292
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655136
INFO:root:FL Epoch: 24 Norm Difference for worker 1903 is 1.037391
INFO:root:FL Epoch: 24 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :694
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598110
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495075
INFO:root:FL Epoch: 24 Norm Difference for worker 694 is 0.964512
INFO:root:FL Epoch: 24 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 694
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6595098639235777 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:1.1022631128629048                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [260, 1328, 1562, 1008, 1420, 1108, 1751, 1218, 692, 333]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 25 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :260
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.766399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 260 is 1.069786
INFO:root:FL Epoch: 25 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1328
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563917
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614075
INFO:root:FL Epoch: 25 Norm Difference for worker 1328 is 1.1024
INFO:root:FL Epoch: 25 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1562
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551751
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555132
INFO:root:FL Epoch: 25 Norm Difference for worker 1562 is 1.107065
INFO:root:FL Epoch: 25 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1008
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588832
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622018
INFO:root:FL Epoch: 25 Norm Difference for worker 1008 is 1.098017
INFO:root:FL Epoch: 25 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1420
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676619
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512575
INFO:root:FL Epoch: 25 Norm Difference for worker 1420 is 1.137506
INFO:root:FL Epoch: 25 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1108
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874990
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563750
INFO:root:FL Epoch: 25 Norm Difference for worker 1108 is 1.141032
INFO:root:FL Epoch: 25 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1751
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709944
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501883
INFO:root:FL Epoch: 25 Norm Difference for worker 1751 is 1.096608
INFO:root:FL Epoch: 25 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1218
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805568
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571571
INFO:root:FL Epoch: 25 Norm Difference for worker 1218 is 1.165796
INFO:root:FL Epoch: 25 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :692
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542540
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508133
INFO:root:FL Epoch: 25 Norm Difference for worker 692 is 1.069152
INFO:root:FL Epoch: 25 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :333
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 333 is 1.055342
INFO:root:FL Epoch: 25 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 260
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6603223997003892 and Test Accuracy:60.0 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.2258922259012859                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [439, 246, 362, 1679, 1362, 170, 1657, 1614, 1917, 1320]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 26 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :439
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616645
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464681
INFO:root:FL Epoch: 26 Norm Difference for worker 439 is 1.111823
INFO:root:FL Epoch: 26 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :246
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 246 is 1.073833
INFO:root:FL Epoch: 26 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :362
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709982
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669509
INFO:root:FL Epoch: 26 Norm Difference for worker 362 is 1.152486
INFO:root:FL Epoch: 26 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1679
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608180
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689561
INFO:root:FL Epoch: 26 Norm Difference for worker 1679 is 1.117771
INFO:root:FL Epoch: 26 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1362
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698358
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565446
INFO:root:FL Epoch: 26 Norm Difference for worker 1362 is 1.015662
INFO:root:FL Epoch: 26 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :170
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 170 is 1.141167
INFO:root:FL Epoch: 26 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1657
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444434
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620855
INFO:root:FL Epoch: 26 Norm Difference for worker 1657 is 1.145631
INFO:root:FL Epoch: 26 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1614
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661379
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803386
INFO:root:FL Epoch: 26 Norm Difference for worker 1614 is 1.148122
INFO:root:FL Epoch: 26 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1917
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773306
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641618
INFO:root:FL Epoch: 26 Norm Difference for worker 1917 is 1.03932
INFO:root:FL Epoch: 26 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1320
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597501
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591028
INFO:root:FL Epoch: 26 Norm Difference for worker 1320 is 1.098324
INFO:root:FL Epoch: 26 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1917
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6684038183268379 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:1.0003155569235485                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1075, 267, 1663, 1839, 613, 438, 198, 37, 1913, 121]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 27 Num points on workers: [200 201 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1075
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698603
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579092
INFO:root:FL Epoch: 27 Norm Difference for worker 1075 is 1.015473
INFO:root:FL Epoch: 27 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :267
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 267 is 1.031505
INFO:root:FL Epoch: 27 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1663
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684851
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678955
INFO:root:FL Epoch: 27 Norm Difference for worker 1663 is 1.00035
INFO:root:FL Epoch: 27 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1839
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638237
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619994
INFO:root:FL Epoch: 27 Norm Difference for worker 1839 is 1.019205
INFO:root:FL Epoch: 27 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :613
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603326
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575007
INFO:root:FL Epoch: 27 Norm Difference for worker 613 is 1.067471
INFO:root:FL Epoch: 27 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :438
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754012
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622332
INFO:root:FL Epoch: 27 Norm Difference for worker 438 is 0.997124
INFO:root:FL Epoch: 27 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :198
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547835
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 198 is 1.088866
INFO:root:FL Epoch: 27 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :37
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 37 is 1.040229
INFO:root:FL Epoch: 27 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1913
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574691
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556712
INFO:root:FL Epoch: 27 Norm Difference for worker 1913 is 0.995644
INFO:root:FL Epoch: 27 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :121
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 121 is 1.050686
INFO:root:FL Epoch: 27 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 27 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 27 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6693436959210564 and Test Accuracy:62.05882352941177 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:1.0610741972923279                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [1561, 1937, 1529, 127, 1679, 80, 524, 312, 421, 966]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :1561
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639123
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577767
INFO:root:FL Epoch: 28 Norm Difference for worker 1561 is 1.059877
INFO:root:FL Epoch: 28 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1937
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703843
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533650
INFO:root:FL Epoch: 28 Norm Difference for worker 1937 is 1.03975
INFO:root:FL Epoch: 28 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1529
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620894
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709349
INFO:root:FL Epoch: 28 Norm Difference for worker 1529 is 1.021388
INFO:root:FL Epoch: 28 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :127
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 127 is 0.964327
INFO:root:FL Epoch: 28 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1679
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649354
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662688
INFO:root:FL Epoch: 28 Norm Difference for worker 1679 is 0.999411
INFO:root:FL Epoch: 28 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :80
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 80 is 1.044993
INFO:root:FL Epoch: 28 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :524
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668355
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593685
INFO:root:FL Epoch: 28 Norm Difference for worker 524 is 0.978527
INFO:root:FL Epoch: 28 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :312
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 312 is 1.03045
INFO:root:FL Epoch: 28 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :421
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781642
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677441
INFO:root:FL Epoch: 28 Norm Difference for worker 421 is 1.008608
INFO:root:FL Epoch: 28 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :966
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685376
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518666
INFO:root:FL Epoch: 28 Norm Difference for worker 966 is 1.049553
INFO:root:FL Epoch: 28 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 127
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6645120995886186 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.1682769258817036                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [1448, 333, 1222, 1427, 1658, 1546, 945, 1651, 1045, 1865]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :1448
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691460
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696225
INFO:root:FL Epoch: 29 Norm Difference for worker 1448 is 0.95024
INFO:root:FL Epoch: 29 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :333
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 333 is 0.961236
INFO:root:FL Epoch: 29 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1222
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647126
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624004
INFO:root:FL Epoch: 29 Norm Difference for worker 1222 is 1.003136
INFO:root:FL Epoch: 29 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1427
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660167
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664527
INFO:root:FL Epoch: 29 Norm Difference for worker 1427 is 0.988624
INFO:root:FL Epoch: 29 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1658
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586575
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632552
INFO:root:FL Epoch: 29 Norm Difference for worker 1658 is 0.98003
INFO:root:FL Epoch: 29 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1546
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678299
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.760438
INFO:root:FL Epoch: 29 Norm Difference for worker 1546 is 0.965881
INFO:root:FL Epoch: 29 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :945
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685763
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511354
INFO:root:FL Epoch: 29 Norm Difference for worker 945 is 0.989445
INFO:root:FL Epoch: 29 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1651
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705456
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535400
INFO:root:FL Epoch: 29 Norm Difference for worker 1651 is 1.023639
INFO:root:FL Epoch: 29 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1045
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637452
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542192
INFO:root:FL Epoch: 29 Norm Difference for worker 1045 is 1.021027
INFO:root:FL Epoch: 29 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1865
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574375
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528319
INFO:root:FL Epoch: 29 Norm Difference for worker 1865 is 1.007702
INFO:root:FL Epoch: 29 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1546
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6663744379492367 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.8927416205406189                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [381, 268, 1769, 1867, 1392, 25, 1850, 1465, 1408, 1091]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :381
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562738
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704661
INFO:root:FL Epoch: 30 Norm Difference for worker 381 is 0.958321
INFO:root:FL Epoch: 30 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :268
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 268 is 0.929332
INFO:root:FL Epoch: 30 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1769
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661549
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599560
INFO:root:FL Epoch: 30 Norm Difference for worker 1769 is 0.947323
INFO:root:FL Epoch: 30 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1867
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568707
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653527
INFO:root:FL Epoch: 30 Norm Difference for worker 1867 is 0.974121
INFO:root:FL Epoch: 30 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1392
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559278
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548021
INFO:root:FL Epoch: 30 Norm Difference for worker 1392 is 0.918009
INFO:root:FL Epoch: 30 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :25
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574611
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 25 is 0.935872
INFO:root:FL Epoch: 30 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1850
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508413
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448689
INFO:root:FL Epoch: 30 Norm Difference for worker 1850 is 0.998489
INFO:root:FL Epoch: 30 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1465
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636225
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702593
INFO:root:FL Epoch: 30 Norm Difference for worker 1465 is 0.94923
INFO:root:FL Epoch: 30 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1408
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582498
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627121
INFO:root:FL Epoch: 30 Norm Difference for worker 1408 is 0.960007
INFO:root:FL Epoch: 30 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1091
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535669
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416829
INFO:root:FL Epoch: 30 Norm Difference for worker 1091 is 0.955727
INFO:root:FL Epoch: 30 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1392
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.662055979756748 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:1.0291313727696736                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [979, 185, 893, 382, 1260, 917, 835, 745, 146, 1473]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 31 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :979
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535030
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766399
INFO:root:FL Epoch: 31 Norm Difference for worker 979 is 1.036378
INFO:root:FL Epoch: 31 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :185
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 185 is 1.019148
INFO:root:FL Epoch: 31 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :893
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521923
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584240
INFO:root:FL Epoch: 31 Norm Difference for worker 893 is 1.113913
INFO:root:FL Epoch: 31 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :382
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599971
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696805
INFO:root:FL Epoch: 31 Norm Difference for worker 382 is 1.046984
INFO:root:FL Epoch: 31 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1260
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615977
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595427
INFO:root:FL Epoch: 31 Norm Difference for worker 1260 is 1.081928
INFO:root:FL Epoch: 31 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :917
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616093
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610959
INFO:root:FL Epoch: 31 Norm Difference for worker 917 is 1.044765
INFO:root:FL Epoch: 31 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :835
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640131
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742947
INFO:root:FL Epoch: 31 Norm Difference for worker 835 is 1.059004
INFO:root:FL Epoch: 31 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :745
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526623
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526525
INFO:root:FL Epoch: 31 Norm Difference for worker 745 is 1.044027
INFO:root:FL Epoch: 31 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :146
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 146 is 1.059258
INFO:root:FL Epoch: 31 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1473
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631535
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462119
INFO:root:FL Epoch: 31 Norm Difference for worker 1473 is 1.035418
INFO:root:FL Epoch: 31 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 979
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6533656996839187 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:0.9126071731249491                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [430, 1490, 1654, 950, 795, 661, 372, 1915, 502, 682]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :430
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560036
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744707
INFO:root:FL Epoch: 32 Norm Difference for worker 430 is 1.029891
INFO:root:FL Epoch: 32 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1490
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657060
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559175
INFO:root:FL Epoch: 32 Norm Difference for worker 1490 is 1.033189
INFO:root:FL Epoch: 32 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1654
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603720
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577389
INFO:root:FL Epoch: 32 Norm Difference for worker 1654 is 0.917997
INFO:root:FL Epoch: 32 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :950
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485586
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487123
INFO:root:FL Epoch: 32 Norm Difference for worker 950 is 1.027824
INFO:root:FL Epoch: 32 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :795
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677776
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550687
INFO:root:FL Epoch: 32 Norm Difference for worker 795 is 1.031342
INFO:root:FL Epoch: 32 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :661
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635610
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637207
INFO:root:FL Epoch: 32 Norm Difference for worker 661 is 1.002439
INFO:root:FL Epoch: 32 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :372
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686776
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590705
INFO:root:FL Epoch: 32 Norm Difference for worker 372 is 1.001614
INFO:root:FL Epoch: 32 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1915
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676955
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467480
INFO:root:FL Epoch: 32 Norm Difference for worker 1915 is 0.925925
INFO:root:FL Epoch: 32 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :502
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688065
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701555
INFO:root:FL Epoch: 32 Norm Difference for worker 502 is 0.966024
INFO:root:FL Epoch: 32 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :682
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614296
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576059
INFO:root:FL Epoch: 32 Norm Difference for worker 682 is 0.979844
INFO:root:FL Epoch: 32 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1654
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 32 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 32 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6322335145052742 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.0465161601702373                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [25, 1615, 467, 685, 756, 1670, 1137, 1785, 1287, 1377]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :25
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 25 is 1.020601
INFO:root:FL Epoch: 33 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1615
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489016
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504020
INFO:root:FL Epoch: 33 Norm Difference for worker 1615 is 1.002052
INFO:root:FL Epoch: 33 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :467
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650462
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570920
INFO:root:FL Epoch: 33 Norm Difference for worker 467 is 0.968324
INFO:root:FL Epoch: 33 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :685
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683364
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584822
INFO:root:FL Epoch: 33 Norm Difference for worker 685 is 1.035261
INFO:root:FL Epoch: 33 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :756
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543079
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675633
INFO:root:FL Epoch: 33 Norm Difference for worker 756 is 1.025362
INFO:root:FL Epoch: 33 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1670
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741678
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655153
INFO:root:FL Epoch: 33 Norm Difference for worker 1670 is 1.003975
INFO:root:FL Epoch: 33 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1137
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820110
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701770
INFO:root:FL Epoch: 33 Norm Difference for worker 1137 is 0.982578
INFO:root:FL Epoch: 33 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1785
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648326
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442134
INFO:root:FL Epoch: 33 Norm Difference for worker 1785 is 0.976927
INFO:root:FL Epoch: 33 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1287
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620463
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626484
INFO:root:FL Epoch: 33 Norm Difference for worker 1287 is 0.987452
INFO:root:FL Epoch: 33 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1377
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576366
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598126
INFO:root:FL Epoch: 33 Norm Difference for worker 1377 is 1.017766
INFO:root:FL Epoch: 33 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 33 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 33 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.643784843823489 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:1.2126832008361816                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1113, 687, 148, 1934, 102, 561, 1239, 104, 1259, 182]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 201 200 201 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1113
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588423
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570151
INFO:root:FL Epoch: 34 Norm Difference for worker 1113 is 1.117615
INFO:root:FL Epoch: 34 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :687
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528595
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555699
INFO:root:FL Epoch: 34 Norm Difference for worker 687 is 1.081209
INFO:root:FL Epoch: 34 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :148
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616235
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 148 is 1.033999
INFO:root:FL Epoch: 34 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1934
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526931
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509105
INFO:root:FL Epoch: 34 Norm Difference for worker 1934 is 1.231915
INFO:root:FL Epoch: 34 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :102
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 102 is 1.102736
INFO:root:FL Epoch: 34 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :561
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699654
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569476
INFO:root:FL Epoch: 34 Norm Difference for worker 561 is 1.152132
INFO:root:FL Epoch: 34 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1239
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799489
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704757
INFO:root:FL Epoch: 34 Norm Difference for worker 1239 is 1.138586
INFO:root:FL Epoch: 34 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :104
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.746774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 104 is 1.136389
INFO:root:FL Epoch: 34 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1259
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637221
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660769
INFO:root:FL Epoch: 34 Norm Difference for worker 1259 is 1.046149
INFO:root:FL Epoch: 34 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :182
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.877062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.770442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 182 is 1.116331
INFO:root:FL Epoch: 34 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 148
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6330001389279085 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.0028221011161804                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1423, 343, 283, 1855, 33, 1681, 485, 1773, 655, 723]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1423
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573389
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563019
INFO:root:FL Epoch: 35 Norm Difference for worker 1423 is 1.05364
INFO:root:FL Epoch: 35 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :343
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867279
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635164
INFO:root:FL Epoch: 35 Norm Difference for worker 343 is 0.956325
INFO:root:FL Epoch: 35 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :283
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 283 is 1.05918
INFO:root:FL Epoch: 35 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1855
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667378
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577286
INFO:root:FL Epoch: 35 Norm Difference for worker 1855 is 0.959364
INFO:root:FL Epoch: 35 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :33
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 33 is 0.981279
INFO:root:FL Epoch: 35 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1681
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662615
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639166
INFO:root:FL Epoch: 35 Norm Difference for worker 1681 is 1.06829
INFO:root:FL Epoch: 35 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :485
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616695
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537035
INFO:root:FL Epoch: 35 Norm Difference for worker 485 is 1.006317
INFO:root:FL Epoch: 35 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1773
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643376
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642599
INFO:root:FL Epoch: 35 Norm Difference for worker 1773 is 1.035149
INFO:root:FL Epoch: 35 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :655
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663851
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.841216
INFO:root:FL Epoch: 35 Norm Difference for worker 655 is 1.064284
INFO:root:FL Epoch: 35 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :723
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648328
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670739
INFO:root:FL Epoch: 35 Norm Difference for worker 723 is 1.039624
INFO:root:FL Epoch: 35 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 343
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6431962847709656 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.0487920939922333                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [937, 20, 102, 1158, 1765, 1821, 393, 616, 1455, 329]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 36 Num points on workers: [200 201 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561458
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725410
INFO:root:FL Epoch: 36 Norm Difference for worker 937 is 1.070278
INFO:root:FL Epoch: 36 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :20
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 20 is 0.995236
INFO:root:FL Epoch: 36 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :102
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 102 is 1.042098
INFO:root:FL Epoch: 36 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1158
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615889
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473500
INFO:root:FL Epoch: 36 Norm Difference for worker 1158 is 0.996124
INFO:root:FL Epoch: 36 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1765
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642315
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531783
INFO:root:FL Epoch: 36 Norm Difference for worker 1765 is 0.995393
INFO:root:FL Epoch: 36 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1821
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562244
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530450
INFO:root:FL Epoch: 36 Norm Difference for worker 1821 is 0.998927
INFO:root:FL Epoch: 36 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :393
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535269
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577036
INFO:root:FL Epoch: 36 Norm Difference for worker 393 is 1.006018
INFO:root:FL Epoch: 36 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :616
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842511
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632583
INFO:root:FL Epoch: 36 Norm Difference for worker 616 is 0.958154
INFO:root:FL Epoch: 36 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1455
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639741
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639280
INFO:root:FL Epoch: 36 Norm Difference for worker 1455 is 1.013096
INFO:root:FL Epoch: 36 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :329
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615911
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.655808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 329 is 0.982667
INFO:root:FL Epoch: 36 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 329
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6523626955116496 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.1076385378837585                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [371, 1198, 1309, 530, 1091, 936, 68, 414, 1378, 1773]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 37 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :371
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744757
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567450
INFO:root:FL Epoch: 37 Norm Difference for worker 371 is 1.074559
INFO:root:FL Epoch: 37 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1198
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586412
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656121
INFO:root:FL Epoch: 37 Norm Difference for worker 1198 is 1.13474
INFO:root:FL Epoch: 37 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1309
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513529
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491737
INFO:root:FL Epoch: 37 Norm Difference for worker 1309 is 1.099233
INFO:root:FL Epoch: 37 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :530
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752765
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500994
INFO:root:FL Epoch: 37 Norm Difference for worker 530 is 1.14494
INFO:root:FL Epoch: 37 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1091
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696961
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554380
INFO:root:FL Epoch: 37 Norm Difference for worker 1091 is 1.089683
INFO:root:FL Epoch: 37 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :936
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598452
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455685
INFO:root:FL Epoch: 37 Norm Difference for worker 936 is 1.110326
INFO:root:FL Epoch: 37 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :68
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.730476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 68 is 1.091313
INFO:root:FL Epoch: 37 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :414
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650446
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563773
INFO:root:FL Epoch: 37 Norm Difference for worker 414 is 1.113438
INFO:root:FL Epoch: 37 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1378
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695722
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567511
INFO:root:FL Epoch: 37 Norm Difference for worker 1378 is 1.167562
INFO:root:FL Epoch: 37 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1773
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679196
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581868
INFO:root:FL Epoch: 37 Norm Difference for worker 1773 is 1.12684
INFO:root:FL Epoch: 37 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 371
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.653632731998668 and Test Accuracy:61.76470588235294 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.1326373219490051                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [501, 1868, 1606, 169, 1363, 1799, 1046, 1681, 1531, 798]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 38 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :501
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648457
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539688
INFO:root:FL Epoch: 38 Norm Difference for worker 501 is 1.016005
INFO:root:FL Epoch: 38 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1868
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663939
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584059
INFO:root:FL Epoch: 38 Norm Difference for worker 1868 is 1.135016
INFO:root:FL Epoch: 38 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1606
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623177
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493988
INFO:root:FL Epoch: 38 Norm Difference for worker 1606 is 0.991306
INFO:root:FL Epoch: 38 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :169
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 169 is 0.97497
INFO:root:FL Epoch: 38 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1363
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565452
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529413
INFO:root:FL Epoch: 38 Norm Difference for worker 1363 is 1.0295
INFO:root:FL Epoch: 38 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1799
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653556
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608747
INFO:root:FL Epoch: 38 Norm Difference for worker 1799 is 0.961021
INFO:root:FL Epoch: 38 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1046
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689563
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603854
INFO:root:FL Epoch: 38 Norm Difference for worker 1046 is 1.010258
INFO:root:FL Epoch: 38 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1681
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625995
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538839
INFO:root:FL Epoch: 38 Norm Difference for worker 1681 is 1.030112
INFO:root:FL Epoch: 38 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1531
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657652
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605359
INFO:root:FL Epoch: 38 Norm Difference for worker 1531 is 1.034214
INFO:root:FL Epoch: 38 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :798
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630645
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543719
INFO:root:FL Epoch: 38 Norm Difference for worker 798 is 1.033382
INFO:root:FL Epoch: 38 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1606
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6494001080008114 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:1.0386267403761547                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [544, 1317, 1425, 579, 945, 879, 886, 1359, 1849, 242]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656006
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667034
INFO:root:FL Epoch: 39 Norm Difference for worker 544 is 1.109894
INFO:root:FL Epoch: 39 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1317
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618437
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490181
INFO:root:FL Epoch: 39 Norm Difference for worker 1317 is 1.171389
INFO:root:FL Epoch: 39 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1425
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651691
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560033
INFO:root:FL Epoch: 39 Norm Difference for worker 1425 is 1.13304
INFO:root:FL Epoch: 39 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :579
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734748
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616306
INFO:root:FL Epoch: 39 Norm Difference for worker 579 is 1.134932
INFO:root:FL Epoch: 39 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :945
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550181
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387518
INFO:root:FL Epoch: 39 Norm Difference for worker 945 is 1.152393
INFO:root:FL Epoch: 39 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :879
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638879
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640246
INFO:root:FL Epoch: 39 Norm Difference for worker 879 is 1.088196
INFO:root:FL Epoch: 39 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :886
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738925
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460331
INFO:root:FL Epoch: 39 Norm Difference for worker 886 is 1.059787
INFO:root:FL Epoch: 39 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1359
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641361
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452386
INFO:root:FL Epoch: 39 Norm Difference for worker 1359 is 1.067802
INFO:root:FL Epoch: 39 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1849
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744573
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571784
INFO:root:FL Epoch: 39 Norm Difference for worker 1849 is 1.118205
INFO:root:FL Epoch: 39 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :242
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 242 is 1.074051
INFO:root:FL Epoch: 39 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 886
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6671811394831714 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:1.3856860597928364                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [658, 768, 1228, 549, 850, 260, 1831, 1836, 459, 1298]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :658
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604255
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614373
INFO:root:FL Epoch: 40 Norm Difference for worker 658 is 1.234505
INFO:root:FL Epoch: 40 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :768
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478261
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420541
INFO:root:FL Epoch: 40 Norm Difference for worker 768 is 1.169
INFO:root:FL Epoch: 40 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1228
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789921
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623461
INFO:root:FL Epoch: 40 Norm Difference for worker 1228 is 1.179066
INFO:root:FL Epoch: 40 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :549
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678380
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462626
INFO:root:FL Epoch: 40 Norm Difference for worker 549 is 1.181455
INFO:root:FL Epoch: 40 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :850
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648213
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697248
INFO:root:FL Epoch: 40 Norm Difference for worker 850 is 1.162567
INFO:root:FL Epoch: 40 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :260
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585472
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 260 is 1.169911
INFO:root:FL Epoch: 40 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1831
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566635
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447776
INFO:root:FL Epoch: 40 Norm Difference for worker 1831 is 1.163853
INFO:root:FL Epoch: 40 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1836
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553963
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597140
INFO:root:FL Epoch: 40 Norm Difference for worker 1836 is 1.145531
INFO:root:FL Epoch: 40 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :459
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495938
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512323
INFO:root:FL Epoch: 40 Norm Difference for worker 459 is 1.266991
INFO:root:FL Epoch: 40 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1298
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524488
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642981
INFO:root:FL Epoch: 40 Norm Difference for worker 1298 is 1.227533
INFO:root:FL Epoch: 40 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 260
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 40 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 40 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.657322084202486 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.2884058157602947                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [1267, 565, 477, 1012, 1492, 882, 1543, 1278, 1765, 900]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :1267
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603986
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715096
INFO:root:FL Epoch: 41 Norm Difference for worker 1267 is 1.148367
INFO:root:FL Epoch: 41 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :565
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630751
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516593
INFO:root:FL Epoch: 41 Norm Difference for worker 565 is 1.197679
INFO:root:FL Epoch: 41 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :477
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692521
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679981
INFO:root:FL Epoch: 41 Norm Difference for worker 477 is 1.134721
INFO:root:FL Epoch: 41 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1012
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836789
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467384
INFO:root:FL Epoch: 41 Norm Difference for worker 1012 is 1.123978
INFO:root:FL Epoch: 41 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1492
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614514
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426638
INFO:root:FL Epoch: 41 Norm Difference for worker 1492 is 1.214612
INFO:root:FL Epoch: 41 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :882
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547814
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399516
INFO:root:FL Epoch: 41 Norm Difference for worker 882 is 1.100061
INFO:root:FL Epoch: 41 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1543
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657784
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491729
INFO:root:FL Epoch: 41 Norm Difference for worker 1543 is 1.157243
INFO:root:FL Epoch: 41 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1278
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517986
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777891
INFO:root:FL Epoch: 41 Norm Difference for worker 1278 is 1.165341
INFO:root:FL Epoch: 41 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1765
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546660
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.789827
INFO:root:FL Epoch: 41 Norm Difference for worker 1765 is 1.156913
INFO:root:FL Epoch: 41 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :900
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690860
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601884
INFO:root:FL Epoch: 41 Norm Difference for worker 900 is 1.230035
INFO:root:FL Epoch: 41 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 882
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 41 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 41 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.6341452125240775 and Test Accuracy:64.11764705882354 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:1.0625775456428528                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1580, 1750, 1154, 1426, 1778, 887, 764, 1052, 396, 1099]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1580
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504846
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373553
INFO:root:FL Epoch: 42 Norm Difference for worker 1580 is 1.092423
INFO:root:FL Epoch: 42 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1750
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532385
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671430
INFO:root:FL Epoch: 42 Norm Difference for worker 1750 is 1.011437
INFO:root:FL Epoch: 42 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1154
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666543
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639550
INFO:root:FL Epoch: 42 Norm Difference for worker 1154 is 1.024173
INFO:root:FL Epoch: 42 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1426
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641816
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596608
INFO:root:FL Epoch: 42 Norm Difference for worker 1426 is 1.090303
INFO:root:FL Epoch: 42 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1778
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731332
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656058
INFO:root:FL Epoch: 42 Norm Difference for worker 1778 is 1.048994
INFO:root:FL Epoch: 42 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :887
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710272
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708013
INFO:root:FL Epoch: 42 Norm Difference for worker 887 is 1.109326
INFO:root:FL Epoch: 42 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :764
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543500
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594379
INFO:root:FL Epoch: 42 Norm Difference for worker 764 is 1.048992
INFO:root:FL Epoch: 42 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1052
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651353
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.805549
INFO:root:FL Epoch: 42 Norm Difference for worker 1052 is 0.985002
INFO:root:FL Epoch: 42 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :396
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674936
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598415
INFO:root:FL Epoch: 42 Norm Difference for worker 396 is 0.972664
INFO:root:FL Epoch: 42 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1099
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831747
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667084
INFO:root:FL Epoch: 42 Norm Difference for worker 1099 is 1.044643
INFO:root:FL Epoch: 42 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6256902568480548 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:0.8663000961144766                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [399, 1738, 751, 1462, 992, 1682, 957, 684, 1846, 1486]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 43 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :399
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772205
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566479
INFO:root:FL Epoch: 43 Norm Difference for worker 399 is 0.939232
INFO:root:FL Epoch: 43 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1738
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744058
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620567
INFO:root:FL Epoch: 43 Norm Difference for worker 1738 is 0.891942
INFO:root:FL Epoch: 43 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :751
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685412
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577357
INFO:root:FL Epoch: 43 Norm Difference for worker 751 is 0.995823
INFO:root:FL Epoch: 43 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1462
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653912
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571858
INFO:root:FL Epoch: 43 Norm Difference for worker 1462 is 0.98442
INFO:root:FL Epoch: 43 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :992
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629508
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511045
INFO:root:FL Epoch: 43 Norm Difference for worker 992 is 0.966483
INFO:root:FL Epoch: 43 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1682
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617424
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706843
INFO:root:FL Epoch: 43 Norm Difference for worker 1682 is 0.902924
INFO:root:FL Epoch: 43 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :957
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562617
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553009
INFO:root:FL Epoch: 43 Norm Difference for worker 957 is 0.90191
INFO:root:FL Epoch: 43 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :684
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519343
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606664
INFO:root:FL Epoch: 43 Norm Difference for worker 684 is 1.008367
INFO:root:FL Epoch: 43 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1846
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559191
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580321
INFO:root:FL Epoch: 43 Norm Difference for worker 1846 is 0.956996
INFO:root:FL Epoch: 43 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1486
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652213
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612808
INFO:root:FL Epoch: 43 Norm Difference for worker 1486 is 0.911355
INFO:root:FL Epoch: 43 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1738
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 43 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 43 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6206016996327568 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.962741365035375                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [1342, 690, 1438, 42, 1408, 485, 1636, 160, 325, 1]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 201 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :1342
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600061
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612732
INFO:root:FL Epoch: 44 Norm Difference for worker 1342 is 0.9482
INFO:root:FL Epoch: 44 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :690
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586118
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545242
INFO:root:FL Epoch: 44 Norm Difference for worker 690 is 0.946543
INFO:root:FL Epoch: 44 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1438
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654474
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663130
INFO:root:FL Epoch: 44 Norm Difference for worker 1438 is 0.974272
INFO:root:FL Epoch: 44 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :42
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 42 is 0.960416
INFO:root:FL Epoch: 44 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1408
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653215
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518692
INFO:root:FL Epoch: 44 Norm Difference for worker 1408 is 1.047196
INFO:root:FL Epoch: 44 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :485
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656209
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521399
INFO:root:FL Epoch: 44 Norm Difference for worker 485 is 1.031418
INFO:root:FL Epoch: 44 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1636
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644525
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646045
INFO:root:FL Epoch: 44 Norm Difference for worker 1636 is 1.002224
INFO:root:FL Epoch: 44 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :160
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 160 is 0.963677
INFO:root:FL Epoch: 44 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :325
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 325 is 1.0154
INFO:root:FL Epoch: 44 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 1 is 0.928356
INFO:root:FL Epoch: 44 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 44 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 44 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6284186524503371 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:1.0985913077990215                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [131, 1341, 630, 1813, 681, 1218, 590, 1927, 822, 1862]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :131
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673860
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 131 is 1.070295
INFO:root:FL Epoch: 45 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1341
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611247
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753546
INFO:root:FL Epoch: 45 Norm Difference for worker 1341 is 1.026106
INFO:root:FL Epoch: 45 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :630
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764366
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726340
INFO:root:FL Epoch: 45 Norm Difference for worker 630 is 1.062403
INFO:root:FL Epoch: 45 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1813
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644911
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473154
INFO:root:FL Epoch: 45 Norm Difference for worker 1813 is 1.13613
INFO:root:FL Epoch: 45 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :681
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716159
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510409
INFO:root:FL Epoch: 45 Norm Difference for worker 681 is 1.071678
INFO:root:FL Epoch: 45 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1218
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675502
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600327
INFO:root:FL Epoch: 45 Norm Difference for worker 1218 is 1.041135
INFO:root:FL Epoch: 45 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :590
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786924
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672113
INFO:root:FL Epoch: 45 Norm Difference for worker 590 is 1.047217
INFO:root:FL Epoch: 45 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1927
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628757
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554989
INFO:root:FL Epoch: 45 Norm Difference for worker 1927 is 1.074836
INFO:root:FL Epoch: 45 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :822
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600971
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741389
INFO:root:FL Epoch: 45 Norm Difference for worker 822 is 1.063604
INFO:root:FL Epoch: 45 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1862
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572485
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578465
INFO:root:FL Epoch: 45 Norm Difference for worker 1862 is 1.165986
INFO:root:FL Epoch: 45 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1218
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6465364414102891 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:1.2735846241315205                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1070, 1321, 1933, 1737, 1799, 403, 1155, 409, 412, 248]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1070
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649305
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537664
INFO:root:FL Epoch: 46 Norm Difference for worker 1070 is 1.00265
INFO:root:FL Epoch: 46 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1321
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526023
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555911
INFO:root:FL Epoch: 46 Norm Difference for worker 1321 is 1.027153
INFO:root:FL Epoch: 46 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1933
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522824
INFO:root:Worker: 1933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660078
INFO:root:FL Epoch: 46 Norm Difference for worker 1933 is 0.984487
INFO:root:FL Epoch: 46 Done on worker:1933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1737
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612156
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540799
INFO:root:FL Epoch: 46 Norm Difference for worker 1737 is 0.999929
INFO:root:FL Epoch: 46 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1799
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678532
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598221
INFO:root:FL Epoch: 46 Norm Difference for worker 1799 is 0.944064
INFO:root:FL Epoch: 46 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :403
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641075
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547610
INFO:root:FL Epoch: 46 Norm Difference for worker 403 is 1.083805
INFO:root:FL Epoch: 46 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1155
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797829
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.770685
INFO:root:FL Epoch: 46 Norm Difference for worker 1155 is 0.996545
INFO:root:FL Epoch: 46 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :409
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444516
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732020
INFO:root:FL Epoch: 46 Norm Difference for worker 409 is 1.025909
INFO:root:FL Epoch: 46 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :412
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.983326
INFO:root:Worker: 412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584293
INFO:root:FL Epoch: 46 Norm Difference for worker 412 is 0.947923
INFO:root:FL Epoch: 46 Done on worker:412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :248
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514250
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 248 is 0.985482
INFO:root:FL Epoch: 46 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1799
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6252629336188821 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:1.1057475407918294                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [739, 156, 1756, 1742, 1575, 1917, 508, 601, 660, 808]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 47 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :739
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726547
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675969
INFO:root:FL Epoch: 47 Norm Difference for worker 739 is 1.055654
INFO:root:FL Epoch: 47 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :156
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 47 Norm Difference for worker 156 is 1.017424
INFO:root:FL Epoch: 47 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1756
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636664
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504656
INFO:root:FL Epoch: 47 Norm Difference for worker 1756 is 1.0308
INFO:root:FL Epoch: 47 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1742
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505466
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563822
INFO:root:FL Epoch: 47 Norm Difference for worker 1742 is 0.977025
INFO:root:FL Epoch: 47 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1575
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597185
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530227
INFO:root:FL Epoch: 47 Norm Difference for worker 1575 is 1.103513
INFO:root:FL Epoch: 47 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1917
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530424
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454986
INFO:root:FL Epoch: 47 Norm Difference for worker 1917 is 1.013009
INFO:root:FL Epoch: 47 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :508
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587910
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521888
INFO:root:FL Epoch: 47 Norm Difference for worker 508 is 1.086089
INFO:root:FL Epoch: 47 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :601
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562693
INFO:root:Worker: 601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582132
INFO:root:FL Epoch: 47 Norm Difference for worker 601 is 1.003755
INFO:root:FL Epoch: 47 Done on worker:601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :660
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517522
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521071
INFO:root:FL Epoch: 47 Norm Difference for worker 660 is 1.070389
INFO:root:FL Epoch: 47 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :808
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485249
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409321
INFO:root:FL Epoch: 47 Norm Difference for worker 808 is 1.079078
INFO:root:FL Epoch: 47 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 601
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 47 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 47 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.6218318273039425 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:1.245047430197398                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [954, 581, 763, 844, 1336, 81, 502, 151, 1637, 1185]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :954
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555679
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510460
INFO:root:FL Epoch: 48 Norm Difference for worker 954 is 1.130583
INFO:root:FL Epoch: 48 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :581
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623844
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556061
INFO:root:FL Epoch: 48 Norm Difference for worker 581 is 1.222191
INFO:root:FL Epoch: 48 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :763
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605520
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580557
INFO:root:FL Epoch: 48 Norm Difference for worker 763 is 1.175634
INFO:root:FL Epoch: 48 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :844
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476850
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624754
INFO:root:FL Epoch: 48 Norm Difference for worker 844 is 1.090099
INFO:root:FL Epoch: 48 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1336
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632360
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527593
INFO:root:FL Epoch: 48 Norm Difference for worker 1336 is 1.159196
INFO:root:FL Epoch: 48 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :81
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 81 is 1.178631
INFO:root:FL Epoch: 48 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :502
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727017
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539522
INFO:root:FL Epoch: 48 Norm Difference for worker 502 is 1.119045
INFO:root:FL Epoch: 48 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :151
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 151 is 1.137863
INFO:root:FL Epoch: 48 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1637
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604329
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610831
INFO:root:FL Epoch: 48 Norm Difference for worker 1637 is 1.066956
INFO:root:FL Epoch: 48 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1185
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656416
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586026
INFO:root:FL Epoch: 48 Norm Difference for worker 1185 is 1.151786
INFO:root:FL Epoch: 48 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.6237185071496403 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.1515554785728455                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [463, 1158, 831, 944, 813, 289, 1379, 161, 82, 997]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :463
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655560
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423266
INFO:root:FL Epoch: 49 Norm Difference for worker 463 is 0.987635
INFO:root:FL Epoch: 49 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1158
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509831
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686410
INFO:root:FL Epoch: 49 Norm Difference for worker 1158 is 1.04231
INFO:root:FL Epoch: 49 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :831
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525059
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546894
INFO:root:FL Epoch: 49 Norm Difference for worker 831 is 1.090378
INFO:root:FL Epoch: 49 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :944
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580437
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787763
INFO:root:FL Epoch: 49 Norm Difference for worker 944 is 1.0126
INFO:root:FL Epoch: 49 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :813
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546824
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565573
INFO:root:FL Epoch: 49 Norm Difference for worker 813 is 1.001092
INFO:root:FL Epoch: 49 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :289
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690340
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 289 is 1.000569
INFO:root:FL Epoch: 49 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1379
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606091
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628009
INFO:root:FL Epoch: 49 Norm Difference for worker 1379 is 1.040122
INFO:root:FL Epoch: 49 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :161
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 161 is 1.02396
INFO:root:FL Epoch: 49 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :82
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577240
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 82 is 0.983297
INFO:root:FL Epoch: 49 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :997
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558851
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540941
INFO:root:FL Epoch: 49 Norm Difference for worker 997 is 1.093499
INFO:root:FL Epoch: 49 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 49 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 49 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.618901804966085 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:1.3382604320844014                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [545, 1346, 1144, 1831, 1069, 1333, 1751, 277, 248, 960]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :545
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522022
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433524
INFO:root:FL Epoch: 50 Norm Difference for worker 545 is 1.190298
INFO:root:FL Epoch: 50 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1346
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727562
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471174
INFO:root:FL Epoch: 50 Norm Difference for worker 1346 is 1.233355
INFO:root:FL Epoch: 50 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1144
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681461
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643413
INFO:root:FL Epoch: 50 Norm Difference for worker 1144 is 1.185787
INFO:root:FL Epoch: 50 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1831
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597132
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562802
INFO:root:FL Epoch: 50 Norm Difference for worker 1831 is 1.250146
INFO:root:FL Epoch: 50 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1069
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731610
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408454
INFO:root:FL Epoch: 50 Norm Difference for worker 1069 is 1.290657
INFO:root:FL Epoch: 50 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1333
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625837
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509866
INFO:root:FL Epoch: 50 Norm Difference for worker 1333 is 1.188692
INFO:root:FL Epoch: 50 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1751
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619007
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541634
INFO:root:FL Epoch: 50 Norm Difference for worker 1751 is 1.233741
INFO:root:FL Epoch: 50 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :277
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 277 is 1.239257
INFO:root:FL Epoch: 50 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :248
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 248 is 1.164635
INFO:root:FL Epoch: 50 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :960
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651369
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451837
INFO:root:FL Epoch: 50 Norm Difference for worker 960 is 1.190432
INFO:root:FL Epoch: 50 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 960
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 50 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 50 Saved Checkpoint at this epoch.
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6376679662395927 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.445591648419698                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [754, 1419, 117, 1887, 1834, 1663, 652, 75, 1343, 430]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :754
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726901
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411184
INFO:root:FL Epoch: 51 Norm Difference for worker 754 is 1.373952
INFO:root:FL Epoch: 51 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1419
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506776
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735834
INFO:root:FL Epoch: 51 Norm Difference for worker 1419 is 1.346341
INFO:root:FL Epoch: 51 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :117
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.895087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 117 is 1.29849
INFO:root:FL Epoch: 51 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1887
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794566
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571293
INFO:root:FL Epoch: 51 Norm Difference for worker 1887 is 1.28108
INFO:root:FL Epoch: 51 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1834
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814695
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317800
INFO:root:FL Epoch: 51 Norm Difference for worker 1834 is 1.384963
INFO:root:FL Epoch: 51 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1663
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614366
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287524
INFO:root:FL Epoch: 51 Norm Difference for worker 1663 is 1.242698
INFO:root:FL Epoch: 51 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :652
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519143
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607723
INFO:root:FL Epoch: 51 Norm Difference for worker 652 is 1.25177
INFO:root:FL Epoch: 51 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :75
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.887875
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 75 is 1.322682
INFO:root:FL Epoch: 51 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1343
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428182
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592085
INFO:root:FL Epoch: 51 Norm Difference for worker 1343 is 1.331583
INFO:root:FL Epoch: 51 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :430
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526865
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342495
INFO:root:FL Epoch: 51 Norm Difference for worker 430 is 1.370846
INFO:root:FL Epoch: 51 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 652
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.676704515429104 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:1.2321818669637044                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [1016, 1103, 1780, 427, 69, 939, 1927, 85, 1377, 1541]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :1016
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587368
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482865
INFO:root:FL Epoch: 52 Norm Difference for worker 1016 is 1.517443
INFO:root:FL Epoch: 52 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1103
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650577
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456308
INFO:root:FL Epoch: 52 Norm Difference for worker 1103 is 1.377339
INFO:root:FL Epoch: 52 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1780
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515486
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632094
INFO:root:FL Epoch: 52 Norm Difference for worker 1780 is 1.33137
INFO:root:FL Epoch: 52 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :427
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704907
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438200
INFO:root:FL Epoch: 52 Norm Difference for worker 427 is 1.425611
INFO:root:FL Epoch: 52 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :69
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599207
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.785625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 69 is 1.454665
INFO:root:FL Epoch: 52 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :939
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628804
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715687
INFO:root:FL Epoch: 52 Norm Difference for worker 939 is 1.488319
INFO:root:FL Epoch: 52 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1927
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702472
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452493
INFO:root:FL Epoch: 52 Norm Difference for worker 1927 is 1.431648
INFO:root:FL Epoch: 52 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :85
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 1.082561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 85 is 1.372417
INFO:root:FL Epoch: 52 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1377
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857188
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481867
INFO:root:FL Epoch: 52 Norm Difference for worker 1377 is 1.428492
INFO:root:FL Epoch: 52 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1541
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825510
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510107
INFO:root:FL Epoch: 52 Norm Difference for worker 1541 is 1.387287
INFO:root:FL Epoch: 52 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.6234106281224419 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:0.9165158271789551                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [976, 865, 1416, 613, 1084, 1287, 1590, 1517, 1751, 112]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :976
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655221
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521210
INFO:root:FL Epoch: 53 Norm Difference for worker 976 is 0.898612
INFO:root:FL Epoch: 53 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :865
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641252
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650673
INFO:root:FL Epoch: 53 Norm Difference for worker 865 is 0.865939
INFO:root:FL Epoch: 53 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1416
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577090
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530345
INFO:root:FL Epoch: 53 Norm Difference for worker 1416 is 0.976193
INFO:root:FL Epoch: 53 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :613
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643506
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542007
INFO:root:FL Epoch: 53 Norm Difference for worker 613 is 0.834186
INFO:root:FL Epoch: 53 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1084
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605255
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480442
INFO:root:FL Epoch: 53 Norm Difference for worker 1084 is 0.931342
INFO:root:FL Epoch: 53 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1287
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618524
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536181
INFO:root:FL Epoch: 53 Norm Difference for worker 1287 is 0.86325
INFO:root:FL Epoch: 53 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1590
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737099
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647968
INFO:root:FL Epoch: 53 Norm Difference for worker 1590 is 0.872857
INFO:root:FL Epoch: 53 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1517
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627244
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488202
INFO:root:FL Epoch: 53 Norm Difference for worker 1517 is 0.906488
INFO:root:FL Epoch: 53 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1751
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608711
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521051
INFO:root:FL Epoch: 53 Norm Difference for worker 1751 is 0.897711
INFO:root:FL Epoch: 53 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :112
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673610
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 112 is 0.883863
INFO:root:FL Epoch: 53 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.6305475568070131 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.2877240180969238                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [431, 348, 1481, 759, 1869, 1192, 866, 1576, 1330, 622]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 54 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :431
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803172
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469242
INFO:root:FL Epoch: 54 Norm Difference for worker 431 is 0.913633
INFO:root:FL Epoch: 54 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :348
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659196
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565368
INFO:root:FL Epoch: 54 Norm Difference for worker 348 is 0.964416
INFO:root:FL Epoch: 54 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1481
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608621
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719489
INFO:root:FL Epoch: 54 Norm Difference for worker 1481 is 0.987563
INFO:root:FL Epoch: 54 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :759
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585296
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544647
INFO:root:FL Epoch: 54 Norm Difference for worker 759 is 0.937786
INFO:root:FL Epoch: 54 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1869
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584743
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713517
INFO:root:FL Epoch: 54 Norm Difference for worker 1869 is 1.011827
INFO:root:FL Epoch: 54 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1192
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565432
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653543
INFO:root:FL Epoch: 54 Norm Difference for worker 1192 is 0.935394
INFO:root:FL Epoch: 54 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :866
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618794
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540799
INFO:root:FL Epoch: 54 Norm Difference for worker 866 is 0.985451
INFO:root:FL Epoch: 54 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1576
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647466
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597715
INFO:root:FL Epoch: 54 Norm Difference for worker 1576 is 0.985812
INFO:root:FL Epoch: 54 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1330
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537506
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626569
INFO:root:FL Epoch: 54 Norm Difference for worker 1330 is 1.009835
INFO:root:FL Epoch: 54 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :622
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465659
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376949
INFO:root:FL Epoch: 54 Norm Difference for worker 622 is 0.964984
INFO:root:FL Epoch: 54 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 431
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.6104963141329148 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:1.1824308236440022                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1830, 398, 216, 479, 1655, 1161, 1239, 183, 871, 332]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1830
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584027
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550149
INFO:root:FL Epoch: 55 Norm Difference for worker 1830 is 1.065649
INFO:root:FL Epoch: 55 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :398
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578574
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635792
INFO:root:FL Epoch: 55 Norm Difference for worker 398 is 1.055616
INFO:root:FL Epoch: 55 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :216
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 216 is 1.080899
INFO:root:FL Epoch: 55 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :479
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656660
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623655
INFO:root:FL Epoch: 55 Norm Difference for worker 479 is 1.086657
INFO:root:FL Epoch: 55 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1655
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664824
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543106
INFO:root:FL Epoch: 55 Norm Difference for worker 1655 is 1.016532
INFO:root:FL Epoch: 55 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1161
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680803
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601197
INFO:root:FL Epoch: 55 Norm Difference for worker 1161 is 1.05706
INFO:root:FL Epoch: 55 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1239
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752633
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695681
INFO:root:FL Epoch: 55 Norm Difference for worker 1239 is 1.022621
INFO:root:FL Epoch: 55 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :183
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 183 is 1.05134
INFO:root:FL Epoch: 55 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :871
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545994
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674193
INFO:root:FL Epoch: 55 Norm Difference for worker 871 is 1.088529
INFO:root:FL Epoch: 55 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :332
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 332 is 1.093628
INFO:root:FL Epoch: 55 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1239
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6192236858255723 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:1.0868945916493733                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [674, 74, 1352, 1659, 212, 122, 1086, 878, 248, 576]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 56 Num points on workers: [200 201 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :674
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652349
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514881
INFO:root:FL Epoch: 56 Norm Difference for worker 674 is 0.946794
INFO:root:FL Epoch: 56 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :74
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 74 is 0.971719
INFO:root:FL Epoch: 56 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1352
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567676
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366911
INFO:root:FL Epoch: 56 Norm Difference for worker 1352 is 1.048189
INFO:root:FL Epoch: 56 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1659
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542703
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510857
INFO:root:FL Epoch: 56 Norm Difference for worker 1659 is 1.036719
INFO:root:FL Epoch: 56 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :212
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.851479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 212 is 0.999794
INFO:root:FL Epoch: 56 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :122
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 122 is 0.971021
INFO:root:FL Epoch: 56 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1086
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554322
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596796
INFO:root:FL Epoch: 56 Norm Difference for worker 1086 is 0.926306
INFO:root:FL Epoch: 56 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :878
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563727
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562117
INFO:root:FL Epoch: 56 Norm Difference for worker 878 is 0.978001
INFO:root:FL Epoch: 56 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :248
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 248 is 0.965256
INFO:root:FL Epoch: 56 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :576
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553134
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494727
INFO:root:FL Epoch: 56 Norm Difference for worker 576 is 1.003114
INFO:root:FL Epoch: 56 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.6313769642044517 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.434896171092987                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [437, 630, 260, 935, 1139, 670, 1528, 1262, 1155, 857]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :437
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456718
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459595
INFO:root:FL Epoch: 57 Norm Difference for worker 437 is 1.079578
INFO:root:FL Epoch: 57 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :630
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678248
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560208
INFO:root:FL Epoch: 57 Norm Difference for worker 630 is 1.112174
INFO:root:FL Epoch: 57 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :260
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 260 is 1.041384
INFO:root:FL Epoch: 57 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :935
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576888
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564058
INFO:root:FL Epoch: 57 Norm Difference for worker 935 is 1.076219
INFO:root:FL Epoch: 57 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1139
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616240
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781012
INFO:root:FL Epoch: 57 Norm Difference for worker 1139 is 1.027302
INFO:root:FL Epoch: 57 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :670
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683130
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651720
INFO:root:FL Epoch: 57 Norm Difference for worker 670 is 1.045087
INFO:root:FL Epoch: 57 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1528
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630611
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538439
INFO:root:FL Epoch: 57 Norm Difference for worker 1528 is 1.084771
INFO:root:FL Epoch: 57 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1262
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742954
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734812
INFO:root:FL Epoch: 57 Norm Difference for worker 1262 is 1.032998
INFO:root:FL Epoch: 57 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1155
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695763
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507135
INFO:root:FL Epoch: 57 Norm Difference for worker 1155 is 1.090626
INFO:root:FL Epoch: 57 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :857
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766967
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617929
INFO:root:FL Epoch: 57 Norm Difference for worker 857 is 1.056308
INFO:root:FL Epoch: 57 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6168861336567822 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:1.0762208700180054                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1099, 1643, 652, 1647, 1401, 970, 202, 340, 737, 424]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1099
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735055
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676777
INFO:root:FL Epoch: 58 Norm Difference for worker 1099 is 1.092936
INFO:root:FL Epoch: 58 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1643
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426614
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656850
INFO:root:FL Epoch: 58 Norm Difference for worker 1643 is 1.082914
INFO:root:FL Epoch: 58 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :652
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332107
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372195
INFO:root:FL Epoch: 58 Norm Difference for worker 652 is 1.128765
INFO:root:FL Epoch: 58 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1647
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656598
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632052
INFO:root:FL Epoch: 58 Norm Difference for worker 1647 is 1.158301
INFO:root:FL Epoch: 58 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1401
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508417
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631188
INFO:root:FL Epoch: 58 Norm Difference for worker 1401 is 1.058294
INFO:root:FL Epoch: 58 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :970
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585836
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413714
INFO:root:FL Epoch: 58 Norm Difference for worker 970 is 1.078251
INFO:root:FL Epoch: 58 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :202
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.873798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 202 is 1.081711
INFO:root:FL Epoch: 58 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :340
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447221
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644070
INFO:root:FL Epoch: 58 Norm Difference for worker 340 is 1.045057
INFO:root:FL Epoch: 58 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :737
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706213
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620627
INFO:root:FL Epoch: 58 Norm Difference for worker 737 is 1.039663
INFO:root:FL Epoch: 58 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :424
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567987
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671441
INFO:root:FL Epoch: 58 Norm Difference for worker 424 is 1.043952
INFO:root:FL Epoch: 58 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6093903306652518 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:1.1602077881495159                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1518, 393, 1939, 1829, 1332, 626, 515, 190, 432, 872]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1518
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598324
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650041
INFO:root:FL Epoch: 59 Norm Difference for worker 1518 is 1.057373
INFO:root:FL Epoch: 59 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :393
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647397
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715548
INFO:root:FL Epoch: 59 Norm Difference for worker 393 is 1.034302
INFO:root:FL Epoch: 59 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1939
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698244
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596498
INFO:root:FL Epoch: 59 Norm Difference for worker 1939 is 1.091561
INFO:root:FL Epoch: 59 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1829
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768866
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485331
INFO:root:FL Epoch: 59 Norm Difference for worker 1829 is 1.024696
INFO:root:FL Epoch: 59 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1332
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960032
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483414
INFO:root:FL Epoch: 59 Norm Difference for worker 1332 is 1.025501
INFO:root:FL Epoch: 59 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :626
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599496
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631516
INFO:root:FL Epoch: 59 Norm Difference for worker 626 is 1.041768
INFO:root:FL Epoch: 59 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :515
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807778
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435800
INFO:root:FL Epoch: 59 Norm Difference for worker 515 is 1.049032
INFO:root:FL Epoch: 59 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :190
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.854060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 190 is 1.051725
INFO:root:FL Epoch: 59 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :432
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669108
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495810
INFO:root:FL Epoch: 59 Norm Difference for worker 432 is 0.999749
INFO:root:FL Epoch: 59 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :872
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541444
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529611
INFO:root:FL Epoch: 59 Norm Difference for worker 872 is 1.073217
INFO:root:FL Epoch: 59 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6142713813220754 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.4808303316434224                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [1539, 874, 994, 1205, 1214, 1221, 130, 141, 1627, 1921]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :1539
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485218
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522431
INFO:root:FL Epoch: 60 Norm Difference for worker 1539 is 1.143608
INFO:root:FL Epoch: 60 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :874
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749941
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488386
INFO:root:FL Epoch: 60 Norm Difference for worker 874 is 1.102342
INFO:root:FL Epoch: 60 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :994
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717420
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507054
INFO:root:FL Epoch: 60 Norm Difference for worker 994 is 1.149297
INFO:root:FL Epoch: 60 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1205
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705455
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623966
INFO:root:FL Epoch: 60 Norm Difference for worker 1205 is 1.10483
INFO:root:FL Epoch: 60 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1214
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509974
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642425
INFO:root:FL Epoch: 60 Norm Difference for worker 1214 is 1.100696
INFO:root:FL Epoch: 60 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1221
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650038
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573123
INFO:root:FL Epoch: 60 Norm Difference for worker 1221 is 1.065172
INFO:root:FL Epoch: 60 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :130
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 130 is 1.095373
INFO:root:FL Epoch: 60 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :141
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 141 is 1.10145
INFO:root:FL Epoch: 60 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1627
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785178
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551159
INFO:root:FL Epoch: 60 Norm Difference for worker 1627 is 1.039554
INFO:root:FL Epoch: 60 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1921
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814647
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547795
INFO:root:FL Epoch: 60 Norm Difference for worker 1921 is 1.06364
INFO:root:FL Epoch: 60 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.6311567513381734 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:1.4944985508918762                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [572, 974, 551, 1386, 1163, 792, 1056, 409, 1340, 935]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 61 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :572
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763144
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438304
INFO:root:FL Epoch: 61 Norm Difference for worker 572 is 1.099648
INFO:root:FL Epoch: 61 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :974
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374544
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472094
INFO:root:FL Epoch: 61 Norm Difference for worker 974 is 1.07771
INFO:root:FL Epoch: 61 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :551
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646694
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621961
INFO:root:FL Epoch: 61 Norm Difference for worker 551 is 0.988658
INFO:root:FL Epoch: 61 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1386
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443209
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602474
INFO:root:FL Epoch: 61 Norm Difference for worker 1386 is 1.050858
INFO:root:FL Epoch: 61 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1163
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577744
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473383
INFO:root:FL Epoch: 61 Norm Difference for worker 1163 is 1.106773
INFO:root:FL Epoch: 61 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :792
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449365
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519980
INFO:root:FL Epoch: 61 Norm Difference for worker 792 is 1.030726
INFO:root:FL Epoch: 61 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1056
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484267
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576722
INFO:root:FL Epoch: 61 Norm Difference for worker 1056 is 1.032751
INFO:root:FL Epoch: 61 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :409
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547874
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576150
INFO:root:FL Epoch: 61 Norm Difference for worker 409 is 1.058082
INFO:root:FL Epoch: 61 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1340
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663070
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570653
INFO:root:FL Epoch: 61 Norm Difference for worker 1340 is 1.039297
INFO:root:FL Epoch: 61 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :935
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567159
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533186
INFO:root:FL Epoch: 61 Norm Difference for worker 935 is 1.106155
INFO:root:FL Epoch: 61 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.6128082450698403 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.4316514531771343                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [1088, 1241, 1200, 596, 397, 1394, 1498, 1026, 1826, 145]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 62 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :1088
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521127
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510997
INFO:root:FL Epoch: 62 Norm Difference for worker 1088 is 1.010213
INFO:root:FL Epoch: 62 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1241
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606658
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567848
INFO:root:FL Epoch: 62 Norm Difference for worker 1241 is 1.028668
INFO:root:FL Epoch: 62 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1200
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579768
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674400
INFO:root:FL Epoch: 62 Norm Difference for worker 1200 is 1.032962
INFO:root:FL Epoch: 62 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :596
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535882
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554682
INFO:root:FL Epoch: 62 Norm Difference for worker 596 is 1.073958
INFO:root:FL Epoch: 62 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :397
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725617
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549317
INFO:root:FL Epoch: 62 Norm Difference for worker 397 is 1.053853
INFO:root:FL Epoch: 62 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1394
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768013
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536874
INFO:root:FL Epoch: 62 Norm Difference for worker 1394 is 1.185053
INFO:root:FL Epoch: 62 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1498
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560742
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630996
INFO:root:FL Epoch: 62 Norm Difference for worker 1498 is 1.043246
INFO:root:FL Epoch: 62 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1026
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519240
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399668
INFO:root:FL Epoch: 62 Norm Difference for worker 1026 is 1.103458
INFO:root:FL Epoch: 62 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1826
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380339
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529794
INFO:root:FL Epoch: 62 Norm Difference for worker 1826 is 1.090157
INFO:root:FL Epoch: 62 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :145
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 145 is 1.061075
INFO:root:FL Epoch: 62 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1200
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.5982680671355304 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.1171758969624836                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1129, 1047, 1125, 1528, 898, 459, 643, 1100, 1870, 1812]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1129
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753772
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630857
INFO:root:FL Epoch: 63 Norm Difference for worker 1129 is 0.894327
INFO:root:FL Epoch: 63 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1047
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733557
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496927
INFO:root:FL Epoch: 63 Norm Difference for worker 1047 is 0.919982
INFO:root:FL Epoch: 63 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1125
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566415
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561741
INFO:root:FL Epoch: 63 Norm Difference for worker 1125 is 0.929732
INFO:root:FL Epoch: 63 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1528
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505452
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400924
INFO:root:FL Epoch: 63 Norm Difference for worker 1528 is 1.050184
INFO:root:FL Epoch: 63 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :898
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526378
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504353
INFO:root:FL Epoch: 63 Norm Difference for worker 898 is 0.986715
INFO:root:FL Epoch: 63 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :459
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644958
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479593
INFO:root:FL Epoch: 63 Norm Difference for worker 459 is 1.030486
INFO:root:FL Epoch: 63 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :643
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597538
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672535
INFO:root:FL Epoch: 63 Norm Difference for worker 643 is 0.900152
INFO:root:FL Epoch: 63 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1100
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729471
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446506
INFO:root:FL Epoch: 63 Norm Difference for worker 1100 is 0.963457
INFO:root:FL Epoch: 63 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1870
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620499
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463275
INFO:root:FL Epoch: 63 Norm Difference for worker 1870 is 0.950497
INFO:root:FL Epoch: 63 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1812
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624322
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553886
INFO:root:FL Epoch: 63 Norm Difference for worker 1812 is 0.967851
INFO:root:FL Epoch: 63 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1129
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 63 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 63 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.5899533138555639 and Test Accuracy:70.0 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.1345936457316081                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [1467, 284, 1291, 998, 1682, 1945, 870, 1113, 566, 1021]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :1467
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756800
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521215
INFO:root:FL Epoch: 64 Norm Difference for worker 1467 is 0.93868
INFO:root:FL Epoch: 64 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :284
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 284 is 1.029188
INFO:root:FL Epoch: 64 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1291
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585689
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431432
INFO:root:FL Epoch: 64 Norm Difference for worker 1291 is 0.990664
INFO:root:FL Epoch: 64 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :998
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617040
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511269
INFO:root:FL Epoch: 64 Norm Difference for worker 998 is 1.025214
INFO:root:FL Epoch: 64 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1682
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656133
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380841
INFO:root:FL Epoch: 64 Norm Difference for worker 1682 is 1.016114
INFO:root:FL Epoch: 64 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1945
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659758
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565725
INFO:root:FL Epoch: 64 Norm Difference for worker 1945 is 0.962611
INFO:root:FL Epoch: 64 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :870
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744579
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720626
INFO:root:FL Epoch: 64 Norm Difference for worker 870 is 1.001245
INFO:root:FL Epoch: 64 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1113
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651258
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580470
INFO:root:FL Epoch: 64 Norm Difference for worker 1113 is 1.002151
INFO:root:FL Epoch: 64 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :566
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639008
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720765
INFO:root:FL Epoch: 64 Norm Difference for worker 566 is 1.027694
INFO:root:FL Epoch: 64 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1021
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478080
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547362
INFO:root:FL Epoch: 64 Norm Difference for worker 1021 is 0.982226
INFO:root:FL Epoch: 64 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1945
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5785126423134523 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:1.1074111262957256                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [784, 1044, 1724, 1263, 1314, 1313, 1783, 1779, 38, 1632]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 65 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :784
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450593
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557677
INFO:root:FL Epoch: 65 Norm Difference for worker 784 is 1.050483
INFO:root:FL Epoch: 65 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1044
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632469
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565708
INFO:root:FL Epoch: 65 Norm Difference for worker 1044 is 1.042453
INFO:root:FL Epoch: 65 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1724
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660336
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651531
INFO:root:FL Epoch: 65 Norm Difference for worker 1724 is 1.100399
INFO:root:FL Epoch: 65 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1263
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784613
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675973
INFO:root:FL Epoch: 65 Norm Difference for worker 1263 is 1.073157
INFO:root:FL Epoch: 65 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1314
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526385
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418864
INFO:root:FL Epoch: 65 Norm Difference for worker 1314 is 1.086655
INFO:root:FL Epoch: 65 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1313
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579838
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313913
INFO:root:FL Epoch: 65 Norm Difference for worker 1313 is 1.137054
INFO:root:FL Epoch: 65 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1783
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664532
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524577
INFO:root:FL Epoch: 65 Norm Difference for worker 1783 is 1.133312
INFO:root:FL Epoch: 65 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1779
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655831
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498377
INFO:root:FL Epoch: 65 Norm Difference for worker 1779 is 1.063185
INFO:root:FL Epoch: 65 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :38
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 38 is 1.008667
INFO:root:FL Epoch: 65 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1632
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562377
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480715
INFO:root:FL Epoch: 65 Norm Difference for worker 1632 is 1.077788
INFO:root:FL Epoch: 65 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.5767682124586666 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.1185900966326396                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1180, 1592, 1737, 1220, 1283, 1538, 1700, 1300, 70, 804]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1180
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614284
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667124
INFO:root:FL Epoch: 66 Norm Difference for worker 1180 is 1.045997
INFO:root:FL Epoch: 66 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1592
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613447
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725220
INFO:root:FL Epoch: 66 Norm Difference for worker 1592 is 1.185941
INFO:root:FL Epoch: 66 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1737
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543343
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570039
INFO:root:FL Epoch: 66 Norm Difference for worker 1737 is 1.0958
INFO:root:FL Epoch: 66 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1220
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574136
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564894
INFO:root:FL Epoch: 66 Norm Difference for worker 1220 is 1.070563
INFO:root:FL Epoch: 66 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1283
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512957
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458061
INFO:root:FL Epoch: 66 Norm Difference for worker 1283 is 1.099006
INFO:root:FL Epoch: 66 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1538
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777202
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537790
INFO:root:FL Epoch: 66 Norm Difference for worker 1538 is 1.088279
INFO:root:FL Epoch: 66 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1700
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753537
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342710
INFO:root:FL Epoch: 66 Norm Difference for worker 1700 is 1.043285
INFO:root:FL Epoch: 66 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1300
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712724
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705061
INFO:root:FL Epoch: 66 Norm Difference for worker 1300 is 1.116632
INFO:root:FL Epoch: 66 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :70
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.879280
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 70 is 1.001717
INFO:root:FL Epoch: 66 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :804
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656567
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559398
INFO:root:FL Epoch: 66 Norm Difference for worker 804 is 1.122517
INFO:root:FL Epoch: 66 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.5927952212445876 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:1.5354668299357097                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [433, 575, 1720, 570, 1195, 1406, 224, 445, 836, 1877]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :433
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550068
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488736
INFO:root:FL Epoch: 67 Norm Difference for worker 433 is 1.187672
INFO:root:FL Epoch: 67 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703249
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638790
INFO:root:FL Epoch: 67 Norm Difference for worker 575 is 1.200818
INFO:root:FL Epoch: 67 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1720
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593624
INFO:root:Worker: 1720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566448
INFO:root:FL Epoch: 67 Norm Difference for worker 1720 is 1.098855
INFO:root:FL Epoch: 67 Done on worker:1720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :570
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706683
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643515
INFO:root:FL Epoch: 67 Norm Difference for worker 570 is 1.110114
INFO:root:FL Epoch: 67 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1195
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609668
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492249
INFO:root:FL Epoch: 67 Norm Difference for worker 1195 is 1.137527
INFO:root:FL Epoch: 67 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1406
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.863279
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555266
INFO:root:FL Epoch: 67 Norm Difference for worker 1406 is 1.246084
INFO:root:FL Epoch: 67 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :224
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 224 is 1.192485
INFO:root:FL Epoch: 67 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :445
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782964
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628848
INFO:root:FL Epoch: 67 Norm Difference for worker 445 is 1.204809
INFO:root:FL Epoch: 67 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :836
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725367
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665086
INFO:root:FL Epoch: 67 Norm Difference for worker 836 is 1.127996
INFO:root:FL Epoch: 67 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1877
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563948
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442258
INFO:root:FL Epoch: 67 Norm Difference for worker 1877 is 1.208462
INFO:root:FL Epoch: 67 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 67 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 67 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5689967274665833 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.4401907324790955                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [54, 1863, 712, 1378, 1204, 903, 1564, 1772, 1873, 1227]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 68 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :54
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 54 is 1.086035
INFO:root:FL Epoch: 68 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1863
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515518
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425522
INFO:root:FL Epoch: 68 Norm Difference for worker 1863 is 1.035511
INFO:root:FL Epoch: 68 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :712
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367213
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633090
INFO:root:FL Epoch: 68 Norm Difference for worker 712 is 1.160463
INFO:root:FL Epoch: 68 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1378
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660582
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431816
INFO:root:FL Epoch: 68 Norm Difference for worker 1378 is 1.103591
INFO:root:FL Epoch: 68 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1204
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822789
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468554
INFO:root:FL Epoch: 68 Norm Difference for worker 1204 is 1.07426
INFO:root:FL Epoch: 68 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :903
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735763
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478858
INFO:root:FL Epoch: 68 Norm Difference for worker 903 is 1.020776
INFO:root:FL Epoch: 68 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1564
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537459
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617350
INFO:root:FL Epoch: 68 Norm Difference for worker 1564 is 1.111476
INFO:root:FL Epoch: 68 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1772
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706388
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590707
INFO:root:FL Epoch: 68 Norm Difference for worker 1772 is 1.057113
INFO:root:FL Epoch: 68 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1873
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587517
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433015
INFO:root:FL Epoch: 68 Norm Difference for worker 1873 is 1.133783
INFO:root:FL Epoch: 68 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1227
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574545
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610219
INFO:root:FL Epoch: 68 Norm Difference for worker 1227 is 1.094912
INFO:root:FL Epoch: 68 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1863
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5841712601044599 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.5650103092193604                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [368, 1628, 73, 1261, 608, 1478, 809, 1325, 1306, 1354]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :368
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571541
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461513
INFO:root:FL Epoch: 69 Norm Difference for worker 368 is 1.212361
INFO:root:FL Epoch: 69 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1628
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594230
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562611
INFO:root:FL Epoch: 69 Norm Difference for worker 1628 is 1.111295
INFO:root:FL Epoch: 69 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :73
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 73 is 1.138593
INFO:root:FL Epoch: 69 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1261
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592789
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531477
INFO:root:FL Epoch: 69 Norm Difference for worker 1261 is 1.193581
INFO:root:FL Epoch: 69 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :608
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551132
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615322
INFO:root:FL Epoch: 69 Norm Difference for worker 608 is 1.153355
INFO:root:FL Epoch: 69 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1478
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524552
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483277
INFO:root:FL Epoch: 69 Norm Difference for worker 1478 is 1.099323
INFO:root:FL Epoch: 69 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :809
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524430
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502537
INFO:root:FL Epoch: 69 Norm Difference for worker 809 is 1.181779
INFO:root:FL Epoch: 69 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1325
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493651
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689674
INFO:root:FL Epoch: 69 Norm Difference for worker 1325 is 1.185382
INFO:root:FL Epoch: 69 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1306
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676896
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404965
INFO:root:FL Epoch: 69 Norm Difference for worker 1306 is 1.201439
INFO:root:FL Epoch: 69 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1354
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532457
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423661
INFO:root:FL Epoch: 69 Norm Difference for worker 1354 is 1.23294
INFO:root:FL Epoch: 69 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 809
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5829544347875258 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.3999648888905842                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [2, 1106, 795, 898, 1082, 59, 191, 1322, 1608, 937]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 70 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :2
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 2 is 1.001129
INFO:root:FL Epoch: 70 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1106
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632253
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736601
INFO:root:FL Epoch: 70 Norm Difference for worker 1106 is 1.08017
INFO:root:FL Epoch: 70 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :795
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532403
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527167
INFO:root:FL Epoch: 70 Norm Difference for worker 795 is 1.045653
INFO:root:FL Epoch: 70 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :898
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634792
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494018
INFO:root:FL Epoch: 70 Norm Difference for worker 898 is 1.072108
INFO:root:FL Epoch: 70 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1082
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623562
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581357
INFO:root:FL Epoch: 70 Norm Difference for worker 1082 is 1.051324
INFO:root:FL Epoch: 70 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :59
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464553
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 59 is 1.062825
INFO:root:FL Epoch: 70 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :191
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 191 is 1.140241
INFO:root:FL Epoch: 70 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1322
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626761
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653643
INFO:root:FL Epoch: 70 Norm Difference for worker 1322 is 1.046919
INFO:root:FL Epoch: 70 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1608
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587212
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401090
INFO:root:FL Epoch: 70 Norm Difference for worker 1608 is 1.084149
INFO:root:FL Epoch: 70 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :937
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512809
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480072
INFO:root:FL Epoch: 70 Norm Difference for worker 937 is 1.09665
INFO:root:FL Epoch: 70 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.5731035102816189 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.4955103397369385                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [466, 984, 1232, 1937, 1000, 1729, 1353, 607, 194, 1226]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :466
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451907
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385630
INFO:root:FL Epoch: 71 Norm Difference for worker 466 is 1.092887
INFO:root:FL Epoch: 71 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :984
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655760
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469726
INFO:root:FL Epoch: 71 Norm Difference for worker 984 is 1.088202
INFO:root:FL Epoch: 71 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1232
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600181
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623111
INFO:root:FL Epoch: 71 Norm Difference for worker 1232 is 1.144988
INFO:root:FL Epoch: 71 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1937
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406865
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686476
INFO:root:FL Epoch: 71 Norm Difference for worker 1937 is 1.193652
INFO:root:FL Epoch: 71 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1000
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732611
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605498
INFO:root:FL Epoch: 71 Norm Difference for worker 1000 is 1.14812
INFO:root:FL Epoch: 71 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1729
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625700
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666737
INFO:root:FL Epoch: 71 Norm Difference for worker 1729 is 1.215772
INFO:root:FL Epoch: 71 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1353
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579127
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492621
INFO:root:FL Epoch: 71 Norm Difference for worker 1353 is 1.134405
INFO:root:FL Epoch: 71 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :607
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429265
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473888
INFO:root:FL Epoch: 71 Norm Difference for worker 607 is 1.05095
INFO:root:FL Epoch: 71 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :194
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.621696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 194 is 1.152351
INFO:root:FL Epoch: 71 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1226
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592120
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502462
INFO:root:FL Epoch: 71 Norm Difference for worker 1226 is 1.166379
INFO:root:FL Epoch: 71 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 607
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.5772236936232623 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.5659303069114685                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1054, 1316, 269, 1086, 1222, 881, 1886, 649, 1904, 331]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1054
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 1.049223
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408588
INFO:root:FL Epoch: 72 Norm Difference for worker 1054 is 1.150872
INFO:root:FL Epoch: 72 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1316
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707956
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435712
INFO:root:FL Epoch: 72 Norm Difference for worker 1316 is 1.106382
INFO:root:FL Epoch: 72 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :269
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 269 is 1.154258
INFO:root:FL Epoch: 72 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1086
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459422
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510136
INFO:root:FL Epoch: 72 Norm Difference for worker 1086 is 1.122677
INFO:root:FL Epoch: 72 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1222
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686667
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421702
INFO:root:FL Epoch: 72 Norm Difference for worker 1222 is 1.142324
INFO:root:FL Epoch: 72 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :881
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479131
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543427
INFO:root:FL Epoch: 72 Norm Difference for worker 881 is 1.160911
INFO:root:FL Epoch: 72 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1886
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481072
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625149
INFO:root:FL Epoch: 72 Norm Difference for worker 1886 is 1.266769
INFO:root:FL Epoch: 72 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :649
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388854
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716168
INFO:root:FL Epoch: 72 Norm Difference for worker 649 is 1.305101
INFO:root:FL Epoch: 72 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1904
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483674
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365309
INFO:root:FL Epoch: 72 Norm Difference for worker 1904 is 1.185151
INFO:root:FL Epoch: 72 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :331
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 331 is 1.158653
INFO:root:FL Epoch: 72 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5888525107327629 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:1.0454968512058258                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1915, 303, 1819, 1410, 1455, 1359, 699, 1199, 411, 1733]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 73 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1915
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779800
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607802
INFO:root:FL Epoch: 73 Norm Difference for worker 1915 is 0.917002
INFO:root:FL Epoch: 73 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :303
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 303 is 0.977938
INFO:root:FL Epoch: 73 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1819
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729976
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698490
INFO:root:FL Epoch: 73 Norm Difference for worker 1819 is 0.975075
INFO:root:FL Epoch: 73 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1410
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520377
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584483
INFO:root:FL Epoch: 73 Norm Difference for worker 1410 is 1.005935
INFO:root:FL Epoch: 73 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1455
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628550
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542976
INFO:root:FL Epoch: 73 Norm Difference for worker 1455 is 0.945611
INFO:root:FL Epoch: 73 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1359
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673106
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488753
INFO:root:FL Epoch: 73 Norm Difference for worker 1359 is 0.968838
INFO:root:FL Epoch: 73 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :699
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623247
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630360
INFO:root:FL Epoch: 73 Norm Difference for worker 699 is 0.959144
INFO:root:FL Epoch: 73 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1199
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681536
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611660
INFO:root:FL Epoch: 73 Norm Difference for worker 1199 is 0.948454
INFO:root:FL Epoch: 73 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :411
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643708
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648426
INFO:root:FL Epoch: 73 Norm Difference for worker 411 is 0.992187
INFO:root:FL Epoch: 73 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1733
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679101
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569426
INFO:root:FL Epoch: 73 Norm Difference for worker 1733 is 0.947566
INFO:root:FL Epoch: 73 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1915
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.605772465467453 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:1.0580015579859416                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [1061, 1487, 1898, 1943, 1731, 366, 513, 1048, 675, 1126]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :1061
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553923
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464642
INFO:root:FL Epoch: 74 Norm Difference for worker 1061 is 0.996565
INFO:root:FL Epoch: 74 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1487
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519833
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427620
INFO:root:FL Epoch: 74 Norm Difference for worker 1487 is 1.074134
INFO:root:FL Epoch: 74 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1898
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484923
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560011
INFO:root:FL Epoch: 74 Norm Difference for worker 1898 is 1.01933
INFO:root:FL Epoch: 74 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1943
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589040
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424576
INFO:root:FL Epoch: 74 Norm Difference for worker 1943 is 0.997202
INFO:root:FL Epoch: 74 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1731
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700489
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595997
INFO:root:FL Epoch: 74 Norm Difference for worker 1731 is 0.992088
INFO:root:FL Epoch: 74 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :366
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526997
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542596
INFO:root:FL Epoch: 74 Norm Difference for worker 366 is 1.062478
INFO:root:FL Epoch: 74 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :513
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609590
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720362
INFO:root:FL Epoch: 74 Norm Difference for worker 513 is 1.038192
INFO:root:FL Epoch: 74 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1048
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802306
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625836
INFO:root:FL Epoch: 74 Norm Difference for worker 1048 is 1.076586
INFO:root:FL Epoch: 74 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :675
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528525
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598965
INFO:root:FL Epoch: 74 Norm Difference for worker 675 is 1.074661
INFO:root:FL Epoch: 74 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1126
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681430
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583826
INFO:root:FL Epoch: 74 Norm Difference for worker 1126 is 1.007509
INFO:root:FL Epoch: 74 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.6051636127864614 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.6324395140012105                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [1138, 802, 1838, 1483, 532, 1411, 1237, 1598, 977, 885]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :1138
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698305
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482329
INFO:root:FL Epoch: 75 Norm Difference for worker 1138 is 1.117645
INFO:root:FL Epoch: 75 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :802
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501693
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668347
INFO:root:FL Epoch: 75 Norm Difference for worker 802 is 1.085179
INFO:root:FL Epoch: 75 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1838
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631475
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420166
INFO:root:FL Epoch: 75 Norm Difference for worker 1838 is 1.023524
INFO:root:FL Epoch: 75 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1483
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553836
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700674
INFO:root:FL Epoch: 75 Norm Difference for worker 1483 is 1.081299
INFO:root:FL Epoch: 75 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :532
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860101
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527119
INFO:root:FL Epoch: 75 Norm Difference for worker 532 is 1.09157
INFO:root:FL Epoch: 75 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1411
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691151
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634997
INFO:root:FL Epoch: 75 Norm Difference for worker 1411 is 1.057491
INFO:root:FL Epoch: 75 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1237
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697541
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738418
INFO:root:FL Epoch: 75 Norm Difference for worker 1237 is 1.079798
INFO:root:FL Epoch: 75 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1598
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856907
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514451
INFO:root:FL Epoch: 75 Norm Difference for worker 1598 is 1.019386
INFO:root:FL Epoch: 75 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :977
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593817
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595552
INFO:root:FL Epoch: 75 Norm Difference for worker 977 is 1.102111
INFO:root:FL Epoch: 75 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :885
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534870
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.825441
INFO:root:FL Epoch: 75 Norm Difference for worker 885 is 1.117407
INFO:root:FL Epoch: 75 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.5904427766799927 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:1.2126855452855427                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [15, 357, 96, 634, 641, 1474, 219, 1205, 225, 1260]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 76 Num points on workers: [201 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :15
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 15 is 1.100079
INFO:root:FL Epoch: 76 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :357
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534547
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465084
INFO:root:FL Epoch: 76 Norm Difference for worker 357 is 1.022637
INFO:root:FL Epoch: 76 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :96
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 96 is 1.108199
INFO:root:FL Epoch: 76 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :634
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554601
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535336
INFO:root:FL Epoch: 76 Norm Difference for worker 634 is 1.103159
INFO:root:FL Epoch: 76 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :641
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577854
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549554
INFO:root:FL Epoch: 76 Norm Difference for worker 641 is 1.165399
INFO:root:FL Epoch: 76 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1474
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615340
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662421
INFO:root:FL Epoch: 76 Norm Difference for worker 1474 is 1.081426
INFO:root:FL Epoch: 76 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :219
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 219 is 1.042201
INFO:root:FL Epoch: 76 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1205
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439230
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527536
INFO:root:FL Epoch: 76 Norm Difference for worker 1205 is 1.088686
INFO:root:FL Epoch: 76 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :225
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 225 is 1.115402
INFO:root:FL Epoch: 76 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1260
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538605
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476135
INFO:root:FL Epoch: 76 Norm Difference for worker 1260 is 1.096825
INFO:root:FL Epoch: 76 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 357
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5786815145436455 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.3819276889165242                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [1079, 1470, 301, 1255, 958, 201, 293, 180, 79, 1407]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09975062 0.09975062 0.10024938 0.09975062 0.09975062 0.10024938
 0.10024938 0.10024938 0.10024938 0.09975062]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 201 200 200 201 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :1079
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618342
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566496
INFO:root:FL Epoch: 77 Norm Difference for worker 1079 is 1.034405
INFO:root:FL Epoch: 77 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1470
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450054
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635102
INFO:root:FL Epoch: 77 Norm Difference for worker 1470 is 1.013698
INFO:root:FL Epoch: 77 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :301
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 301 is 1.021633
INFO:root:FL Epoch: 77 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1255
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455289
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542152
INFO:root:FL Epoch: 77 Norm Difference for worker 1255 is 1.080474
INFO:root:FL Epoch: 77 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :958
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603472
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639308
INFO:root:FL Epoch: 77 Norm Difference for worker 958 is 1.043262
INFO:root:FL Epoch: 77 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :201
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 201 is 0.98821
INFO:root:FL Epoch: 77 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :293
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.739977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 293 is 1.041056
INFO:root:FL Epoch: 77 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :180
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538508
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 180 is 1.073455
INFO:root:FL Epoch: 77 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :79
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 79 is 0.979895
INFO:root:FL Epoch: 77 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1407
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597292
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448585
INFO:root:FL Epoch: 77 Norm Difference for worker 1407 is 0.998162
INFO:root:FL Epoch: 77 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1470
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5828477635103113 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.43992018699646                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [725, 1725, 1451, 1094, 739, 661, 346, 708, 1322, 129]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :725
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689116
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562940
INFO:root:FL Epoch: 78 Norm Difference for worker 725 is 1.107696
INFO:root:FL Epoch: 78 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1725
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549973
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618837
INFO:root:FL Epoch: 78 Norm Difference for worker 1725 is 1.14655
INFO:root:FL Epoch: 78 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1451
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615777
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471697
INFO:root:FL Epoch: 78 Norm Difference for worker 1451 is 1.099451
INFO:root:FL Epoch: 78 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1094
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805321
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610205
INFO:root:FL Epoch: 78 Norm Difference for worker 1094 is 1.02277
INFO:root:FL Epoch: 78 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :739
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582373
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671400
INFO:root:FL Epoch: 78 Norm Difference for worker 739 is 1.11231
INFO:root:FL Epoch: 78 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :661
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576401
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531251
INFO:root:FL Epoch: 78 Norm Difference for worker 661 is 1.15501
INFO:root:FL Epoch: 78 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :346
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462220
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556943
INFO:root:FL Epoch: 78 Norm Difference for worker 346 is 1.124071
INFO:root:FL Epoch: 78 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :708
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552186
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499436
INFO:root:FL Epoch: 78 Norm Difference for worker 708 is 1.079996
INFO:root:FL Epoch: 78 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1322
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964720
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610563
INFO:root:FL Epoch: 78 Norm Difference for worker 1322 is 1.094832
INFO:root:FL Epoch: 78 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :129
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 129 is 1.074264
INFO:root:FL Epoch: 78 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1094
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.6023405281936421 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.4384623169898987                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1714, 1307, 230, 892, 725, 1049, 1303, 511, 1853, 442]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 79 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1714
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527987
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524291
INFO:root:FL Epoch: 79 Norm Difference for worker 1714 is 1.005962
INFO:root:FL Epoch: 79 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1307
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653620
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614985
INFO:root:FL Epoch: 79 Norm Difference for worker 1307 is 0.953403
INFO:root:FL Epoch: 79 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :230
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 230 is 0.938899
INFO:root:FL Epoch: 79 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :892
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554607
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587656
INFO:root:FL Epoch: 79 Norm Difference for worker 892 is 0.903752
INFO:root:FL Epoch: 79 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :725
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626768
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584380
INFO:root:FL Epoch: 79 Norm Difference for worker 725 is 0.931525
INFO:root:FL Epoch: 79 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1049
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611293
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575701
INFO:root:FL Epoch: 79 Norm Difference for worker 1049 is 0.871125
INFO:root:FL Epoch: 79 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1303
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569027
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530783
INFO:root:FL Epoch: 79 Norm Difference for worker 1303 is 0.990795
INFO:root:FL Epoch: 79 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :511
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543383
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454137
INFO:root:FL Epoch: 79 Norm Difference for worker 511 is 0.994501
INFO:root:FL Epoch: 79 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1853
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557901
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540480
INFO:root:FL Epoch: 79 Norm Difference for worker 1853 is 0.952673
INFO:root:FL Epoch: 79 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :442
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560545
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596532
INFO:root:FL Epoch: 79 Norm Difference for worker 442 is 0.930953
INFO:root:FL Epoch: 79 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.5847804861910203 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.4686288237571716                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [611, 1586, 1335, 1086, 217, 1761, 1610, 551, 268, 1838]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 80 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :611
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765278
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620167
INFO:root:FL Epoch: 80 Norm Difference for worker 611 is 1.050089
INFO:root:FL Epoch: 80 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1586
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490836
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502093
INFO:root:FL Epoch: 80 Norm Difference for worker 1586 is 1.045134
INFO:root:FL Epoch: 80 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709992
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552848
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.040237
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1086
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546984
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456922
INFO:root:FL Epoch: 80 Norm Difference for worker 1086 is 1.003785
INFO:root:FL Epoch: 80 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :217
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 217 is 1.061863
INFO:root:FL Epoch: 80 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1761
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659463
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515610
INFO:root:FL Epoch: 80 Norm Difference for worker 1761 is 1.138408
INFO:root:FL Epoch: 80 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1610
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725514
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673610
INFO:root:FL Epoch: 80 Norm Difference for worker 1610 is 1.016921
INFO:root:FL Epoch: 80 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :551
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394263
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626558
INFO:root:FL Epoch: 80 Norm Difference for worker 551 is 0.983655
INFO:root:FL Epoch: 80 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :268
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 268 is 0.990615
INFO:root:FL Epoch: 80 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1838
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374765
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475213
INFO:root:FL Epoch: 80 Norm Difference for worker 1838 is 1.002228
INFO:root:FL Epoch: 80 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 268
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5919871978900012 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:1.343499521414439                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1186, 1816, 1050, 105, 190, 1693, 1897, 405, 673, 155]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1186
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824219
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506682
INFO:root:FL Epoch: 81 Norm Difference for worker 1186 is 1.016876
INFO:root:FL Epoch: 81 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1816
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578606
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.761495
INFO:root:FL Epoch: 81 Norm Difference for worker 1816 is 1.016453
INFO:root:FL Epoch: 81 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1050
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433814
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612183
INFO:root:FL Epoch: 81 Norm Difference for worker 1050 is 1.031253
INFO:root:FL Epoch: 81 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :105
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 105 is 1.048275
INFO:root:FL Epoch: 81 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :190
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.755715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 190 is 1.05687
INFO:root:FL Epoch: 81 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1693
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678711
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562459
INFO:root:FL Epoch: 81 Norm Difference for worker 1693 is 1.037603
INFO:root:FL Epoch: 81 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1897
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594972
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588371
INFO:root:FL Epoch: 81 Norm Difference for worker 1897 is 1.049973
INFO:root:FL Epoch: 81 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :405
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553366
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399096
INFO:root:FL Epoch: 81 Norm Difference for worker 405 is 1.024518
INFO:root:FL Epoch: 81 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :673
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570974
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746606
INFO:root:FL Epoch: 81 Norm Difference for worker 673 is 1.066351
INFO:root:FL Epoch: 81 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :155
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 155 is 1.055515
INFO:root:FL Epoch: 81 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1186
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5782712417490342 and Test Accuracy:70.0 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.502182165781657                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1486, 1071, 1840, 542, 212, 1019, 1135, 336, 455, 1920]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1486
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633486
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619631
INFO:root:FL Epoch: 82 Norm Difference for worker 1486 is 1.053166
INFO:root:FL Epoch: 82 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1071
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614577
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581304
INFO:root:FL Epoch: 82 Norm Difference for worker 1071 is 1.070217
INFO:root:FL Epoch: 82 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1840
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643590
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.779858
INFO:root:FL Epoch: 82 Norm Difference for worker 1840 is 1.008978
INFO:root:FL Epoch: 82 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :542
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515492
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407303
INFO:root:FL Epoch: 82 Norm Difference for worker 542 is 1.059246
INFO:root:FL Epoch: 82 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :212
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 212 is 1.10538
INFO:root:FL Epoch: 82 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1019
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596459
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567140
INFO:root:FL Epoch: 82 Norm Difference for worker 1019 is 1.04498
INFO:root:FL Epoch: 82 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1135
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678068
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680556
INFO:root:FL Epoch: 82 Norm Difference for worker 1135 is 1.051945
INFO:root:FL Epoch: 82 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :336
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 336 is 0.985091
INFO:root:FL Epoch: 82 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :455
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697689
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598756
INFO:root:FL Epoch: 82 Norm Difference for worker 455 is 1.084813
INFO:root:FL Epoch: 82 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1920
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535184
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640998
INFO:root:FL Epoch: 82 Norm Difference for worker 1920 is 1.005671
INFO:root:FL Epoch: 82 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 336
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.5847971562077018 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.57529217004776                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1047, 481, 1351, 1279, 927, 433, 1581, 1292, 78, 1551]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1047
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757208
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536264
INFO:root:FL Epoch: 83 Norm Difference for worker 1047 is 1.215454
INFO:root:FL Epoch: 83 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :481
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601330
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525143
INFO:root:FL Epoch: 83 Norm Difference for worker 481 is 1.236903
INFO:root:FL Epoch: 83 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1351
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813482
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.876764
INFO:root:FL Epoch: 83 Norm Difference for worker 1351 is 1.155328
INFO:root:FL Epoch: 83 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1279
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864754
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455238
INFO:root:FL Epoch: 83 Norm Difference for worker 1279 is 1.159636
INFO:root:FL Epoch: 83 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :927
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613995
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460257
INFO:root:FL Epoch: 83 Norm Difference for worker 927 is 1.161224
INFO:root:FL Epoch: 83 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :433
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710135
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494522
INFO:root:FL Epoch: 83 Norm Difference for worker 433 is 1.255277
INFO:root:FL Epoch: 83 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1581
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676601
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389699
INFO:root:FL Epoch: 83 Norm Difference for worker 1581 is 1.231923
INFO:root:FL Epoch: 83 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1292
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669961
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532481
INFO:root:FL Epoch: 83 Norm Difference for worker 1292 is 1.204679
INFO:root:FL Epoch: 83 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :78
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 78 is 1.129134
INFO:root:FL Epoch: 83 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1551
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544247
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612301
INFO:root:FL Epoch: 83 Norm Difference for worker 1551 is 1.192197
INFO:root:FL Epoch: 83 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.5998337444137124 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.4514855742454529                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1748, 1571, 1610, 1107, 1165, 138, 1307, 528, 210, 1354]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1748
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630298
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589405
INFO:root:FL Epoch: 84 Norm Difference for worker 1748 is 1.058672
INFO:root:FL Epoch: 84 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1571
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736886
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479783
INFO:root:FL Epoch: 84 Norm Difference for worker 1571 is 1.043139
INFO:root:FL Epoch: 84 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1610
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715926
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526036
INFO:root:FL Epoch: 84 Norm Difference for worker 1610 is 1.077353
INFO:root:FL Epoch: 84 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1107
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463739
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454116
INFO:root:FL Epoch: 84 Norm Difference for worker 1107 is 1.126465
INFO:root:FL Epoch: 84 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1165
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508845
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444153
INFO:root:FL Epoch: 84 Norm Difference for worker 1165 is 1.100402
INFO:root:FL Epoch: 84 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :138
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 138 is 1.039974
INFO:root:FL Epoch: 84 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1307
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566677
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708862
INFO:root:FL Epoch: 84 Norm Difference for worker 1307 is 1.074581
INFO:root:FL Epoch: 84 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :528
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515995
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665263
INFO:root:FL Epoch: 84 Norm Difference for worker 528 is 1.074328
INFO:root:FL Epoch: 84 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :210
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 210 is 1.017516
INFO:root:FL Epoch: 84 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1354
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640067
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579102
INFO:root:FL Epoch: 84 Norm Difference for worker 1354 is 1.038177
INFO:root:FL Epoch: 84 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 138
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5987609694985783 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:1.15507177511851                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [1331, 211, 1476, 1318, 749, 1936, 1164, 247, 878, 856]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 85 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :1331
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1331 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664392
INFO:root:Worker: 1331 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589539
INFO:root:FL Epoch: 85 Norm Difference for worker 1331 is 0.989664
INFO:root:FL Epoch: 85 Done on worker:1331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :211
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 211 is 1.023956
INFO:root:FL Epoch: 85 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1476
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634979
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587444
INFO:root:FL Epoch: 85 Norm Difference for worker 1476 is 0.993975
INFO:root:FL Epoch: 85 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1318
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592077
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681851
INFO:root:FL Epoch: 85 Norm Difference for worker 1318 is 1.108001
INFO:root:FL Epoch: 85 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :749
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495566
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472155
INFO:root:FL Epoch: 85 Norm Difference for worker 749 is 1.023112
INFO:root:FL Epoch: 85 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1936
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448148
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531142
INFO:root:FL Epoch: 85 Norm Difference for worker 1936 is 0.997061
INFO:root:FL Epoch: 85 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1164
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711428
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512502
INFO:root:FL Epoch: 85 Norm Difference for worker 1164 is 1.024797
INFO:root:FL Epoch: 85 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :247
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 247 is 1.002691
INFO:root:FL Epoch: 85 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :878
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698103
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640750
INFO:root:FL Epoch: 85 Norm Difference for worker 878 is 1.008995
INFO:root:FL Epoch: 85 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :856
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608960
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551039
INFO:root:FL Epoch: 85 Norm Difference for worker 856 is 1.009503
INFO:root:FL Epoch: 85 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1936
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5991613268852234 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:1.3681130210558574                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1250, 726, 513, 1657, 767, 1017, 793, 1475, 1148, 166]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1250
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450802
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500296
INFO:root:FL Epoch: 86 Norm Difference for worker 1250 is 1.162227
INFO:root:FL Epoch: 86 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :726
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587839
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481314
INFO:root:FL Epoch: 86 Norm Difference for worker 726 is 1.19866
INFO:root:FL Epoch: 86 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :513
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781643
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537196
INFO:root:FL Epoch: 86 Norm Difference for worker 513 is 1.197835
INFO:root:FL Epoch: 86 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1657
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684356
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418919
INFO:root:FL Epoch: 86 Norm Difference for worker 1657 is 1.21626
INFO:root:FL Epoch: 86 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :767
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563602
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724349
INFO:root:FL Epoch: 86 Norm Difference for worker 767 is 1.171746
INFO:root:FL Epoch: 86 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1017
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747202
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581079
INFO:root:FL Epoch: 86 Norm Difference for worker 1017 is 1.109759
INFO:root:FL Epoch: 86 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :793
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515589
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623422
INFO:root:FL Epoch: 86 Norm Difference for worker 793 is 1.185189
INFO:root:FL Epoch: 86 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1475
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607235
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615344
INFO:root:FL Epoch: 86 Norm Difference for worker 1475 is 1.206911
INFO:root:FL Epoch: 86 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1148
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557104
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601483
INFO:root:FL Epoch: 86 Norm Difference for worker 1148 is 1.110211
INFO:root:FL Epoch: 86 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :166
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 166 is 1.169093
INFO:root:FL Epoch: 86 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1017
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5838437220629524 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:1.4118685324986775                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1748, 78, 1370, 513, 444, 929, 782, 1466, 476, 183]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1748
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558823
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716342
INFO:root:FL Epoch: 87 Norm Difference for worker 1748 is 1.020815
INFO:root:FL Epoch: 87 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :78
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353040
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 78 is 0.957497
INFO:root:FL Epoch: 87 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1370
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584907
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630105
INFO:root:FL Epoch: 87 Norm Difference for worker 1370 is 1.069852
INFO:root:FL Epoch: 87 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :513
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623629
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687161
INFO:root:FL Epoch: 87 Norm Difference for worker 513 is 1.021319
INFO:root:FL Epoch: 87 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :444
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643454
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470142
INFO:root:FL Epoch: 87 Norm Difference for worker 444 is 1.053914
INFO:root:FL Epoch: 87 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :929
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556700
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514880
INFO:root:FL Epoch: 87 Norm Difference for worker 929 is 0.941196
INFO:root:FL Epoch: 87 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :782
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510690
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479616
INFO:root:FL Epoch: 87 Norm Difference for worker 782 is 0.991224
INFO:root:FL Epoch: 87 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1466
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638939
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540308
INFO:root:FL Epoch: 87 Norm Difference for worker 1466 is 1.015407
INFO:root:FL Epoch: 87 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :476
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646675
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365576
INFO:root:FL Epoch: 87 Norm Difference for worker 476 is 0.975407
INFO:root:FL Epoch: 87 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :183
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 183 is 1.023345
INFO:root:FL Epoch: 87 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 929
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5918564761386198 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.0800088445345561                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [638, 214, 67, 401, 119, 258, 1308, 523, 527, 1093]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 88 Num points on workers: [200 201 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :638
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671893
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454758
INFO:root:FL Epoch: 88 Norm Difference for worker 638 is 0.952512
INFO:root:FL Epoch: 88 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :214
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 214 is 1.012059
INFO:root:FL Epoch: 88 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :67
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 67 is 1.001181
INFO:root:FL Epoch: 88 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :401
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638201
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547093
INFO:root:FL Epoch: 88 Norm Difference for worker 401 is 1.007427
INFO:root:FL Epoch: 88 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :119
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486306
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 119 is 0.994023
INFO:root:FL Epoch: 88 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :258
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 258 is 0.963369
INFO:root:FL Epoch: 88 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1308
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763195
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576039
INFO:root:FL Epoch: 88 Norm Difference for worker 1308 is 1.001763
INFO:root:FL Epoch: 88 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :523
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741371
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628668
INFO:root:FL Epoch: 88 Norm Difference for worker 523 is 0.954943
INFO:root:FL Epoch: 88 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :527
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634349
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550047
INFO:root:FL Epoch: 88 Norm Difference for worker 527 is 0.925541
INFO:root:FL Epoch: 88 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1093
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584712
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445709
INFO:root:FL Epoch: 88 Norm Difference for worker 1093 is 0.967638
INFO:root:FL Epoch: 88 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5928058238590465 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.6052781740824382                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1784, 190, 103, 1411, 1762, 166, 1110, 1334, 554, 1792]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 89 Num points on workers: [200 201 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1784
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604426
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494224
INFO:root:FL Epoch: 89 Norm Difference for worker 1784 is 1.256009
INFO:root:FL Epoch: 89 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :190
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.569870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 190 is 1.284437
INFO:root:FL Epoch: 89 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :103
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 103 is 1.15294
INFO:root:FL Epoch: 89 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1411
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596524
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457066
INFO:root:FL Epoch: 89 Norm Difference for worker 1411 is 1.167412
INFO:root:FL Epoch: 89 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1762
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506806
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611917
INFO:root:FL Epoch: 89 Norm Difference for worker 1762 is 1.125672
INFO:root:FL Epoch: 89 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :166
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 166 is 1.246777
INFO:root:FL Epoch: 89 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1110
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572259
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582967
INFO:root:FL Epoch: 89 Norm Difference for worker 1110 is 1.22349
INFO:root:FL Epoch: 89 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1334
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405143
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484469
INFO:root:FL Epoch: 89 Norm Difference for worker 1334 is 1.24077
INFO:root:FL Epoch: 89 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :554
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646733
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498164
INFO:root:FL Epoch: 89 Norm Difference for worker 554 is 1.236434
INFO:root:FL Epoch: 89 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1792
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796378
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391450
INFO:root:FL Epoch: 89 Norm Difference for worker 1792 is 1.151917
INFO:root:FL Epoch: 89 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1762
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.6144445433336145 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.710828185081482                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [51, 896, 1855, 1459, 1389, 1093, 57, 1572, 209, 660]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 90 Num points on workers: [201 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :51
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 51 is 1.166706
INFO:root:FL Epoch: 90 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :896
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847775
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612473
INFO:root:FL Epoch: 90 Norm Difference for worker 896 is 1.168359
INFO:root:FL Epoch: 90 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1855
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629411
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462224
INFO:root:FL Epoch: 90 Norm Difference for worker 1855 is 1.203363
INFO:root:FL Epoch: 90 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1459
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615954
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662831
INFO:root:FL Epoch: 90 Norm Difference for worker 1459 is 1.227447
INFO:root:FL Epoch: 90 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1389
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498383
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487431
INFO:root:FL Epoch: 90 Norm Difference for worker 1389 is 1.237637
INFO:root:FL Epoch: 90 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1093
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606235
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643901
INFO:root:FL Epoch: 90 Norm Difference for worker 1093 is 1.137361
INFO:root:FL Epoch: 90 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :57
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 57 is 1.058432
INFO:root:FL Epoch: 90 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1572
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693294
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636744
INFO:root:FL Epoch: 90 Norm Difference for worker 1572 is 1.090837
INFO:root:FL Epoch: 90 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :209
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 209 is 1.192853
INFO:root:FL Epoch: 90 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :660
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650940
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453286
INFO:root:FL Epoch: 90 Norm Difference for worker 660 is 1.18197
INFO:root:FL Epoch: 90 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5988919577177834 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.1467896302541096                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [966, 54, 1094, 543, 1563, 555, 607, 840, 187, 1896]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 91 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :966
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595693
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659551
INFO:root:FL Epoch: 91 Norm Difference for worker 966 is 1.138754
INFO:root:FL Epoch: 91 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :54
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572872
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 54 is 1.075731
INFO:root:FL Epoch: 91 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1094
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493572
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562826
INFO:root:FL Epoch: 91 Norm Difference for worker 1094 is 1.026979
INFO:root:FL Epoch: 91 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :543
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564089
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469826
INFO:root:FL Epoch: 91 Norm Difference for worker 543 is 1.151886
INFO:root:FL Epoch: 91 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1563
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658827
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506869
INFO:root:FL Epoch: 91 Norm Difference for worker 1563 is 1.139343
INFO:root:FL Epoch: 91 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :555
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671846
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615491
INFO:root:FL Epoch: 91 Norm Difference for worker 555 is 1.15522
INFO:root:FL Epoch: 91 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :607
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581438
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452714
INFO:root:FL Epoch: 91 Norm Difference for worker 607 is 1.109461
INFO:root:FL Epoch: 91 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :840
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630626
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574655
INFO:root:FL Epoch: 91 Norm Difference for worker 840 is 1.146799
INFO:root:FL Epoch: 91 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :187
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610444
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 187 is 1.104879
INFO:root:FL Epoch: 91 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1896
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485139
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628581
INFO:root:FL Epoch: 91 Norm Difference for worker 1896 is 1.115334
INFO:root:FL Epoch: 91 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1094
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.6149002050652224 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:1.4928716619809468                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [98, 1528, 667, 1166, 637, 1209, 1450, 520, 1658, 1641]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :98
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 98 is 1.190036
INFO:root:FL Epoch: 92 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1528
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299360
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396735
INFO:root:FL Epoch: 92 Norm Difference for worker 1528 is 1.138323
INFO:root:FL Epoch: 92 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :667
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689800
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527490
INFO:root:FL Epoch: 92 Norm Difference for worker 667 is 1.137523
INFO:root:FL Epoch: 92 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1166
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1166 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805361
INFO:root:Worker: 1166 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591287
INFO:root:FL Epoch: 92 Norm Difference for worker 1166 is 1.120314
INFO:root:FL Epoch: 92 Done on worker:1166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :637
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702325
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563630
INFO:root:FL Epoch: 92 Norm Difference for worker 637 is 1.190308
INFO:root:FL Epoch: 92 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1209
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611277
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583581
INFO:root:FL Epoch: 92 Norm Difference for worker 1209 is 1.173753
INFO:root:FL Epoch: 92 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1450
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743394
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498105
INFO:root:FL Epoch: 92 Norm Difference for worker 1450 is 1.234827
INFO:root:FL Epoch: 92 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :520
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701061
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579885
INFO:root:FL Epoch: 92 Norm Difference for worker 520 is 1.212326
INFO:root:FL Epoch: 92 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1658
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482454
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509407
INFO:root:FL Epoch: 92 Norm Difference for worker 1658 is 1.170359
INFO:root:FL Epoch: 92 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1641
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611039
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667253
INFO:root:FL Epoch: 92 Norm Difference for worker 1641 is 1.115878
INFO:root:FL Epoch: 92 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 667
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.6187864296576556 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:1.5796409050623577                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [678, 1468, 966, 1866, 1529, 1048, 450, 243, 995, 1303]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 93 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :678
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617705
INFO:root:Worker: 678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546063
INFO:root:FL Epoch: 93 Norm Difference for worker 678 is 1.248235
INFO:root:FL Epoch: 93 Done on worker:678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1468
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666784
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695606
INFO:root:FL Epoch: 93 Norm Difference for worker 1468 is 1.376185
INFO:root:FL Epoch: 93 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :966
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485636
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627044
INFO:root:FL Epoch: 93 Norm Difference for worker 966 is 1.290598
INFO:root:FL Epoch: 93 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1866
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579679
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560923
INFO:root:FL Epoch: 93 Norm Difference for worker 1866 is 1.303801
INFO:root:FL Epoch: 93 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1529
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540079
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539495
INFO:root:FL Epoch: 93 Norm Difference for worker 1529 is 1.29732
INFO:root:FL Epoch: 93 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1048
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568123
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527511
INFO:root:FL Epoch: 93 Norm Difference for worker 1048 is 1.366761
INFO:root:FL Epoch: 93 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :450
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673310
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677985
INFO:root:FL Epoch: 93 Norm Difference for worker 450 is 1.252846
INFO:root:FL Epoch: 93 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :243
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 243 is 1.263865
INFO:root:FL Epoch: 93 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :995
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617798
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491787
INFO:root:FL Epoch: 93 Norm Difference for worker 995 is 1.272945
INFO:root:FL Epoch: 93 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1303
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545313
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767611
INFO:root:FL Epoch: 93 Norm Difference for worker 1303 is 1.300413
INFO:root:FL Epoch: 93 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 450
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.6072986686930937 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:1.2216909130414326                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1760, 296, 14, 157, 132, 495, 1052, 1804, 1057, 391]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1760
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701618
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494757
INFO:root:FL Epoch: 94 Norm Difference for worker 1760 is 1.067739
INFO:root:FL Epoch: 94 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :296
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 296 is 0.996241
INFO:root:FL Epoch: 94 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :14
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563099
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 14 is 1.001367
INFO:root:FL Epoch: 94 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :157
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 157 is 1.027643
INFO:root:FL Epoch: 94 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :132
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 132 is 1.08528
INFO:root:FL Epoch: 94 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :495
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608168
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483572
INFO:root:FL Epoch: 94 Norm Difference for worker 495 is 0.991883
INFO:root:FL Epoch: 94 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1052
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552049
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470502
INFO:root:FL Epoch: 94 Norm Difference for worker 1052 is 0.979476
INFO:root:FL Epoch: 94 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1804
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660885
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681646
INFO:root:FL Epoch: 94 Norm Difference for worker 1804 is 1.010276
INFO:root:FL Epoch: 94 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1057
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726754
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524489
INFO:root:FL Epoch: 94 Norm Difference for worker 1057 is 0.976184
INFO:root:FL Epoch: 94 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :391
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567928
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512207
INFO:root:FL Epoch: 94 Norm Difference for worker 391 is 1.037152
INFO:root:FL Epoch: 94 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1057
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.5970808863639832 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.1487654050191243                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [427, 742, 1673, 395, 361, 760, 936, 1811, 160, 1178]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :427
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527068
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463424
INFO:root:FL Epoch: 95 Norm Difference for worker 427 is 1.034021
INFO:root:FL Epoch: 95 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :742
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618119
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458703
INFO:root:FL Epoch: 95 Norm Difference for worker 742 is 1.067734
INFO:root:FL Epoch: 95 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1673
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602863
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543000
INFO:root:FL Epoch: 95 Norm Difference for worker 1673 is 1.044984
INFO:root:FL Epoch: 95 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :395
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657556
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342791
INFO:root:FL Epoch: 95 Norm Difference for worker 395 is 1.077104
INFO:root:FL Epoch: 95 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :361
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591795
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497626
INFO:root:FL Epoch: 95 Norm Difference for worker 361 is 1.035733
INFO:root:FL Epoch: 95 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :760
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627782
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534188
INFO:root:FL Epoch: 95 Norm Difference for worker 760 is 1.022446
INFO:root:FL Epoch: 95 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :936
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678647
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557243
INFO:root:FL Epoch: 95 Norm Difference for worker 936 is 1.091727
INFO:root:FL Epoch: 95 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1811
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604856
INFO:root:Worker: 1811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560910
INFO:root:FL Epoch: 95 Norm Difference for worker 1811 is 1.103525
INFO:root:FL Epoch: 95 Done on worker:1811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :160
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.860422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 160 is 1.060356
INFO:root:FL Epoch: 95 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1178
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542199
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538476
INFO:root:FL Epoch: 95 Norm Difference for worker 1178 is 1.132884
INFO:root:FL Epoch: 95 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 361
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.593233758912367 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.3922044436136882                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1315, 1289, 1805, 618, 157, 322, 603, 549, 1199, 717]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1315
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597547
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572748
INFO:root:FL Epoch: 96 Norm Difference for worker 1315 is 1.06803
INFO:root:FL Epoch: 96 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1289
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539768
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461234
INFO:root:FL Epoch: 96 Norm Difference for worker 1289 is 1.042383
INFO:root:FL Epoch: 96 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1805
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508123
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551247
INFO:root:FL Epoch: 96 Norm Difference for worker 1805 is 1.138038
INFO:root:FL Epoch: 96 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :618
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557151
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425680
INFO:root:FL Epoch: 96 Norm Difference for worker 618 is 1.121113
INFO:root:FL Epoch: 96 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :157
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 157 is 1.074333
INFO:root:FL Epoch: 96 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :322
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.768155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 322 is 1.130031
INFO:root:FL Epoch: 96 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :603
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708905
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564452
INFO:root:FL Epoch: 96 Norm Difference for worker 603 is 1.080767
INFO:root:FL Epoch: 96 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :549
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581889
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678056
INFO:root:FL Epoch: 96 Norm Difference for worker 549 is 1.092546
INFO:root:FL Epoch: 96 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573970
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671831
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 1.074005
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :717
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448370
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596093
INFO:root:FL Epoch: 96 Norm Difference for worker 717 is 1.012778
INFO:root:FL Epoch: 96 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 717
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.5919770212734446 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.4037792285283406                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [908, 47, 426, 160, 1728, 173, 1789, 991, 1563, 990]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 97 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :908
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347971
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405296
INFO:root:FL Epoch: 97 Norm Difference for worker 908 is 1.044937
INFO:root:FL Epoch: 97 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :47
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 47 is 1.182204
INFO:root:FL Epoch: 97 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :426
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754914
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421064
INFO:root:FL Epoch: 97 Norm Difference for worker 426 is 1.019606
INFO:root:FL Epoch: 97 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :160
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 160 is 1.068507
INFO:root:FL Epoch: 97 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1728
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691222
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744270
INFO:root:FL Epoch: 97 Norm Difference for worker 1728 is 1.02287
INFO:root:FL Epoch: 97 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :173
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 173 is 1.059291
INFO:root:FL Epoch: 97 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1789
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735355
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658547
INFO:root:FL Epoch: 97 Norm Difference for worker 1789 is 1.033108
INFO:root:FL Epoch: 97 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :991
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664312
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422332
INFO:root:FL Epoch: 97 Norm Difference for worker 991 is 1.001347
INFO:root:FL Epoch: 97 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1563
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520521
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763448
INFO:root:FL Epoch: 97 Norm Difference for worker 1563 is 1.102901
INFO:root:FL Epoch: 97 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :990
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510723
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543321
INFO:root:FL Epoch: 97 Norm Difference for worker 990 is 1.084016
INFO:root:FL Epoch: 97 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 991
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5863733011133531 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:1.1501611471176147                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [1601, 1878, 1839, 710, 196, 722, 617, 62, 845, 1053]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 98 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :1601
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576036
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528211
INFO:root:FL Epoch: 98 Norm Difference for worker 1601 is 0.997437
INFO:root:FL Epoch: 98 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1878
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481557
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417324
INFO:root:FL Epoch: 98 Norm Difference for worker 1878 is 0.991226
INFO:root:FL Epoch: 98 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1839
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594217
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648204
INFO:root:FL Epoch: 98 Norm Difference for worker 1839 is 0.95873
INFO:root:FL Epoch: 98 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :710
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591724
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469160
INFO:root:FL Epoch: 98 Norm Difference for worker 710 is 0.998227
INFO:root:FL Epoch: 98 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :196
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 196 is 1.02208
INFO:root:FL Epoch: 98 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :722
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508887
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568879
INFO:root:FL Epoch: 98 Norm Difference for worker 722 is 1.005104
INFO:root:FL Epoch: 98 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :617
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527192
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549374
INFO:root:FL Epoch: 98 Norm Difference for worker 617 is 1.064084
INFO:root:FL Epoch: 98 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :62
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 62 is 1.004929
INFO:root:FL Epoch: 98 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :845
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640508
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461419
INFO:root:FL Epoch: 98 Norm Difference for worker 845 is 1.055313
INFO:root:FL Epoch: 98 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1053
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450566
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503842
INFO:root:FL Epoch: 98 Norm Difference for worker 1053 is 0.932303
INFO:root:FL Epoch: 98 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1053
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.5948699554976296 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.3029261231422424                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1560, 286, 1639, 216, 1333, 1207, 1190, 927, 1900, 255]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 99 Num points on workers: [200 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1560
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544807
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668204
INFO:root:FL Epoch: 99 Norm Difference for worker 1560 is 1.166527
INFO:root:FL Epoch: 99 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :286
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 286 is 1.078711
INFO:root:FL Epoch: 99 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1639
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681725
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509047
INFO:root:FL Epoch: 99 Norm Difference for worker 1639 is 1.183977
INFO:root:FL Epoch: 99 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :216
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 216 is 1.140877
INFO:root:FL Epoch: 99 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1333
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669049
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570175
INFO:root:FL Epoch: 99 Norm Difference for worker 1333 is 1.192492
INFO:root:FL Epoch: 99 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1207
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591503
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633658
INFO:root:FL Epoch: 99 Norm Difference for worker 1207 is 1.135276
INFO:root:FL Epoch: 99 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1190
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669131
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556457
INFO:root:FL Epoch: 99 Norm Difference for worker 1190 is 1.138485
INFO:root:FL Epoch: 99 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :927
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488426
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383688
INFO:root:FL Epoch: 99 Norm Difference for worker 927 is 1.132887
INFO:root:FL Epoch: 99 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1900
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867235
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516470
INFO:root:FL Epoch: 99 Norm Difference for worker 1900 is 1.152023
INFO:root:FL Epoch: 99 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :255
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 255 is 1.153355
INFO:root:FL Epoch: 99 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 286
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.6030350152183982 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.5344138542811077                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [566, 397, 958, 1124, 1705, 489, 549, 677, 727, 1192]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :566
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670806
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574683
INFO:root:FL Epoch: 100 Norm Difference for worker 566 is 1.251921
INFO:root:FL Epoch: 100 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :397
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838890
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626627
INFO:root:FL Epoch: 100 Norm Difference for worker 397 is 1.182779
INFO:root:FL Epoch: 100 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :958
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553735
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655532
INFO:root:FL Epoch: 100 Norm Difference for worker 958 is 1.201292
INFO:root:FL Epoch: 100 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1124
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617955
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523025
INFO:root:FL Epoch: 100 Norm Difference for worker 1124 is 1.243864
INFO:root:FL Epoch: 100 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1705
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618434
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541076
INFO:root:FL Epoch: 100 Norm Difference for worker 1705 is 1.234554
INFO:root:FL Epoch: 100 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :489
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555467
INFO:root:Worker: 489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435863
INFO:root:FL Epoch: 100 Norm Difference for worker 489 is 1.200034
INFO:root:FL Epoch: 100 Done on worker:489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :549
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631796
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536139
INFO:root:FL Epoch: 100 Norm Difference for worker 549 is 1.254251
INFO:root:FL Epoch: 100 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :677
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616356
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436623
INFO:root:FL Epoch: 100 Norm Difference for worker 677 is 1.188295
INFO:root:FL Epoch: 100 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :727
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673481
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523593
INFO:root:FL Epoch: 100 Norm Difference for worker 727 is 1.171695
INFO:root:FL Epoch: 100 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1192
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613567
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579607
INFO:root:FL Epoch: 100 Norm Difference for worker 1192 is 1.270452
INFO:root:FL Epoch: 100 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 397
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 100 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 100 Saved Checkpoint at this epoch.
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5908514717045952 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:1.3362860282262166                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 725, 428, 1389, 1077, 878, 883, 1482, 266, 174]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770994
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510318
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.2603997712333997 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.4003495365381241 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 1.604141
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :725
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633084
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459900
INFO:root:FL Epoch: 101 Norm Difference for worker 725 is 0.990004
INFO:root:FL Epoch: 101 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :428
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719320
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479985
INFO:root:FL Epoch: 101 Norm Difference for worker 428 is 1.061767
INFO:root:FL Epoch: 101 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1389
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751688
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618958
INFO:root:FL Epoch: 101 Norm Difference for worker 1389 is 1.135584
INFO:root:FL Epoch: 101 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1077
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590091
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514748
INFO:root:FL Epoch: 101 Norm Difference for worker 1077 is 1.045912
INFO:root:FL Epoch: 101 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :878
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743281
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590686
INFO:root:FL Epoch: 101 Norm Difference for worker 878 is 1.023302
INFO:root:FL Epoch: 101 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :883
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571420
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490005
INFO:root:FL Epoch: 101 Norm Difference for worker 883 is 1.080626
INFO:root:FL Epoch: 101 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1482
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671518
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525551
INFO:root:FL Epoch: 101 Norm Difference for worker 1482 is 0.99173
INFO:root:FL Epoch: 101 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :266
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 266 is 1.031254
INFO:root:FL Epoch: 101 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :174
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 174 is 0.965848
INFO:root:FL Epoch: 101 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 174
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.5870054136304295 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:1.2805803020795186                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1266, 1803, 1221, 1111, 1533, 1766, 251, 315, 923, 163]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1266
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500954
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660880
INFO:root:FL Epoch: 102 Norm Difference for worker 1266 is 0.995536
INFO:root:FL Epoch: 102 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1803
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695926
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526342
INFO:root:FL Epoch: 102 Norm Difference for worker 1803 is 1.027693
INFO:root:FL Epoch: 102 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1221
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486809
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567582
INFO:root:FL Epoch: 102 Norm Difference for worker 1221 is 0.957008
INFO:root:FL Epoch: 102 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1111
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690864
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529708
INFO:root:FL Epoch: 102 Norm Difference for worker 1111 is 1.003113
INFO:root:FL Epoch: 102 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1533
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488140
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564394
INFO:root:FL Epoch: 102 Norm Difference for worker 1533 is 0.993023
INFO:root:FL Epoch: 102 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1766
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663656
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502302
INFO:root:FL Epoch: 102 Norm Difference for worker 1766 is 0.965798
INFO:root:FL Epoch: 102 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :251
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503482
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 251 is 0.973691
INFO:root:FL Epoch: 102 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :315
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 315 is 1.0124
INFO:root:FL Epoch: 102 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :923
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495259
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437118
INFO:root:FL Epoch: 102 Norm Difference for worker 923 is 0.981179
INFO:root:FL Epoch: 102 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :163
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423321
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 163 is 0.989727
INFO:root:FL Epoch: 102 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1221
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5819991423803217 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:1.1747530301411946                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1108, 1054, 832, 2, 733, 259, 1609, 492, 805, 252]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1108
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725587
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622386
INFO:root:FL Epoch: 103 Norm Difference for worker 1108 is 1.087124
INFO:root:FL Epoch: 103 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1054
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636053
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636246
INFO:root:FL Epoch: 103 Norm Difference for worker 1054 is 1.093772
INFO:root:FL Epoch: 103 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :832
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659813
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482603
INFO:root:FL Epoch: 103 Norm Difference for worker 832 is 1.060765
INFO:root:FL Epoch: 103 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :2
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525038
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 2 is 1.026969
INFO:root:FL Epoch: 103 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :733
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747628
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499110
INFO:root:FL Epoch: 103 Norm Difference for worker 733 is 1.059996
INFO:root:FL Epoch: 103 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :259
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 259 is 1.039629
INFO:root:FL Epoch: 103 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1609
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544874
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473022
INFO:root:FL Epoch: 103 Norm Difference for worker 1609 is 1.089634
INFO:root:FL Epoch: 103 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :492
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530655
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501265
INFO:root:FL Epoch: 103 Norm Difference for worker 492 is 1.106433
INFO:root:FL Epoch: 103 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :805
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563464
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444244
INFO:root:FL Epoch: 103 Norm Difference for worker 805 is 1.029158
INFO:root:FL Epoch: 103 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :252
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607960
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 252 is 1.041341
INFO:root:FL Epoch: 103 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 259
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 103 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 103 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.5656115623081431 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:1.1940138339996338                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [1654, 1521, 939, 1926, 1651, 121, 1704, 1306, 1357, 1334]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :1654
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573342
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517245
INFO:root:FL Epoch: 104 Norm Difference for worker 1654 is 1.007499
INFO:root:FL Epoch: 104 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1521
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323813
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522528
INFO:root:FL Epoch: 104 Norm Difference for worker 1521 is 1.031496
INFO:root:FL Epoch: 104 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :939
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496622
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621306
INFO:root:FL Epoch: 104 Norm Difference for worker 939 is 1.077076
INFO:root:FL Epoch: 104 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1926
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729379
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378845
INFO:root:FL Epoch: 104 Norm Difference for worker 1926 is 1.083781
INFO:root:FL Epoch: 104 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1651
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498236
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701735
INFO:root:FL Epoch: 104 Norm Difference for worker 1651 is 1.098678
INFO:root:FL Epoch: 104 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :121
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658669
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 121 is 1.0607
INFO:root:FL Epoch: 104 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1704
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488727
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601736
INFO:root:FL Epoch: 104 Norm Difference for worker 1704 is 1.115406
INFO:root:FL Epoch: 104 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1306
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558656
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501639
INFO:root:FL Epoch: 104 Norm Difference for worker 1306 is 1.027774
INFO:root:FL Epoch: 104 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1357
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487915
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583484
INFO:root:FL Epoch: 104 Norm Difference for worker 1357 is 1.071498
INFO:root:FL Epoch: 104 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1334
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544299
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600569
INFO:root:FL Epoch: 104 Norm Difference for worker 1334 is 1.110255
INFO:root:FL Epoch: 104 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1306
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 104 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 104 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5613651170450098 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:1.2481984496116638                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1569, 1401, 1376, 1073, 575, 304, 1838, 1556, 614, 446]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1569
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473231
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622971
INFO:root:FL Epoch: 105 Norm Difference for worker 1569 is 1.103036
INFO:root:FL Epoch: 105 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1401
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428071
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410128
INFO:root:FL Epoch: 105 Norm Difference for worker 1401 is 0.987888
INFO:root:FL Epoch: 105 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1376
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605169
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532123
INFO:root:FL Epoch: 105 Norm Difference for worker 1376 is 1.069101
INFO:root:FL Epoch: 105 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1073
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604085
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630028
INFO:root:FL Epoch: 105 Norm Difference for worker 1073 is 1.020548
INFO:root:FL Epoch: 105 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :575
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798173
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618291
INFO:root:FL Epoch: 105 Norm Difference for worker 575 is 1.071866
INFO:root:FL Epoch: 105 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :304
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 304 is 1.014713
INFO:root:FL Epoch: 105 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1838
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579864
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432624
INFO:root:FL Epoch: 105 Norm Difference for worker 1838 is 1.012101
INFO:root:FL Epoch: 105 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1556
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514247
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536693
INFO:root:FL Epoch: 105 Norm Difference for worker 1556 is 1.035663
INFO:root:FL Epoch: 105 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :614
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665820
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388371
INFO:root:FL Epoch: 105 Norm Difference for worker 614 is 1.004143
INFO:root:FL Epoch: 105 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :446
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462925
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587562
INFO:root:FL Epoch: 105 Norm Difference for worker 446 is 1.039594
INFO:root:FL Epoch: 105 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.561578194884693 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:1.4592610200246174                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [1679, 1739, 199, 1440, 338, 699, 1806, 1265, 516, 1472]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :1679
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792331
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732079
INFO:root:FL Epoch: 106 Norm Difference for worker 1679 is 1.223822
INFO:root:FL Epoch: 106 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1739
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590041
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590925
INFO:root:FL Epoch: 106 Norm Difference for worker 1739 is 1.146185
INFO:root:FL Epoch: 106 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :199
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.877782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 199 is 1.259975
INFO:root:FL Epoch: 106 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1440
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793932
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572256
INFO:root:FL Epoch: 106 Norm Difference for worker 1440 is 1.248949
INFO:root:FL Epoch: 106 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :338
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 338 is 1.153382
INFO:root:FL Epoch: 106 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :699
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637323
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496748
INFO:root:FL Epoch: 106 Norm Difference for worker 699 is 1.192724
INFO:root:FL Epoch: 106 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1806
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637928
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637469
INFO:root:FL Epoch: 106 Norm Difference for worker 1806 is 1.158657
INFO:root:FL Epoch: 106 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444940
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522239
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.20384
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :516
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505385
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556482
INFO:root:FL Epoch: 106 Norm Difference for worker 516 is 1.229301
INFO:root:FL Epoch: 106 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1472
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462864
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485025
INFO:root:FL Epoch: 106 Norm Difference for worker 1472 is 1.280407
INFO:root:FL Epoch: 106 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1806
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5633451833444483 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.455219308535258                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1758, 1210, 1336, 877, 940, 1896, 1774, 858, 102, 589]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1758
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401764
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477405
INFO:root:FL Epoch: 107 Norm Difference for worker 1758 is 1.090593
INFO:root:FL Epoch: 107 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1210
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642751
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.837858
INFO:root:FL Epoch: 107 Norm Difference for worker 1210 is 1.069315
INFO:root:FL Epoch: 107 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1336
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540056
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471250
INFO:root:FL Epoch: 107 Norm Difference for worker 1336 is 1.066962
INFO:root:FL Epoch: 107 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :877
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722449
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479577
INFO:root:FL Epoch: 107 Norm Difference for worker 877 is 1.108288
INFO:root:FL Epoch: 107 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :940
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635786
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448097
INFO:root:FL Epoch: 107 Norm Difference for worker 940 is 1.130242
INFO:root:FL Epoch: 107 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1896
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719563
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713153
INFO:root:FL Epoch: 107 Norm Difference for worker 1896 is 1.135043
INFO:root:FL Epoch: 107 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1774
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527237
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502003
INFO:root:FL Epoch: 107 Norm Difference for worker 1774 is 1.068497
INFO:root:FL Epoch: 107 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :858
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536921
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479247
INFO:root:FL Epoch: 107 Norm Difference for worker 858 is 1.163734
INFO:root:FL Epoch: 107 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :102
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658928
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.742556
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 102 is 1.075723
INFO:root:FL Epoch: 107 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :589
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630588
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590860
INFO:root:FL Epoch: 107 Norm Difference for worker 589 is 0.998053
INFO:root:FL Epoch: 107 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 589
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.57353516887216 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.5947172443072002                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [725, 585, 470, 1893, 1475, 1098, 1823, 421, 55, 1106]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 108 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :725
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593854
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526378
INFO:root:FL Epoch: 108 Norm Difference for worker 725 is 1.122929
INFO:root:FL Epoch: 108 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :585
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489998
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552495
INFO:root:FL Epoch: 108 Norm Difference for worker 585 is 1.085287
INFO:root:FL Epoch: 108 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :470
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.887396
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608983
INFO:root:FL Epoch: 108 Norm Difference for worker 470 is 1.085214
INFO:root:FL Epoch: 108 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1893
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639393
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546755
INFO:root:FL Epoch: 108 Norm Difference for worker 1893 is 1.102288
INFO:root:FL Epoch: 108 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1475
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669511
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513732
INFO:root:FL Epoch: 108 Norm Difference for worker 1475 is 1.167569
INFO:root:FL Epoch: 108 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1098
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537770
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352520
INFO:root:FL Epoch: 108 Norm Difference for worker 1098 is 1.12254
INFO:root:FL Epoch: 108 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1823
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578632
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778937
INFO:root:FL Epoch: 108 Norm Difference for worker 1823 is 1.10912
INFO:root:FL Epoch: 108 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :421
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654153
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317206
INFO:root:FL Epoch: 108 Norm Difference for worker 421 is 1.118979
INFO:root:FL Epoch: 108 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :55
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 55 is 1.128785
INFO:root:FL Epoch: 108 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1106
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612543
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518258
INFO:root:FL Epoch: 108 Norm Difference for worker 1106 is 1.075252
INFO:root:FL Epoch: 108 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1106
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.5563042637179879 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:1.1309194962183635                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [242, 843, 368, 459, 1173, 1797, 1209, 458, 219, 48]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 109 Num points on workers: [201 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :242
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 242 is 1.054786
INFO:root:FL Epoch: 109 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :843
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715997
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599608
INFO:root:FL Epoch: 109 Norm Difference for worker 843 is 1.051268
INFO:root:FL Epoch: 109 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :368
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619862
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619228
INFO:root:FL Epoch: 109 Norm Difference for worker 368 is 1.045476
INFO:root:FL Epoch: 109 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :459
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694481
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486567
INFO:root:FL Epoch: 109 Norm Difference for worker 459 is 1.105218
INFO:root:FL Epoch: 109 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1173
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490615
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515331
INFO:root:FL Epoch: 109 Norm Difference for worker 1173 is 1.05158
INFO:root:FL Epoch: 109 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1797
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620297
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444670
INFO:root:FL Epoch: 109 Norm Difference for worker 1797 is 1.076495
INFO:root:FL Epoch: 109 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1209
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603132
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452689
INFO:root:FL Epoch: 109 Norm Difference for worker 1209 is 1.135422
INFO:root:FL Epoch: 109 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :458
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448995
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567192
INFO:root:FL Epoch: 109 Norm Difference for worker 458 is 1.085958
INFO:root:FL Epoch: 109 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :219
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 219 is 1.036256
INFO:root:FL Epoch: 109 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :48
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 48 is 1.049388
INFO:root:FL Epoch: 109 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1173
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.563173374708961 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.2666313449541728                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [1081, 1684, 197, 1630, 248, 75, 321, 1551, 1279, 1870]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 110 Num points on workers: [200 200 201 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :1081
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765086
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667341
INFO:root:FL Epoch: 110 Norm Difference for worker 1081 is 1.12811
INFO:root:FL Epoch: 110 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1684
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402396
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497298
INFO:root:FL Epoch: 110 Norm Difference for worker 1684 is 1.117977
INFO:root:FL Epoch: 110 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :197
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 197 is 1.090125
INFO:root:FL Epoch: 110 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1630
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618587
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451268
INFO:root:FL Epoch: 110 Norm Difference for worker 1630 is 1.169317
INFO:root:FL Epoch: 110 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :248
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 248 is 1.076477
INFO:root:FL Epoch: 110 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :75
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461467
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 75 is 1.095157
INFO:root:FL Epoch: 110 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :321
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 321 is 1.106737
INFO:root:FL Epoch: 110 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1551
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600741
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631715
INFO:root:FL Epoch: 110 Norm Difference for worker 1551 is 1.084815
INFO:root:FL Epoch: 110 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1279
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610873
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522059
INFO:root:FL Epoch: 110 Norm Difference for worker 1279 is 1.08098
INFO:root:FL Epoch: 110 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1870
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510960
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509079
INFO:root:FL Epoch: 110 Norm Difference for worker 1870 is 1.150815
INFO:root:FL Epoch: 110 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 321
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.572102452025694 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.4231914679209392                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1066, 1282, 1638, 316, 667, 38, 1787, 333, 20]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 200 201 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.938447
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577707
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.23742245882749557 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.3961586594581604 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 1.644415
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1066
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778737
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558814
INFO:root:FL Epoch: 111 Norm Difference for worker 1066 is 1.118065
INFO:root:FL Epoch: 111 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1282
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501338
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531194
INFO:root:FL Epoch: 111 Norm Difference for worker 1282 is 1.004785
INFO:root:FL Epoch: 111 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1638
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573115
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626042
INFO:root:FL Epoch: 111 Norm Difference for worker 1638 is 1.124873
INFO:root:FL Epoch: 111 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :316
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 316 is 1.043009
INFO:root:FL Epoch: 111 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :667
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444960
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447639
INFO:root:FL Epoch: 111 Norm Difference for worker 667 is 1.044816
INFO:root:FL Epoch: 111 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :38
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588455
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463170
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 38 is 1.036915
INFO:root:FL Epoch: 111 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1787
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740181
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680824
INFO:root:FL Epoch: 111 Norm Difference for worker 1787 is 1.014451
INFO:root:FL Epoch: 111 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :333
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 333 is 0.977206
INFO:root:FL Epoch: 111 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :20
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506585
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 20 is 1.018499
INFO:root:FL Epoch: 111 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.5669856404556948 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:1.748894989490509                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [1888, 879, 1707, 336, 860, 1709, 480, 1097, 1609, 1665]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 112 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :1888
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604081
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582410
INFO:root:FL Epoch: 112 Norm Difference for worker 1888 is 1.303817
INFO:root:FL Epoch: 112 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :879
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717651
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586501
INFO:root:FL Epoch: 112 Norm Difference for worker 879 is 1.245931
INFO:root:FL Epoch: 112 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1707
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400502
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538445
INFO:root:FL Epoch: 112 Norm Difference for worker 1707 is 1.241245
INFO:root:FL Epoch: 112 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :336
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 336 is 1.201265
INFO:root:FL Epoch: 112 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :860
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720301
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529966
INFO:root:FL Epoch: 112 Norm Difference for worker 860 is 1.414274
INFO:root:FL Epoch: 112 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1709
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599305
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560508
INFO:root:FL Epoch: 112 Norm Difference for worker 1709 is 1.232008
INFO:root:FL Epoch: 112 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :480
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762763
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539122
INFO:root:FL Epoch: 112 Norm Difference for worker 480 is 1.353301
INFO:root:FL Epoch: 112 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1097
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444655
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455646
INFO:root:FL Epoch: 112 Norm Difference for worker 1097 is 1.221966
INFO:root:FL Epoch: 112 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1609
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435067
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462418
INFO:root:FL Epoch: 112 Norm Difference for worker 1609 is 1.290498
INFO:root:FL Epoch: 112 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1665
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761391
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448145
INFO:root:FL Epoch: 112 Norm Difference for worker 1665 is 1.248608
INFO:root:FL Epoch: 112 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 336
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.5702436443637399 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:1.4979860583941143                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [634, 1413, 1175, 359, 95, 1125, 1027, 1076, 1642, 138]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 113 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :634
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812603
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441050
INFO:root:FL Epoch: 113 Norm Difference for worker 634 is 1.316944
INFO:root:FL Epoch: 113 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1413
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513014
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527835
INFO:root:FL Epoch: 113 Norm Difference for worker 1413 is 1.394792
INFO:root:FL Epoch: 113 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1175
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656708
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464574
INFO:root:FL Epoch: 113 Norm Difference for worker 1175 is 1.455007
INFO:root:FL Epoch: 113 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :359
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483998
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416696
INFO:root:FL Epoch: 113 Norm Difference for worker 359 is 1.287792
INFO:root:FL Epoch: 113 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :95
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 95 is 1.327867
INFO:root:FL Epoch: 113 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1125
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351694
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354980
INFO:root:FL Epoch: 113 Norm Difference for worker 1125 is 1.310992
INFO:root:FL Epoch: 113 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1027
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601148
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515629
INFO:root:FL Epoch: 113 Norm Difference for worker 1027 is 1.316481
INFO:root:FL Epoch: 113 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1076
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475737
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679884
INFO:root:FL Epoch: 113 Norm Difference for worker 1076 is 1.337839
INFO:root:FL Epoch: 113 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1642
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707432
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317594
INFO:root:FL Epoch: 113 Norm Difference for worker 1642 is 1.367567
INFO:root:FL Epoch: 113 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :138
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 138 is 1.30243
INFO:root:FL Epoch: 113 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 359
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.5569922275402966 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:1.0843968292077382                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1012, 1480, 1792, 1122, 1644, 523, 1858, 1147, 1021, 1124]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1012
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709929
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643590
INFO:root:FL Epoch: 114 Norm Difference for worker 1012 is 0.895509
INFO:root:FL Epoch: 114 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1480
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717122
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602257
INFO:root:FL Epoch: 114 Norm Difference for worker 1480 is 1.011862
INFO:root:FL Epoch: 114 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1792
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516915
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403255
INFO:root:FL Epoch: 114 Norm Difference for worker 1792 is 1.003421
INFO:root:FL Epoch: 114 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1122
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806821
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672432
INFO:root:FL Epoch: 114 Norm Difference for worker 1122 is 1.020466
INFO:root:FL Epoch: 114 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1644
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641882
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468330
INFO:root:FL Epoch: 114 Norm Difference for worker 1644 is 0.97226
INFO:root:FL Epoch: 114 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :523
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510757
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610419
INFO:root:FL Epoch: 114 Norm Difference for worker 523 is 1.037302
INFO:root:FL Epoch: 114 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1858
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683332
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.864020
INFO:root:FL Epoch: 114 Norm Difference for worker 1858 is 1.033755
INFO:root:FL Epoch: 114 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1147
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743070
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419044
INFO:root:FL Epoch: 114 Norm Difference for worker 1147 is 1.026096
INFO:root:FL Epoch: 114 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1021
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594157
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598215
INFO:root:FL Epoch: 114 Norm Difference for worker 1021 is 0.963933
INFO:root:FL Epoch: 114 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1124
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640123
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531948
INFO:root:FL Epoch: 114 Norm Difference for worker 1124 is 1.052937
INFO:root:FL Epoch: 114 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.5655560458407682 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:1.1756262580553691                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [248, 840, 1124, 1314, 1212, 896, 678, 1863, 1090, 1413]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532959
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 248 is 0.96547
INFO:root:FL Epoch: 115 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :840
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385769
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605403
INFO:root:FL Epoch: 115 Norm Difference for worker 840 is 1.002521
INFO:root:FL Epoch: 115 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1124
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525735
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596062
INFO:root:FL Epoch: 115 Norm Difference for worker 1124 is 1.061443
INFO:root:FL Epoch: 115 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1314
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660735
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484336
INFO:root:FL Epoch: 115 Norm Difference for worker 1314 is 1.032906
INFO:root:FL Epoch: 115 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1212
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397455
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551678
INFO:root:FL Epoch: 115 Norm Difference for worker 1212 is 1.004569
INFO:root:FL Epoch: 115 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :896
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524529
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497298
INFO:root:FL Epoch: 115 Norm Difference for worker 896 is 1.000501
INFO:root:FL Epoch: 115 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :678
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581915
INFO:root:Worker: 678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437444
INFO:root:FL Epoch: 115 Norm Difference for worker 678 is 0.997597
INFO:root:FL Epoch: 115 Done on worker:678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1863
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488679
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302350
INFO:root:FL Epoch: 115 Norm Difference for worker 1863 is 1.021294
INFO:root:FL Epoch: 115 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1090
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640422
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388178
INFO:root:FL Epoch: 115 Norm Difference for worker 1090 is 0.98648
INFO:root:FL Epoch: 115 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1413
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595448
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447717
INFO:root:FL Epoch: 115 Norm Difference for worker 1413 is 1.009967
INFO:root:FL Epoch: 115 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1212
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.5509168908876532 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:1.43073566754659                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [730, 263, 1165, 1753, 705, 111, 1410, 1513, 966, 1146]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :730
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577838
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400287
INFO:root:FL Epoch: 116 Norm Difference for worker 730 is 1.161549
INFO:root:FL Epoch: 116 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :263
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.708605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 263 is 1.083708
INFO:root:FL Epoch: 116 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1165
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526944
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603454
INFO:root:FL Epoch: 116 Norm Difference for worker 1165 is 1.188384
INFO:root:FL Epoch: 116 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1753
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658682
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536959
INFO:root:FL Epoch: 116 Norm Difference for worker 1753 is 1.063804
INFO:root:FL Epoch: 116 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :705
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601916
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493648
INFO:root:FL Epoch: 116 Norm Difference for worker 705 is 1.095454
INFO:root:FL Epoch: 116 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :111
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 111 is 1.153382
INFO:root:FL Epoch: 116 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1410
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464463
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472902
INFO:root:FL Epoch: 116 Norm Difference for worker 1410 is 1.134435
INFO:root:FL Epoch: 116 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1513
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598864
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539192
INFO:root:FL Epoch: 116 Norm Difference for worker 1513 is 1.112331
INFO:root:FL Epoch: 116 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :966
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435878
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477311
INFO:root:FL Epoch: 116 Norm Difference for worker 966 is 1.097431
INFO:root:FL Epoch: 116 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1146
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492819
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451389
INFO:root:FL Epoch: 116 Norm Difference for worker 1146 is 1.077432
INFO:root:FL Epoch: 116 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.5750563162214616 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:1.6315001050631206                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [1472, 984, 91, 1939, 66, 1773, 1521, 1260, 996, 1015]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 117 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :1472
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624603
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531922
INFO:root:FL Epoch: 117 Norm Difference for worker 1472 is 1.1669
INFO:root:FL Epoch: 117 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :984
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434368
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550231
INFO:root:FL Epoch: 117 Norm Difference for worker 984 is 1.038055
INFO:root:FL Epoch: 117 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :91
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310372
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.563607
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 91 is 1.092592
INFO:root:FL Epoch: 117 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1939
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576511
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744119
INFO:root:FL Epoch: 117 Norm Difference for worker 1939 is 1.137455
INFO:root:FL Epoch: 117 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :66
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383186
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 66 is 1.117183
INFO:root:FL Epoch: 117 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1773
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497615
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564913
INFO:root:FL Epoch: 117 Norm Difference for worker 1773 is 1.119975
INFO:root:FL Epoch: 117 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1521
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687280
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402037
INFO:root:FL Epoch: 117 Norm Difference for worker 1521 is 1.036318
INFO:root:FL Epoch: 117 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1260
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591805
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401862
INFO:root:FL Epoch: 117 Norm Difference for worker 1260 is 1.09547
INFO:root:FL Epoch: 117 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :996
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545019
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432649
INFO:root:FL Epoch: 117 Norm Difference for worker 996 is 1.071902
INFO:root:FL Epoch: 117 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1015
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454208
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439174
INFO:root:FL Epoch: 117 Norm Difference for worker 1015 is 1.04065
INFO:root:FL Epoch: 117 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1521
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.5599593800656936 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:1.5092776417732239                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [1758, 1659, 759, 39, 1657, 1084, 1143, 1784, 353, 1176]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 118 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :1758
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623780
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506252
INFO:root:FL Epoch: 118 Norm Difference for worker 1758 is 1.030532
INFO:root:FL Epoch: 118 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1659
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737570
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581040
INFO:root:FL Epoch: 118 Norm Difference for worker 1659 is 1.176595
INFO:root:FL Epoch: 118 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :759
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515735
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531416
INFO:root:FL Epoch: 118 Norm Difference for worker 759 is 1.077652
INFO:root:FL Epoch: 118 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :39
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 39 is 1.127341
INFO:root:FL Epoch: 118 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1657
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516511
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469032
INFO:root:FL Epoch: 118 Norm Difference for worker 1657 is 1.130625
INFO:root:FL Epoch: 118 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1084
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699033
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357852
INFO:root:FL Epoch: 118 Norm Difference for worker 1084 is 1.041886
INFO:root:FL Epoch: 118 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1143
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639612
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479471
INFO:root:FL Epoch: 118 Norm Difference for worker 1143 is 1.10982
INFO:root:FL Epoch: 118 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1784
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525503
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581079
INFO:root:FL Epoch: 118 Norm Difference for worker 1784 is 1.110384
INFO:root:FL Epoch: 118 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :353
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738548
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477127
INFO:root:FL Epoch: 118 Norm Difference for worker 353 is 1.18619
INFO:root:FL Epoch: 118 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1176
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351389
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556488
INFO:root:FL Epoch: 118 Norm Difference for worker 1176 is 1.030795
INFO:root:FL Epoch: 118 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 759
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.5805295863572288 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:1.5147671898206074                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [511, 1924, 870, 831, 1279, 1748, 1797, 1553, 8, 1941]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :511
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531271
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569630
INFO:root:FL Epoch: 119 Norm Difference for worker 511 is 0.981453
INFO:root:FL Epoch: 119 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1924
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554626
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526176
INFO:root:FL Epoch: 119 Norm Difference for worker 1924 is 0.907714
INFO:root:FL Epoch: 119 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :870
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533031
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504587
INFO:root:FL Epoch: 119 Norm Difference for worker 870 is 0.917584
INFO:root:FL Epoch: 119 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :831
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455211
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445533
INFO:root:FL Epoch: 119 Norm Difference for worker 831 is 0.985105
INFO:root:FL Epoch: 119 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1279
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655184
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452540
INFO:root:FL Epoch: 119 Norm Difference for worker 1279 is 0.90757
INFO:root:FL Epoch: 119 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455583
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499085
INFO:root:FL Epoch: 119 Norm Difference for worker 1748 is 0.932358
INFO:root:FL Epoch: 119 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1797
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517117
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554729
INFO:root:FL Epoch: 119 Norm Difference for worker 1797 is 0.977574
INFO:root:FL Epoch: 119 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1553
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701104
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424444
INFO:root:FL Epoch: 119 Norm Difference for worker 1553 is 0.960387
INFO:root:FL Epoch: 119 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :8
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 8 is 0.921597
INFO:root:FL Epoch: 119 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1941
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649202
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482036
INFO:root:FL Epoch: 119 Norm Difference for worker 1941 is 0.90485
INFO:root:FL Epoch: 119 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1924
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.5717726437484517 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:1.5774369438489277                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [743, 607, 1234, 1221, 401, 218, 803, 392, 1307, 1344]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :743
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512106
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466528
INFO:root:FL Epoch: 120 Norm Difference for worker 743 is 0.979039
INFO:root:FL Epoch: 120 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :607
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612918
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386797
INFO:root:FL Epoch: 120 Norm Difference for worker 607 is 0.980576
INFO:root:FL Epoch: 120 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1234
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706234
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709910
INFO:root:FL Epoch: 120 Norm Difference for worker 1234 is 1.026143
INFO:root:FL Epoch: 120 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1221
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594302
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506357
INFO:root:FL Epoch: 120 Norm Difference for worker 1221 is 0.983571
INFO:root:FL Epoch: 120 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :401
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545130
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551151
INFO:root:FL Epoch: 120 Norm Difference for worker 401 is 1.018885
INFO:root:FL Epoch: 120 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :218
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 218 is 0.987246
INFO:root:FL Epoch: 120 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :803
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651983
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412645
INFO:root:FL Epoch: 120 Norm Difference for worker 803 is 1.003556
INFO:root:FL Epoch: 120 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :392
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617481
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327794
INFO:root:FL Epoch: 120 Norm Difference for worker 392 is 0.939871
INFO:root:FL Epoch: 120 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1307
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653158
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544509
INFO:root:FL Epoch: 120 Norm Difference for worker 1307 is 1.010273
INFO:root:FL Epoch: 120 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1344
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756381
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490464
INFO:root:FL Epoch: 120 Norm Difference for worker 1344 is 0.979794
INFO:root:FL Epoch: 120 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 392
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.5730180582579445 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:1.5440818270047505                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1395, 1368, 368, 396, 473, 540, 277, 806, 1218]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837422
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462439
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.25855133682489395 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.45878187716007235 Backdoor Train Accuracy: 82.0
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 1.683995
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1395
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771339
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644119
INFO:root:FL Epoch: 121 Norm Difference for worker 1395 is 0.966856
INFO:root:FL Epoch: 121 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1368
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574715
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628588
INFO:root:FL Epoch: 121 Norm Difference for worker 1368 is 0.971626
INFO:root:FL Epoch: 121 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :368
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655026
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669395
INFO:root:FL Epoch: 121 Norm Difference for worker 368 is 1.010815
INFO:root:FL Epoch: 121 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :396
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604984
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677910
INFO:root:FL Epoch: 121 Norm Difference for worker 396 is 1.044676
INFO:root:FL Epoch: 121 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :473
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454852
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431400
INFO:root:FL Epoch: 121 Norm Difference for worker 473 is 1.014651
INFO:root:FL Epoch: 121 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :540
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711283
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405630
INFO:root:FL Epoch: 121 Norm Difference for worker 540 is 0.981482
INFO:root:FL Epoch: 121 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :277
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450652
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 121 Norm Difference for worker 277 is 0.972977
INFO:root:FL Epoch: 121 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :806
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659342
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458682
INFO:root:FL Epoch: 121 Norm Difference for worker 806 is 0.996101
INFO:root:FL Epoch: 121 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1218
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522174
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708709
INFO:root:FL Epoch: 121 Norm Difference for worker 1218 is 1.003712
INFO:root:FL Epoch: 121 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1395
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.5629388584810144 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:1.5049755970637004                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [664, 1830, 514, 538, 321, 841, 425, 413, 188, 881]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 122 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :664
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660906
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638970
INFO:root:FL Epoch: 122 Norm Difference for worker 664 is 0.987636
INFO:root:FL Epoch: 122 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1830
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496210
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491507
INFO:root:FL Epoch: 122 Norm Difference for worker 1830 is 0.969902
INFO:root:FL Epoch: 122 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :514
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446949
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504370
INFO:root:FL Epoch: 122 Norm Difference for worker 514 is 0.971347
INFO:root:FL Epoch: 122 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :538
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604949
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487328
INFO:root:FL Epoch: 122 Norm Difference for worker 538 is 0.958744
INFO:root:FL Epoch: 122 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :321
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382525
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 321 is 0.978892
INFO:root:FL Epoch: 122 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :841
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646593
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585586
INFO:root:FL Epoch: 122 Norm Difference for worker 841 is 0.932898
INFO:root:FL Epoch: 122 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :425
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536196
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615305
INFO:root:FL Epoch: 122 Norm Difference for worker 425 is 0.964082
INFO:root:FL Epoch: 122 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :413
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693375
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398405
INFO:root:FL Epoch: 122 Norm Difference for worker 413 is 0.996663
INFO:root:FL Epoch: 122 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :188
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 188 is 0.986072
INFO:root:FL Epoch: 122 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :881
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410145
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501760
INFO:root:FL Epoch: 122 Norm Difference for worker 881 is 0.969797
INFO:root:FL Epoch: 122 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 321
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.5561455277835622 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:1.891696274280548                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [312, 525, 894, 284, 917, 167, 874, 1446, 104, 1604]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 123 Num points on workers: [201 200 200 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :312
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.758985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 312 is 1.166327
INFO:root:FL Epoch: 123 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :525
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517287
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687221
INFO:root:FL Epoch: 123 Norm Difference for worker 525 is 1.153568
INFO:root:FL Epoch: 123 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :894
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615331
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256246
INFO:root:FL Epoch: 123 Norm Difference for worker 894 is 1.112065
INFO:root:FL Epoch: 123 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :284
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 284 is 1.184984
INFO:root:FL Epoch: 123 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :917
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556068
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521536
INFO:root:FL Epoch: 123 Norm Difference for worker 917 is 1.177695
INFO:root:FL Epoch: 123 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :167
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 167 is 1.104413
INFO:root:FL Epoch: 123 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :874
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840936
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640133
INFO:root:FL Epoch: 123 Norm Difference for worker 874 is 1.193465
INFO:root:FL Epoch: 123 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1446
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550310
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644759
INFO:root:FL Epoch: 123 Norm Difference for worker 1446 is 1.136207
INFO:root:FL Epoch: 123 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :104
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 104 is 1.174178
INFO:root:FL Epoch: 123 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1604
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618086
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470010
INFO:root:FL Epoch: 123 Norm Difference for worker 1604 is 1.193684
INFO:root:FL Epoch: 123 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 894
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5909989020403694 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:1.7709627548853557                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [419, 166, 1182, 1563, 761, 145, 642, 44, 546, 896]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 124 Num points on workers: [200 201 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :419
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492484
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642792
INFO:root:FL Epoch: 124 Norm Difference for worker 419 is 1.084182
INFO:root:FL Epoch: 124 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :166
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 166 is 1.114842
INFO:root:FL Epoch: 124 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1182
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293703
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517069
INFO:root:FL Epoch: 124 Norm Difference for worker 1182 is 1.13979
INFO:root:FL Epoch: 124 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1563
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729968
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591866
INFO:root:FL Epoch: 124 Norm Difference for worker 1563 is 1.165565
INFO:root:FL Epoch: 124 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :761
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642777
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429288
INFO:root:FL Epoch: 124 Norm Difference for worker 761 is 1.223487
INFO:root:FL Epoch: 124 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :145
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 145 is 1.06301
INFO:root:FL Epoch: 124 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :642
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588901
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548514
INFO:root:FL Epoch: 124 Norm Difference for worker 642 is 1.146837
INFO:root:FL Epoch: 124 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :44
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 44 is 1.132676
INFO:root:FL Epoch: 124 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :546
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586856
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411297
INFO:root:FL Epoch: 124 Norm Difference for worker 546 is 1.177919
INFO:root:FL Epoch: 124 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :896
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548119
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336474
INFO:root:FL Epoch: 124 Norm Difference for worker 896 is 1.128755
INFO:root:FL Epoch: 124 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 419
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.559565593214596 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:1.5645933747291565                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [8, 627, 1067, 1695, 482, 1524, 1627, 330, 266, 821]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 125 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :8
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 8 is 1.032954
INFO:root:FL Epoch: 125 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :627
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429170
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478960
INFO:root:FL Epoch: 125 Norm Difference for worker 627 is 1.057805
INFO:root:FL Epoch: 125 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1067
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582531
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439696
INFO:root:FL Epoch: 125 Norm Difference for worker 1067 is 1.06595
INFO:root:FL Epoch: 125 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1695
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390951
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565545
INFO:root:FL Epoch: 125 Norm Difference for worker 1695 is 1.093668
INFO:root:FL Epoch: 125 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :482
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412028
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431208
INFO:root:FL Epoch: 125 Norm Difference for worker 482 is 1.035809
INFO:root:FL Epoch: 125 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1524
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397703
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644305
INFO:root:FL Epoch: 125 Norm Difference for worker 1524 is 1.136086
INFO:root:FL Epoch: 125 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1627
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575609
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396421
INFO:root:FL Epoch: 125 Norm Difference for worker 1627 is 1.050902
INFO:root:FL Epoch: 125 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :330
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 330 is 1.086869
INFO:root:FL Epoch: 125 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :266
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 266 is 1.066837
INFO:root:FL Epoch: 125 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :821
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657465
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483009
INFO:root:FL Epoch: 125 Norm Difference for worker 821 is 1.104668
INFO:root:FL Epoch: 125 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.5679271571776446 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:1.882936676343282                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1913, 9, 272, 1804, 1551, 514, 110, 1379, 1400, 85]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 126 Num points on workers: [200 201 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1913
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445613
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559974
INFO:root:FL Epoch: 126 Norm Difference for worker 1913 is 1.224028
INFO:root:FL Epoch: 126 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :9
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.788948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 9 is 1.296102
INFO:root:FL Epoch: 126 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :272
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.409769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 272 is 1.160646
INFO:root:FL Epoch: 126 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1804
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486552
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490578
INFO:root:FL Epoch: 126 Norm Difference for worker 1804 is 1.278758
INFO:root:FL Epoch: 126 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1551
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676221
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408509
INFO:root:FL Epoch: 126 Norm Difference for worker 1551 is 1.159109
INFO:root:FL Epoch: 126 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :514
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445446
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443109
INFO:root:FL Epoch: 126 Norm Difference for worker 514 is 1.138173
INFO:root:FL Epoch: 126 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :110
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 110 is 1.318062
INFO:root:FL Epoch: 126 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1379
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008702
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458897
INFO:root:FL Epoch: 126 Norm Difference for worker 1379 is 1.262441
INFO:root:FL Epoch: 126 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1400
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494371
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584617
INFO:root:FL Epoch: 126 Norm Difference for worker 1400 is 1.311971
INFO:root:FL Epoch: 126 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :85
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 85 is 1.204059
INFO:root:FL Epoch: 126 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1551
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.5518564774709589 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:1.6798484325408936                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [1298, 816, 924, 1183, 1636, 1734, 973, 568, 208, 1198]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :1298
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511767
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400087
INFO:root:FL Epoch: 127 Norm Difference for worker 1298 is 1.152841
INFO:root:FL Epoch: 127 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :816
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550442
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429121
INFO:root:FL Epoch: 127 Norm Difference for worker 816 is 1.116432
INFO:root:FL Epoch: 127 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :924
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663487
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519443
INFO:root:FL Epoch: 127 Norm Difference for worker 924 is 1.144238
INFO:root:FL Epoch: 127 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1183
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543272
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540454
INFO:root:FL Epoch: 127 Norm Difference for worker 1183 is 1.112758
INFO:root:FL Epoch: 127 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1636
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639893
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827023
INFO:root:FL Epoch: 127 Norm Difference for worker 1636 is 1.160395
INFO:root:FL Epoch: 127 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1734
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640320
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573854
INFO:root:FL Epoch: 127 Norm Difference for worker 1734 is 1.115929
INFO:root:FL Epoch: 127 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :973
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520177
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485513
INFO:root:FL Epoch: 127 Norm Difference for worker 973 is 1.178734
INFO:root:FL Epoch: 127 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :568
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675767
INFO:root:Worker: 568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553149
INFO:root:FL Epoch: 127 Norm Difference for worker 568 is 1.178883
INFO:root:FL Epoch: 127 Done on worker:568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :208
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 208 is 1.157103
INFO:root:FL Epoch: 127 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1198
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561389
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718877
INFO:root:FL Epoch: 127 Norm Difference for worker 1198 is 1.105137
INFO:root:FL Epoch: 127 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1734
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.5544667559511521 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:1.8859346707661946                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [1235, 477, 1755, 725, 1827, 1674, 181, 893, 1386, 1499]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 128 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :1235
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643659
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442653
INFO:root:FL Epoch: 128 Norm Difference for worker 1235 is 1.131261
INFO:root:FL Epoch: 128 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :477
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617678
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437907
INFO:root:FL Epoch: 128 Norm Difference for worker 477 is 1.058538
INFO:root:FL Epoch: 128 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1755
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549981
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622502
INFO:root:FL Epoch: 128 Norm Difference for worker 1755 is 1.161687
INFO:root:FL Epoch: 128 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :725
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502046
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458021
INFO:root:FL Epoch: 128 Norm Difference for worker 725 is 1.126136
INFO:root:FL Epoch: 128 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1827
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684533
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513171
INFO:root:FL Epoch: 128 Norm Difference for worker 1827 is 1.09946
INFO:root:FL Epoch: 128 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1674
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567140
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370395
INFO:root:FL Epoch: 128 Norm Difference for worker 1674 is 1.123737
INFO:root:FL Epoch: 128 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :181
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 181 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 181 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 181 is 1.181295
INFO:root:FL Epoch: 128 Done on worker:181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :893
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555890
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605172
INFO:root:FL Epoch: 128 Norm Difference for worker 893 is 1.157599
INFO:root:FL Epoch: 128 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1386
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592621
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398595
INFO:root:FL Epoch: 128 Norm Difference for worker 1386 is 1.138927
INFO:root:FL Epoch: 128 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1499
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456499
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506109
INFO:root:FL Epoch: 128 Norm Difference for worker 1499 is 1.180716
INFO:root:FL Epoch: 128 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.5460996172007393 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:2.079637328783671                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [806, 1278, 766, 1914, 909, 1075, 395, 1556, 444, 966]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :806
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 1.167885
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617848
INFO:root:FL Epoch: 129 Norm Difference for worker 806 is 1.247985
INFO:root:FL Epoch: 129 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1278
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529965
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512020
INFO:root:FL Epoch: 129 Norm Difference for worker 1278 is 1.175752
INFO:root:FL Epoch: 129 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :766
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535655
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359619
INFO:root:FL Epoch: 129 Norm Difference for worker 766 is 1.101229
INFO:root:FL Epoch: 129 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1914
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471499
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308820
INFO:root:FL Epoch: 129 Norm Difference for worker 1914 is 1.14242
INFO:root:FL Epoch: 129 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :909
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426227
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555516
INFO:root:FL Epoch: 129 Norm Difference for worker 909 is 1.093837
INFO:root:FL Epoch: 129 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1075
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521668
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561402
INFO:root:FL Epoch: 129 Norm Difference for worker 1075 is 1.238429
INFO:root:FL Epoch: 129 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :395
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551594
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493628
INFO:root:FL Epoch: 129 Norm Difference for worker 395 is 1.186282
INFO:root:FL Epoch: 129 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1556
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320380
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414144
INFO:root:FL Epoch: 129 Norm Difference for worker 1556 is 1.165088
INFO:root:FL Epoch: 129 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :444
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627579
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573085
INFO:root:FL Epoch: 129 Norm Difference for worker 444 is 1.23719
INFO:root:FL Epoch: 129 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :966
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423514
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587285
INFO:root:FL Epoch: 129 Norm Difference for worker 966 is 1.191339
INFO:root:FL Epoch: 129 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.5405855108709896 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:2.1008076071739197                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [435, 881, 1615, 458, 1746, 1167, 187, 536, 1890, 785]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 130 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :435
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637987
INFO:root:Worker: 435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490209
INFO:root:FL Epoch: 130 Norm Difference for worker 435 is 1.314957
INFO:root:FL Epoch: 130 Done on worker:435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :881
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570279
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338867
INFO:root:FL Epoch: 130 Norm Difference for worker 881 is 1.217512
INFO:root:FL Epoch: 130 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1615
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370706
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409547
INFO:root:FL Epoch: 130 Norm Difference for worker 1615 is 1.252061
INFO:root:FL Epoch: 130 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :458
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739806
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502467
INFO:root:FL Epoch: 130 Norm Difference for worker 458 is 1.246705
INFO:root:FL Epoch: 130 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1746
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644701
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386027
INFO:root:FL Epoch: 130 Norm Difference for worker 1746 is 1.244292
INFO:root:FL Epoch: 130 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1167
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883358
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537715
INFO:root:FL Epoch: 130 Norm Difference for worker 1167 is 1.282821
INFO:root:FL Epoch: 130 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :187
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506949
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 187 is 1.246786
INFO:root:FL Epoch: 130 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :536
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388955
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464090
INFO:root:FL Epoch: 130 Norm Difference for worker 536 is 1.204121
INFO:root:FL Epoch: 130 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1890
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679887
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429562
INFO:root:FL Epoch: 130 Norm Difference for worker 1890 is 1.22906
INFO:root:FL Epoch: 130 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :785
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611886
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536965
INFO:root:FL Epoch: 130 Norm Difference for worker 785 is 1.281562
INFO:root:FL Epoch: 130 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.5428827667937559 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:2.101033926010132                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 222, 1626, 1476, 962, 1666, 210, 446, 110, 1185]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 131 Num points on workers: [200 201 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.308997
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648359
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.25082210451364517 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.43331616222858427 Backdoor Train Accuracy: 82.5
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 1.941935
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :222
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394214
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 222 is 1.130404
INFO:root:FL Epoch: 131 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1626
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707810
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662005
INFO:root:FL Epoch: 131 Norm Difference for worker 1626 is 1.138566
INFO:root:FL Epoch: 131 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1476
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605384
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464062
INFO:root:FL Epoch: 131 Norm Difference for worker 1476 is 1.241776
INFO:root:FL Epoch: 131 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :962
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478104
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.804212
INFO:root:FL Epoch: 131 Norm Difference for worker 962 is 1.200083
INFO:root:FL Epoch: 131 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1666
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720636
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747144
INFO:root:FL Epoch: 131 Norm Difference for worker 1666 is 1.276817
INFO:root:FL Epoch: 131 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :210
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 210 is 1.138735
INFO:root:FL Epoch: 131 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :446
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487029
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450054
INFO:root:FL Epoch: 131 Norm Difference for worker 446 is 1.133345
INFO:root:FL Epoch: 131 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :110
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 110 is 1.257395
INFO:root:FL Epoch: 131 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1185
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758137
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496313
INFO:root:FL Epoch: 131 Norm Difference for worker 1185 is 1.184667
INFO:root:FL Epoch: 131 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 210
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.5315814894788405 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:1.5121741493542988                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [134, 1676, 1771, 154, 166, 1747, 1906, 1574, 226, 1601]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 132 Num points on workers: [201 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :134
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 134 is 1.026585
INFO:root:FL Epoch: 132 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1676
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428599
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512747
INFO:root:FL Epoch: 132 Norm Difference for worker 1676 is 1.046354
INFO:root:FL Epoch: 132 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1771
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636351
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504741
INFO:root:FL Epoch: 132 Norm Difference for worker 1771 is 1.082639
INFO:root:FL Epoch: 132 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :154
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.857743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 154 is 1.088159
INFO:root:FL Epoch: 132 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :166
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.563326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 166 is 1.051015
INFO:root:FL Epoch: 132 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1747
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655273
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461624
INFO:root:FL Epoch: 132 Norm Difference for worker 1747 is 1.05084
INFO:root:FL Epoch: 132 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1906
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702793
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585268
INFO:root:FL Epoch: 132 Norm Difference for worker 1906 is 1.042231
INFO:root:FL Epoch: 132 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1574
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544795
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487473
INFO:root:FL Epoch: 132 Norm Difference for worker 1574 is 1.093881
INFO:root:FL Epoch: 132 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :226
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579192
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 226 is 1.078195
INFO:root:FL Epoch: 132 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1601
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515169
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472083
INFO:root:FL Epoch: 132 Norm Difference for worker 1601 is 1.081532
INFO:root:FL Epoch: 132 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1747
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.530896889812806 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:1.576700250307719                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [259, 1700, 1731, 1307, 1926, 196, 1034, 1663, 681, 1912]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 133 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :259
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 259 is 1.069313
INFO:root:FL Epoch: 133 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571707
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454681
INFO:root:FL Epoch: 133 Norm Difference for worker 1700 is 1.087545
INFO:root:FL Epoch: 133 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1731
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573134
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387126
INFO:root:FL Epoch: 133 Norm Difference for worker 1731 is 0.993177
INFO:root:FL Epoch: 133 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1307
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571631
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547978
INFO:root:FL Epoch: 133 Norm Difference for worker 1307 is 1.083677
INFO:root:FL Epoch: 133 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1926
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360998
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510098
INFO:root:FL Epoch: 133 Norm Difference for worker 1926 is 1.084152
INFO:root:FL Epoch: 133 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :196
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 196 is 1.062254
INFO:root:FL Epoch: 133 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1034
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513878
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471557
INFO:root:FL Epoch: 133 Norm Difference for worker 1034 is 1.070806
INFO:root:FL Epoch: 133 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1663
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505176
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473038
INFO:root:FL Epoch: 133 Norm Difference for worker 1663 is 1.032726
INFO:root:FL Epoch: 133 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :681
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806158
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564811
INFO:root:FL Epoch: 133 Norm Difference for worker 681 is 1.056368
INFO:root:FL Epoch: 133 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1912
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546841
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471434
INFO:root:FL Epoch: 133 Norm Difference for worker 1912 is 1.120699
INFO:root:FL Epoch: 133 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.5396897862939274 and Test Accuracy:70.0 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:1.827796717484792                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1762, 1215, 45, 1845, 286, 1365, 1646, 1010, 1553, 844]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1762
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459689
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273052
INFO:root:FL Epoch: 134 Norm Difference for worker 1762 is 1.042546
INFO:root:FL Epoch: 134 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1215
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505593
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591958
INFO:root:FL Epoch: 134 Norm Difference for worker 1215 is 1.114289
INFO:root:FL Epoch: 134 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :45
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706903
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 45 is 1.241629
INFO:root:FL Epoch: 134 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1845
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599645
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625193
INFO:root:FL Epoch: 134 Norm Difference for worker 1845 is 1.218875
INFO:root:FL Epoch: 134 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :286
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 286 is 1.126315
INFO:root:FL Epoch: 134 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1365
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557803
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533391
INFO:root:FL Epoch: 134 Norm Difference for worker 1365 is 1.144069
INFO:root:FL Epoch: 134 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1646
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543575
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454999
INFO:root:FL Epoch: 134 Norm Difference for worker 1646 is 1.0871
INFO:root:FL Epoch: 134 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1010
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 1.130047
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558184
INFO:root:FL Epoch: 134 Norm Difference for worker 1010 is 1.144828
INFO:root:FL Epoch: 134 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1553
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333606
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515056
INFO:root:FL Epoch: 134 Norm Difference for worker 1553 is 1.064261
INFO:root:FL Epoch: 134 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :844
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605768
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527527
INFO:root:FL Epoch: 134 Norm Difference for worker 844 is 1.106013
INFO:root:FL Epoch: 134 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1553
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.5530578599256628 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:1.8377761046091716                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1923, 1447, 270, 798, 544, 980, 460, 1745, 163, 154]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 200 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1923
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745128
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536672
INFO:root:FL Epoch: 135 Norm Difference for worker 1923 is 1.158361
INFO:root:FL Epoch: 135 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1447
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623348
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496586
INFO:root:FL Epoch: 135 Norm Difference for worker 1447 is 1.104891
INFO:root:FL Epoch: 135 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :270
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 270 is 1.170879
INFO:root:FL Epoch: 135 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :798
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546268
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441520
INFO:root:FL Epoch: 135 Norm Difference for worker 798 is 1.138866
INFO:root:FL Epoch: 135 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :544
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367898
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.751968
INFO:root:FL Epoch: 135 Norm Difference for worker 544 is 1.187403
INFO:root:FL Epoch: 135 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :980
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696854
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488410
INFO:root:FL Epoch: 135 Norm Difference for worker 980 is 1.135873
INFO:root:FL Epoch: 135 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :460
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619991
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523200
INFO:root:FL Epoch: 135 Norm Difference for worker 460 is 1.276201
INFO:root:FL Epoch: 135 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1745
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514581
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430974
INFO:root:FL Epoch: 135 Norm Difference for worker 1745 is 1.123075
INFO:root:FL Epoch: 135 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :163
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444000
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 163 is 1.242662
INFO:root:FL Epoch: 135 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :154
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619742
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 154 is 1.33716
INFO:root:FL Epoch: 135 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1745
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.5390671666930703 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:1.616659144560496                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [279, 1641, 891, 1730, 629, 33, 1866, 1168, 116, 768]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 136 Num points on workers: [201 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :279
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533141
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 279 is 1.063063
INFO:root:FL Epoch: 136 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1641
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608134
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523799
INFO:root:FL Epoch: 136 Norm Difference for worker 1641 is 1.058753
INFO:root:FL Epoch: 136 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :891
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501255
INFO:root:Worker: 891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668609
INFO:root:FL Epoch: 136 Norm Difference for worker 891 is 1.150216
INFO:root:FL Epoch: 136 Done on worker:891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1730
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414262
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648615
INFO:root:FL Epoch: 136 Norm Difference for worker 1730 is 1.102068
INFO:root:FL Epoch: 136 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :629
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633971
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279383
INFO:root:FL Epoch: 136 Norm Difference for worker 629 is 1.098392
INFO:root:FL Epoch: 136 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :33
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574949
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 33 is 1.100655
INFO:root:FL Epoch: 136 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1866
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618095
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662001
INFO:root:FL Epoch: 136 Norm Difference for worker 1866 is 1.047641
INFO:root:FL Epoch: 136 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1168
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586043
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550835
INFO:root:FL Epoch: 136 Norm Difference for worker 1168 is 1.020754
INFO:root:FL Epoch: 136 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :116
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 116 is 1.108869
INFO:root:FL Epoch: 136 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :768
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694099
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397403
INFO:root:FL Epoch: 136 Norm Difference for worker 768 is 1.046439
INFO:root:FL Epoch: 136 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1168
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.5281058847904205 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:1.571021854877472                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [1360, 906, 174, 354, 57, 1402, 694, 1585, 751, 225]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 201 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :1360
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409263
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660136
INFO:root:FL Epoch: 137 Norm Difference for worker 1360 is 1.084407
INFO:root:FL Epoch: 137 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :906
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519939
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418739
INFO:root:FL Epoch: 137 Norm Difference for worker 906 is 1.054376
INFO:root:FL Epoch: 137 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :174
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620342
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 174 is 0.983878
INFO:root:FL Epoch: 137 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :354
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579224
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573579
INFO:root:FL Epoch: 137 Norm Difference for worker 354 is 1.082928
INFO:root:FL Epoch: 137 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :57
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618066
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.720502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 57 is 0.98941
INFO:root:FL Epoch: 137 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1402
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593665
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464821
INFO:root:FL Epoch: 137 Norm Difference for worker 1402 is 1.029537
INFO:root:FL Epoch: 137 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :694
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562529
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527008
INFO:root:FL Epoch: 137 Norm Difference for worker 694 is 1.021208
INFO:root:FL Epoch: 137 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1585
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483573
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389298
INFO:root:FL Epoch: 137 Norm Difference for worker 1585 is 1.116221
INFO:root:FL Epoch: 137 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :751
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755495
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241592
INFO:root:FL Epoch: 137 Norm Difference for worker 751 is 1.05926
INFO:root:FL Epoch: 137 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :225
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 225 is 1.107236
INFO:root:FL Epoch: 137 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.5459327610100017 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:1.529892881711324                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [278, 1091, 1259, 475, 72, 827, 1604, 738, 263, 818]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 138 Num points on workers: [201 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :278
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 278 is 1.031344
INFO:root:FL Epoch: 138 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1091
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577129
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553715
INFO:root:FL Epoch: 138 Norm Difference for worker 1091 is 1.108994
INFO:root:FL Epoch: 138 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1259
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633483
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669067
INFO:root:FL Epoch: 138 Norm Difference for worker 1259 is 1.001808
INFO:root:FL Epoch: 138 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :475
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608622
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453125
INFO:root:FL Epoch: 138 Norm Difference for worker 475 is 1.054485
INFO:root:FL Epoch: 138 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :72
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453309
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 72 is 1.007903
INFO:root:FL Epoch: 138 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :827
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537489
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623539
INFO:root:FL Epoch: 138 Norm Difference for worker 827 is 1.069361
INFO:root:FL Epoch: 138 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1604
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636235
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584982
INFO:root:FL Epoch: 138 Norm Difference for worker 1604 is 1.079731
INFO:root:FL Epoch: 138 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :738
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516302
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662702
INFO:root:FL Epoch: 138 Norm Difference for worker 738 is 1.091586
INFO:root:FL Epoch: 138 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :263
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332939
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 263 is 1.03628
INFO:root:FL Epoch: 138 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :818
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646389
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631757
INFO:root:FL Epoch: 138 Norm Difference for worker 818 is 1.032625
INFO:root:FL Epoch: 138 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.5506911067401662 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:1.2231623729070027                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [1104, 1882, 211, 1240, 589, 1791, 931, 314, 1652, 1945]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 139 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :1104
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563370
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667067
INFO:root:FL Epoch: 139 Norm Difference for worker 1104 is 0.936313
INFO:root:FL Epoch: 139 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1882
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435117
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473370
INFO:root:FL Epoch: 139 Norm Difference for worker 1882 is 0.93627
INFO:root:FL Epoch: 139 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :211
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 211 is 0.933352
INFO:root:FL Epoch: 139 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1240
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726547
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647196
INFO:root:FL Epoch: 139 Norm Difference for worker 1240 is 0.964683
INFO:root:FL Epoch: 139 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :589
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805854
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473308
INFO:root:FL Epoch: 139 Norm Difference for worker 589 is 0.929786
INFO:root:FL Epoch: 139 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1791
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843221
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581656
INFO:root:FL Epoch: 139 Norm Difference for worker 1791 is 0.965941
INFO:root:FL Epoch: 139 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :931
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628575
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456973
INFO:root:FL Epoch: 139 Norm Difference for worker 931 is 0.986542
INFO:root:FL Epoch: 139 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :314
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.780475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614742
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 314 is 0.957671
INFO:root:FL Epoch: 139 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1652
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690111
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573380
INFO:root:FL Epoch: 139 Norm Difference for worker 1652 is 0.940289
INFO:root:FL Epoch: 139 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1945
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582340
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365213
INFO:root:FL Epoch: 139 Norm Difference for worker 1945 is 0.976269
INFO:root:FL Epoch: 139 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 589
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.5383322642130011 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:1.5456412235895793                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [112, 969, 1814, 1150, 986, 1819, 48, 650, 117, 1216]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 140 Num points on workers: [201 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :112
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 112 is 1.02817
INFO:root:FL Epoch: 140 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :969
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412599
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362080
INFO:root:FL Epoch: 140 Norm Difference for worker 969 is 1.02424
INFO:root:FL Epoch: 140 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1814
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689411
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398642
INFO:root:FL Epoch: 140 Norm Difference for worker 1814 is 1.025223
INFO:root:FL Epoch: 140 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1150
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542912
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681967
INFO:root:FL Epoch: 140 Norm Difference for worker 1150 is 1.036099
INFO:root:FL Epoch: 140 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :986
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900278
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647967
INFO:root:FL Epoch: 140 Norm Difference for worker 986 is 1.075885
INFO:root:FL Epoch: 140 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1819
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579832
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626651
INFO:root:FL Epoch: 140 Norm Difference for worker 1819 is 1.051746
INFO:root:FL Epoch: 140 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :48
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 48 is 1.000548
INFO:root:FL Epoch: 140 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :650
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677132
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477134
INFO:root:FL Epoch: 140 Norm Difference for worker 650 is 1.034488
INFO:root:FL Epoch: 140 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :117
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560461
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 117 is 0.996632
INFO:root:FL Epoch: 140 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1216
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637837
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495348
INFO:root:FL Epoch: 140 Norm Difference for worker 1216 is 1.06307
INFO:root:FL Epoch: 140 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 48
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.5293054177480585 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:1.4483819603919983                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 847, 348, 1203, 1247, 1752, 1077, 630, 852, 549]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812823
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633059
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.2954671035210292 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.41301841735839845 Backdoor Train Accuracy: 86.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 1.673979
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :847
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514113
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446025
INFO:root:FL Epoch: 141 Norm Difference for worker 847 is 0.97194
INFO:root:FL Epoch: 141 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :348
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609576
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497077
INFO:root:FL Epoch: 141 Norm Difference for worker 348 is 1.003116
INFO:root:FL Epoch: 141 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1203
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619250
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636541
INFO:root:FL Epoch: 141 Norm Difference for worker 1203 is 1.094428
INFO:root:FL Epoch: 141 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1247
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689133
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524982
INFO:root:FL Epoch: 141 Norm Difference for worker 1247 is 1.044649
INFO:root:FL Epoch: 141 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1752
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694486
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363746
INFO:root:FL Epoch: 141 Norm Difference for worker 1752 is 1.106516
INFO:root:FL Epoch: 141 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1077
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479930
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295770
INFO:root:FL Epoch: 141 Norm Difference for worker 1077 is 1.05376
INFO:root:FL Epoch: 141 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :630
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617766
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456651
INFO:root:FL Epoch: 141 Norm Difference for worker 630 is 1.078786
INFO:root:FL Epoch: 141 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :852
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559761
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496181
INFO:root:FL Epoch: 141 Norm Difference for worker 852 is 1.030787
INFO:root:FL Epoch: 141 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634712
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557853
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.095338
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 348
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 141 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 141 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.5440567854572745 and Test Accuracy:75.0 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:1.5018125176429749                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [752, 1148, 735, 1623, 1295, 1134, 466, 1667, 1130, 1538]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :752
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602701
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473366
INFO:root:FL Epoch: 142 Norm Difference for worker 752 is 1.131431
INFO:root:FL Epoch: 142 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1148
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494422
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409068
INFO:root:FL Epoch: 142 Norm Difference for worker 1148 is 1.113341
INFO:root:FL Epoch: 142 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :735
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504870
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649006
INFO:root:FL Epoch: 142 Norm Difference for worker 735 is 1.086065
INFO:root:FL Epoch: 142 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1623
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464320
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517510
INFO:root:FL Epoch: 142 Norm Difference for worker 1623 is 1.103487
INFO:root:FL Epoch: 142 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1295
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608136
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433410
INFO:root:FL Epoch: 142 Norm Difference for worker 1295 is 1.061442
INFO:root:FL Epoch: 142 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1134
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495655
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345593
INFO:root:FL Epoch: 142 Norm Difference for worker 1134 is 1.186301
INFO:root:FL Epoch: 142 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :466
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537540
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596033
INFO:root:FL Epoch: 142 Norm Difference for worker 466 is 0.997874
INFO:root:FL Epoch: 142 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1667
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608119
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766344
INFO:root:FL Epoch: 142 Norm Difference for worker 1667 is 1.078661
INFO:root:FL Epoch: 142 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1130
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450439
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522615
INFO:root:FL Epoch: 142 Norm Difference for worker 1130 is 1.22384
INFO:root:FL Epoch: 142 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1538
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637045
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527189
INFO:root:FL Epoch: 142 Norm Difference for worker 1538 is 1.117962
INFO:root:FL Epoch: 142 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 466
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.5356373331126045 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:1.528493603070577                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1147, 69, 638, 1747, 1518, 692, 1267, 1754, 1756, 821]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 143 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1147
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699069
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587512
INFO:root:FL Epoch: 143 Norm Difference for worker 1147 is 1.312886
INFO:root:FL Epoch: 143 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :69
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461026
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 69 is 1.181133
INFO:root:FL Epoch: 143 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :638
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574769
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403207
INFO:root:FL Epoch: 143 Norm Difference for worker 638 is 1.110109
INFO:root:FL Epoch: 143 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1747
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426321
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325714
INFO:root:FL Epoch: 143 Norm Difference for worker 1747 is 1.185247
INFO:root:FL Epoch: 143 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1518
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534073
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324552
INFO:root:FL Epoch: 143 Norm Difference for worker 1518 is 1.284091
INFO:root:FL Epoch: 143 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :692
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494682
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510823
INFO:root:FL Epoch: 143 Norm Difference for worker 692 is 1.305288
INFO:root:FL Epoch: 143 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1267
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366538
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540050
INFO:root:FL Epoch: 143 Norm Difference for worker 1267 is 1.180539
INFO:root:FL Epoch: 143 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1754
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502969
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663066
INFO:root:FL Epoch: 143 Norm Difference for worker 1754 is 1.125176
INFO:root:FL Epoch: 143 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1756
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410153
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554165
INFO:root:FL Epoch: 143 Norm Difference for worker 1756 is 1.19458
INFO:root:FL Epoch: 143 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :821
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544848
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590270
INFO:root:FL Epoch: 143 Norm Difference for worker 821 is 1.203242
INFO:root:FL Epoch: 143 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.5432242260259741 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:1.6358601053555806                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1610, 1581, 1101, 1061, 1350, 1109, 903, 792, 1408, 639]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1610
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369870
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500102
INFO:root:FL Epoch: 144 Norm Difference for worker 1610 is 1.420818
INFO:root:FL Epoch: 144 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1581
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755991
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562646
INFO:root:FL Epoch: 144 Norm Difference for worker 1581 is 1.375925
INFO:root:FL Epoch: 144 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1101
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680305
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491170
INFO:root:FL Epoch: 144 Norm Difference for worker 1101 is 1.21472
INFO:root:FL Epoch: 144 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1061
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687169
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681366
INFO:root:FL Epoch: 144 Norm Difference for worker 1061 is 1.311066
INFO:root:FL Epoch: 144 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1350
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702022
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504269
INFO:root:FL Epoch: 144 Norm Difference for worker 1350 is 1.290595
INFO:root:FL Epoch: 144 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1109
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711835
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550192
INFO:root:FL Epoch: 144 Norm Difference for worker 1109 is 1.349351
INFO:root:FL Epoch: 144 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :903
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521230
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553749
INFO:root:FL Epoch: 144 Norm Difference for worker 903 is 1.292093
INFO:root:FL Epoch: 144 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :792
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756429
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384987
INFO:root:FL Epoch: 144 Norm Difference for worker 792 is 1.274384
INFO:root:FL Epoch: 144 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1408
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646036
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470409
INFO:root:FL Epoch: 144 Norm Difference for worker 1408 is 1.368267
INFO:root:FL Epoch: 144 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :639
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457647
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411994
INFO:root:FL Epoch: 144 Norm Difference for worker 639 is 1.162924
INFO:root:FL Epoch: 144 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.5368296854636249 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:1.9247915943463643                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [593, 1441, 1324, 718, 641, 611, 1429, 657, 840, 1004]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 145 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :593
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603015
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384906
INFO:root:FL Epoch: 145 Norm Difference for worker 593 is 1.322419
INFO:root:FL Epoch: 145 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1441
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355360
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534845
INFO:root:FL Epoch: 145 Norm Difference for worker 1441 is 1.246436
INFO:root:FL Epoch: 145 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1324
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492243
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468247
INFO:root:FL Epoch: 145 Norm Difference for worker 1324 is 1.299037
INFO:root:FL Epoch: 145 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :718
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556804
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582267
INFO:root:FL Epoch: 145 Norm Difference for worker 718 is 1.29936
INFO:root:FL Epoch: 145 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :641
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514660
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.794885
INFO:root:FL Epoch: 145 Norm Difference for worker 641 is 1.425168
INFO:root:FL Epoch: 145 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :611
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577936
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385160
INFO:root:FL Epoch: 145 Norm Difference for worker 611 is 1.325367
INFO:root:FL Epoch: 145 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1429
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873171
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387723
INFO:root:FL Epoch: 145 Norm Difference for worker 1429 is 1.249098
INFO:root:FL Epoch: 145 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :657
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762973
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555025
INFO:root:FL Epoch: 145 Norm Difference for worker 657 is 1.251886
INFO:root:FL Epoch: 145 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :840
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628275
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565095
INFO:root:FL Epoch: 145 Norm Difference for worker 840 is 1.214694
INFO:root:FL Epoch: 145 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1004
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613336
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483941
INFO:root:FL Epoch: 145 Norm Difference for worker 1004 is 1.309305
INFO:root:FL Epoch: 145 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1429
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.5362020713441512 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:1.5142362316449482                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [210, 25, 20, 407, 1117, 1625, 609, 799, 24, 823]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 146 Num points on workers: [201 201 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :210
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363746
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 210 is 1.018108
INFO:root:FL Epoch: 146 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :25
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.409711
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571535
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 25 is 1.045203
INFO:root:FL Epoch: 146 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :20
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 20 is 1.068092
INFO:root:FL Epoch: 146 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :407
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637031
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428466
INFO:root:FL Epoch: 146 Norm Difference for worker 407 is 1.016631
INFO:root:FL Epoch: 146 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1117
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503093
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458706
INFO:root:FL Epoch: 146 Norm Difference for worker 1117 is 1.044145
INFO:root:FL Epoch: 146 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1625
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688841
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452712
INFO:root:FL Epoch: 146 Norm Difference for worker 1625 is 1.075398
INFO:root:FL Epoch: 146 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :609
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560711
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529979
INFO:root:FL Epoch: 146 Norm Difference for worker 609 is 1.134795
INFO:root:FL Epoch: 146 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :799
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607069
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479460
INFO:root:FL Epoch: 146 Norm Difference for worker 799 is 1.060427
INFO:root:FL Epoch: 146 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :24
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 24 is 1.120756
INFO:root:FL Epoch: 146 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :823
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420652
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441007
INFO:root:FL Epoch: 146 Norm Difference for worker 823 is 1.056433
INFO:root:FL Epoch: 146 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.5475588318179635 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:1.908741533756256                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [416, 1, 880, 409, 510, 1701, 1033, 1133, 696, 163]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 147 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :416
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699273
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422989
INFO:root:FL Epoch: 147 Norm Difference for worker 416 is 1.140658
INFO:root:FL Epoch: 147 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 1.017612
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 1 is 1.071036
INFO:root:FL Epoch: 147 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :880
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548715
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488395
INFO:root:FL Epoch: 147 Norm Difference for worker 880 is 1.115066
INFO:root:FL Epoch: 147 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :409
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563533
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497449
INFO:root:FL Epoch: 147 Norm Difference for worker 409 is 1.147468
INFO:root:FL Epoch: 147 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :510
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615881
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654586
INFO:root:FL Epoch: 147 Norm Difference for worker 510 is 1.161458
INFO:root:FL Epoch: 147 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1701
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522245
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358072
INFO:root:FL Epoch: 147 Norm Difference for worker 1701 is 1.046494
INFO:root:FL Epoch: 147 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1033
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613372
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415198
INFO:root:FL Epoch: 147 Norm Difference for worker 1033 is 1.058282
INFO:root:FL Epoch: 147 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1133
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841832
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426297
INFO:root:FL Epoch: 147 Norm Difference for worker 1133 is 1.167492
INFO:root:FL Epoch: 147 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :696
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740081
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428258
INFO:root:FL Epoch: 147 Norm Difference for worker 696 is 1.144227
INFO:root:FL Epoch: 147 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :163
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661114
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377405
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 163 is 1.139143
INFO:root:FL Epoch: 147 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.5336369153331307 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:1.3619617819786072                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [942, 781, 1222, 801, 823, 334, 916, 602, 101, 553]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :942
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604664
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478880
INFO:root:FL Epoch: 148 Norm Difference for worker 942 is 0.967069
INFO:root:FL Epoch: 148 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :781
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479286
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655762
INFO:root:FL Epoch: 148 Norm Difference for worker 781 is 0.983232
INFO:root:FL Epoch: 148 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1222
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476590
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401976
INFO:root:FL Epoch: 148 Norm Difference for worker 1222 is 1.020039
INFO:root:FL Epoch: 148 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :801
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385897
INFO:root:Worker: 801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309056
INFO:root:FL Epoch: 148 Norm Difference for worker 801 is 0.977748
INFO:root:FL Epoch: 148 Done on worker:801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :823
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519437
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454392
INFO:root:FL Epoch: 148 Norm Difference for worker 823 is 0.999361
INFO:root:FL Epoch: 148 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :334
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582771
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 334 is 1.054839
INFO:root:FL Epoch: 148 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :916
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529738
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528333
INFO:root:FL Epoch: 148 Norm Difference for worker 916 is 1.014348
INFO:root:FL Epoch: 148 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :602
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561070
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419759
INFO:root:FL Epoch: 148 Norm Difference for worker 602 is 1.063278
INFO:root:FL Epoch: 148 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :101
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 101 is 1.026134
INFO:root:FL Epoch: 148 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :553
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439128
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469467
INFO:root:FL Epoch: 148 Norm Difference for worker 553 is 0.973555
INFO:root:FL Epoch: 148 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 801
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.5343678891658783 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:1.8940229415893555                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [574, 350, 747, 196, 505, 561, 379, 1777, 689, 1396]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :574
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571831
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544840
INFO:root:FL Epoch: 149 Norm Difference for worker 574 is 1.217388
INFO:root:FL Epoch: 149 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :350
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664705
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672806
INFO:root:FL Epoch: 149 Norm Difference for worker 350 is 1.222078
INFO:root:FL Epoch: 149 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :747
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486441
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408829
INFO:root:FL Epoch: 149 Norm Difference for worker 747 is 1.162792
INFO:root:FL Epoch: 149 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :196
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 196 is 1.194239
INFO:root:FL Epoch: 149 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :505
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565437
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470320
INFO:root:FL Epoch: 149 Norm Difference for worker 505 is 1.206452
INFO:root:FL Epoch: 149 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :561
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743545
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526362
INFO:root:FL Epoch: 149 Norm Difference for worker 561 is 1.22389
INFO:root:FL Epoch: 149 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :379
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488124
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296230
INFO:root:FL Epoch: 149 Norm Difference for worker 379 is 1.235453
INFO:root:FL Epoch: 149 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1777
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525436
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561067
INFO:root:FL Epoch: 149 Norm Difference for worker 1777 is 1.225681
INFO:root:FL Epoch: 149 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :689
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454083
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569235
INFO:root:FL Epoch: 149 Norm Difference for worker 689 is 1.283144
INFO:root:FL Epoch: 149 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1396
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675228
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490880
INFO:root:FL Epoch: 149 Norm Difference for worker 1396 is 1.179048
INFO:root:FL Epoch: 149 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 747
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.5614793914205888 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:1.7500080267588298                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [1265, 1756, 1912, 1934, 307, 422, 297, 1150, 1736, 501]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 150 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :1265
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503399
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664057
INFO:root:FL Epoch: 150 Norm Difference for worker 1265 is 1.170508
INFO:root:FL Epoch: 150 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1756
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602804
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417559
INFO:root:FL Epoch: 150 Norm Difference for worker 1756 is 1.110452
INFO:root:FL Epoch: 150 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1912
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510044
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391022
INFO:root:FL Epoch: 150 Norm Difference for worker 1912 is 1.120217
INFO:root:FL Epoch: 150 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1934
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535228
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424184
INFO:root:FL Epoch: 150 Norm Difference for worker 1934 is 1.18896
INFO:root:FL Epoch: 150 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :307
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 307 is 1.118994
INFO:root:FL Epoch: 150 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :422
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561168
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393519
INFO:root:FL Epoch: 150 Norm Difference for worker 422 is 1.125586
INFO:root:FL Epoch: 150 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :297
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 297 is 1.135766
INFO:root:FL Epoch: 150 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1150
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545574
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520541
INFO:root:FL Epoch: 150 Norm Difference for worker 1150 is 1.092189
INFO:root:FL Epoch: 150 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1736
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567179
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529858
INFO:root:FL Epoch: 150 Norm Difference for worker 1736 is 1.108528
INFO:root:FL Epoch: 150 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :501
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545799
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428457
INFO:root:FL Epoch: 150 Norm Difference for worker 501 is 1.175095
INFO:root:FL Epoch: 150 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1150
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.5591686964035034 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:1.9106526772181194                             and Backdoor Test Accuracy:0.8333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1062, 746, 880, 211, 125, 1337, 847, 1578, 1047]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907817
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440100
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.289921077589194 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.39062553346157075 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 1.755016
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1062
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872176
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631435
INFO:root:FL Epoch: 151 Norm Difference for worker 1062 is 1.106858
INFO:root:FL Epoch: 151 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :746
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499156
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599485
INFO:root:FL Epoch: 151 Norm Difference for worker 746 is 1.096066
INFO:root:FL Epoch: 151 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :880
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642139
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476528
INFO:root:FL Epoch: 151 Norm Difference for worker 880 is 1.074011
INFO:root:FL Epoch: 151 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :211
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 211 is 1.098727
INFO:root:FL Epoch: 151 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :125
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 125 is 1.002039
INFO:root:FL Epoch: 151 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1337
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571281
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653428
INFO:root:FL Epoch: 151 Norm Difference for worker 1337 is 1.062786
INFO:root:FL Epoch: 151 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :847
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361102
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642065
INFO:root:FL Epoch: 151 Norm Difference for worker 847 is 1.037627
INFO:root:FL Epoch: 151 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1578
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552557
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439809
INFO:root:FL Epoch: 151 Norm Difference for worker 1578 is 0.935269
INFO:root:FL Epoch: 151 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1047
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583226
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590672
INFO:root:FL Epoch: 151 Norm Difference for worker 1047 is 1.079729
INFO:root:FL Epoch: 151 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.5590715986840865 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:1.780287782351176                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1645, 723, 1486, 636, 239, 17, 61, 1600, 1273, 742]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1645
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550868
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579175
INFO:root:FL Epoch: 152 Norm Difference for worker 1645 is 1.086433
INFO:root:FL Epoch: 152 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :723
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425231
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619896
INFO:root:FL Epoch: 152 Norm Difference for worker 723 is 1.011546
INFO:root:FL Epoch: 152 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1486
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604934
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579529
INFO:root:FL Epoch: 152 Norm Difference for worker 1486 is 1.105827
INFO:root:FL Epoch: 152 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :636
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612071
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.842631
INFO:root:FL Epoch: 152 Norm Difference for worker 636 is 1.071001
INFO:root:FL Epoch: 152 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :239
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660040
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 239 is 1.052709
INFO:root:FL Epoch: 152 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :17
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.729750
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 17 is 1.091081
INFO:root:FL Epoch: 152 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :61
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 61 is 1.079958
INFO:root:FL Epoch: 152 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1600
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733720
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639062
INFO:root:FL Epoch: 152 Norm Difference for worker 1600 is 1.136869
INFO:root:FL Epoch: 152 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1273
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525582
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606669
INFO:root:FL Epoch: 152 Norm Difference for worker 1273 is 1.09572
INFO:root:FL Epoch: 152 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :742
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465626
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426327
INFO:root:FL Epoch: 152 Norm Difference for worker 742 is 1.090545
INFO:root:FL Epoch: 152 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.5524579041144427 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:1.512710730234782                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [1336, 356, 514, 71, 511, 1668, 1694, 1746, 159, 534]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :1336
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816840
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417779
INFO:root:FL Epoch: 153 Norm Difference for worker 1336 is 0.931964
INFO:root:FL Epoch: 153 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :356
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480249
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632501
INFO:root:FL Epoch: 153 Norm Difference for worker 356 is 0.909516
INFO:root:FL Epoch: 153 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :514
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584054
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665012
INFO:root:FL Epoch: 153 Norm Difference for worker 514 is 0.929313
INFO:root:FL Epoch: 153 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :71
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 71 is 0.929785
INFO:root:FL Epoch: 153 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :511
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686901
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480703
INFO:root:FL Epoch: 153 Norm Difference for worker 511 is 0.935629
INFO:root:FL Epoch: 153 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1668
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477554
INFO:root:Worker: 1668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339523
INFO:root:FL Epoch: 153 Norm Difference for worker 1668 is 0.918246
INFO:root:FL Epoch: 153 Done on worker:1668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1694
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802267
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613140
INFO:root:FL Epoch: 153 Norm Difference for worker 1694 is 0.943086
INFO:root:FL Epoch: 153 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1746
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522890
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639756
INFO:root:FL Epoch: 153 Norm Difference for worker 1746 is 1.022945
INFO:root:FL Epoch: 153 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :159
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596812
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 159 is 0.889739
INFO:root:FL Epoch: 153 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :534
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722727
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394971
INFO:root:FL Epoch: 153 Norm Difference for worker 534 is 0.939407
INFO:root:FL Epoch: 153 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 159
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.5621559234226451 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:1.6578883330027263                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [913, 1139, 497, 1501, 1753, 486, 765, 1484, 806, 227]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :913
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682570
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618296
INFO:root:FL Epoch: 154 Norm Difference for worker 913 is 1.008071
INFO:root:FL Epoch: 154 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1139
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627844
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396465
INFO:root:FL Epoch: 154 Norm Difference for worker 1139 is 0.91485
INFO:root:FL Epoch: 154 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :497
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580803
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489103
INFO:root:FL Epoch: 154 Norm Difference for worker 497 is 0.922914
INFO:root:FL Epoch: 154 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1501
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547087
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435754
INFO:root:FL Epoch: 154 Norm Difference for worker 1501 is 0.933392
INFO:root:FL Epoch: 154 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1753
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567797
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498905
INFO:root:FL Epoch: 154 Norm Difference for worker 1753 is 0.878338
INFO:root:FL Epoch: 154 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :486
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575659
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572709
INFO:root:FL Epoch: 154 Norm Difference for worker 486 is 0.887568
INFO:root:FL Epoch: 154 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :765
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505609
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457773
INFO:root:FL Epoch: 154 Norm Difference for worker 765 is 1.030995
INFO:root:FL Epoch: 154 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1484
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779197
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508648
INFO:root:FL Epoch: 154 Norm Difference for worker 1484 is 0.908608
INFO:root:FL Epoch: 154 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :806
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545852
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597936
INFO:root:FL Epoch: 154 Norm Difference for worker 806 is 0.945074
INFO:root:FL Epoch: 154 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :227
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 227 is 0.904099
INFO:root:FL Epoch: 154 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.5749384322587181 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:1.9946562846501668                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [578, 1140, 516, 1456, 1074, 131, 1204, 1321, 461, 1448]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 155 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :578
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744737
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541132
INFO:root:FL Epoch: 155 Norm Difference for worker 578 is 1.016389
INFO:root:FL Epoch: 155 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1140
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629106
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418591
INFO:root:FL Epoch: 155 Norm Difference for worker 1140 is 1.037261
INFO:root:FL Epoch: 155 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :516
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718443
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379237
INFO:root:FL Epoch: 155 Norm Difference for worker 516 is 1.035578
INFO:root:FL Epoch: 155 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1456
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739967
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484876
INFO:root:FL Epoch: 155 Norm Difference for worker 1456 is 0.973133
INFO:root:FL Epoch: 155 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1074
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566194
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604375
INFO:root:FL Epoch: 155 Norm Difference for worker 1074 is 1.047508
INFO:root:FL Epoch: 155 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :131
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560040
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 131 is 1.009661
INFO:root:FL Epoch: 155 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1204
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555017
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536495
INFO:root:FL Epoch: 155 Norm Difference for worker 1204 is 1.140154
INFO:root:FL Epoch: 155 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1321
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592445
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422808
INFO:root:FL Epoch: 155 Norm Difference for worker 1321 is 1.101231
INFO:root:FL Epoch: 155 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :461
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652879
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618722
INFO:root:FL Epoch: 155 Norm Difference for worker 461 is 1.055243
INFO:root:FL Epoch: 155 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1448
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557363
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583719
INFO:root:FL Epoch: 155 Norm Difference for worker 1448 is 1.10029
INFO:root:FL Epoch: 155 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1456
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.5583636585403892 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:1.8214539686838787                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [696, 1797, 656, 1869, 1172, 58, 1684, 1548, 455, 393]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :696
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618317
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437821
INFO:root:FL Epoch: 156 Norm Difference for worker 696 is 1.00731
INFO:root:FL Epoch: 156 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1797
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505013
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636468
INFO:root:FL Epoch: 156 Norm Difference for worker 1797 is 0.99664
INFO:root:FL Epoch: 156 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :656
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463762
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552482
INFO:root:FL Epoch: 156 Norm Difference for worker 656 is 0.981783
INFO:root:FL Epoch: 156 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1869
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633033
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380364
INFO:root:FL Epoch: 156 Norm Difference for worker 1869 is 0.994501
INFO:root:FL Epoch: 156 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1172
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719438
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579382
INFO:root:FL Epoch: 156 Norm Difference for worker 1172 is 1.000445
INFO:root:FL Epoch: 156 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :58
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 58 is 0.998895
INFO:root:FL Epoch: 156 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1684
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643135
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581051
INFO:root:FL Epoch: 156 Norm Difference for worker 1684 is 1.067655
INFO:root:FL Epoch: 156 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1548
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628532
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.849277
INFO:root:FL Epoch: 156 Norm Difference for worker 1548 is 0.996714
INFO:root:FL Epoch: 156 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :455
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624473
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509400
INFO:root:FL Epoch: 156 Norm Difference for worker 455 is 1.005644
INFO:root:FL Epoch: 156 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :393
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571628
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559230
INFO:root:FL Epoch: 156 Norm Difference for worker 393 is 0.94767
INFO:root:FL Epoch: 156 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 393
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.5455245445756352 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:1.7499889334042866                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [119, 1745, 975, 1803, 569, 507, 827, 1363, 1405, 731]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 157 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :119
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 119 is 0.947357
INFO:root:FL Epoch: 157 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1745
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411178
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442422
INFO:root:FL Epoch: 157 Norm Difference for worker 1745 is 0.933299
INFO:root:FL Epoch: 157 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :975
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624164
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592269
INFO:root:FL Epoch: 157 Norm Difference for worker 975 is 1.041609
INFO:root:FL Epoch: 157 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1803
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681751
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749131
INFO:root:FL Epoch: 157 Norm Difference for worker 1803 is 0.98411
INFO:root:FL Epoch: 157 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :569
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524430
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545271
INFO:root:FL Epoch: 157 Norm Difference for worker 569 is 0.960177
INFO:root:FL Epoch: 157 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :507
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666954
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433183
INFO:root:FL Epoch: 157 Norm Difference for worker 507 is 0.93418
INFO:root:FL Epoch: 157 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :827
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581532
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461601
INFO:root:FL Epoch: 157 Norm Difference for worker 827 is 0.894586
INFO:root:FL Epoch: 157 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1363
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764886
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482075
INFO:root:FL Epoch: 157 Norm Difference for worker 1363 is 0.997794
INFO:root:FL Epoch: 157 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1405
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745142
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307041
INFO:root:FL Epoch: 157 Norm Difference for worker 1405 is 0.969154
INFO:root:FL Epoch: 157 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :731
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724880
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346973
INFO:root:FL Epoch: 157 Norm Difference for worker 731 is 0.975771
INFO:root:FL Epoch: 157 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1745
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.5405011843232548 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:2.0849727789560952                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [13, 1353, 116, 1208, 1857, 461, 1534, 301, 826, 574]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 158 Num points on workers: [201 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :13
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 13 is 1.160812
INFO:root:FL Epoch: 158 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1353
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600858
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481428
INFO:root:FL Epoch: 158 Norm Difference for worker 1353 is 1.156137
INFO:root:FL Epoch: 158 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :116
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549916
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 116 is 1.181684
INFO:root:FL Epoch: 158 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1208
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437468
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587905
INFO:root:FL Epoch: 158 Norm Difference for worker 1208 is 1.139051
INFO:root:FL Epoch: 158 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1857
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647328
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446740
INFO:root:FL Epoch: 158 Norm Difference for worker 1857 is 1.138247
INFO:root:FL Epoch: 158 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :461
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472467
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488796
INFO:root:FL Epoch: 158 Norm Difference for worker 461 is 1.107467
INFO:root:FL Epoch: 158 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1534
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437213
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368484
INFO:root:FL Epoch: 158 Norm Difference for worker 1534 is 1.205298
INFO:root:FL Epoch: 158 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :301
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 301 is 1.209042
INFO:root:FL Epoch: 158 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :826
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704431
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354813
INFO:root:FL Epoch: 158 Norm Difference for worker 826 is 1.151673
INFO:root:FL Epoch: 158 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :574
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505636
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589433
INFO:root:FL Epoch: 158 Norm Difference for worker 574 is 1.231397
INFO:root:FL Epoch: 158 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.5578537057427799 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:2.294247627258301                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [1009, 1163, 526, 1612, 1699, 1879, 1255, 1793, 790, 1663]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :1009
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446990
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535707
INFO:root:FL Epoch: 159 Norm Difference for worker 1009 is 1.322344
INFO:root:FL Epoch: 159 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1163
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624454
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307970
INFO:root:FL Epoch: 159 Norm Difference for worker 1163 is 1.234376
INFO:root:FL Epoch: 159 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :526
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471978
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666360
INFO:root:FL Epoch: 159 Norm Difference for worker 526 is 1.28546
INFO:root:FL Epoch: 159 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1612
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843043
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627799
INFO:root:FL Epoch: 159 Norm Difference for worker 1612 is 1.206141
INFO:root:FL Epoch: 159 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1699
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442571
INFO:root:Worker: 1699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358884
INFO:root:FL Epoch: 159 Norm Difference for worker 1699 is 1.188731
INFO:root:FL Epoch: 159 Done on worker:1699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1879
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694823
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376206
INFO:root:FL Epoch: 159 Norm Difference for worker 1879 is 1.187743
INFO:root:FL Epoch: 159 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1255
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657838
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587779
INFO:root:FL Epoch: 159 Norm Difference for worker 1255 is 1.20036
INFO:root:FL Epoch: 159 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1793
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857444
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473557
INFO:root:FL Epoch: 159 Norm Difference for worker 1793 is 1.23278
INFO:root:FL Epoch: 159 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :790
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544445
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470994
INFO:root:FL Epoch: 159 Norm Difference for worker 790 is 1.218984
INFO:root:FL Epoch: 159 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1663
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457624
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564258
INFO:root:FL Epoch: 159 Norm Difference for worker 1663 is 1.112706
INFO:root:FL Epoch: 159 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.5556105848620919 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:1.9793331424395244                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [285, 1202, 1057, 1346, 158, 334, 869, 1252, 1342, 599]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 160 Num points on workers: [201 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :285
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 285 is 1.158267
INFO:root:FL Epoch: 160 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1202
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508092
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534369
INFO:root:FL Epoch: 160 Norm Difference for worker 1202 is 1.052964
INFO:root:FL Epoch: 160 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1057
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471053
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360713
INFO:root:FL Epoch: 160 Norm Difference for worker 1057 is 1.029525
INFO:root:FL Epoch: 160 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1346
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428868
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357220
INFO:root:FL Epoch: 160 Norm Difference for worker 1346 is 1.118397
INFO:root:FL Epoch: 160 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :158
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 158 is 1.184201
INFO:root:FL Epoch: 160 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :334
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 334 is 1.137497
INFO:root:FL Epoch: 160 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :869
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423888
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391666
INFO:root:FL Epoch: 160 Norm Difference for worker 869 is 1.102671
INFO:root:FL Epoch: 160 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1252
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660957
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497918
INFO:root:FL Epoch: 160 Norm Difference for worker 1252 is 1.176635
INFO:root:FL Epoch: 160 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1342
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588099
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441134
INFO:root:FL Epoch: 160 Norm Difference for worker 1342 is 1.155365
INFO:root:FL Epoch: 160 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :599
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424897
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523972
INFO:root:FL Epoch: 160 Norm Difference for worker 599 is 1.139454
INFO:root:FL Epoch: 160 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1057
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.5870193295619067 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:2.346250136693319                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 496, 947, 946, 124, 357, 1821, 1167, 1106, 1890]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786596
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499904
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.29801227400700253 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.46306254863739016 Backdoor Train Accuracy: 78.0
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 2.149469
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :496
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483685
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577013
INFO:root:FL Epoch: 161 Norm Difference for worker 496 is 1.141725
INFO:root:FL Epoch: 161 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :947
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774467
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710137
INFO:root:FL Epoch: 161 Norm Difference for worker 947 is 1.120097
INFO:root:FL Epoch: 161 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :946
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625078
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442968
INFO:root:FL Epoch: 161 Norm Difference for worker 946 is 1.175355
INFO:root:FL Epoch: 161 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :124
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 1.117086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 124 is 1.232757
INFO:root:FL Epoch: 161 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :357
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509607
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497762
INFO:root:FL Epoch: 161 Norm Difference for worker 357 is 1.189742
INFO:root:FL Epoch: 161 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1821
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571470
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587799
INFO:root:FL Epoch: 161 Norm Difference for worker 1821 is 1.146461
INFO:root:FL Epoch: 161 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1167
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362402
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576697
INFO:root:FL Epoch: 161 Norm Difference for worker 1167 is 1.156649
INFO:root:FL Epoch: 161 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1106
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413212
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316150
INFO:root:FL Epoch: 161 Norm Difference for worker 1106 is 1.121074
INFO:root:FL Epoch: 161 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1890
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431438
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553767
INFO:root:FL Epoch: 161 Norm Difference for worker 1890 is 1.161506
INFO:root:FL Epoch: 161 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 496
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.5418166570803699 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:1.7663448850313823                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [1195, 447, 382, 542, 1541, 1857, 1401, 959, 353, 639]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :1195
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696515
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421355
INFO:root:FL Epoch: 162 Norm Difference for worker 1195 is 0.974489
INFO:root:FL Epoch: 162 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :447
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553916
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519219
INFO:root:FL Epoch: 162 Norm Difference for worker 447 is 1.020245
INFO:root:FL Epoch: 162 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :382
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594095
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663940
INFO:root:FL Epoch: 162 Norm Difference for worker 382 is 1.061662
INFO:root:FL Epoch: 162 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :542
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381952
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476789
INFO:root:FL Epoch: 162 Norm Difference for worker 542 is 0.98201
INFO:root:FL Epoch: 162 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1541
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627252
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455608
INFO:root:FL Epoch: 162 Norm Difference for worker 1541 is 1.006369
INFO:root:FL Epoch: 162 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1857
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519662
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442127
INFO:root:FL Epoch: 162 Norm Difference for worker 1857 is 1.004095
INFO:root:FL Epoch: 162 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1401
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558734
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507855
INFO:root:FL Epoch: 162 Norm Difference for worker 1401 is 0.974038
INFO:root:FL Epoch: 162 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :959
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519284
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635266
INFO:root:FL Epoch: 162 Norm Difference for worker 959 is 1.040306
INFO:root:FL Epoch: 162 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :353
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495705
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535243
INFO:root:FL Epoch: 162 Norm Difference for worker 353 is 1.049553
INFO:root:FL Epoch: 162 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :639
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375485
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422484
INFO:root:FL Epoch: 162 Norm Difference for worker 639 is 0.980401
INFO:root:FL Epoch: 162 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1401
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 162 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 162 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.511914940441356 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:1.3906989097595215                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1039, 1302, 1461, 1694, 369, 370, 1333, 149, 1393, 1591]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1039
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537297
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508581
INFO:root:FL Epoch: 163 Norm Difference for worker 1039 is 0.988153
INFO:root:FL Epoch: 163 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1302
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643300
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399022
INFO:root:FL Epoch: 163 Norm Difference for worker 1302 is 0.948293
INFO:root:FL Epoch: 163 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1461
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524235
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535731
INFO:root:FL Epoch: 163 Norm Difference for worker 1461 is 0.977309
INFO:root:FL Epoch: 163 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1694
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616925
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478660
INFO:root:FL Epoch: 163 Norm Difference for worker 1694 is 0.975486
INFO:root:FL Epoch: 163 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :369
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565645
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344098
INFO:root:FL Epoch: 163 Norm Difference for worker 369 is 0.961394
INFO:root:FL Epoch: 163 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :370
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458089
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622534
INFO:root:FL Epoch: 163 Norm Difference for worker 370 is 0.964515
INFO:root:FL Epoch: 163 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1333
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486736
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509306
INFO:root:FL Epoch: 163 Norm Difference for worker 1333 is 0.977586
INFO:root:FL Epoch: 163 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :149
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 149 is 0.987609
INFO:root:FL Epoch: 163 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1393
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685283
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567794
INFO:root:FL Epoch: 163 Norm Difference for worker 1393 is 0.911225
INFO:root:FL Epoch: 163 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1591
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576248
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437643
INFO:root:FL Epoch: 163 Norm Difference for worker 1591 is 1.00895
INFO:root:FL Epoch: 163 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1393
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.5105415968333974 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:1.3630629380544026                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1395, 106, 70, 481, 1703, 1708, 239, 768, 1573, 942]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 164 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1395
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602714
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367931
INFO:root:FL Epoch: 164 Norm Difference for worker 1395 is 0.956164
INFO:root:FL Epoch: 164 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :106
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 106 is 1.012476
INFO:root:FL Epoch: 164 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :70
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 70 is 0.949821
INFO:root:FL Epoch: 164 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :481
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574369
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508109
INFO:root:FL Epoch: 164 Norm Difference for worker 481 is 1.023906
INFO:root:FL Epoch: 164 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1703
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719938
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493588
INFO:root:FL Epoch: 164 Norm Difference for worker 1703 is 0.948046
INFO:root:FL Epoch: 164 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1708
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502812
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553900
INFO:root:FL Epoch: 164 Norm Difference for worker 1708 is 0.963386
INFO:root:FL Epoch: 164 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :239
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 239 is 1.051849
INFO:root:FL Epoch: 164 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :768
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728867
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510443
INFO:root:FL Epoch: 164 Norm Difference for worker 768 is 0.965019
INFO:root:FL Epoch: 164 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1573
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437265
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560135
INFO:root:FL Epoch: 164 Norm Difference for worker 1573 is 0.986768
INFO:root:FL Epoch: 164 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :942
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801581
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589839
INFO:root:FL Epoch: 164 Norm Difference for worker 942 is 0.961403
INFO:root:FL Epoch: 164 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1395
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.4942779067684622 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:1.6220875978469849                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [96, 658, 45, 672, 465, 437, 165, 1430, 931, 554]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 165 Num points on workers: [201 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :96
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.769930
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 96 is 1.172709
INFO:root:FL Epoch: 165 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :658
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532922
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578623
INFO:root:FL Epoch: 165 Norm Difference for worker 658 is 1.247398
INFO:root:FL Epoch: 165 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :45
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.938460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 45 is 1.287089
INFO:root:FL Epoch: 165 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :672
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618636
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518142
INFO:root:FL Epoch: 165 Norm Difference for worker 672 is 1.075536
INFO:root:FL Epoch: 165 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :465
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650811
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563935
INFO:root:FL Epoch: 165 Norm Difference for worker 465 is 1.117556
INFO:root:FL Epoch: 165 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :437
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618450
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403649
INFO:root:FL Epoch: 165 Norm Difference for worker 437 is 1.063238
INFO:root:FL Epoch: 165 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :165
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 165 is 1.183108
INFO:root:FL Epoch: 165 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1430
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565469
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514457
INFO:root:FL Epoch: 165 Norm Difference for worker 1430 is 1.16383
INFO:root:FL Epoch: 165 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :931
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639275
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518076
INFO:root:FL Epoch: 165 Norm Difference for worker 931 is 1.200348
INFO:root:FL Epoch: 165 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :554
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505170
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487155
INFO:root:FL Epoch: 165 Norm Difference for worker 554 is 1.060031
INFO:root:FL Epoch: 165 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 672
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 165 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 165 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.4860425310976365 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:1.5222924947738647                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [1360, 1418, 1882, 1505, 1902, 1525, 1059, 1776, 1019, 1636]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 166 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :1360
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483428
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321929
INFO:root:FL Epoch: 166 Norm Difference for worker 1360 is 1.029108
INFO:root:FL Epoch: 166 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1418
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457825
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511948
INFO:root:FL Epoch: 166 Norm Difference for worker 1418 is 1.014667
INFO:root:FL Epoch: 166 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1882
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637848
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506356
INFO:root:FL Epoch: 166 Norm Difference for worker 1882 is 0.979483
INFO:root:FL Epoch: 166 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1505
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574809
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452253
INFO:root:FL Epoch: 166 Norm Difference for worker 1505 is 0.996419
INFO:root:FL Epoch: 166 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1902
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430040
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579953
INFO:root:FL Epoch: 166 Norm Difference for worker 1902 is 0.962427
INFO:root:FL Epoch: 166 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1525
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734590
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498984
INFO:root:FL Epoch: 166 Norm Difference for worker 1525 is 1.050076
INFO:root:FL Epoch: 166 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1059
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532482
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423675
INFO:root:FL Epoch: 166 Norm Difference for worker 1059 is 1.009659
INFO:root:FL Epoch: 166 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1776
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510843
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661825
INFO:root:FL Epoch: 166 Norm Difference for worker 1776 is 1.020528
INFO:root:FL Epoch: 166 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1019
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860700
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602964
INFO:root:FL Epoch: 166 Norm Difference for worker 1019 is 0.962002
INFO:root:FL Epoch: 166 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1636
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519657
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461417
INFO:root:FL Epoch: 166 Norm Difference for worker 1636 is 1.09804
INFO:root:FL Epoch: 166 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1019
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.4849439088036032 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:1.759540855884552                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [340, 1624, 673, 1586, 1285, 1451, 825, 217, 181, 847]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :340
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426011
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438385
INFO:root:FL Epoch: 167 Norm Difference for worker 340 is 1.028855
INFO:root:FL Epoch: 167 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1624
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548169
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445461
INFO:root:FL Epoch: 167 Norm Difference for worker 1624 is 1.043043
INFO:root:FL Epoch: 167 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :673
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448600
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392120
INFO:root:FL Epoch: 167 Norm Difference for worker 673 is 1.033889
INFO:root:FL Epoch: 167 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1586
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740666
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553998
INFO:root:FL Epoch: 167 Norm Difference for worker 1586 is 1.079566
INFO:root:FL Epoch: 167 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1285
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406341
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535738
INFO:root:FL Epoch: 167 Norm Difference for worker 1285 is 1.03362
INFO:root:FL Epoch: 167 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1451
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374646
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472572
INFO:root:FL Epoch: 167 Norm Difference for worker 1451 is 1.05658
INFO:root:FL Epoch: 167 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :825
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525439
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496144
INFO:root:FL Epoch: 167 Norm Difference for worker 825 is 0.966988
INFO:root:FL Epoch: 167 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :217
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 217 is 1.011021
INFO:root:FL Epoch: 167 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :181
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 181 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 181 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 181 is 0.989197
INFO:root:FL Epoch: 167 Done on worker:181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :847
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709691
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583278
INFO:root:FL Epoch: 167 Norm Difference for worker 847 is 1.041848
INFO:root:FL Epoch: 167 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.48495756177341237 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:1.6038652857144673                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [959, 1158, 1033, 500, 266, 1200, 1552, 1623, 469, 1340]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :959
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720414
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492282
INFO:root:FL Epoch: 168 Norm Difference for worker 959 is 1.065086
INFO:root:FL Epoch: 168 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1158
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675798
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316883
INFO:root:FL Epoch: 168 Norm Difference for worker 1158 is 0.966062
INFO:root:FL Epoch: 168 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1033
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501762
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534996
INFO:root:FL Epoch: 168 Norm Difference for worker 1033 is 0.98089
INFO:root:FL Epoch: 168 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :500
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521923
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407619
INFO:root:FL Epoch: 168 Norm Difference for worker 500 is 1.031599
INFO:root:FL Epoch: 168 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :266
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488756
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 266 is 1.01972
INFO:root:FL Epoch: 168 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1200
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510801
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556684
INFO:root:FL Epoch: 168 Norm Difference for worker 1200 is 1.013989
INFO:root:FL Epoch: 168 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1552
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514453
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416765
INFO:root:FL Epoch: 168 Norm Difference for worker 1552 is 1.007084
INFO:root:FL Epoch: 168 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1623
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672477
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468694
INFO:root:FL Epoch: 168 Norm Difference for worker 1623 is 1.020419
INFO:root:FL Epoch: 168 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :469
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471112
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428939
INFO:root:FL Epoch: 168 Norm Difference for worker 469 is 0.994467
INFO:root:FL Epoch: 168 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1340
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531296
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445765
INFO:root:FL Epoch: 168 Norm Difference for worker 1340 is 1.019327
INFO:root:FL Epoch: 168 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1033
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.48143993055119233 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:1.6329842408498128                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [1348, 723, 116, 142, 1660, 361, 1637, 1511, 73, 426]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 169 Num points on workers: [200 200 201 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :1348
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589702
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425551
INFO:root:FL Epoch: 169 Norm Difference for worker 1348 is 0.985947
INFO:root:FL Epoch: 169 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :723
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386555
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296630
INFO:root:FL Epoch: 169 Norm Difference for worker 723 is 0.999865
INFO:root:FL Epoch: 169 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :116
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.747333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 116 is 1.059233
INFO:root:FL Epoch: 169 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :142
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 142 is 1.008206
INFO:root:FL Epoch: 169 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1660
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504585
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530482
INFO:root:FL Epoch: 169 Norm Difference for worker 1660 is 1.051119
INFO:root:FL Epoch: 169 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :361
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686474
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444235
INFO:root:FL Epoch: 169 Norm Difference for worker 361 is 1.037165
INFO:root:FL Epoch: 169 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1637
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533870
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524152
INFO:root:FL Epoch: 169 Norm Difference for worker 1637 is 1.015867
INFO:root:FL Epoch: 169 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1511
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485207
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572796
INFO:root:FL Epoch: 169 Norm Difference for worker 1511 is 1.054071
INFO:root:FL Epoch: 169 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :73
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.718913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 73 is 1.143671
INFO:root:FL Epoch: 169 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :426
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385876
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467772
INFO:root:FL Epoch: 169 Norm Difference for worker 426 is 1.021003
INFO:root:FL Epoch: 169 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.48083869148703184 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:1.6436920563379924                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [1482, 1232, 977, 1512, 1577, 632, 1062, 906, 240, 497]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 170 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :1482
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699351
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649010
INFO:root:FL Epoch: 170 Norm Difference for worker 1482 is 1.081343
INFO:root:FL Epoch: 170 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1232
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492706
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591322
INFO:root:FL Epoch: 170 Norm Difference for worker 1232 is 1.095655
INFO:root:FL Epoch: 170 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :977
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479484
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371346
INFO:root:FL Epoch: 170 Norm Difference for worker 977 is 1.047533
INFO:root:FL Epoch: 170 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1512
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485352
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380536
INFO:root:FL Epoch: 170 Norm Difference for worker 1512 is 1.059616
INFO:root:FL Epoch: 170 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1577
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688119
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597046
INFO:root:FL Epoch: 170 Norm Difference for worker 1577 is 1.062942
INFO:root:FL Epoch: 170 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :632
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628959
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602002
INFO:root:FL Epoch: 170 Norm Difference for worker 632 is 1.080645
INFO:root:FL Epoch: 170 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1062
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471029
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551946
INFO:root:FL Epoch: 170 Norm Difference for worker 1062 is 1.158466
INFO:root:FL Epoch: 170 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :906
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640924
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571015
INFO:root:FL Epoch: 170 Norm Difference for worker 906 is 1.075545
INFO:root:FL Epoch: 170 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :240
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 240 is 1.111021
INFO:root:FL Epoch: 170 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :497
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604425
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222836
INFO:root:FL Epoch: 170 Norm Difference for worker 497 is 1.023959
INFO:root:FL Epoch: 170 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.48217883530785055 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:1.7393715381622314                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1128, 743, 313, 1429, 358, 102, 504, 23, 1606]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.421509
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461137
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.3151290565729141 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.39716050028800964 Backdoor Train Accuracy: 85.5
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 1.65148
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1128
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527420
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616300
INFO:root:FL Epoch: 171 Norm Difference for worker 1128 is 1.055867
INFO:root:FL Epoch: 171 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :743
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592696
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378604
INFO:root:FL Epoch: 171 Norm Difference for worker 743 is 1.094988
INFO:root:FL Epoch: 171 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :313
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 313 is 1.110227
INFO:root:FL Epoch: 171 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1429
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367013
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358119
INFO:root:FL Epoch: 171 Norm Difference for worker 1429 is 1.050307
INFO:root:FL Epoch: 171 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :358
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503122
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514677
INFO:root:FL Epoch: 171 Norm Difference for worker 358 is 1.031934
INFO:root:FL Epoch: 171 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :102
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 102 is 1.037938
INFO:root:FL Epoch: 171 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :504
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531273
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362776
INFO:root:FL Epoch: 171 Norm Difference for worker 504 is 1.052927
INFO:root:FL Epoch: 171 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :23
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.800090
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541642
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 23 is 1.080087
INFO:root:FL Epoch: 171 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1606
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508020
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474999
INFO:root:FL Epoch: 171 Norm Difference for worker 1606 is 1.046281
INFO:root:FL Epoch: 171 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 102
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.4947348482468549 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:1.7425910631815593                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [952, 783, 280, 515, 1479, 19, 1030, 117, 1085, 1083]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :952
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485623
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697500
INFO:root:FL Epoch: 172 Norm Difference for worker 952 is 1.032007
INFO:root:FL Epoch: 172 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :783
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705461
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607497
INFO:root:FL Epoch: 172 Norm Difference for worker 783 is 0.961842
INFO:root:FL Epoch: 172 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :280
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 280 is 0.945286
INFO:root:FL Epoch: 172 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :515
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481707
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641991
INFO:root:FL Epoch: 172 Norm Difference for worker 515 is 0.990599
INFO:root:FL Epoch: 172 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1479
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555207
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618638
INFO:root:FL Epoch: 172 Norm Difference for worker 1479 is 0.992696
INFO:root:FL Epoch: 172 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :19
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593797
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 19 is 1.050557
INFO:root:FL Epoch: 172 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1030
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755432
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396095
INFO:root:FL Epoch: 172 Norm Difference for worker 1030 is 1.038386
INFO:root:FL Epoch: 172 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :117
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 117 is 0.963176
INFO:root:FL Epoch: 172 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1085
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538913
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590236
INFO:root:FL Epoch: 172 Norm Difference for worker 1085 is 0.964522
INFO:root:FL Epoch: 172 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1083
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642604
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406396
INFO:root:FL Epoch: 172 Norm Difference for worker 1083 is 0.996087
INFO:root:FL Epoch: 172 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 280
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.5024865830645842 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:1.98337318499883                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1628, 979, 254, 531, 878, 811, 754, 483, 335, 446]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1628
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556136
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586389
INFO:root:FL Epoch: 173 Norm Difference for worker 1628 is 1.052335
INFO:root:FL Epoch: 173 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :979
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679484
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555352
INFO:root:FL Epoch: 173 Norm Difference for worker 979 is 1.015199
INFO:root:FL Epoch: 173 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :254
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584968
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 254 is 0.923526
INFO:root:FL Epoch: 173 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :531
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551980
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459058
INFO:root:FL Epoch: 173 Norm Difference for worker 531 is 0.982697
INFO:root:FL Epoch: 173 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :878
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685084
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750409
INFO:root:FL Epoch: 173 Norm Difference for worker 878 is 1.030063
INFO:root:FL Epoch: 173 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :811
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394449
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541143
INFO:root:FL Epoch: 173 Norm Difference for worker 811 is 1.023594
INFO:root:FL Epoch: 173 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :754
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642174
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444266
INFO:root:FL Epoch: 173 Norm Difference for worker 754 is 0.996029
INFO:root:FL Epoch: 173 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :483
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605412
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381827
INFO:root:FL Epoch: 173 Norm Difference for worker 483 is 0.933633
INFO:root:FL Epoch: 173 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :335
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 335 is 1.033006
INFO:root:FL Epoch: 173 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :446
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460168
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437341
INFO:root:FL Epoch: 173 Norm Difference for worker 446 is 1.001539
INFO:root:FL Epoch: 173 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 254
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 173 Saving Best Checkpoint at this epoch.
INFO:root:FL Epoch: 173 Saved Best Checkpoint at this epoch.
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.4856381661751691 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:1.6706750988960266                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [236, 1367, 1538, 385, 191, 300, 1040, 1714, 235, 1351]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 174 Num points on workers: [201 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :236
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 236 is 1.00102
INFO:root:FL Epoch: 174 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1367
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637618
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589456
INFO:root:FL Epoch: 174 Norm Difference for worker 1367 is 1.160675
INFO:root:FL Epoch: 174 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1538
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550579
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462336
INFO:root:FL Epoch: 174 Norm Difference for worker 1538 is 1.029387
INFO:root:FL Epoch: 174 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :385
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576492
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573166
INFO:root:FL Epoch: 174 Norm Difference for worker 385 is 0.985711
INFO:root:FL Epoch: 174 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :191
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 191 is 1.01645
INFO:root:FL Epoch: 174 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :300
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 300 is 1.036018
INFO:root:FL Epoch: 174 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1040
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436668
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506139
INFO:root:FL Epoch: 174 Norm Difference for worker 1040 is 1.040953
INFO:root:FL Epoch: 174 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1714
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587573
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604413
INFO:root:FL Epoch: 174 Norm Difference for worker 1714 is 0.983206
INFO:root:FL Epoch: 174 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :235
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 235 is 0.985506
INFO:root:FL Epoch: 174 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1351
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550655
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392271
INFO:root:FL Epoch: 174 Norm Difference for worker 1351 is 0.991544
INFO:root:FL Epoch: 174 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1351
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.5076165690141565 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:1.2717184623082478                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [1337, 806, 575, 1105, 1160, 274, 1608, 1054, 242, 1760]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :1337
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470158
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530989
INFO:root:FL Epoch: 175 Norm Difference for worker 1337 is 0.802293
INFO:root:FL Epoch: 175 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :806
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689196
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624970
INFO:root:FL Epoch: 175 Norm Difference for worker 806 is 0.861208
INFO:root:FL Epoch: 175 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :575
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687397
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622535
INFO:root:FL Epoch: 175 Norm Difference for worker 575 is 0.900659
INFO:root:FL Epoch: 175 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1105
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484465
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382991
INFO:root:FL Epoch: 175 Norm Difference for worker 1105 is 0.885976
INFO:root:FL Epoch: 175 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1160
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412932
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630081
INFO:root:FL Epoch: 175 Norm Difference for worker 1160 is 0.898259
INFO:root:FL Epoch: 175 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :274
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 274 is 0.870023
INFO:root:FL Epoch: 175 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1608
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604820
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501629
INFO:root:FL Epoch: 175 Norm Difference for worker 1608 is 0.890103
INFO:root:FL Epoch: 175 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1054
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427472
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465655
INFO:root:FL Epoch: 175 Norm Difference for worker 1054 is 0.892908
INFO:root:FL Epoch: 175 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :242
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 242 is 0.850854
INFO:root:FL Epoch: 175 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1760
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600218
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577347
INFO:root:FL Epoch: 175 Norm Difference for worker 1760 is 0.909954
INFO:root:FL Epoch: 175 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.5049104234751534 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:1.2367899417877197                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [1247, 1290, 1658, 1782, 576, 1064, 527, 1179, 401, 1717]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :1247
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682986
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583104
INFO:root:FL Epoch: 176 Norm Difference for worker 1247 is 0.925729
INFO:root:FL Epoch: 176 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1290
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581455
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748267
INFO:root:FL Epoch: 176 Norm Difference for worker 1290 is 0.939931
INFO:root:FL Epoch: 176 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1658
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557474
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320921
INFO:root:FL Epoch: 176 Norm Difference for worker 1658 is 0.945426
INFO:root:FL Epoch: 176 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1782
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646774
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375196
INFO:root:FL Epoch: 176 Norm Difference for worker 1782 is 0.97621
INFO:root:FL Epoch: 176 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :576
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595878
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428500
INFO:root:FL Epoch: 176 Norm Difference for worker 576 is 0.918936
INFO:root:FL Epoch: 176 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1064
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557198
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530575
INFO:root:FL Epoch: 176 Norm Difference for worker 1064 is 0.908051
INFO:root:FL Epoch: 176 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :527
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574239
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568280
INFO:root:FL Epoch: 176 Norm Difference for worker 527 is 0.897451
INFO:root:FL Epoch: 176 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1179
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511680
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464996
INFO:root:FL Epoch: 176 Norm Difference for worker 1179 is 0.96891
INFO:root:FL Epoch: 176 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :401
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618165
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578541
INFO:root:FL Epoch: 176 Norm Difference for worker 401 is 0.912207
INFO:root:FL Epoch: 176 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1717
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492689
INFO:root:Worker: 1717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476716
INFO:root:FL Epoch: 176 Norm Difference for worker 1717 is 0.889386
INFO:root:FL Epoch: 176 Done on worker:1717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 527
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.490984988563201 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:1.3861957589785259                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [1431, 149, 1817, 8, 1203, 231, 630, 1409, 1281, 880]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :1431
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451193
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336743
INFO:root:FL Epoch: 177 Norm Difference for worker 1431 is 0.948338
INFO:root:FL Epoch: 177 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :149
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 149 is 0.945744
INFO:root:FL Epoch: 177 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1817
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502222
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551997
INFO:root:FL Epoch: 177 Norm Difference for worker 1817 is 0.962542
INFO:root:FL Epoch: 177 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 0.93261
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1203
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511074
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656342
INFO:root:FL Epoch: 177 Norm Difference for worker 1203 is 0.897941
INFO:root:FL Epoch: 177 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :231
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 231 is 0.911183
INFO:root:FL Epoch: 177 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :630
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527439
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681037
INFO:root:FL Epoch: 177 Norm Difference for worker 630 is 0.949723
INFO:root:FL Epoch: 177 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1409
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520347
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424794
INFO:root:FL Epoch: 177 Norm Difference for worker 1409 is 0.936401
INFO:root:FL Epoch: 177 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1281
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549051
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310495
INFO:root:FL Epoch: 177 Norm Difference for worker 1281 is 0.993501
INFO:root:FL Epoch: 177 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :880
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641775
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457952
INFO:root:FL Epoch: 177 Norm Difference for worker 880 is 0.921452
INFO:root:FL Epoch: 177 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.4889959272216348 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:1.6800360480944316                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [666, 1812, 1517, 1854, 1567, 1906, 1580, 1065, 1576, 561]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608832
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349535
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.117726
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1812
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340003
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377027
INFO:root:FL Epoch: 178 Norm Difference for worker 1812 is 1.112835
INFO:root:FL Epoch: 178 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1517
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760606
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449066
INFO:root:FL Epoch: 178 Norm Difference for worker 1517 is 1.118138
INFO:root:FL Epoch: 178 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1854
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714067
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432755
INFO:root:FL Epoch: 178 Norm Difference for worker 1854 is 1.137785
INFO:root:FL Epoch: 178 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1567
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820081
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437902
INFO:root:FL Epoch: 178 Norm Difference for worker 1567 is 1.137284
INFO:root:FL Epoch: 178 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1906
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496116
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722198
INFO:root:FL Epoch: 178 Norm Difference for worker 1906 is 1.057473
INFO:root:FL Epoch: 178 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1580
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423800
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374273
INFO:root:FL Epoch: 178 Norm Difference for worker 1580 is 1.057039
INFO:root:FL Epoch: 178 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1065
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559807
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578094
INFO:root:FL Epoch: 178 Norm Difference for worker 1065 is 1.17283
INFO:root:FL Epoch: 178 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1576
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659405
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364040
INFO:root:FL Epoch: 178 Norm Difference for worker 1576 is 1.070601
INFO:root:FL Epoch: 178 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :561
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.914609
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690513
INFO:root:FL Epoch: 178 Norm Difference for worker 561 is 1.133447
INFO:root:FL Epoch: 178 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.4944510494961458 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:1.5480271180470784                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1007, 528, 1736, 577, 987, 560, 843, 1494, 775, 1667]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1007
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333407
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440293
INFO:root:FL Epoch: 179 Norm Difference for worker 1007 is 1.02954
INFO:root:FL Epoch: 179 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :528
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742381
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569890
INFO:root:FL Epoch: 179 Norm Difference for worker 528 is 0.972021
INFO:root:FL Epoch: 179 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1736
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585304
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357481
INFO:root:FL Epoch: 179 Norm Difference for worker 1736 is 0.991086
INFO:root:FL Epoch: 179 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :577
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558734
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523989
INFO:root:FL Epoch: 179 Norm Difference for worker 577 is 0.977172
INFO:root:FL Epoch: 179 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :987
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518447
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438314
INFO:root:FL Epoch: 179 Norm Difference for worker 987 is 1.045209
INFO:root:FL Epoch: 179 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :560
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504251
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512533
INFO:root:FL Epoch: 179 Norm Difference for worker 560 is 1.021057
INFO:root:FL Epoch: 179 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :843
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818787
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503750
INFO:root:FL Epoch: 179 Norm Difference for worker 843 is 1.017568
INFO:root:FL Epoch: 179 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1494
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776162
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438415
INFO:root:FL Epoch: 179 Norm Difference for worker 1494 is 1.00255
INFO:root:FL Epoch: 179 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :775
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493492
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672507
INFO:root:FL Epoch: 179 Norm Difference for worker 775 is 1.032073
INFO:root:FL Epoch: 179 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1667
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492260
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489485
INFO:root:FL Epoch: 179 Norm Difference for worker 1667 is 1.059346
INFO:root:FL Epoch: 179 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 577
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.49311263596310334 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:1.503787875175476                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1715, 892, 1248, 640, 407, 1291, 747, 82, 1125, 395]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1715
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512453
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502008
INFO:root:FL Epoch: 180 Norm Difference for worker 1715 is 1.016621
INFO:root:FL Epoch: 180 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :892
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581548
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550447
INFO:root:FL Epoch: 180 Norm Difference for worker 892 is 0.942531
INFO:root:FL Epoch: 180 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1248
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728263
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560620
INFO:root:FL Epoch: 180 Norm Difference for worker 1248 is 0.991597
INFO:root:FL Epoch: 180 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :640
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632014
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486198
INFO:root:FL Epoch: 180 Norm Difference for worker 640 is 1.033596
INFO:root:FL Epoch: 180 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :407
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415111
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339069
INFO:root:FL Epoch: 180 Norm Difference for worker 407 is 0.991017
INFO:root:FL Epoch: 180 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1291
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684438
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471192
INFO:root:FL Epoch: 180 Norm Difference for worker 1291 is 0.923134
INFO:root:FL Epoch: 180 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :747
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477906
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367498
INFO:root:FL Epoch: 180 Norm Difference for worker 747 is 1.025226
INFO:root:FL Epoch: 180 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :82
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 82 is 0.945078
INFO:root:FL Epoch: 180 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1125
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418963
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452961
INFO:root:FL Epoch: 180 Norm Difference for worker 1125 is 0.979842
INFO:root:FL Epoch: 180 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :395
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617544
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393878
INFO:root:FL Epoch: 180 Norm Difference for worker 395 is 1.028189
INFO:root:FL Epoch: 180 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1291
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.483295260106816 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:1.5534935196240742                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 28, 1729, 475, 301, 21, 1428, 1065, 1257, 1472]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 181 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925181
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430181
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.28290431946516037 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.33811878114938737 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 1.756599
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :28
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 28 is 1.059145
INFO:root:FL Epoch: 181 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1729
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434468
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514124
INFO:root:FL Epoch: 181 Norm Difference for worker 1729 is 1.175904
INFO:root:FL Epoch: 181 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :475
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502258
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261236
INFO:root:FL Epoch: 181 Norm Difference for worker 475 is 1.134506
INFO:root:FL Epoch: 181 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :301
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479411
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 301 is 1.175113
INFO:root:FL Epoch: 181 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :21
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 21 is 1.122923
INFO:root:FL Epoch: 181 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1428
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486201
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622830
INFO:root:FL Epoch: 181 Norm Difference for worker 1428 is 1.161064
INFO:root:FL Epoch: 181 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1065
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717099
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547089
INFO:root:FL Epoch: 181 Norm Difference for worker 1065 is 1.224837
INFO:root:FL Epoch: 181 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1257
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718400
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582423
INFO:root:FL Epoch: 181 Norm Difference for worker 1257 is 1.169904
INFO:root:FL Epoch: 181 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1472
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410920
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478609
INFO:root:FL Epoch: 181 Norm Difference for worker 1472 is 1.166662
INFO:root:FL Epoch: 181 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.4976654035203597 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:1.496202011903127                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1214, 290, 152, 33, 404, 856, 222, 1685, 218, 373]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 182 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1214
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423376
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546668
INFO:root:FL Epoch: 182 Norm Difference for worker 1214 is 1.049366
INFO:root:FL Epoch: 182 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :290
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 290 is 1.056595
INFO:root:FL Epoch: 182 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :152
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 152 is 1.014491
INFO:root:FL Epoch: 182 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :33
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536731
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 33 is 1.102366
INFO:root:FL Epoch: 182 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :404
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840782
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442996
INFO:root:FL Epoch: 182 Norm Difference for worker 404 is 1.069627
INFO:root:FL Epoch: 182 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :856
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501484
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540331
INFO:root:FL Epoch: 182 Norm Difference for worker 856 is 1.149418
INFO:root:FL Epoch: 182 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :222
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.399507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 222 is 1.002954
INFO:root:FL Epoch: 182 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1685
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477752
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560639
INFO:root:FL Epoch: 182 Norm Difference for worker 1685 is 1.014624
INFO:root:FL Epoch: 182 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :218
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498381
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 218 is 1.041636
INFO:root:FL Epoch: 182 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :373
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524060
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383079
INFO:root:FL Epoch: 182 Norm Difference for worker 373 is 1.073718
INFO:root:FL Epoch: 182 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.5222268998622894 and Test Accuracy:75.0 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:1.7915838758150737                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1540, 853, 194, 931, 971, 892, 514, 287, 1467, 1603]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1540
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578256
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762867
INFO:root:FL Epoch: 183 Norm Difference for worker 1540 is 1.182953
INFO:root:FL Epoch: 183 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :853
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420366
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766857
INFO:root:FL Epoch: 183 Norm Difference for worker 853 is 1.168425
INFO:root:FL Epoch: 183 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :194
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 194 is 1.142527
INFO:root:FL Epoch: 183 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :931
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520449
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425935
INFO:root:FL Epoch: 183 Norm Difference for worker 931 is 1.216168
INFO:root:FL Epoch: 183 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :971
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474789
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440292
INFO:root:FL Epoch: 183 Norm Difference for worker 971 is 1.124583
INFO:root:FL Epoch: 183 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :892
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561116
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535802
INFO:root:FL Epoch: 183 Norm Difference for worker 892 is 1.095347
INFO:root:FL Epoch: 183 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :514
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565389
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384508
INFO:root:FL Epoch: 183 Norm Difference for worker 514 is 1.118621
INFO:root:FL Epoch: 183 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :287
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.774293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 287 is 1.146728
INFO:root:FL Epoch: 183 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1467
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645280
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.751942
INFO:root:FL Epoch: 183 Norm Difference for worker 1467 is 1.171995
INFO:root:FL Epoch: 183 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1603
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756840
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523466
INFO:root:FL Epoch: 183 Norm Difference for worker 1603 is 1.10154
INFO:root:FL Epoch: 183 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1603
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.5260780611458946 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:1.910546898841858                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1810, 158, 999, 464, 1856, 1267, 1872, 1777, 1932, 540]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1810
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633563
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509676
INFO:root:FL Epoch: 184 Norm Difference for worker 1810 is 1.105302
INFO:root:FL Epoch: 184 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :158
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312429
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 158 is 1.180973
INFO:root:FL Epoch: 184 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :999
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386564
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410177
INFO:root:FL Epoch: 184 Norm Difference for worker 999 is 1.19025
INFO:root:FL Epoch: 184 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :464
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442977
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536204
INFO:root:FL Epoch: 184 Norm Difference for worker 464 is 1.161268
INFO:root:FL Epoch: 184 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1856
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670100
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392173
INFO:root:FL Epoch: 184 Norm Difference for worker 1856 is 1.196929
INFO:root:FL Epoch: 184 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1267
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543573
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577758
INFO:root:FL Epoch: 184 Norm Difference for worker 1267 is 1.12787
INFO:root:FL Epoch: 184 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1872
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362646
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462056
INFO:root:FL Epoch: 184 Norm Difference for worker 1872 is 1.136104
INFO:root:FL Epoch: 184 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1777
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420573
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423251
INFO:root:FL Epoch: 184 Norm Difference for worker 1777 is 1.14181
INFO:root:FL Epoch: 184 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1932
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426225
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450266
INFO:root:FL Epoch: 184 Norm Difference for worker 1932 is 1.129384
INFO:root:FL Epoch: 184 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :540
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748644
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618151
INFO:root:FL Epoch: 184 Norm Difference for worker 540 is 1.177844
INFO:root:FL Epoch: 184 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1267
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.5332053356310901 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:1.5788679122924805                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1888, 1190, 1127, 991, 1603, 1478, 816, 1268, 1558, 234]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1888
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616966
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372093
INFO:root:FL Epoch: 185 Norm Difference for worker 1888 is 0.984734
INFO:root:FL Epoch: 185 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1190
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577475
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329290
INFO:root:FL Epoch: 185 Norm Difference for worker 1190 is 0.967305
INFO:root:FL Epoch: 185 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1127
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1127 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620963
INFO:root:Worker: 1127 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597464
INFO:root:FL Epoch: 185 Norm Difference for worker 1127 is 0.974332
INFO:root:FL Epoch: 185 Done on worker:1127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :991
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436948
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472408
INFO:root:FL Epoch: 185 Norm Difference for worker 991 is 0.951362
INFO:root:FL Epoch: 185 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1603
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459793
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496489
INFO:root:FL Epoch: 185 Norm Difference for worker 1603 is 0.922477
INFO:root:FL Epoch: 185 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1478
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536827
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458557
INFO:root:FL Epoch: 185 Norm Difference for worker 1478 is 0.936728
INFO:root:FL Epoch: 185 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :816
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583147
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466050
INFO:root:FL Epoch: 185 Norm Difference for worker 816 is 0.981291
INFO:root:FL Epoch: 185 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1268
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442047
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574865
INFO:root:FL Epoch: 185 Norm Difference for worker 1268 is 0.980286
INFO:root:FL Epoch: 185 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1558
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546419
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568223
INFO:root:FL Epoch: 185 Norm Difference for worker 1558 is 0.932665
INFO:root:FL Epoch: 185 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :234
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 234 is 0.997334
INFO:root:FL Epoch: 185 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1603
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.5465944882701425 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:2.1001795530319214                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [87, 1215, 923, 1875, 888, 1441, 1942, 138, 725, 1833]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 186 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :87
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 87 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 87 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 87 is 1.504251
INFO:root:FL Epoch: 186 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1215
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748857
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497797
INFO:root:FL Epoch: 186 Norm Difference for worker 1215 is 1.492937
INFO:root:FL Epoch: 186 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :923
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682906
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419925
INFO:root:FL Epoch: 186 Norm Difference for worker 923 is 1.262398
INFO:root:FL Epoch: 186 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1875
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483225
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.758006
INFO:root:FL Epoch: 186 Norm Difference for worker 1875 is 1.436288
INFO:root:FL Epoch: 186 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869052
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368094
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.452464
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1441
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612202
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277224
INFO:root:FL Epoch: 186 Norm Difference for worker 1441 is 1.411302
INFO:root:FL Epoch: 186 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1942
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392793
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367086
INFO:root:FL Epoch: 186 Norm Difference for worker 1942 is 1.601395
INFO:root:FL Epoch: 186 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :138
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.280517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 138 is 1.481695
INFO:root:FL Epoch: 186 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :725
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679425
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368237
INFO:root:FL Epoch: 186 Norm Difference for worker 725 is 1.489628
INFO:root:FL Epoch: 186 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1833
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728440
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705558
INFO:root:FL Epoch: 186 Norm Difference for worker 1833 is 1.391483
INFO:root:FL Epoch: 186 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 923
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.5218735232072718 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:1.5027283827463787                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [829, 1030, 1117, 581, 1213, 254, 1260, 925, 1813, 1619]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 187 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :829
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713048
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521696
INFO:root:FL Epoch: 187 Norm Difference for worker 829 is 1.193957
INFO:root:FL Epoch: 187 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1030
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685053
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430752
INFO:root:FL Epoch: 187 Norm Difference for worker 1030 is 1.251728
INFO:root:FL Epoch: 187 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1117
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626517
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385853
INFO:root:FL Epoch: 187 Norm Difference for worker 1117 is 1.112906
INFO:root:FL Epoch: 187 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :581
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756302
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494240
INFO:root:FL Epoch: 187 Norm Difference for worker 581 is 1.270987
INFO:root:FL Epoch: 187 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1213
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1213 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596404
INFO:root:Worker: 1213 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519181
INFO:root:FL Epoch: 187 Norm Difference for worker 1213 is 1.177383
INFO:root:FL Epoch: 187 Done on worker:1213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :254
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 254 is 1.004053
INFO:root:FL Epoch: 187 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1260
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583797
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541584
INFO:root:FL Epoch: 187 Norm Difference for worker 1260 is 1.18959
INFO:root:FL Epoch: 187 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :925
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506525
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362862
INFO:root:FL Epoch: 187 Norm Difference for worker 925 is 1.074772
INFO:root:FL Epoch: 187 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1813
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552705
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461167
INFO:root:FL Epoch: 187 Norm Difference for worker 1813 is 1.112103
INFO:root:FL Epoch: 187 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1619
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590258
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718045
INFO:root:FL Epoch: 187 Norm Difference for worker 1619 is 1.232653
INFO:root:FL Epoch: 187 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.5312622943345238 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:1.748121718565623                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [225, 1689, 881, 1886, 860, 409, 1241, 686, 360, 231]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 188 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :225
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 225 is 1.111997
INFO:root:FL Epoch: 188 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1689
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507433
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.812595
INFO:root:FL Epoch: 188 Norm Difference for worker 1689 is 1.155785
INFO:root:FL Epoch: 188 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :881
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437749
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524265
INFO:root:FL Epoch: 188 Norm Difference for worker 881 is 1.003034
INFO:root:FL Epoch: 188 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1886
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539797
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340206
INFO:root:FL Epoch: 188 Norm Difference for worker 1886 is 1.047178
INFO:root:FL Epoch: 188 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :860
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558555
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.794151
INFO:root:FL Epoch: 188 Norm Difference for worker 860 is 1.178976
INFO:root:FL Epoch: 188 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :409
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766656
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523650
INFO:root:FL Epoch: 188 Norm Difference for worker 409 is 1.131042
INFO:root:FL Epoch: 188 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1241
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510213
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446785
INFO:root:FL Epoch: 188 Norm Difference for worker 1241 is 1.055451
INFO:root:FL Epoch: 188 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :686
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667624
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538387
INFO:root:FL Epoch: 188 Norm Difference for worker 686 is 1.107261
INFO:root:FL Epoch: 188 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :360
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894530
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547873
INFO:root:FL Epoch: 188 Norm Difference for worker 360 is 1.0973
INFO:root:FL Epoch: 188 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :231
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 231 is 0.940054
INFO:root:FL Epoch: 188 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.5350131164578831 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:2.0559292435646057                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [941, 108, 1146, 935, 1362, 1694, 880, 193, 1326, 1581]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 189 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :941
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566383
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449354
INFO:root:FL Epoch: 189 Norm Difference for worker 941 is 1.195121
INFO:root:FL Epoch: 189 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :108
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 108 is 1.080033
INFO:root:FL Epoch: 189 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1146
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549888
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460029
INFO:root:FL Epoch: 189 Norm Difference for worker 1146 is 1.214123
INFO:root:FL Epoch: 189 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :935
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569146
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412027
INFO:root:FL Epoch: 189 Norm Difference for worker 935 is 1.290285
INFO:root:FL Epoch: 189 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1362
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796461
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539581
INFO:root:FL Epoch: 189 Norm Difference for worker 1362 is 1.19251
INFO:root:FL Epoch: 189 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1694
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561171
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666583
INFO:root:FL Epoch: 189 Norm Difference for worker 1694 is 1.265069
INFO:root:FL Epoch: 189 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :880
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520745
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525478
INFO:root:FL Epoch: 189 Norm Difference for worker 880 is 1.254594
INFO:root:FL Epoch: 189 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :193
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 193 is 1.31979
INFO:root:FL Epoch: 189 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1326
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 1.128465
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546980
INFO:root:FL Epoch: 189 Norm Difference for worker 1326 is 1.317953
INFO:root:FL Epoch: 189 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1581
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651544
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417345
INFO:root:FL Epoch: 189 Norm Difference for worker 1581 is 1.271361
INFO:root:FL Epoch: 189 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.5158157313571257 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:1.9471601446469624                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [1025, 1038, 99, 1766, 821, 741, 1366, 1215, 1823, 1722]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 190 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :1025
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575822
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501708
INFO:root:FL Epoch: 190 Norm Difference for worker 1025 is 1.113914
INFO:root:FL Epoch: 190 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1038
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774424
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582779
INFO:root:FL Epoch: 190 Norm Difference for worker 1038 is 1.170165
INFO:root:FL Epoch: 190 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :99
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 99 is 1.130417
INFO:root:FL Epoch: 190 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1766
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333096
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502836
INFO:root:FL Epoch: 190 Norm Difference for worker 1766 is 1.198937
INFO:root:FL Epoch: 190 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :821
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527536
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711515
INFO:root:FL Epoch: 190 Norm Difference for worker 821 is 1.175658
INFO:root:FL Epoch: 190 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :741
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716272
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687560
INFO:root:FL Epoch: 190 Norm Difference for worker 741 is 1.228187
INFO:root:FL Epoch: 190 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1366
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727855
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609012
INFO:root:FL Epoch: 190 Norm Difference for worker 1366 is 1.1973
INFO:root:FL Epoch: 190 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1215
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465138
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.909105
INFO:root:FL Epoch: 190 Norm Difference for worker 1215 is 1.226693
INFO:root:FL Epoch: 190 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1823
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426907
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422843
INFO:root:FL Epoch: 190 Norm Difference for worker 1823 is 1.256026
INFO:root:FL Epoch: 190 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1722
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556947
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464704
INFO:root:FL Epoch: 190 Norm Difference for worker 1722 is 1.171762
INFO:root:FL Epoch: 190 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.5209732949733734 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:1.7375021974245708                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 917, 911, 990, 1301, 347, 546, 1428, 550, 452]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.030177
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485117
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.3017677466074626 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.37252649664878845 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 1.713241
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :917
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751098
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451169
INFO:root:FL Epoch: 191 Norm Difference for worker 917 is 1.121328
INFO:root:FL Epoch: 191 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :911
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773415
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497951
INFO:root:FL Epoch: 191 Norm Difference for worker 911 is 1.093881
INFO:root:FL Epoch: 191 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :990
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561634
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659531
INFO:root:FL Epoch: 191 Norm Difference for worker 990 is 1.182642
INFO:root:FL Epoch: 191 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1301
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588004
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571836
INFO:root:FL Epoch: 191 Norm Difference for worker 1301 is 1.138336
INFO:root:FL Epoch: 191 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :347
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611812
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691778
INFO:root:FL Epoch: 191 Norm Difference for worker 347 is 1.089887
INFO:root:FL Epoch: 191 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :546
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390371
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519278
INFO:root:FL Epoch: 191 Norm Difference for worker 546 is 1.121734
INFO:root:FL Epoch: 191 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1428
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530700
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411180
INFO:root:FL Epoch: 191 Norm Difference for worker 1428 is 1.065351
INFO:root:FL Epoch: 191 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :550
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484005
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385166
INFO:root:FL Epoch: 191 Norm Difference for worker 550 is 1.121017
INFO:root:FL Epoch: 191 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :452
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607119
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582430
INFO:root:FL Epoch: 191 Norm Difference for worker 452 is 1.020569
INFO:root:FL Epoch: 191 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 452
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.5390840225359973 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:1.837581992149353                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [881, 1359, 460, 768, 1825, 1861, 1170, 1923, 174, 1013]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :881
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306181
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408933
INFO:root:FL Epoch: 192 Norm Difference for worker 881 is 0.994126
INFO:root:FL Epoch: 192 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1359
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795378
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648658
INFO:root:FL Epoch: 192 Norm Difference for worker 1359 is 1.055722
INFO:root:FL Epoch: 192 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :460
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851970
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497155
INFO:root:FL Epoch: 192 Norm Difference for worker 460 is 1.11097
INFO:root:FL Epoch: 192 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :768
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609434
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462202
INFO:root:FL Epoch: 192 Norm Difference for worker 768 is 1.077822
INFO:root:FL Epoch: 192 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1825
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813921
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565434
INFO:root:FL Epoch: 192 Norm Difference for worker 1825 is 1.051177
INFO:root:FL Epoch: 192 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1861
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565982
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534979
INFO:root:FL Epoch: 192 Norm Difference for worker 1861 is 1.072946
INFO:root:FL Epoch: 192 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1170
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617710
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741052
INFO:root:FL Epoch: 192 Norm Difference for worker 1170 is 1.135412
INFO:root:FL Epoch: 192 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1923
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453991
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.864952
INFO:root:FL Epoch: 192 Norm Difference for worker 1923 is 1.123245
INFO:root:FL Epoch: 192 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :174
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 174 is 1.028225
INFO:root:FL Epoch: 192 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1013
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703582
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419607
INFO:root:FL Epoch: 192 Norm Difference for worker 1013 is 1.085579
INFO:root:FL Epoch: 192 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.5283083074233111 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:2.0024213790893555                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [856, 1080, 734, 1781, 1228, 855, 596, 1509, 238, 1468]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :856
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874640
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.789005
INFO:root:FL Epoch: 193 Norm Difference for worker 856 is 1.426198
INFO:root:FL Epoch: 193 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1080
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687745
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593568
INFO:root:FL Epoch: 193 Norm Difference for worker 1080 is 1.263196
INFO:root:FL Epoch: 193 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :734
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600363
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607561
INFO:root:FL Epoch: 193 Norm Difference for worker 734 is 1.222732
INFO:root:FL Epoch: 193 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1781
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435304
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355088
INFO:root:FL Epoch: 193 Norm Difference for worker 1781 is 1.250089
INFO:root:FL Epoch: 193 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1228
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833808
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530392
INFO:root:FL Epoch: 193 Norm Difference for worker 1228 is 1.294233
INFO:root:FL Epoch: 193 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :855
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512265
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366834
INFO:root:FL Epoch: 193 Norm Difference for worker 855 is 1.282521
INFO:root:FL Epoch: 193 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :596
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658512
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746669
INFO:root:FL Epoch: 193 Norm Difference for worker 596 is 1.357285
INFO:root:FL Epoch: 193 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1509
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809597
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.821489
INFO:root:FL Epoch: 193 Norm Difference for worker 1509 is 1.345914
INFO:root:FL Epoch: 193 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :238
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 238 is 1.216208
INFO:root:FL Epoch: 193 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1468
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765643
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647498
INFO:root:FL Epoch: 193 Norm Difference for worker 1468 is 1.434469
INFO:root:FL Epoch: 193 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1080
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.514018698650248 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:1.35990967353185                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [321, 1229, 315, 1652, 1339, 834, 150, 448, 650, 1218]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :321
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 321 is 0.94196
INFO:root:FL Epoch: 194 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1229
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663709
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514816
INFO:root:FL Epoch: 194 Norm Difference for worker 1229 is 0.907102
INFO:root:FL Epoch: 194 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :315
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536197
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.777815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 315 is 0.873415
INFO:root:FL Epoch: 194 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1652
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474273
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558648
INFO:root:FL Epoch: 194 Norm Difference for worker 1652 is 0.925438
INFO:root:FL Epoch: 194 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1339
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551815
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425380
INFO:root:FL Epoch: 194 Norm Difference for worker 1339 is 0.920629
INFO:root:FL Epoch: 194 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :834
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573716
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631410
INFO:root:FL Epoch: 194 Norm Difference for worker 834 is 0.910677
INFO:root:FL Epoch: 194 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :150
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 150 is 0.946746
INFO:root:FL Epoch: 194 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :448
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563744
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602585
INFO:root:FL Epoch: 194 Norm Difference for worker 448 is 0.882887
INFO:root:FL Epoch: 194 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :650
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549246
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577192
INFO:root:FL Epoch: 194 Norm Difference for worker 650 is 0.947524
INFO:root:FL Epoch: 194 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1218
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601831
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505579
INFO:root:FL Epoch: 194 Norm Difference for worker 1218 is 0.957052
INFO:root:FL Epoch: 194 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 315
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.5165675317539888 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:1.3742698629697163                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [617, 318, 431, 448, 881, 1109, 472, 639, 1209, 703]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :617
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625560
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428252
INFO:root:FL Epoch: 195 Norm Difference for worker 617 is 0.945822
INFO:root:FL Epoch: 195 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :318
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 318 is 0.847434
INFO:root:FL Epoch: 195 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :431
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638108
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463385
INFO:root:FL Epoch: 195 Norm Difference for worker 431 is 0.860016
INFO:root:FL Epoch: 195 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :448
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646711
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708563
INFO:root:FL Epoch: 195 Norm Difference for worker 448 is 0.831885
INFO:root:FL Epoch: 195 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :881
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415733
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438180
INFO:root:FL Epoch: 195 Norm Difference for worker 881 is 0.915252
INFO:root:FL Epoch: 195 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1109
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497451
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408804
INFO:root:FL Epoch: 195 Norm Difference for worker 1109 is 0.855513
INFO:root:FL Epoch: 195 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :472
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732302
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462907
INFO:root:FL Epoch: 195 Norm Difference for worker 472 is 0.942088
INFO:root:FL Epoch: 195 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :639
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599752
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425871
INFO:root:FL Epoch: 195 Norm Difference for worker 639 is 0.885374
INFO:root:FL Epoch: 195 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1209
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626337
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480166
INFO:root:FL Epoch: 195 Norm Difference for worker 1209 is 0.891329
INFO:root:FL Epoch: 195 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :703
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484899
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685741
INFO:root:FL Epoch: 195 Norm Difference for worker 703 is 0.890692
INFO:root:FL Epoch: 195 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.5098778263610952 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:1.878350039323171                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [845, 1016, 1464, 84, 564, 253, 1499, 830, 1654, 1787]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :845
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554070
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499779
INFO:root:FL Epoch: 196 Norm Difference for worker 845 is 1.32735
INFO:root:FL Epoch: 196 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1016
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454911
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543491
INFO:root:FL Epoch: 196 Norm Difference for worker 1016 is 1.483077
INFO:root:FL Epoch: 196 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1464
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441844
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405629
INFO:root:FL Epoch: 196 Norm Difference for worker 1464 is 1.287227
INFO:root:FL Epoch: 196 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :84
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.825699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 84 is 1.480695
INFO:root:FL Epoch: 196 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :564
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422984
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610647
INFO:root:FL Epoch: 196 Norm Difference for worker 564 is 1.431233
INFO:root:FL Epoch: 196 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :253
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.282500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 253 is 1.395223
INFO:root:FL Epoch: 196 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1499
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816612
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379033
INFO:root:FL Epoch: 196 Norm Difference for worker 1499 is 1.439992
INFO:root:FL Epoch: 196 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :830
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389173
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442568
INFO:root:FL Epoch: 196 Norm Difference for worker 830 is 1.209671
INFO:root:FL Epoch: 196 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1654
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471384
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571479
INFO:root:FL Epoch: 196 Norm Difference for worker 1654 is 1.47299
INFO:root:FL Epoch: 196 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1787
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662687
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517077
INFO:root:FL Epoch: 196 Norm Difference for worker 1787 is 1.389809
INFO:root:FL Epoch: 196 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.5092510826447431 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:1.697602927684784                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1309, 1133, 1254, 1673, 364, 1942, 685, 1660, 1463, 436]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1309
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443214
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440447
INFO:root:FL Epoch: 197 Norm Difference for worker 1309 is 1.101517
INFO:root:FL Epoch: 197 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1133
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516505
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543330
INFO:root:FL Epoch: 197 Norm Difference for worker 1133 is 1.275782
INFO:root:FL Epoch: 197 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1254
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705002
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465061
INFO:root:FL Epoch: 197 Norm Difference for worker 1254 is 1.201068
INFO:root:FL Epoch: 197 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1673
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 1.118812
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670699
INFO:root:FL Epoch: 197 Norm Difference for worker 1673 is 1.213414
INFO:root:FL Epoch: 197 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :364
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567020
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531185
INFO:root:FL Epoch: 197 Norm Difference for worker 364 is 1.18747
INFO:root:FL Epoch: 197 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1942
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663862
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371774
INFO:root:FL Epoch: 197 Norm Difference for worker 1942 is 1.223038
INFO:root:FL Epoch: 197 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :685
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473842
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477430
INFO:root:FL Epoch: 197 Norm Difference for worker 685 is 1.16128
INFO:root:FL Epoch: 197 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1660
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409618
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290366
INFO:root:FL Epoch: 197 Norm Difference for worker 1660 is 1.146665
INFO:root:FL Epoch: 197 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1463
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543179
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507281
INFO:root:FL Epoch: 197 Norm Difference for worker 1463 is 1.309377
INFO:root:FL Epoch: 197 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :436
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588773
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596455
INFO:root:FL Epoch: 197 Norm Difference for worker 436 is 1.199779
INFO:root:FL Epoch: 197 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1309
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.5102401516016792 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:1.453972319761912                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [842, 787, 125, 204, 231, 293, 419, 770, 397, 1052]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 201 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :842
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597161
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538133
INFO:root:FL Epoch: 198 Norm Difference for worker 842 is 1.127755
INFO:root:FL Epoch: 198 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :787
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833630
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476312
INFO:root:FL Epoch: 198 Norm Difference for worker 787 is 1.111111
INFO:root:FL Epoch: 198 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :125
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 125 is 1.134298
INFO:root:FL Epoch: 198 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :204
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748047
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.760961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 204 is 1.171785
INFO:root:FL Epoch: 198 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :231
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.279803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 231 is 0.938857
INFO:root:FL Epoch: 198 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :293
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 293 is 1.021789
INFO:root:FL Epoch: 198 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :419
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527522
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484137
INFO:root:FL Epoch: 198 Norm Difference for worker 419 is 0.940214
INFO:root:FL Epoch: 198 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :770
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548742
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617053
INFO:root:FL Epoch: 198 Norm Difference for worker 770 is 1.084732
INFO:root:FL Epoch: 198 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :397
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889917
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546614
INFO:root:FL Epoch: 198 Norm Difference for worker 397 is 1.124718
INFO:root:FL Epoch: 198 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1052
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673549
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533330
INFO:root:FL Epoch: 198 Norm Difference for worker 1052 is 1.063058
INFO:root:FL Epoch: 198 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.5065143467748866 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:1.8240975538889568                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [913, 870, 912, 1774, 844, 1428, 1445, 1451, 881, 1753]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 199 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :913
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727118
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535911
INFO:root:FL Epoch: 199 Norm Difference for worker 913 is 1.480311
INFO:root:FL Epoch: 199 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :870
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.995396
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516141
INFO:root:FL Epoch: 199 Norm Difference for worker 870 is 1.466901
INFO:root:FL Epoch: 199 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :912
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683347
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391887
INFO:root:FL Epoch: 199 Norm Difference for worker 912 is 1.350561
INFO:root:FL Epoch: 199 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1774
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504831
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548337
INFO:root:FL Epoch: 199 Norm Difference for worker 1774 is 1.173204
INFO:root:FL Epoch: 199 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :844
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754014
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583238
INFO:root:FL Epoch: 199 Norm Difference for worker 844 is 1.24999
INFO:root:FL Epoch: 199 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1428
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 1.009484
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528853
INFO:root:FL Epoch: 199 Norm Difference for worker 1428 is 1.401133
INFO:root:FL Epoch: 199 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1445
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655971
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438793
INFO:root:FL Epoch: 199 Norm Difference for worker 1445 is 1.398306
INFO:root:FL Epoch: 199 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1451
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289411
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324667
INFO:root:FL Epoch: 199 Norm Difference for worker 1451 is 1.252919
INFO:root:FL Epoch: 199 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :881
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.158284
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159891
INFO:root:FL Epoch: 199 Norm Difference for worker 881 is 0.881189
INFO:root:FL Epoch: 199 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1753
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723042
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229344
INFO:root:FL Epoch: 199 Norm Difference for worker 1753 is 1.126947
INFO:root:FL Epoch: 199 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.5366672864731621 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:2.4730542500813804                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [819, 826, 1484, 701, 1698, 763, 1089, 214, 1866, 1460]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :819
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661786
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680637
INFO:root:FL Epoch: 200 Norm Difference for worker 819 is 1.573824
INFO:root:FL Epoch: 200 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :826
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366420
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335789
INFO:root:FL Epoch: 200 Norm Difference for worker 826 is 1.665559
INFO:root:FL Epoch: 200 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1484
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621173
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.752150
INFO:root:FL Epoch: 200 Norm Difference for worker 1484 is 1.575552
INFO:root:FL Epoch: 200 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :701
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521494
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427358
INFO:root:FL Epoch: 200 Norm Difference for worker 701 is 1.582772
INFO:root:FL Epoch: 200 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1698
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450548
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516476
INFO:root:FL Epoch: 200 Norm Difference for worker 1698 is 1.657621
INFO:root:FL Epoch: 200 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :763
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334756
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594948
INFO:root:FL Epoch: 200 Norm Difference for worker 763 is 1.615335
INFO:root:FL Epoch: 200 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1089
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.975237
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534573
INFO:root:FL Epoch: 200 Norm Difference for worker 1089 is 1.518469
INFO:root:FL Epoch: 200 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :214
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 214 is 1.699733
INFO:root:FL Epoch: 200 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1866
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497162
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452654
INFO:root:FL Epoch: 200 Norm Difference for worker 1866 is 1.568291
INFO:root:FL Epoch: 200 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1460
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700951
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396989
INFO:root:FL Epoch: 200 Norm Difference for worker 1460 is 1.525329
INFO:root:FL Epoch: 200 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:FL Epoch: 200 Saving Checkpoint at this epoch.
INFO:root:FL Epoch: 200 Saved Checkpoint at this epoch.
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.49332811376627755 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:1.559895932674408                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 430, 1591, 1204, 550, 1376, 13, 1342, 989, 1929]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.075866
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490953
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.19011705368757248 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.32082020938396455 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 1.781576
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :430
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412106
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533393
INFO:root:FL Epoch: 201 Norm Difference for worker 430 is 1.158291
INFO:root:FL Epoch: 201 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1591
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500595
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333507
INFO:root:FL Epoch: 201 Norm Difference for worker 1591 is 1.072103
INFO:root:FL Epoch: 201 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1204
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548303
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530369
INFO:root:FL Epoch: 201 Norm Difference for worker 1204 is 1.223395
INFO:root:FL Epoch: 201 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :550
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645561
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480849
INFO:root:FL Epoch: 201 Norm Difference for worker 550 is 1.160758
INFO:root:FL Epoch: 201 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1376
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534069
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349732
INFO:root:FL Epoch: 201 Norm Difference for worker 1376 is 1.135691
INFO:root:FL Epoch: 201 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :13
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 13 is 1.168113
INFO:root:FL Epoch: 201 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1342
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878825
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469734
INFO:root:FL Epoch: 201 Norm Difference for worker 1342 is 1.104035
INFO:root:FL Epoch: 201 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :989
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731662
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484901
INFO:root:FL Epoch: 201 Norm Difference for worker 989 is 1.084521
INFO:root:FL Epoch: 201 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1929
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346926
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491921
INFO:root:FL Epoch: 201 Norm Difference for worker 1929 is 1.062099
INFO:root:FL Epoch: 201 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 989
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.497665953986785 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:1.4467748204867046                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [228, 63, 1185, 217, 46, 1390, 1242, 1500, 222, 1611]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.10024938 0.10024938 0.09975062
 0.09975062 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 202 Num points on workers: [201 201 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :228
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 228 is 0.993352
INFO:root:FL Epoch: 202 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :63
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.563729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 63 is 1.029025
INFO:root:FL Epoch: 202 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1185
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452341
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687746
INFO:root:FL Epoch: 202 Norm Difference for worker 1185 is 1.034387
INFO:root:FL Epoch: 202 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :217
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697650
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 217 is 0.993465
INFO:root:FL Epoch: 202 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :46
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 46 is 0.997626
INFO:root:FL Epoch: 202 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1390
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414483
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260963
INFO:root:FL Epoch: 202 Norm Difference for worker 1390 is 0.957492
INFO:root:FL Epoch: 202 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1242
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695905
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669222
INFO:root:FL Epoch: 202 Norm Difference for worker 1242 is 1.002623
INFO:root:FL Epoch: 202 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1500
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616672
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484405
INFO:root:FL Epoch: 202 Norm Difference for worker 1500 is 0.952326
INFO:root:FL Epoch: 202 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :222
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.360747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 222 is 1.009524
INFO:root:FL Epoch: 202 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1611
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401581
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396599
INFO:root:FL Epoch: 202 Norm Difference for worker 1611 is 0.994002
INFO:root:FL Epoch: 202 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1500
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.4913773554212907 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:1.409212330977122                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1931, 1445, 1591, 1204, 659, 1551, 1020, 143, 496, 149]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1931
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433486
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438605
INFO:root:FL Epoch: 203 Norm Difference for worker 1931 is 0.955197
INFO:root:FL Epoch: 203 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1445
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694382
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443738
INFO:root:FL Epoch: 203 Norm Difference for worker 1445 is 0.988262
INFO:root:FL Epoch: 203 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1591
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538349
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425829
INFO:root:FL Epoch: 203 Norm Difference for worker 1591 is 0.928402
INFO:root:FL Epoch: 203 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1204
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801002
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.834988
INFO:root:FL Epoch: 203 Norm Difference for worker 1204 is 1.048938
INFO:root:FL Epoch: 203 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :659
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615203
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.826935
INFO:root:FL Epoch: 203 Norm Difference for worker 659 is 1.018724
INFO:root:FL Epoch: 203 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1551
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713540
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469203
INFO:root:FL Epoch: 203 Norm Difference for worker 1551 is 0.938741
INFO:root:FL Epoch: 203 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1020
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465026
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437023
INFO:root:FL Epoch: 203 Norm Difference for worker 1020 is 0.984253
INFO:root:FL Epoch: 203 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :143
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 143 is 0.998871
INFO:root:FL Epoch: 203 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :496
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648699
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359469
INFO:root:FL Epoch: 203 Norm Difference for worker 496 is 0.878988
INFO:root:FL Epoch: 203 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :149
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487266
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 149 is 0.989575
INFO:root:FL Epoch: 203 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 496
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.4886428257998298 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:1.774297058582306                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [1199, 1247, 793, 1840, 1242, 1130, 355, 1325, 417, 66]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :1199
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568440
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621173
INFO:root:FL Epoch: 204 Norm Difference for worker 1199 is 1.029704
INFO:root:FL Epoch: 204 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1247
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644354
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738424
INFO:root:FL Epoch: 204 Norm Difference for worker 1247 is 1.099563
INFO:root:FL Epoch: 204 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :793
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683831
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413175
INFO:root:FL Epoch: 204 Norm Difference for worker 793 is 1.036232
INFO:root:FL Epoch: 204 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1840
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651247
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578719
INFO:root:FL Epoch: 204 Norm Difference for worker 1840 is 1.122706
INFO:root:FL Epoch: 204 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1242
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818617
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383540
INFO:root:FL Epoch: 204 Norm Difference for worker 1242 is 1.006516
INFO:root:FL Epoch: 204 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1130
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485797
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463310
INFO:root:FL Epoch: 204 Norm Difference for worker 1130 is 1.223362
INFO:root:FL Epoch: 204 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :355
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475279
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571725
INFO:root:FL Epoch: 204 Norm Difference for worker 355 is 1.084847
INFO:root:FL Epoch: 204 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1325
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825044
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435189
INFO:root:FL Epoch: 204 Norm Difference for worker 1325 is 1.16525
INFO:root:FL Epoch: 204 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :417
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573917
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558169
INFO:root:FL Epoch: 204 Norm Difference for worker 417 is 1.021349
INFO:root:FL Epoch: 204 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :66
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405525
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 66 is 1.007577
INFO:root:FL Epoch: 204 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1242
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.49298345166094165 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:1.369807283083598                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1885, 524, 171, 743, 3, 1407, 231, 431, 57, 1021]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 205 Num points on workers: [200 200 201 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1885
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524982
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595607
INFO:root:FL Epoch: 205 Norm Difference for worker 1885 is 0.97389
INFO:root:FL Epoch: 205 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :524
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342445
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495037
INFO:root:FL Epoch: 205 Norm Difference for worker 524 is 0.945804
INFO:root:FL Epoch: 205 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 171 is 0.954958
INFO:root:FL Epoch: 205 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :743
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416452
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511491
INFO:root:FL Epoch: 205 Norm Difference for worker 743 is 0.974574
INFO:root:FL Epoch: 205 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :3
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 3 is 1.020998
INFO:root:FL Epoch: 205 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1407
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456542
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416981
INFO:root:FL Epoch: 205 Norm Difference for worker 1407 is 1.037846
INFO:root:FL Epoch: 205 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :231
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.244712
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 231 is 0.902478
INFO:root:FL Epoch: 205 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :431
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540508
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417215
INFO:root:FL Epoch: 205 Norm Difference for worker 431 is 0.996063
INFO:root:FL Epoch: 205 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :57
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388759
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359296
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 57 is 0.943529
INFO:root:FL Epoch: 205 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1021
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500499
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500115
INFO:root:FL Epoch: 205 Norm Difference for worker 1021 is 0.900297
INFO:root:FL Epoch: 205 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.5057184845209122 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:1.8351661960283916                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [982, 838, 1325, 1699, 1536, 1723, 1578, 459, 1517, 555]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 206 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :982
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496375
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391470
INFO:root:FL Epoch: 206 Norm Difference for worker 982 is 1.424704
INFO:root:FL Epoch: 206 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 1.434985
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379974
INFO:root:FL Epoch: 206 Norm Difference for worker 838 is 1.363637
INFO:root:FL Epoch: 206 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1325
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689755
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615218
INFO:root:FL Epoch: 206 Norm Difference for worker 1325 is 1.513594
INFO:root:FL Epoch: 206 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1699
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1699 Train Epoch: 0 [0/200 (0%)]	Loss: 1.132991
INFO:root:Worker: 1699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375219
INFO:root:FL Epoch: 206 Norm Difference for worker 1699 is 1.528994
INFO:root:FL Epoch: 206 Done on worker:1699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1536
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420584
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258525
INFO:root:FL Epoch: 206 Norm Difference for worker 1536 is 1.422365
INFO:root:FL Epoch: 206 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1723
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637784
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389469
INFO:root:FL Epoch: 206 Norm Difference for worker 1723 is 1.335254
INFO:root:FL Epoch: 206 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1578
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565296
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430136
INFO:root:FL Epoch: 206 Norm Difference for worker 1578 is 1.13294
INFO:root:FL Epoch: 206 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :459
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623569
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415263
INFO:root:FL Epoch: 206 Norm Difference for worker 459 is 1.404463
INFO:root:FL Epoch: 206 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1517
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937010
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457019
INFO:root:FL Epoch: 206 Norm Difference for worker 1517 is 1.426354
INFO:root:FL Epoch: 206 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :555
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795091
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419045
INFO:root:FL Epoch: 206 Norm Difference for worker 555 is 1.320444
INFO:root:FL Epoch: 206 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5130903089747709 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:1.7564587593078613                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1024, 1479, 1906, 856, 1319, 693, 140, 527, 1531, 394]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1024
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737468
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539443
INFO:root:FL Epoch: 207 Norm Difference for worker 1024 is 1.228513
INFO:root:FL Epoch: 207 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1479
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332192
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499798
INFO:root:FL Epoch: 207 Norm Difference for worker 1479 is 1.289557
INFO:root:FL Epoch: 207 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1906
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228698
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305994
INFO:root:FL Epoch: 207 Norm Difference for worker 1906 is 1.155764
INFO:root:FL Epoch: 207 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :856
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.891005
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460684
INFO:root:FL Epoch: 207 Norm Difference for worker 856 is 1.413615
INFO:root:FL Epoch: 207 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1319
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633568
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.850221
INFO:root:FL Epoch: 207 Norm Difference for worker 1319 is 1.335404
INFO:root:FL Epoch: 207 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :693
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481898
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553339
INFO:root:FL Epoch: 207 Norm Difference for worker 693 is 1.176486
INFO:root:FL Epoch: 207 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :140
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483036
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 140 is 1.217413
INFO:root:FL Epoch: 207 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :527
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571364
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611608
INFO:root:FL Epoch: 207 Norm Difference for worker 527 is 1.26142
INFO:root:FL Epoch: 207 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1531
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660638
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629597
INFO:root:FL Epoch: 207 Norm Difference for worker 1531 is 1.325103
INFO:root:FL Epoch: 207 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :394
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662804
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401335
INFO:root:FL Epoch: 207 Norm Difference for worker 394 is 1.317169
INFO:root:FL Epoch: 207 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.5184269196846906 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:1.603890875975291                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1071, 265, 40, 783, 244, 310, 1634, 1042, 1666, 462]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 208 Num points on workers: [200 201 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1071
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779450
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611771
INFO:root:FL Epoch: 208 Norm Difference for worker 1071 is 1.137962
INFO:root:FL Epoch: 208 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :265
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.801571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 265 is 1.155574
INFO:root:FL Epoch: 208 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :40
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 40 is 1.147514
INFO:root:FL Epoch: 208 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :783
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870658
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646961
INFO:root:FL Epoch: 208 Norm Difference for worker 783 is 1.110258
INFO:root:FL Epoch: 208 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :244
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 244 is 1.023472
INFO:root:FL Epoch: 208 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :310
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609320
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568835
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 310 is 1.079021
INFO:root:FL Epoch: 208 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1634
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769955
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479409
INFO:root:FL Epoch: 208 Norm Difference for worker 1634 is 1.160913
INFO:root:FL Epoch: 208 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1042
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743683
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306992
INFO:root:FL Epoch: 208 Norm Difference for worker 1042 is 1.08711
INFO:root:FL Epoch: 208 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1666
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638297
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609876
INFO:root:FL Epoch: 208 Norm Difference for worker 1666 is 1.073585
INFO:root:FL Epoch: 208 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :462
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661866
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548028
INFO:root:FL Epoch: 208 Norm Difference for worker 462 is 1.174172
INFO:root:FL Epoch: 208 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 244
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.516201913356781 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:1.5254147052764893                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [307, 20, 991, 110, 278, 1633, 1786, 701, 1348, 329]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.10024938 0.10024938 0.09975062
 0.09975062 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 209 Num points on workers: [201 201 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :307
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598484
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 307 is 1.128953
INFO:root:FL Epoch: 209 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :20
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 20 is 1.095848
INFO:root:FL Epoch: 209 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :991
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566173
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438415
INFO:root:FL Epoch: 209 Norm Difference for worker 991 is 1.078465
INFO:root:FL Epoch: 209 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :110
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407735
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364324
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 110 is 1.111555
INFO:root:FL Epoch: 209 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :278
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.788940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.651866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 278 is 1.150852
INFO:root:FL Epoch: 209 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1633
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679565
INFO:root:Worker: 1633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609889
INFO:root:FL Epoch: 209 Norm Difference for worker 1633 is 1.094267
INFO:root:FL Epoch: 209 Done on worker:1633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1786
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429981
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395030
INFO:root:FL Epoch: 209 Norm Difference for worker 1786 is 1.149191
INFO:root:FL Epoch: 209 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :701
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576107
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564902
INFO:root:FL Epoch: 209 Norm Difference for worker 701 is 1.110746
INFO:root:FL Epoch: 209 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1348
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846213
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272837
INFO:root:FL Epoch: 209 Norm Difference for worker 1348 is 1.057743
INFO:root:FL Epoch: 209 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :329
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617964
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 329 is 1.00061
INFO:root:FL Epoch: 209 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 329
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5287414315868827 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:1.7758200764656067                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [1204, 154, 1655, 1760, 595, 999, 1871, 200, 248, 1641]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 210 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :1204
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512231
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405244
INFO:root:FL Epoch: 210 Norm Difference for worker 1204 is 1.185677
INFO:root:FL Epoch: 210 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :154
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624309
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 154 is 1.14413
INFO:root:FL Epoch: 210 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1655
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644531
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423330
INFO:root:FL Epoch: 210 Norm Difference for worker 1655 is 1.20486
INFO:root:FL Epoch: 210 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429289
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541194
INFO:root:FL Epoch: 210 Norm Difference for worker 1760 is 1.283287
INFO:root:FL Epoch: 210 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :595
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670523
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559729
INFO:root:FL Epoch: 210 Norm Difference for worker 595 is 1.172095
INFO:root:FL Epoch: 210 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :999
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557806
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284206
INFO:root:FL Epoch: 210 Norm Difference for worker 999 is 1.169188
INFO:root:FL Epoch: 210 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1871
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711571
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272774
INFO:root:FL Epoch: 210 Norm Difference for worker 1871 is 1.254863
INFO:root:FL Epoch: 210 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :200
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 200 is 1.166761
INFO:root:FL Epoch: 210 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :248
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.779822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 248 is 1.105999
INFO:root:FL Epoch: 210 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1641
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663309
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386499
INFO:root:FL Epoch: 210 Norm Difference for worker 1641 is 1.16905
INFO:root:FL Epoch: 210 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 248
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.521051790784387 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:1.6559844613075256                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 153, 580, 204, 80, 531, 769, 399, 1316, 923]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 211 Num points on workers: [200 201 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859939
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366572
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.24411449333031973 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.36509045362472536 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 1.738404
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :153
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.280582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 153 is 0.920745
INFO:root:FL Epoch: 211 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :580
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518470
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449228
INFO:root:FL Epoch: 211 Norm Difference for worker 580 is 1.008
INFO:root:FL Epoch: 211 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :204
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535836
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.708717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 204 is 1.017398
INFO:root:FL Epoch: 211 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :80
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 80 is 0.939415
INFO:root:FL Epoch: 211 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :531
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552653
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520054
INFO:root:FL Epoch: 211 Norm Difference for worker 531 is 0.935375
INFO:root:FL Epoch: 211 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :769
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602755
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609266
INFO:root:FL Epoch: 211 Norm Difference for worker 769 is 1.034859
INFO:root:FL Epoch: 211 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :399
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624361
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322640
INFO:root:FL Epoch: 211 Norm Difference for worker 399 is 1.00413
INFO:root:FL Epoch: 211 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1316
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499437
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551649
INFO:root:FL Epoch: 211 Norm Difference for worker 1316 is 0.945638
INFO:root:FL Epoch: 211 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :923
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588105
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346987
INFO:root:FL Epoch: 211 Norm Difference for worker 923 is 0.957215
INFO:root:FL Epoch: 211 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 153
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5200645976206836 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:1.487466295560201                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [806, 758, 1499, 509, 448, 1242, 1500, 1347, 1376, 1643]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :806
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540795
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542601
INFO:root:FL Epoch: 212 Norm Difference for worker 806 is 0.89875
INFO:root:FL Epoch: 212 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :758
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538073
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526991
INFO:root:FL Epoch: 212 Norm Difference for worker 758 is 0.868393
INFO:root:FL Epoch: 212 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1499
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571876
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510568
INFO:root:FL Epoch: 212 Norm Difference for worker 1499 is 0.912448
INFO:root:FL Epoch: 212 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :509
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651643
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364458
INFO:root:FL Epoch: 212 Norm Difference for worker 509 is 0.93493
INFO:root:FL Epoch: 212 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :448
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503055
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594346
INFO:root:FL Epoch: 212 Norm Difference for worker 448 is 0.86219
INFO:root:FL Epoch: 212 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1242
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352910
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348713
INFO:root:FL Epoch: 212 Norm Difference for worker 1242 is 0.889357
INFO:root:FL Epoch: 212 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1500
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501822
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436739
INFO:root:FL Epoch: 212 Norm Difference for worker 1500 is 0.878879
INFO:root:FL Epoch: 212 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1347
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694599
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613890
INFO:root:FL Epoch: 212 Norm Difference for worker 1347 is 0.972223
INFO:root:FL Epoch: 212 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1376
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585033
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439945
INFO:root:FL Epoch: 212 Norm Difference for worker 1376 is 0.918696
INFO:root:FL Epoch: 212 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1643
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582805
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431047
INFO:root:FL Epoch: 212 Norm Difference for worker 1643 is 0.934229
INFO:root:FL Epoch: 212 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1500
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.5057261533596936 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:1.856714169184367                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [246, 1067, 718, 1531, 146, 179, 1881, 1016, 1818, 1901]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 213 Num points on workers: [201 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :246
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.731362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 246 is 1.150712
INFO:root:FL Epoch: 213 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1067
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582760
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700694
INFO:root:FL Epoch: 213 Norm Difference for worker 1067 is 1.203561
INFO:root:FL Epoch: 213 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :718
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790476
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365302
INFO:root:FL Epoch: 213 Norm Difference for worker 718 is 1.092618
INFO:root:FL Epoch: 213 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1531
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564352
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657134
INFO:root:FL Epoch: 213 Norm Difference for worker 1531 is 1.18682
INFO:root:FL Epoch: 213 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :146
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 146 is 1.211989
INFO:root:FL Epoch: 213 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :179
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466676
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 179 is 1.176949
INFO:root:FL Epoch: 213 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1881
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469555
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333104
INFO:root:FL Epoch: 213 Norm Difference for worker 1881 is 1.049141
INFO:root:FL Epoch: 213 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1016
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522300
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585430
INFO:root:FL Epoch: 213 Norm Difference for worker 1016 is 1.165283
INFO:root:FL Epoch: 213 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1818
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383510
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459133
INFO:root:FL Epoch: 213 Norm Difference for worker 1818 is 1.130519
INFO:root:FL Epoch: 213 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1901
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745196
INFO:root:Worker: 1901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627352
INFO:root:FL Epoch: 213 Norm Difference for worker 1901 is 1.111737
INFO:root:FL Epoch: 213 Done on worker:1901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1881
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5035590809934279 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:1.664459486802419                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1193, 52, 1029, 1165, 652, 79, 223, 1090, 625, 1403]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 214 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1193
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541068
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479874
INFO:root:FL Epoch: 214 Norm Difference for worker 1193 is 1.067099
INFO:root:FL Epoch: 214 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :52
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363510
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 52 is 1.070522
INFO:root:FL Epoch: 214 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1029
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682154
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450755
INFO:root:FL Epoch: 214 Norm Difference for worker 1029 is 1.057359
INFO:root:FL Epoch: 214 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1165
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528001
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562441
INFO:root:FL Epoch: 214 Norm Difference for worker 1165 is 1.056951
INFO:root:FL Epoch: 214 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :652
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580286
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371176
INFO:root:FL Epoch: 214 Norm Difference for worker 652 is 1.025193
INFO:root:FL Epoch: 214 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :79
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 79 is 0.965077
INFO:root:FL Epoch: 214 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :223
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 223 is 1.025913
INFO:root:FL Epoch: 214 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1090
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507184
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684688
INFO:root:FL Epoch: 214 Norm Difference for worker 1090 is 1.062924
INFO:root:FL Epoch: 214 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :625
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391620
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631659
INFO:root:FL Epoch: 214 Norm Difference for worker 625 is 0.989547
INFO:root:FL Epoch: 214 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1403
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483872
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570134
INFO:root:FL Epoch: 214 Norm Difference for worker 1403 is 0.991195
INFO:root:FL Epoch: 214 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1403
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5153007191770217 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:1.4693072438240051                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [545, 1605, 1807, 1863, 325, 1338, 1902, 352, 1473, 926]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :545
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669774
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582992
INFO:root:FL Epoch: 215 Norm Difference for worker 545 is 0.8609
INFO:root:FL Epoch: 215 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1605
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614159
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541348
INFO:root:FL Epoch: 215 Norm Difference for worker 1605 is 0.884597
INFO:root:FL Epoch: 215 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1807
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567342
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447311
INFO:root:FL Epoch: 215 Norm Difference for worker 1807 is 0.902001
INFO:root:FL Epoch: 215 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1863
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498834
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487760
INFO:root:FL Epoch: 215 Norm Difference for worker 1863 is 0.895386
INFO:root:FL Epoch: 215 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :325
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 325 is 0.922825
INFO:root:FL Epoch: 215 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1338
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594473
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465465
INFO:root:FL Epoch: 215 Norm Difference for worker 1338 is 0.882416
INFO:root:FL Epoch: 215 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1902
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399006
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394189
INFO:root:FL Epoch: 215 Norm Difference for worker 1902 is 0.848689
INFO:root:FL Epoch: 215 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :352
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634698
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534504
INFO:root:FL Epoch: 215 Norm Difference for worker 352 is 0.878512
INFO:root:FL Epoch: 215 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1473
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572200
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617233
INFO:root:FL Epoch: 215 Norm Difference for worker 1473 is 0.937604
INFO:root:FL Epoch: 215 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :926
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492488
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550990
INFO:root:FL Epoch: 215 Norm Difference for worker 926 is 0.862908
INFO:root:FL Epoch: 215 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1902
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5031386175576378 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:1.5143356919288635                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [5, 177, 1455, 536, 1109, 460, 844, 1487, 620, 1413]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 216 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :5
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 5 is 0.951472
INFO:root:FL Epoch: 216 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :177
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487946
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 177 is 0.926979
INFO:root:FL Epoch: 216 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1455
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432407
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439677
INFO:root:FL Epoch: 216 Norm Difference for worker 1455 is 0.972617
INFO:root:FL Epoch: 216 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :536
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638351
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492716
INFO:root:FL Epoch: 216 Norm Difference for worker 536 is 0.938446
INFO:root:FL Epoch: 216 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1109
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414449
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482351
INFO:root:FL Epoch: 216 Norm Difference for worker 1109 is 0.980731
INFO:root:FL Epoch: 216 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :460
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527988
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571051
INFO:root:FL Epoch: 216 Norm Difference for worker 460 is 0.959773
INFO:root:FL Epoch: 216 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :844
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411556
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545074
INFO:root:FL Epoch: 216 Norm Difference for worker 844 is 0.912043
INFO:root:FL Epoch: 216 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1487
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445769
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468806
INFO:root:FL Epoch: 216 Norm Difference for worker 1487 is 0.974269
INFO:root:FL Epoch: 216 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :620
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625504
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507168
INFO:root:FL Epoch: 216 Norm Difference for worker 620 is 0.907638
INFO:root:FL Epoch: 216 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1413
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652034
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530523
INFO:root:FL Epoch: 216 Norm Difference for worker 1413 is 0.915638
INFO:root:FL Epoch: 216 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.5134205695460824 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:1.6643596291542053                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [443, 449, 385, 1602, 764, 1149, 1077, 381, 1067, 5]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :443
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560574
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565184
INFO:root:FL Epoch: 217 Norm Difference for worker 443 is 0.955648
INFO:root:FL Epoch: 217 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :449
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664794
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478942
INFO:root:FL Epoch: 217 Norm Difference for worker 449 is 0.922526
INFO:root:FL Epoch: 217 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :385
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540870
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666761
INFO:root:FL Epoch: 217 Norm Difference for worker 385 is 0.959464
INFO:root:FL Epoch: 217 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1602
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581613
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450498
INFO:root:FL Epoch: 217 Norm Difference for worker 1602 is 0.944666
INFO:root:FL Epoch: 217 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :764
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601042
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551891
INFO:root:FL Epoch: 217 Norm Difference for worker 764 is 0.88404
INFO:root:FL Epoch: 217 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1149
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456777
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489409
INFO:root:FL Epoch: 217 Norm Difference for worker 1149 is 0.950073
INFO:root:FL Epoch: 217 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1077
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494089
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347901
INFO:root:FL Epoch: 217 Norm Difference for worker 1077 is 0.955563
INFO:root:FL Epoch: 217 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :381
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549634
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291080
INFO:root:FL Epoch: 217 Norm Difference for worker 381 is 0.925745
INFO:root:FL Epoch: 217 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1067
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750099
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478695
INFO:root:FL Epoch: 217 Norm Difference for worker 1067 is 0.937709
INFO:root:FL Epoch: 217 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :5
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 5 is 0.928629
INFO:root:FL Epoch: 217 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 764
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.5161376875989577 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:1.9044817487398784                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1206, 1292, 1674, 942, 925, 757, 820, 216, 898, 1576]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 218 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1206
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568976
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458968
INFO:root:FL Epoch: 218 Norm Difference for worker 1206 is 0.90095
INFO:root:FL Epoch: 218 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1292
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630940
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486171
INFO:root:FL Epoch: 218 Norm Difference for worker 1292 is 0.949564
INFO:root:FL Epoch: 218 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1674
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380341
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473695
INFO:root:FL Epoch: 218 Norm Difference for worker 1674 is 0.906612
INFO:root:FL Epoch: 218 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :942
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787299
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621984
INFO:root:FL Epoch: 218 Norm Difference for worker 942 is 0.957371
INFO:root:FL Epoch: 218 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :925
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465945
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397468
INFO:root:FL Epoch: 218 Norm Difference for worker 925 is 0.876895
INFO:root:FL Epoch: 218 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :757
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516123
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526851
INFO:root:FL Epoch: 218 Norm Difference for worker 757 is 0.909543
INFO:root:FL Epoch: 218 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :820
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680728
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478546
INFO:root:FL Epoch: 218 Norm Difference for worker 820 is 0.909285
INFO:root:FL Epoch: 218 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :216
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 216 is 0.979541
INFO:root:FL Epoch: 218 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :898
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490998
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490956
INFO:root:FL Epoch: 218 Norm Difference for worker 898 is 0.932038
INFO:root:FL Epoch: 218 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1576
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774223
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602002
INFO:root:FL Epoch: 218 Norm Difference for worker 1576 is 0.913104
INFO:root:FL Epoch: 218 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1206
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.5031597386388218 and Test Accuracy:75.0 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:2.1566081047058105                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [1667, 119, 810, 493, 1696, 180, 766, 1036, 836, 477]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 219 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :1667
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298468
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515702
INFO:root:FL Epoch: 219 Norm Difference for worker 1667 is 1.01559
INFO:root:FL Epoch: 219 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :119
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470110
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 119 is 1.083753
INFO:root:FL Epoch: 219 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :810
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711846
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508603
INFO:root:FL Epoch: 219 Norm Difference for worker 810 is 1.133058
INFO:root:FL Epoch: 219 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :493
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459346
INFO:root:Worker: 493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575727
INFO:root:FL Epoch: 219 Norm Difference for worker 493 is 1.120778
INFO:root:FL Epoch: 219 Done on worker:493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1696
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290367
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281041
INFO:root:FL Epoch: 219 Norm Difference for worker 1696 is 1.016677
INFO:root:FL Epoch: 219 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :180
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 180 is 1.040171
INFO:root:FL Epoch: 219 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :766
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439175
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395282
INFO:root:FL Epoch: 219 Norm Difference for worker 766 is 1.065294
INFO:root:FL Epoch: 219 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1036
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680134
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517352
INFO:root:FL Epoch: 219 Norm Difference for worker 1036 is 1.097359
INFO:root:FL Epoch: 219 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :836
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612226
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428484
INFO:root:FL Epoch: 219 Norm Difference for worker 836 is 1.113665
INFO:root:FL Epoch: 219 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315751
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436856
INFO:root:FL Epoch: 219 Norm Difference for worker 477 is 1.035329
INFO:root:FL Epoch: 219 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 477
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.5094282960190493 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:2.179142872492472                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [983, 828, 933, 37, 1000, 793, 879, 504, 458, 1665]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :983
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.927197
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418475
INFO:root:FL Epoch: 220 Norm Difference for worker 983 is 1.075998
INFO:root:FL Epoch: 220 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :828
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682512
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496365
INFO:root:FL Epoch: 220 Norm Difference for worker 828 is 1.183372
INFO:root:FL Epoch: 220 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :933
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644927
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485047
INFO:root:FL Epoch: 220 Norm Difference for worker 933 is 1.048375
INFO:root:FL Epoch: 220 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :37
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632630
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 37 is 1.030023
INFO:root:FL Epoch: 220 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1000
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732107
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486305
INFO:root:FL Epoch: 220 Norm Difference for worker 1000 is 1.071319
INFO:root:FL Epoch: 220 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :793
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592602
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443658
INFO:root:FL Epoch: 220 Norm Difference for worker 793 is 1.045136
INFO:root:FL Epoch: 220 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :879
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739073
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447423
INFO:root:FL Epoch: 220 Norm Difference for worker 879 is 0.994291
INFO:root:FL Epoch: 220 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :504
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641979
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654498
INFO:root:FL Epoch: 220 Norm Difference for worker 504 is 1.036138
INFO:root:FL Epoch: 220 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :458
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389693
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452099
INFO:root:FL Epoch: 220 Norm Difference for worker 458 is 1.069032
INFO:root:FL Epoch: 220 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1665
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450850
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450467
INFO:root:FL Epoch: 220 Norm Difference for worker 1665 is 1.054983
INFO:root:FL Epoch: 220 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 879
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.4981357507845935 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:2.0076207915941873                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1618, 1494, 1021, 910, 591, 1561, 1638, 1423, 1772]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.051422
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582924
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.253851093351841 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.36734760403633115 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 1.729167
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1618
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554752
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480818
INFO:root:FL Epoch: 221 Norm Difference for worker 1618 is 0.941671
INFO:root:FL Epoch: 221 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1494
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443397
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465170
INFO:root:FL Epoch: 221 Norm Difference for worker 1494 is 0.989053
INFO:root:FL Epoch: 221 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1021
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654982
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409820
INFO:root:FL Epoch: 221 Norm Difference for worker 1021 is 0.964455
INFO:root:FL Epoch: 221 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :910
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418304
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361266
INFO:root:FL Epoch: 221 Norm Difference for worker 910 is 1.028949
INFO:root:FL Epoch: 221 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :591
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877159
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481236
INFO:root:FL Epoch: 221 Norm Difference for worker 591 is 1.035365
INFO:root:FL Epoch: 221 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1561
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407050
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528227
INFO:root:FL Epoch: 221 Norm Difference for worker 1561 is 0.98845
INFO:root:FL Epoch: 221 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1638
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492889
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326200
INFO:root:FL Epoch: 221 Norm Difference for worker 1638 is 0.997622
INFO:root:FL Epoch: 221 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1423
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640046
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484996
INFO:root:FL Epoch: 221 Norm Difference for worker 1423 is 0.982461
INFO:root:FL Epoch: 221 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1772
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451864
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730560
INFO:root:FL Epoch: 221 Norm Difference for worker 1772 is 0.958165
INFO:root:FL Epoch: 221 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1618
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.5032716130509096 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:2.1032568216323853                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [470, 797, 198, 456, 966, 100, 371, 847, 1564, 804]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :470
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802100
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533697
INFO:root:FL Epoch: 222 Norm Difference for worker 470 is 1.01647
INFO:root:FL Epoch: 222 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :797
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856112
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437655
INFO:root:FL Epoch: 222 Norm Difference for worker 797 is 1.044252
INFO:root:FL Epoch: 222 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :198
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 198 is 1.075738
INFO:root:FL Epoch: 222 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :456
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529569
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398885
INFO:root:FL Epoch: 222 Norm Difference for worker 456 is 1.013194
INFO:root:FL Epoch: 222 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :966
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448744
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268052
INFO:root:FL Epoch: 222 Norm Difference for worker 966 is 0.994396
INFO:root:FL Epoch: 222 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :100
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 100 is 0.952361
INFO:root:FL Epoch: 222 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :371
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574908
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256381
INFO:root:FL Epoch: 222 Norm Difference for worker 371 is 0.985948
INFO:root:FL Epoch: 222 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :847
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812681
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453778
INFO:root:FL Epoch: 222 Norm Difference for worker 847 is 1.011592
INFO:root:FL Epoch: 222 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1564
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542619
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361192
INFO:root:FL Epoch: 222 Norm Difference for worker 1564 is 1.006747
INFO:root:FL Epoch: 222 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809551
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648566
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 1.022107
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 100
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.5114676864708171 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:1.902389903863271                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [693, 900, 1891, 914, 1339, 1170, 1747, 1173, 1100, 1280]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 223 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :693
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305369
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439786
INFO:root:FL Epoch: 223 Norm Difference for worker 693 is 0.913369
INFO:root:FL Epoch: 223 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :900
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596801
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445453
INFO:root:FL Epoch: 223 Norm Difference for worker 900 is 1.027669
INFO:root:FL Epoch: 223 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1891
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520481
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532923
INFO:root:FL Epoch: 223 Norm Difference for worker 1891 is 0.982923
INFO:root:FL Epoch: 223 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :914
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564296
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584435
INFO:root:FL Epoch: 223 Norm Difference for worker 914 is 0.963035
INFO:root:FL Epoch: 223 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1339
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616114
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405658
INFO:root:FL Epoch: 223 Norm Difference for worker 1339 is 0.940337
INFO:root:FL Epoch: 223 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1170
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685390
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607437
INFO:root:FL Epoch: 223 Norm Difference for worker 1170 is 0.990837
INFO:root:FL Epoch: 223 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1747
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469949
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378670
INFO:root:FL Epoch: 223 Norm Difference for worker 1747 is 0.930972
INFO:root:FL Epoch: 223 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1173
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459184
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430140
INFO:root:FL Epoch: 223 Norm Difference for worker 1173 is 0.958655
INFO:root:FL Epoch: 223 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1100
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780265
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541472
INFO:root:FL Epoch: 223 Norm Difference for worker 1100 is 0.981996
INFO:root:FL Epoch: 223 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1280
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639617
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566851
INFO:root:FL Epoch: 223 Norm Difference for worker 1280 is 0.942581
INFO:root:FL Epoch: 223 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.5302146936164183 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:2.5068122148513794                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [121, 432, 1521, 472, 447, 591, 1014, 127, 151, 1304]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 224 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :121
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418975
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 121 is 1.261716
INFO:root:FL Epoch: 224 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :432
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.918814
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475619
INFO:root:FL Epoch: 224 Norm Difference for worker 432 is 1.074986
INFO:root:FL Epoch: 224 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1521
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305349
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307397
INFO:root:FL Epoch: 224 Norm Difference for worker 1521 is 1.049121
INFO:root:FL Epoch: 224 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :472
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492145
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485114
INFO:root:FL Epoch: 224 Norm Difference for worker 472 is 1.193186
INFO:root:FL Epoch: 224 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :447
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389041
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652104
INFO:root:FL Epoch: 224 Norm Difference for worker 447 is 1.204699
INFO:root:FL Epoch: 224 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :591
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681163
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519641
INFO:root:FL Epoch: 224 Norm Difference for worker 591 is 1.289577
INFO:root:FL Epoch: 224 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1014
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580290
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562109
INFO:root:FL Epoch: 224 Norm Difference for worker 1014 is 1.201727
INFO:root:FL Epoch: 224 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :127
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.824868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 127 is 1.222286
INFO:root:FL Epoch: 224 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :151
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.736358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 151 is 1.213673
INFO:root:FL Epoch: 224 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1304
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447319
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469175
INFO:root:FL Epoch: 224 Norm Difference for worker 1304 is 1.151437
INFO:root:FL Epoch: 224 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.5375120219062356 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:2.4629204670588174                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [969, 9, 1523, 1343, 1486, 451, 775, 353, 1539, 1452]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :969
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648719
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570825
INFO:root:FL Epoch: 225 Norm Difference for worker 969 is 1.053643
INFO:root:FL Epoch: 225 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :9
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773447
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 9 is 1.135529
INFO:root:FL Epoch: 225 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1523
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759751
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464260
INFO:root:FL Epoch: 225 Norm Difference for worker 1523 is 1.097875
INFO:root:FL Epoch: 225 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1343
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706002
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305075
INFO:root:FL Epoch: 225 Norm Difference for worker 1343 is 1.080236
INFO:root:FL Epoch: 225 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1486
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.961398
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396636
INFO:root:FL Epoch: 225 Norm Difference for worker 1486 is 1.142576
INFO:root:FL Epoch: 225 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :451
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566957
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535481
INFO:root:FL Epoch: 225 Norm Difference for worker 451 is 1.164213
INFO:root:FL Epoch: 225 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :775
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451471
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578660
INFO:root:FL Epoch: 225 Norm Difference for worker 775 is 1.189277
INFO:root:FL Epoch: 225 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :353
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561367
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343717
INFO:root:FL Epoch: 225 Norm Difference for worker 353 is 1.115017
INFO:root:FL Epoch: 225 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1539
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653004
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657229
INFO:root:FL Epoch: 225 Norm Difference for worker 1539 is 1.21235
INFO:root:FL Epoch: 225 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1452
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522873
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448676
INFO:root:FL Epoch: 225 Norm Difference for worker 1452 is 1.177024
INFO:root:FL Epoch: 225 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.48657617674154396 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:1.9806251525878906                             and Backdoor Test Accuracy:4.166666666666667 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [1485, 555, 1594, 643, 1912, 754, 1378, 1133, 549, 1650]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :1485
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323338
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467309
INFO:root:FL Epoch: 226 Norm Difference for worker 1485 is 0.983205
INFO:root:FL Epoch: 226 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :555
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462787
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301716
INFO:root:FL Epoch: 226 Norm Difference for worker 555 is 1.036293
INFO:root:FL Epoch: 226 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1594
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690037
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433105
INFO:root:FL Epoch: 226 Norm Difference for worker 1594 is 0.978382
INFO:root:FL Epoch: 226 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :643
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576112
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482130
INFO:root:FL Epoch: 226 Norm Difference for worker 643 is 1.006165
INFO:root:FL Epoch: 226 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1912
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583917
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555432
INFO:root:FL Epoch: 226 Norm Difference for worker 1912 is 0.99532
INFO:root:FL Epoch: 226 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :754
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635375
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469001
INFO:root:FL Epoch: 226 Norm Difference for worker 754 is 1.031597
INFO:root:FL Epoch: 226 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1378
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620351
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493809
INFO:root:FL Epoch: 226 Norm Difference for worker 1378 is 1.07883
INFO:root:FL Epoch: 226 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1133
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500288
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561201
INFO:root:FL Epoch: 226 Norm Difference for worker 1133 is 1.071064
INFO:root:FL Epoch: 226 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :549
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515402
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495887
INFO:root:FL Epoch: 226 Norm Difference for worker 549 is 1.048734
INFO:root:FL Epoch: 226 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1650
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581253
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401131
INFO:root:FL Epoch: 226 Norm Difference for worker 1650 is 1.047974
INFO:root:FL Epoch: 226 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.4773430894402897 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:1.9728786945343018                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [648, 1867, 874, 93, 920, 1013, 990, 1773, 1689, 32]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 227 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :648
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417262
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340952
INFO:root:FL Epoch: 227 Norm Difference for worker 648 is 1.010164
INFO:root:FL Epoch: 227 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1867
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459625
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467258
INFO:root:FL Epoch: 227 Norm Difference for worker 1867 is 0.970651
INFO:root:FL Epoch: 227 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :874
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526606
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500840
INFO:root:FL Epoch: 227 Norm Difference for worker 874 is 1.059461
INFO:root:FL Epoch: 227 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :93
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 93 is 0.951449
INFO:root:FL Epoch: 227 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :920
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457510
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735133
INFO:root:FL Epoch: 227 Norm Difference for worker 920 is 1.027058
INFO:root:FL Epoch: 227 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1013
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.906588
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609703
INFO:root:FL Epoch: 227 Norm Difference for worker 1013 is 0.960932
INFO:root:FL Epoch: 227 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :990
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640889
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345660
INFO:root:FL Epoch: 227 Norm Difference for worker 990 is 0.952886
INFO:root:FL Epoch: 227 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1773
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677779
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508936
INFO:root:FL Epoch: 227 Norm Difference for worker 1773 is 0.973373
INFO:root:FL Epoch: 227 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1689
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724299
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608868
INFO:root:FL Epoch: 227 Norm Difference for worker 1689 is 1.008459
INFO:root:FL Epoch: 227 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :32
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 32 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 32 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 32 is 0.967542
INFO:root:FL Epoch: 227 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 93
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.5178476484382853 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:2.176314870516459                             and Backdoor Test Accuracy:2.5 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [955, 1887, 1204, 1791, 1059, 1428, 634, 1557, 1872, 1924]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :955
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364454
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485218
INFO:root:FL Epoch: 228 Norm Difference for worker 955 is 1.030135
INFO:root:FL Epoch: 228 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1887
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557321
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360944
INFO:root:FL Epoch: 228 Norm Difference for worker 1887 is 0.915298
INFO:root:FL Epoch: 228 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1204
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409165
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491974
INFO:root:FL Epoch: 228 Norm Difference for worker 1204 is 0.985694
INFO:root:FL Epoch: 228 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1791
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546078
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402762
INFO:root:FL Epoch: 228 Norm Difference for worker 1791 is 1.045575
INFO:root:FL Epoch: 228 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1059
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531963
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425973
INFO:root:FL Epoch: 228 Norm Difference for worker 1059 is 0.943924
INFO:root:FL Epoch: 228 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1428
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562143
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465488
INFO:root:FL Epoch: 228 Norm Difference for worker 1428 is 0.974541
INFO:root:FL Epoch: 228 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :634
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471276
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512944
INFO:root:FL Epoch: 228 Norm Difference for worker 634 is 0.909873
INFO:root:FL Epoch: 228 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1557
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452896
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495230
INFO:root:FL Epoch: 228 Norm Difference for worker 1557 is 0.913025
INFO:root:FL Epoch: 228 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1872
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621165
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428766
INFO:root:FL Epoch: 228 Norm Difference for worker 1872 is 0.925243
INFO:root:FL Epoch: 228 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1924
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583332
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364694
INFO:root:FL Epoch: 228 Norm Difference for worker 1924 is 0.976537
INFO:root:FL Epoch: 228 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.5291711688041687 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:2.0812991857528687                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [671, 1129, 39, 772, 577, 1248, 637, 639, 299, 1080]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :671
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635323
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464143
INFO:root:FL Epoch: 229 Norm Difference for worker 671 is 0.995556
INFO:root:FL Epoch: 229 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1129
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472482
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474449
INFO:root:FL Epoch: 229 Norm Difference for worker 1129 is 0.966552
INFO:root:FL Epoch: 229 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :39
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.884082
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 39 is 0.946484
INFO:root:FL Epoch: 229 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :772
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573062
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610879
INFO:root:FL Epoch: 229 Norm Difference for worker 772 is 1.015174
INFO:root:FL Epoch: 229 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :577
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506628
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550035
INFO:root:FL Epoch: 229 Norm Difference for worker 577 is 0.920503
INFO:root:FL Epoch: 229 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1248
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585221
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443842
INFO:root:FL Epoch: 229 Norm Difference for worker 1248 is 0.976153
INFO:root:FL Epoch: 229 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :637
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433613
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416590
INFO:root:FL Epoch: 229 Norm Difference for worker 637 is 1.009744
INFO:root:FL Epoch: 229 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :639
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551530
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507535
INFO:root:FL Epoch: 229 Norm Difference for worker 639 is 0.857807
INFO:root:FL Epoch: 229 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :299
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721439
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 299 is 0.901101
INFO:root:FL Epoch: 229 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1080
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336753
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587361
INFO:root:FL Epoch: 229 Norm Difference for worker 1080 is 0.944968
INFO:root:FL Epoch: 229 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.4893825632684371 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:2.1388880411783853                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [873, 775, 828, 1248, 996, 1499, 76, 1770, 747, 595]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :873
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522254
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483804
INFO:root:FL Epoch: 230 Norm Difference for worker 873 is 1.082209
INFO:root:FL Epoch: 230 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :775
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532763
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515704
INFO:root:FL Epoch: 230 Norm Difference for worker 775 is 1.097808
INFO:root:FL Epoch: 230 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :828
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556258
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686422
INFO:root:FL Epoch: 230 Norm Difference for worker 828 is 1.214205
INFO:root:FL Epoch: 230 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1248
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522641
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534637
INFO:root:FL Epoch: 230 Norm Difference for worker 1248 is 1.07402
INFO:root:FL Epoch: 230 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :996
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572343
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435844
INFO:root:FL Epoch: 230 Norm Difference for worker 996 is 1.073058
INFO:root:FL Epoch: 230 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1499
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490804
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472714
INFO:root:FL Epoch: 230 Norm Difference for worker 1499 is 1.062431
INFO:root:FL Epoch: 230 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :76
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665436
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 76 is 1.04907
INFO:root:FL Epoch: 230 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1770
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807635
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474257
INFO:root:FL Epoch: 230 Norm Difference for worker 1770 is 1.097049
INFO:root:FL Epoch: 230 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :747
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614385
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401119
INFO:root:FL Epoch: 230 Norm Difference for worker 747 is 1.044999
INFO:root:FL Epoch: 230 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :595
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487732
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572432
INFO:root:FL Epoch: 230 Norm Difference for worker 595 is 1.075163
INFO:root:FL Epoch: 230 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1248
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.4780900846509373 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:1.6172364950180054                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 983, 1374, 129, 320, 1346, 124, 1736, 1616, 1905]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.150415
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652199
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.2328977808356285 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.3832990050315857 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 1.629279
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :983
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397977
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568982
INFO:root:FL Epoch: 231 Norm Difference for worker 983 is 1.035659
INFO:root:FL Epoch: 231 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1374
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495938
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663231
INFO:root:FL Epoch: 231 Norm Difference for worker 1374 is 0.978343
INFO:root:FL Epoch: 231 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :129
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403315
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 129 is 1.046893
INFO:root:FL Epoch: 231 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :320
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477531
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425725
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 320 is 1.028237
INFO:root:FL Epoch: 231 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1346
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464438
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378810
INFO:root:FL Epoch: 231 Norm Difference for worker 1346 is 0.92108
INFO:root:FL Epoch: 231 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :124
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.861642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 124 is 1.024075
INFO:root:FL Epoch: 231 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1736
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565132
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367280
INFO:root:FL Epoch: 231 Norm Difference for worker 1736 is 0.994774
INFO:root:FL Epoch: 231 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391121
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640468
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 1.002217
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1905
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384340
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359180
INFO:root:FL Epoch: 231 Norm Difference for worker 1905 is 0.929506
INFO:root:FL Epoch: 231 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1346
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.47890795329037833 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:1.5758103728294373                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1343, 469, 1642, 1238, 1114, 788, 936, 377, 528, 36]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1343
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427931
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342435
INFO:root:FL Epoch: 232 Norm Difference for worker 1343 is 0.905489
INFO:root:FL Epoch: 232 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :469
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609415
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616806
INFO:root:FL Epoch: 232 Norm Difference for worker 469 is 0.924982
INFO:root:FL Epoch: 232 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1642
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643738
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561369
INFO:root:FL Epoch: 232 Norm Difference for worker 1642 is 0.991252
INFO:root:FL Epoch: 232 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1238
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642144
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505855
INFO:root:FL Epoch: 232 Norm Difference for worker 1238 is 0.945607
INFO:root:FL Epoch: 232 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1114
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564318
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698055
INFO:root:FL Epoch: 232 Norm Difference for worker 1114 is 1.057449
INFO:root:FL Epoch: 232 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :788
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531243
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469056
INFO:root:FL Epoch: 232 Norm Difference for worker 788 is 1.001548
INFO:root:FL Epoch: 232 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :936
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643110
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510269
INFO:root:FL Epoch: 232 Norm Difference for worker 936 is 0.97831
INFO:root:FL Epoch: 232 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :377
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635153
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491938
INFO:root:FL Epoch: 232 Norm Difference for worker 377 is 0.974698
INFO:root:FL Epoch: 232 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :528
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608918
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405917
INFO:root:FL Epoch: 232 Norm Difference for worker 528 is 0.999381
INFO:root:FL Epoch: 232 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :36
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 36 is 1.000938
INFO:root:FL Epoch: 232 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.47200574331423817 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:2.2621344725290933                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [778, 1186, 81, 1407, 1252, 174, 1613, 698, 583, 220]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :778
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612564
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563158
INFO:root:FL Epoch: 233 Norm Difference for worker 778 is 1.195972
INFO:root:FL Epoch: 233 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1186
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688698
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335977
INFO:root:FL Epoch: 233 Norm Difference for worker 1186 is 1.081057
INFO:root:FL Epoch: 233 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :81
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 81 is 1.180779
INFO:root:FL Epoch: 233 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1407
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303543
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399058
INFO:root:FL Epoch: 233 Norm Difference for worker 1407 is 1.181502
INFO:root:FL Epoch: 233 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1252
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925529
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595246
INFO:root:FL Epoch: 233 Norm Difference for worker 1252 is 1.110816
INFO:root:FL Epoch: 233 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :174
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 174 is 1.088068
INFO:root:FL Epoch: 233 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1613
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591304
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289273
INFO:root:FL Epoch: 233 Norm Difference for worker 1613 is 1.147053
INFO:root:FL Epoch: 233 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :698
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570609
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399689
INFO:root:FL Epoch: 233 Norm Difference for worker 698 is 1.192673
INFO:root:FL Epoch: 233 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :583
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610001
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574323
INFO:root:FL Epoch: 233 Norm Difference for worker 583 is 1.168411
INFO:root:FL Epoch: 233 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :220
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 220 is 1.106156
INFO:root:FL Epoch: 233 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.4914107287631315 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:1.6061739921569824                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1156, 1523, 1918, 1420, 1146, 679, 124, 1799, 803, 836]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1156
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465835
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445174
INFO:root:FL Epoch: 234 Norm Difference for worker 1156 is 0.845411
INFO:root:FL Epoch: 234 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1523
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501181
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711407
INFO:root:FL Epoch: 234 Norm Difference for worker 1523 is 0.829667
INFO:root:FL Epoch: 234 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1918
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573812
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475723
INFO:root:FL Epoch: 234 Norm Difference for worker 1918 is 0.852801
INFO:root:FL Epoch: 234 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1420
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597585
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454623
INFO:root:FL Epoch: 234 Norm Difference for worker 1420 is 0.862212
INFO:root:FL Epoch: 234 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1146
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826799
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703980
INFO:root:FL Epoch: 234 Norm Difference for worker 1146 is 0.795496
INFO:root:FL Epoch: 234 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :679
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534075
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368612
INFO:root:FL Epoch: 234 Norm Difference for worker 679 is 0.871276
INFO:root:FL Epoch: 234 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :124
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 124 is 0.871115
INFO:root:FL Epoch: 234 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1799
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497550
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482705
INFO:root:FL Epoch: 234 Norm Difference for worker 1799 is 0.853621
INFO:root:FL Epoch: 234 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :803
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471165
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616215
INFO:root:FL Epoch: 234 Norm Difference for worker 803 is 0.815696
INFO:root:FL Epoch: 234 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :836
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698885
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548014
INFO:root:FL Epoch: 234 Norm Difference for worker 836 is 0.854759
INFO:root:FL Epoch: 234 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 803
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.47968195466434255 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:1.6993968884150188                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [241, 775, 456, 1916, 28, 1890, 1777, 1368, 615, 1249]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 235 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :241
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.799463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622196
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 241 is 0.951975
INFO:root:FL Epoch: 235 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :775
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484615
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346639
INFO:root:FL Epoch: 235 Norm Difference for worker 775 is 0.933377
INFO:root:FL Epoch: 235 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :456
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511875
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421574
INFO:root:FL Epoch: 235 Norm Difference for worker 456 is 0.87535
INFO:root:FL Epoch: 235 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1916
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544326
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461593
INFO:root:FL Epoch: 235 Norm Difference for worker 1916 is 0.917008
INFO:root:FL Epoch: 235 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :28
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 28 is 0.826467
INFO:root:FL Epoch: 235 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1890
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542444
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714396
INFO:root:FL Epoch: 235 Norm Difference for worker 1890 is 0.88788
INFO:root:FL Epoch: 235 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1777
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792601
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436371
INFO:root:FL Epoch: 235 Norm Difference for worker 1777 is 0.907931
INFO:root:FL Epoch: 235 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1368
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699597
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506341
INFO:root:FL Epoch: 235 Norm Difference for worker 1368 is 0.90959
INFO:root:FL Epoch: 235 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :615
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830942
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548464
INFO:root:FL Epoch: 235 Norm Difference for worker 615 is 0.863486
INFO:root:FL Epoch: 235 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1249
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588209
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630576
INFO:root:FL Epoch: 235 Norm Difference for worker 1249 is 0.959915
INFO:root:FL Epoch: 235 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.48376983579467325 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:2.1417680978775024                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [756, 291, 147, 1733, 178, 42, 3, 1153, 1239, 1698]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.09975062 0.10024938 0.10024938
 0.10024938 0.09975062 0.09975062 0.09975062]
INFO:root:FL Epoch: 236 Num points on workers: [200 201 201 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :756
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454259
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413397
INFO:root:FL Epoch: 236 Norm Difference for worker 756 is 1.107235
INFO:root:FL Epoch: 236 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :291
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.789945
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605239
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 291 is 1.001075
INFO:root:FL Epoch: 236 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :147
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 147 is 1.056864
INFO:root:FL Epoch: 236 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1733
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639807
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522450
INFO:root:FL Epoch: 236 Norm Difference for worker 1733 is 1.072213
INFO:root:FL Epoch: 236 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466944
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 178 is 1.059356
INFO:root:FL Epoch: 236 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :42
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.309317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.885526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 42 is 0.988939
INFO:root:FL Epoch: 236 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :3
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 3 is 1.118228
INFO:root:FL Epoch: 236 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1153
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757561
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300311
INFO:root:FL Epoch: 236 Norm Difference for worker 1153 is 1.064111
INFO:root:FL Epoch: 236 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1239
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408493
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673776
INFO:root:FL Epoch: 236 Norm Difference for worker 1239 is 1.063179
INFO:root:FL Epoch: 236 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1698
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606387
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413822
INFO:root:FL Epoch: 236 Norm Difference for worker 1698 is 1.1189
INFO:root:FL Epoch: 236 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.47890683132059436 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:1.7182068626085918                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [1370, 1658, 708, 759, 918, 1219, 1148, 1159, 682, 546]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 237 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :1370
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595320
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458961
INFO:root:FL Epoch: 237 Norm Difference for worker 1370 is 0.933898
INFO:root:FL Epoch: 237 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1658
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594964
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519429
INFO:root:FL Epoch: 237 Norm Difference for worker 1658 is 0.950373
INFO:root:FL Epoch: 237 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :708
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432486
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298710
INFO:root:FL Epoch: 237 Norm Difference for worker 708 is 0.888208
INFO:root:FL Epoch: 237 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :759
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828251
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450755
INFO:root:FL Epoch: 237 Norm Difference for worker 759 is 1.025647
INFO:root:FL Epoch: 237 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :918
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667958
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500201
INFO:root:FL Epoch: 237 Norm Difference for worker 918 is 0.963548
INFO:root:FL Epoch: 237 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1219
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665492
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639585
INFO:root:FL Epoch: 237 Norm Difference for worker 1219 is 1.013775
INFO:root:FL Epoch: 237 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1148
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457600
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532282
INFO:root:FL Epoch: 237 Norm Difference for worker 1148 is 0.900266
INFO:root:FL Epoch: 237 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1159
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593950
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284266
INFO:root:FL Epoch: 237 Norm Difference for worker 1159 is 0.926653
INFO:root:FL Epoch: 237 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :682
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710526
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551430
INFO:root:FL Epoch: 237 Norm Difference for worker 682 is 0.97618
INFO:root:FL Epoch: 237 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :546
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418164
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360604
INFO:root:FL Epoch: 237 Norm Difference for worker 546 is 0.953813
INFO:root:FL Epoch: 237 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 708
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.49384702128522534 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:1.7725418607393901                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [234, 54, 1627, 925, 1099, 1451, 413, 99, 692, 632]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 238 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :234
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 234 is 1.038451
INFO:root:FL Epoch: 238 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :54
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 54 is 0.973009
INFO:root:FL Epoch: 238 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1627
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472370
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353450
INFO:root:FL Epoch: 238 Norm Difference for worker 1627 is 0.882625
INFO:root:FL Epoch: 238 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :925
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318915
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416120
INFO:root:FL Epoch: 238 Norm Difference for worker 925 is 0.870488
INFO:root:FL Epoch: 238 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1099
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569032
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559431
INFO:root:FL Epoch: 238 Norm Difference for worker 1099 is 0.995648
INFO:root:FL Epoch: 238 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1451
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403724
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392430
INFO:root:FL Epoch: 238 Norm Difference for worker 1451 is 0.929992
INFO:root:FL Epoch: 238 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :413
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470713
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487515
INFO:root:FL Epoch: 238 Norm Difference for worker 413 is 0.955766
INFO:root:FL Epoch: 238 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :99
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 99 is 0.90552
INFO:root:FL Epoch: 238 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :692
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783568
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453394
INFO:root:FL Epoch: 238 Norm Difference for worker 692 is 0.986565
INFO:root:FL Epoch: 238 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :632
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488339
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431769
INFO:root:FL Epoch: 238 Norm Difference for worker 632 is 0.976075
INFO:root:FL Epoch: 238 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.543150980682934 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:2.442974050839742                             and Backdoor Test Accuracy:5.833333333333333 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1944, 1724, 1779, 803, 1839, 1224, 1020, 1562, 1284, 847]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1944
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704530
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357891
INFO:root:FL Epoch: 239 Norm Difference for worker 1944 is 1.046234
INFO:root:FL Epoch: 239 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1724
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418009
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639742
INFO:root:FL Epoch: 239 Norm Difference for worker 1724 is 1.161082
INFO:root:FL Epoch: 239 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1779
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841885
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488412
INFO:root:FL Epoch: 239 Norm Difference for worker 1779 is 1.184644
INFO:root:FL Epoch: 239 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :803
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416282
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521132
INFO:root:FL Epoch: 239 Norm Difference for worker 803 is 0.94444
INFO:root:FL Epoch: 239 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1839
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593340
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299973
INFO:root:FL Epoch: 239 Norm Difference for worker 1839 is 1.10357
INFO:root:FL Epoch: 239 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1224
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650132
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306991
INFO:root:FL Epoch: 239 Norm Difference for worker 1224 is 1.197258
INFO:root:FL Epoch: 239 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1020
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664800
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384710
INFO:root:FL Epoch: 239 Norm Difference for worker 1020 is 1.102588
INFO:root:FL Epoch: 239 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1562
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896342
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629267
INFO:root:FL Epoch: 239 Norm Difference for worker 1562 is 1.202525
INFO:root:FL Epoch: 239 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1284
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512646
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455569
INFO:root:FL Epoch: 239 Norm Difference for worker 1284 is 1.085836
INFO:root:FL Epoch: 239 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :847
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537660
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543639
INFO:root:FL Epoch: 239 Norm Difference for worker 847 is 1.092661
INFO:root:FL Epoch: 239 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 803
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.49297109596869526 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:1.928743580977122                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1700, 1947, 227, 1223, 1724, 931, 941, 1328, 768, 1319]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1700
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414553
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511373
INFO:root:FL Epoch: 240 Norm Difference for worker 1700 is 1.109339
INFO:root:FL Epoch: 240 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1947
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619719
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648646
INFO:root:FL Epoch: 240 Norm Difference for worker 1947 is 1.074165
INFO:root:FL Epoch: 240 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :227
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.760183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 227 is 1.109151
INFO:root:FL Epoch: 240 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1223
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700090
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462198
INFO:root:FL Epoch: 240 Norm Difference for worker 1223 is 1.126698
INFO:root:FL Epoch: 240 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1724
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809764
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456593
INFO:root:FL Epoch: 240 Norm Difference for worker 1724 is 1.18919
INFO:root:FL Epoch: 240 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :931
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403394
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518300
INFO:root:FL Epoch: 240 Norm Difference for worker 931 is 1.137094
INFO:root:FL Epoch: 240 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :941
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601828
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331033
INFO:root:FL Epoch: 240 Norm Difference for worker 941 is 1.005552
INFO:root:FL Epoch: 240 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1328
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754429
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349833
INFO:root:FL Epoch: 240 Norm Difference for worker 1328 is 1.114459
INFO:root:FL Epoch: 240 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :768
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585818
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515221
INFO:root:FL Epoch: 240 Norm Difference for worker 768 is 1.131098
INFO:root:FL Epoch: 240 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1319
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508480
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429719
INFO:root:FL Epoch: 240 Norm Difference for worker 1319 is 1.160161
INFO:root:FL Epoch: 240 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.4892648651319392 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:1.9012757738431294                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 569, 14, 452, 1546, 1283, 1017, 977, 829, 1129]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.027174
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445031
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.2731291974584262 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.3638853907585144 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 1.643353
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :569
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527156
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374461
INFO:root:FL Epoch: 241 Norm Difference for worker 569 is 0.981111
INFO:root:FL Epoch: 241 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :14
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 14 is 0.945953
INFO:root:FL Epoch: 241 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :452
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345541
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242212
INFO:root:FL Epoch: 241 Norm Difference for worker 452 is 0.895453
INFO:root:FL Epoch: 241 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1546
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518333
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501481
INFO:root:FL Epoch: 241 Norm Difference for worker 1546 is 0.929996
INFO:root:FL Epoch: 241 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1283
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435376
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540738
INFO:root:FL Epoch: 241 Norm Difference for worker 1283 is 0.975108
INFO:root:FL Epoch: 241 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1017
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600224
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383954
INFO:root:FL Epoch: 241 Norm Difference for worker 1017 is 0.984947
INFO:root:FL Epoch: 241 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :977
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367525
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537434
INFO:root:FL Epoch: 241 Norm Difference for worker 977 is 1.003361
INFO:root:FL Epoch: 241 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :829
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435641
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289329
INFO:root:FL Epoch: 241 Norm Difference for worker 829 is 0.980479
INFO:root:FL Epoch: 241 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1129
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336679
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312259
INFO:root:FL Epoch: 241 Norm Difference for worker 1129 is 0.946569
INFO:root:FL Epoch: 241 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 452
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5084396513069377 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:2.20369819800059                             and Backdoor Test Accuracy:6.666666666666667 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [674, 306, 1588, 405, 739, 406, 450, 1851, 796, 1779]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 242 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :674
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453610
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453936
INFO:root:FL Epoch: 242 Norm Difference for worker 674 is 1.212934
INFO:root:FL Epoch: 242 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :306
