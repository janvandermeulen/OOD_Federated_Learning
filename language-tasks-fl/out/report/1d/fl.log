INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [595, 500, 859, 383, 1838, 1939, 1125, 353, 1260, 1834]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :595
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688655
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678628
INFO:root:FL Epoch: 1 Norm Difference for worker 595 is 0.309219
INFO:root:FL Epoch: 1 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :500
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687979
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695450
INFO:root:FL Epoch: 1 Norm Difference for worker 500 is 0.312871
INFO:root:FL Epoch: 1 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :859
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688206
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692797
INFO:root:FL Epoch: 1 Norm Difference for worker 859 is 0.339252
INFO:root:FL Epoch: 1 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :383
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695146
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691239
INFO:root:FL Epoch: 1 Norm Difference for worker 383 is 0.294267
INFO:root:FL Epoch: 1 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1838
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693395
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685373
INFO:root:FL Epoch: 1 Norm Difference for worker 1838 is 0.288625
INFO:root:FL Epoch: 1 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1939
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689367
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690727
INFO:root:FL Epoch: 1 Norm Difference for worker 1939 is 0.282308
INFO:root:FL Epoch: 1 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1125
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693816
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691197
INFO:root:FL Epoch: 1 Norm Difference for worker 1125 is 0.309659
INFO:root:FL Epoch: 1 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :353
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698617
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688889
INFO:root:FL Epoch: 1 Norm Difference for worker 353 is 0.281798
INFO:root:FL Epoch: 1 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1260
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694889
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697892
INFO:root:FL Epoch: 1 Norm Difference for worker 1260 is 0.342221
INFO:root:FL Epoch: 1 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1834
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689608
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693329
INFO:root:FL Epoch: 1 Norm Difference for worker 1834 is 0.292841
INFO:root:FL Epoch: 1 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6931471649338218 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6931493878364563                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1016
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682484
INFO:root:FL Epoch: 2 Norm Difference for worker 1016 is 0.199461
INFO:root:FL Epoch: 2 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :543
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686132
INFO:root:FL Epoch: 2 Norm Difference for worker 543 is 0.129183
INFO:root:FL Epoch: 2 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1103
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695153
INFO:root:FL Epoch: 2 Norm Difference for worker 1103 is 0.112292
INFO:root:FL Epoch: 2 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1820
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690798
INFO:root:FL Epoch: 2 Norm Difference for worker 1820 is 0.102648
INFO:root:FL Epoch: 2 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :768
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680106
INFO:root:FL Epoch: 2 Norm Difference for worker 768 is 0.223139
INFO:root:FL Epoch: 2 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1316
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 2 Norm Difference for worker 1316 is 0.067654
INFO:root:FL Epoch: 2 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699614
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.242509
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :276
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696043
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 276 is 0.15256
INFO:root:FL Epoch: 2 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :207
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 207 is 0.101277
INFO:root:FL Epoch: 2 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :159
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690922
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 159 is 0.046638
INFO:root:FL Epoch: 2 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6937327910872066 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.6690187454223633                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 3 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :263
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 263 is 0.128182
INFO:root:FL Epoch: 3 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1554
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695888
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676354
INFO:root:FL Epoch: 3 Norm Difference for worker 1554 is 0.380831
INFO:root:FL Epoch: 3 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1266
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693445
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693326
INFO:root:FL Epoch: 3 Norm Difference for worker 1266 is 0.037575
INFO:root:FL Epoch: 3 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :982
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693445
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696528
INFO:root:FL Epoch: 3 Norm Difference for worker 982 is 0.077052
INFO:root:FL Epoch: 3 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700773
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689365
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.10156
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :475
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695888
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 3 Norm Difference for worker 475 is 0.087834
INFO:root:FL Epoch: 3 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1357
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691003
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689237
INFO:root:FL Epoch: 3 Norm Difference for worker 1357 is 0.052221
INFO:root:FL Epoch: 3 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :684
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695888
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692304
INFO:root:FL Epoch: 3 Norm Difference for worker 684 is 0.059023
INFO:root:FL Epoch: 3 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1506
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683675
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697435
INFO:root:FL Epoch: 3 Norm Difference for worker 1506 is 0.12502
INFO:root:FL Epoch: 3 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1238
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695888
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693490
INFO:root:FL Epoch: 3 Norm Difference for worker 1238 is 0.057477
INFO:root:FL Epoch: 3 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6936853773453656 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.6703242659568787                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :979
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688796
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714724
INFO:root:FL Epoch: 4 Norm Difference for worker 979 is 0.12036
INFO:root:FL Epoch: 4 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :915
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686487
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688276
INFO:root:FL Epoch: 4 Norm Difference for worker 915 is 0.296849
INFO:root:FL Epoch: 4 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1324
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691105
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713777
INFO:root:FL Epoch: 4 Norm Difference for worker 1324 is 0.104342
INFO:root:FL Epoch: 4 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1034
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700341
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695481
INFO:root:FL Epoch: 4 Norm Difference for worker 1034 is 0.148736
INFO:root:FL Epoch: 4 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :360
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688796
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683863
INFO:root:FL Epoch: 4 Norm Difference for worker 360 is 0.128423
INFO:root:FL Epoch: 4 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1751
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693414
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697430
INFO:root:FL Epoch: 4 Norm Difference for worker 1751 is 0.038648
INFO:root:FL Epoch: 4 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1025
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686487
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688725
INFO:root:FL Epoch: 4 Norm Difference for worker 1025 is 0.002912
INFO:root:FL Epoch: 4 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :153
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 153 is 0.316939
INFO:root:FL Epoch: 4 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1482
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691105
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690063
INFO:root:FL Epoch: 4 Norm Difference for worker 1482 is 0.086238
INFO:root:FL Epoch: 4 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :274
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692013
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 274 is 0.085787
INFO:root:FL Epoch: 4 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6942278076620663 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.6576084494590759                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 5 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :786
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690183
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689654
INFO:root:FL Epoch: 5 Norm Difference for worker 786 is 0.078081
INFO:root:FL Epoch: 5 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :115
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682944
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 115 is 0.149547
INFO:root:FL Epoch: 5 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :329
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 329 is 0.014097
INFO:root:FL Epoch: 5 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :440
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682944
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694760
INFO:root:FL Epoch: 5 Norm Difference for worker 440 is 0.057526
INFO:root:FL Epoch: 5 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1220
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697421
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693411
INFO:root:FL Epoch: 5 Norm Difference for worker 1220 is 0.023277
INFO:root:FL Epoch: 5 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :622
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697421
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696771
INFO:root:FL Epoch: 5 Norm Difference for worker 622 is 0.187908
INFO:root:FL Epoch: 5 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1865
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701041
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683277
INFO:root:FL Epoch: 5 Norm Difference for worker 1865 is 0.123164
INFO:root:FL Epoch: 5 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1868
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711899
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693379
INFO:root:FL Epoch: 5 Norm Difference for worker 1868 is 0.180445
INFO:root:FL Epoch: 5 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1776
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675705
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683451
INFO:root:FL Epoch: 5 Norm Difference for worker 1776 is 0.130624
INFO:root:FL Epoch: 5 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1316
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697421
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688817
INFO:root:FL Epoch: 5 Norm Difference for worker 1316 is 0.00441
INFO:root:FL Epoch: 5 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6939835583462435 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.662824809551239                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 6 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :1197
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681303
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650750
INFO:root:FL Epoch: 6 Norm Difference for worker 1197 is 0.429873
INFO:root:FL Epoch: 6 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1507
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681303
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691748
INFO:root:FL Epoch: 6 Norm Difference for worker 1507 is 0.298859
INFO:root:FL Epoch: 6 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1435
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687462
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697502
INFO:root:FL Epoch: 6 Norm Difference for worker 1435 is 0.011343
INFO:root:FL Epoch: 6 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1040
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690542
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690773
INFO:root:FL Epoch: 6 Norm Difference for worker 1040 is 0.054078
INFO:root:FL Epoch: 6 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1420
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690542
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672847
INFO:root:FL Epoch: 6 Norm Difference for worker 1420 is 0.447692
INFO:root:FL Epoch: 6 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :361
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696701
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689003
INFO:root:FL Epoch: 6 Norm Difference for worker 361 is 0.167244
INFO:root:FL Epoch: 6 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1002
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687462
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690934
INFO:root:FL Epoch: 6 Norm Difference for worker 1002 is 0.13003
INFO:root:FL Epoch: 6 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :327
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 327 is 0.024058
INFO:root:FL Epoch: 6 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :674
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696701
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686340
INFO:root:FL Epoch: 6 Norm Difference for worker 674 is 0.341676
INFO:root:FL Epoch: 6 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1021
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693621
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689620
INFO:root:FL Epoch: 6 Norm Difference for worker 1021 is 0.011717
INFO:root:FL Epoch: 6 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6930795452174019 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.7067691683769226                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 7 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :1809
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690533
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693702
INFO:root:FL Epoch: 7 Norm Difference for worker 1809 is 0.050881
INFO:root:FL Epoch: 7 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :835
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698651
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695378
INFO:root:FL Epoch: 7 Norm Difference for worker 835 is 0.104791
INFO:root:FL Epoch: 7 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :972
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690533
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679188
INFO:root:FL Epoch: 7 Norm Difference for worker 972 is 0.047051
INFO:root:FL Epoch: 7 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1512
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698651
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683041
INFO:root:FL Epoch: 7 Norm Difference for worker 1512 is 0.134548
INFO:root:FL Epoch: 7 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1161
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693239
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691399
INFO:root:FL Epoch: 7 Norm Difference for worker 1161 is 0.015646
INFO:root:FL Epoch: 7 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1280
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694592
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694061
INFO:root:FL Epoch: 7 Norm Difference for worker 1280 is 0.004919
INFO:root:FL Epoch: 7 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1341
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693239
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678529
INFO:root:FL Epoch: 7 Norm Difference for worker 1341 is 0.236865
INFO:root:FL Epoch: 7 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :243
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 243 is 0.043239
INFO:root:FL Epoch: 7 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1257
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694592
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692220
INFO:root:FL Epoch: 7 Norm Difference for worker 1257 is 0.077634
INFO:root:FL Epoch: 7 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :863
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686473
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691128
INFO:root:FL Epoch: 7 Norm Difference for worker 863 is 0.094706
INFO:root:FL Epoch: 7 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.693332272417405 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.6824183464050293                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1434
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693205
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693778
INFO:root:FL Epoch: 8 Norm Difference for worker 1434 is 0.025428
INFO:root:FL Epoch: 8 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :721
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695363
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694618
INFO:root:FL Epoch: 8 Norm Difference for worker 721 is 0.044471
INFO:root:FL Epoch: 8 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :363
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681411
INFO:root:FL Epoch: 8 Norm Difference for worker 363 is 0.346459
INFO:root:FL Epoch: 8 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :467
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696441
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690075
INFO:root:FL Epoch: 8 Norm Difference for worker 467 is 0.149051
INFO:root:FL Epoch: 8 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1443
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697520
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672031
INFO:root:FL Epoch: 8 Norm Difference for worker 1443 is 0.25556
INFO:root:FL Epoch: 8 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1573
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692127
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694660
INFO:root:FL Epoch: 8 Norm Difference for worker 1573 is 0.180564
INFO:root:FL Epoch: 8 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.089873
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :475
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689969
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693218
INFO:root:FL Epoch: 8 Norm Difference for worker 475 is 0.056183
INFO:root:FL Epoch: 8 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1216
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704669
INFO:root:FL Epoch: 8 Norm Difference for worker 1216 is 0.050061
INFO:root:FL Epoch: 8 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :521
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698599
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691410
INFO:root:FL Epoch: 8 Norm Difference for worker 521 is 0.038919
INFO:root:FL Epoch: 8 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6931386800373301 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.6938967108726501                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1154
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693297
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693214
INFO:root:FL Epoch: 9 Norm Difference for worker 1154 is 0.056776
INFO:root:FL Epoch: 9 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :257
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 257 is 0.13979
INFO:root:FL Epoch: 9 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1894
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692923
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702432
INFO:root:FL Epoch: 9 Norm Difference for worker 1894 is 0.040566
INFO:root:FL Epoch: 9 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :729
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693222
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688252
INFO:root:FL Epoch: 9 Norm Difference for worker 729 is 0.054758
INFO:root:FL Epoch: 9 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1361
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691184
INFO:root:FL Epoch: 9 Norm Difference for worker 1361 is 0.075922
INFO:root:FL Epoch: 9 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :634
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693073
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695723
INFO:root:FL Epoch: 9 Norm Difference for worker 634 is 0.122382
INFO:root:FL Epoch: 9 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693297
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692532
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.041136
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :657
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693522
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 9 Norm Difference for worker 657 is 0.085167
INFO:root:FL Epoch: 9 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :28
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 28 is 0.022273
INFO:root:FL Epoch: 9 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :344
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693205
INFO:root:FL Epoch: 9 Norm Difference for worker 344 is 0.038137
INFO:root:FL Epoch: 9 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6931697726249695 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.7187886238098145                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :322
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 322 is 0.084419
INFO:root:FL Epoch: 10 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1069
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701064
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695114
INFO:root:FL Epoch: 10 Norm Difference for worker 1069 is 0.176352
INFO:root:FL Epoch: 10 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685871
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691459
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.001647
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :716
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701064
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702013
INFO:root:FL Epoch: 10 Norm Difference for worker 716 is 0.117502
INFO:root:FL Epoch: 10 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1613
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693468
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691345
INFO:root:FL Epoch: 10 Norm Difference for worker 1613 is 0.021214
INFO:root:FL Epoch: 10 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1184
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698532
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678406
INFO:root:FL Epoch: 10 Norm Difference for worker 1184 is 0.12005
INFO:root:FL Epoch: 10 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1191
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703596
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685262
INFO:root:FL Epoch: 10 Norm Difference for worker 1191 is 0.326854
INFO:root:FL Epoch: 10 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :27
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 27 is 0.208898
INFO:root:FL Epoch: 10 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1904
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696000
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687724
INFO:root:FL Epoch: 10 Norm Difference for worker 1904 is 0.296823
INFO:root:FL Epoch: 10 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :291
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.664495
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 291 is 0.293934
INFO:root:FL Epoch: 10 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6931996731197133 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.6893185973167419                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [1409, 1122, 467, 247, 1802, 1801, 1139, 1528, 498, 594]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :1409
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692771
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693351
INFO:root:FL Epoch: 11 Norm Difference for worker 1409 is 0.082969
INFO:root:FL Epoch: 11 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1122
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693326
INFO:root:FL Epoch: 11 Norm Difference for worker 1122 is 0.100792
INFO:root:FL Epoch: 11 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :467
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693922
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698508
INFO:root:FL Epoch: 11 Norm Difference for worker 467 is 0.145243
INFO:root:FL Epoch: 11 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :247
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 247 is 0.29284
INFO:root:FL Epoch: 11 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1802
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692004
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691281
INFO:root:FL Epoch: 11 Norm Difference for worker 1802 is 0.055157
INFO:root:FL Epoch: 11 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1801
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694689
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688673
INFO:root:FL Epoch: 11 Norm Difference for worker 1801 is 0.086065
INFO:root:FL Epoch: 11 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1139
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691620
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689144
INFO:root:FL Epoch: 11 Norm Difference for worker 1139 is 0.253757
INFO:root:FL Epoch: 11 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1528
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693922
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686289
INFO:root:FL Epoch: 11 Norm Difference for worker 1528 is 0.236498
INFO:root:FL Epoch: 11 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :498
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693538
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692312
INFO:root:FL Epoch: 11 Norm Difference for worker 498 is 0.068963
INFO:root:FL Epoch: 11 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :594
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693264
INFO:root:FL Epoch: 11 Norm Difference for worker 594 is 0.121255
INFO:root:FL Epoch: 11 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6932909243247088 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.6843138337135315                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1405
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696736
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679095
INFO:root:FL Epoch: 12 Norm Difference for worker 1405 is 0.186414
INFO:root:FL Epoch: 12 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1244
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692299
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695561
INFO:root:FL Epoch: 12 Norm Difference for worker 1244 is 0.045963
INFO:root:FL Epoch: 12 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :380
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690525
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689939
INFO:root:FL Epoch: 12 Norm Difference for worker 380 is 0.094304
INFO:root:FL Epoch: 12 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :125
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 125 is 0.06182
INFO:root:FL Epoch: 12 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :802
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692276
INFO:root:FL Epoch: 12 Norm Difference for worker 802 is 0.115612
INFO:root:FL Epoch: 12 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :840
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699208
INFO:root:FL Epoch: 12 Norm Difference for worker 840 is 0.116541
INFO:root:FL Epoch: 12 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1334
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691412
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688888
INFO:root:FL Epoch: 12 Norm Difference for worker 1334 is 0.031321
INFO:root:FL Epoch: 12 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691412
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688575
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.046723
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :689
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694961
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693279
INFO:root:FL Epoch: 12 Norm Difference for worker 689 is 0.096761
INFO:root:FL Epoch: 12 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1036
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692299
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688453
INFO:root:FL Epoch: 12 Norm Difference for worker 1036 is 0.262303
INFO:root:FL Epoch: 12 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6931397914886475 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.6937843561172485                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1930
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693338
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696025
INFO:root:FL Epoch: 13 Norm Difference for worker 1930 is 0.107639
INFO:root:FL Epoch: 13 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1474
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693020
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690442
INFO:root:FL Epoch: 13 Norm Difference for worker 1474 is 0.07011
INFO:root:FL Epoch: 13 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :442
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693084
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687627
INFO:root:FL Epoch: 13 Norm Difference for worker 442 is 0.083887
INFO:root:FL Epoch: 13 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :232
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 232 is 0.069393
INFO:root:FL Epoch: 13 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :116
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 116 is 0.157298
INFO:root:FL Epoch: 13 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :202
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 202 is 0.133778
INFO:root:FL Epoch: 13 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1081
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693084
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694221
INFO:root:FL Epoch: 13 Norm Difference for worker 1081 is 0.034442
INFO:root:FL Epoch: 13 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :606
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692956
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693170
INFO:root:FL Epoch: 13 Norm Difference for worker 606 is 0.007922
INFO:root:FL Epoch: 13 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1303
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693211
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696766
INFO:root:FL Epoch: 13 Norm Difference for worker 1303 is 0.122817
INFO:root:FL Epoch: 13 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :945
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692956
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690277
INFO:root:FL Epoch: 13 Norm Difference for worker 945 is 0.07404
INFO:root:FL Epoch: 13 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6931505343493294 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.717244565486908                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1163
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693431
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686569
INFO:root:FL Epoch: 14 Norm Difference for worker 1163 is 0.040642
INFO:root:FL Epoch: 14 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1460
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688668
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690408
INFO:root:FL Epoch: 14 Norm Difference for worker 1460 is 0.005263
INFO:root:FL Epoch: 14 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :409
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683905
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710297
INFO:root:FL Epoch: 14 Norm Difference for worker 409 is 0.159957
INFO:root:FL Epoch: 14 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1123
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695812
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693330
INFO:root:FL Epoch: 14 Norm Difference for worker 1123 is 0.005382
INFO:root:FL Epoch: 14 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :604
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702956
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694979
INFO:root:FL Epoch: 14 Norm Difference for worker 604 is 0.040683
INFO:root:FL Epoch: 14 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :200
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699637
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 200 is 0.003168
INFO:root:FL Epoch: 14 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :551
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691049
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692564
INFO:root:FL Epoch: 14 Norm Difference for worker 551 is 0.098351
INFO:root:FL Epoch: 14 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1222
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698193
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693488
INFO:root:FL Epoch: 14 Norm Difference for worker 1222 is 0.115342
INFO:root:FL Epoch: 14 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1589
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695812
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691663
INFO:root:FL Epoch: 14 Norm Difference for worker 1589 is 0.15522
INFO:root:FL Epoch: 14 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :746
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688668
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693368
INFO:root:FL Epoch: 14 Norm Difference for worker 746 is 0.001048
INFO:root:FL Epoch: 14 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6930794260081123 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:0.7067078948020935                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 15 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :1506
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689197
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691660
INFO:root:FL Epoch: 15 Norm Difference for worker 1506 is 0.04056
INFO:root:FL Epoch: 15 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :196
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 196 is 0.054283
INFO:root:FL Epoch: 15 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1478
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689197
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684942
INFO:root:FL Epoch: 15 Norm Difference for worker 1478 is 0.024704
INFO:root:FL Epoch: 15 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694585
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693431
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 0.137396
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1923
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695932
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693185
INFO:root:FL Epoch: 15 Norm Difference for worker 1923 is 0.042705
INFO:root:FL Epoch: 15 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :91
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 91 is 0.129773
INFO:root:FL Epoch: 15 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :242
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 242 is 0.010766
INFO:root:FL Epoch: 15 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1709
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693238
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693002
INFO:root:FL Epoch: 15 Norm Difference for worker 1709 is 0.057091
INFO:root:FL Epoch: 15 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1297
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693238
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693341
INFO:root:FL Epoch: 15 Norm Difference for worker 1297 is 0.045833
INFO:root:FL Epoch: 15 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1000
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695932
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697225
INFO:root:FL Epoch: 15 Norm Difference for worker 1000 is 0.144645
INFO:root:FL Epoch: 15 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6935023139504826 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:0.6759299635887146                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :639
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695035
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695034
INFO:root:FL Epoch: 16 Norm Difference for worker 639 is 0.155497
INFO:root:FL Epoch: 16 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :327
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 327 is 0.072415
INFO:root:FL Epoch: 16 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :503
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691561
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693238
INFO:root:FL Epoch: 16 Norm Difference for worker 503 is 0.075426
INFO:root:FL Epoch: 16 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1110
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693298
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678841
INFO:root:FL Epoch: 16 Norm Difference for worker 1110 is 0.18704
INFO:root:FL Epoch: 16 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :839
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696772
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695494
INFO:root:FL Epoch: 16 Norm Difference for worker 839 is 0.060727
INFO:root:FL Epoch: 16 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :472
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695035
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694218
INFO:root:FL Epoch: 16 Norm Difference for worker 472 is 0.113771
INFO:root:FL Epoch: 16 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :274
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 274 is 0.118833
INFO:root:FL Epoch: 16 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :481
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691561
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693308
INFO:root:FL Epoch: 16 Norm Difference for worker 481 is 0.039978
INFO:root:FL Epoch: 16 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :805
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691561
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693201
INFO:root:FL Epoch: 16 Norm Difference for worker 805 is 0.052882
INFO:root:FL Epoch: 16 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1606
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695035
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692697
INFO:root:FL Epoch: 16 Norm Difference for worker 1606 is 0.091986
INFO:root:FL Epoch: 16 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6934773501227883 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:0.6767858862876892                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :116
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 116 is 0.230758
INFO:root:FL Epoch: 17 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1658
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696583
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693333
INFO:root:FL Epoch: 17 Norm Difference for worker 1658 is 0.324117
INFO:root:FL Epoch: 17 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :988
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691634
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721343
INFO:root:FL Epoch: 17 Norm Difference for worker 988 is 0.136139
INFO:root:FL Epoch: 17 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1655
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691634
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682422
INFO:root:FL Epoch: 17 Norm Difference for worker 1655 is 0.268914
INFO:root:FL Epoch: 17 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :62
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 62 is 0.046623
INFO:root:FL Epoch: 17 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :870
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691634
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692989
INFO:root:FL Epoch: 17 Norm Difference for worker 870 is 0.227316
INFO:root:FL Epoch: 17 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :955
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694933
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692720
INFO:root:FL Epoch: 17 Norm Difference for worker 955 is 0.045021
INFO:root:FL Epoch: 17 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :304
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 304 is 0.090911
INFO:root:FL Epoch: 17 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1427
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694933
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694284
INFO:root:FL Epoch: 17 Norm Difference for worker 1427 is 0.044283
INFO:root:FL Epoch: 17 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :652
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696583
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693222
INFO:root:FL Epoch: 17 Norm Difference for worker 652 is 0.085264
INFO:root:FL Epoch: 17 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6932041434680715 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:0.6890386939048767                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1037
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692332
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695611
INFO:root:FL Epoch: 18 Norm Difference for worker 1037 is 0.052932
INFO:root:FL Epoch: 18 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1375
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693567
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676434
INFO:root:FL Epoch: 18 Norm Difference for worker 1375 is 0.238415
INFO:root:FL Epoch: 18 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :637
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692332
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686212
INFO:root:FL Epoch: 18 Norm Difference for worker 637 is 0.12665
INFO:root:FL Epoch: 18 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :293
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 293 is 0.067759
INFO:root:FL Epoch: 18 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1435
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693567
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691298
INFO:root:FL Epoch: 18 Norm Difference for worker 1435 is 0.009485
INFO:root:FL Epoch: 18 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1294
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693979
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699823
INFO:root:FL Epoch: 18 Norm Difference for worker 1294 is 0.068094
INFO:root:FL Epoch: 18 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :712
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695214
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693432
INFO:root:FL Epoch: 18 Norm Difference for worker 712 is 0.23852
INFO:root:FL Epoch: 18 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :440
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693979
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698181
INFO:root:FL Epoch: 18 Norm Difference for worker 440 is 0.163139
INFO:root:FL Epoch: 18 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1768
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694803
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689014
INFO:root:FL Epoch: 18 Norm Difference for worker 1768 is 0.077185
INFO:root:FL Epoch: 18 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1805
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693567
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702530
INFO:root:FL Epoch: 18 Norm Difference for worker 1805 is 0.223029
INFO:root:FL Epoch: 18 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.693221414790434 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:0.6879886388778687                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 19 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :772
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669946
INFO:root:FL Epoch: 19 Norm Difference for worker 772 is 0.290826
INFO:root:FL Epoch: 19 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :212
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 212 is 0.222064
INFO:root:FL Epoch: 19 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :407
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693678
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682959
INFO:root:FL Epoch: 19 Norm Difference for worker 407 is 0.329974
INFO:root:FL Epoch: 19 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :782
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693678
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684832
INFO:root:FL Epoch: 19 Norm Difference for worker 782 is 0.05327
INFO:root:FL Epoch: 19 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1093
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694195
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694718
INFO:root:FL Epoch: 19 Norm Difference for worker 1093 is 0.064308
INFO:root:FL Epoch: 19 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1764
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691609
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688647
INFO:root:FL Epoch: 19 Norm Difference for worker 1764 is 0.227128
INFO:root:FL Epoch: 19 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692643
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 0.183148
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :351
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693678
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693562
INFO:root:FL Epoch: 19 Norm Difference for worker 351 is 0.040658
INFO:root:FL Epoch: 19 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1391
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693678
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 19 Norm Difference for worker 1391 is 0.032093
INFO:root:FL Epoch: 19 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :334
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 334 is 0.12679
INFO:root:FL Epoch: 19 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6932757391649134 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:0.6850534081459045                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :697
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691555
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705123
INFO:root:FL Epoch: 20 Norm Difference for worker 697 is 0.126641
INFO:root:FL Epoch: 20 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1059
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694775
INFO:root:FL Epoch: 20 Norm Difference for worker 1059 is 0.354021
INFO:root:FL Epoch: 20 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :940
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693993
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696401
INFO:root:FL Epoch: 20 Norm Difference for worker 940 is 0.089756
INFO:root:FL Epoch: 20 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1796
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694806
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693337
INFO:root:FL Epoch: 20 Norm Difference for worker 1796 is 0.08948
INFO:root:FL Epoch: 20 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1162
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690742
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693455
INFO:root:FL Epoch: 20 Norm Difference for worker 1162 is 0.085661
INFO:root:FL Epoch: 20 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1765
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692367
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703410
INFO:root:FL Epoch: 20 Norm Difference for worker 1765 is 0.14556
INFO:root:FL Epoch: 20 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :469
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693993
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688925
INFO:root:FL Epoch: 20 Norm Difference for worker 469 is 0.173608
INFO:root:FL Epoch: 20 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1470
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689369
INFO:root:FL Epoch: 20 Norm Difference for worker 1470 is 0.150417
INFO:root:FL Epoch: 20 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :442
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693993
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695665
INFO:root:FL Epoch: 20 Norm Difference for worker 442 is 0.0685
INFO:root:FL Epoch: 20 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1373
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711026
INFO:root:FL Epoch: 20 Norm Difference for worker 1373 is 0.061702
INFO:root:FL Epoch: 20 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6934033106355106 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:0.6794962882995605                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [188, 485, 797, 1233, 876, 159, 811, 1592, 1089, 1895]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :188
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 188 is 0.02036
INFO:root:FL Epoch: 21 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :485
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695991
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684419
INFO:root:FL Epoch: 21 Norm Difference for worker 485 is 0.245495
INFO:root:FL Epoch: 21 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :797
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703105
INFO:root:FL Epoch: 21 Norm Difference for worker 797 is 0.126989
INFO:root:FL Epoch: 21 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1233
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690493
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691758
INFO:root:FL Epoch: 21 Norm Difference for worker 1233 is 0.013427
INFO:root:FL Epoch: 21 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :876
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694616
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692258
INFO:root:FL Epoch: 21 Norm Difference for worker 876 is 0.05547
INFO:root:FL Epoch: 21 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :159
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694616
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693311
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 159 is 0.009606
INFO:root:FL Epoch: 21 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :811
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690493
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691028
INFO:root:FL Epoch: 21 Norm Difference for worker 811 is 0.174729
INFO:root:FL Epoch: 21 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1592
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694134
INFO:root:FL Epoch: 21 Norm Difference for worker 1592 is 0.084212
INFO:root:FL Epoch: 21 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1089
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689118
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693458
INFO:root:FL Epoch: 21 Norm Difference for worker 1089 is 0.006149
INFO:root:FL Epoch: 21 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1895
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698740
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697879
INFO:root:FL Epoch: 21 Norm Difference for worker 1895 is 0.06806
INFO:root:FL Epoch: 21 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6932724223417395 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:0.6852216124534607                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 22 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :1716
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693975
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688643
INFO:root:FL Epoch: 22 Norm Difference for worker 1716 is 0.056547
INFO:root:FL Epoch: 22 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :910
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693179
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695901
INFO:root:FL Epoch: 22 Norm Difference for worker 910 is 0.114909
INFO:root:FL Epoch: 22 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1098
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694770
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686207
INFO:root:FL Epoch: 22 Norm Difference for worker 1098 is 0.161846
INFO:root:FL Epoch: 22 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1721
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694770
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693542
INFO:root:FL Epoch: 22 Norm Difference for worker 1721 is 0.068419
INFO:root:FL Epoch: 22 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :576
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693974
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705398
INFO:root:FL Epoch: 22 Norm Difference for worker 576 is 0.074729
INFO:root:FL Epoch: 22 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :104
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691587
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682657
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 104 is 0.151541
INFO:root:FL Epoch: 22 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1834
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689200
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694237
INFO:root:FL Epoch: 22 Norm Difference for worker 1834 is 0.051051
INFO:root:FL Epoch: 22 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1178
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693179
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701164
INFO:root:FL Epoch: 22 Norm Difference for worker 1178 is 0.211257
INFO:root:FL Epoch: 22 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :810
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693179
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685093
INFO:root:FL Epoch: 22 Norm Difference for worker 810 is 0.264019
INFO:root:FL Epoch: 22 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1047
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692383
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692970
INFO:root:FL Epoch: 22 Norm Difference for worker 1047 is 0.055209
INFO:root:FL Epoch: 22 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.693722549606772 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:0.6692976355552673                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1150
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695853
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696542
INFO:root:FL Epoch: 23 Norm Difference for worker 1150 is 0.16372
INFO:root:FL Epoch: 23 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :703
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688610
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696434
INFO:root:FL Epoch: 23 Norm Difference for worker 703 is 0.109372
INFO:root:FL Epoch: 23 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1942
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686196
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686539
INFO:root:FL Epoch: 23 Norm Difference for worker 1942 is 0.054094
INFO:root:FL Epoch: 23 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :362
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681368
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 23 Norm Difference for worker 362 is 0.182779
INFO:root:FL Epoch: 23 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1475
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698267
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699735
INFO:root:FL Epoch: 23 Norm Difference for worker 1475 is 0.03727
INFO:root:FL Epoch: 23 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :742
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688610
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691255
INFO:root:FL Epoch: 23 Norm Difference for worker 742 is 0.095583
INFO:root:FL Epoch: 23 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695853
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693225
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 0.242638
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :355
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698267
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683157
INFO:root:FL Epoch: 23 Norm Difference for worker 355 is 0.235509
INFO:root:FL Epoch: 23 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :747
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693439
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 23 Norm Difference for worker 747 is 0.098359
INFO:root:FL Epoch: 23 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :802
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693439
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695628
INFO:root:FL Epoch: 23 Norm Difference for worker 802 is 0.213108
INFO:root:FL Epoch: 23 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6937153619878432 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:0.7417545914649963                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708518
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700853
INFO:root:FL Epoch: 24 Norm Difference for worker 858 is 0.172484
INFO:root:FL Epoch: 24 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :699
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684778
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691901
INFO:root:FL Epoch: 24 Norm Difference for worker 699 is 0.049746
INFO:root:FL Epoch: 24 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :206
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 206 is 0.131211
INFO:root:FL Epoch: 24 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1820
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680030
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693013
INFO:root:FL Epoch: 24 Norm Difference for worker 1820 is 0.214034
INFO:root:FL Epoch: 24 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1414
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703770
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700197
INFO:root:FL Epoch: 24 Norm Difference for worker 1414 is 0.24458
INFO:root:FL Epoch: 24 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :474
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689526
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694044
INFO:root:FL Epoch: 24 Norm Difference for worker 474 is 0.133554
INFO:root:FL Epoch: 24 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :7
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 7 is 0.01691
INFO:root:FL Epoch: 24 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1914
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694274
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695657
INFO:root:FL Epoch: 24 Norm Difference for worker 1914 is 0.126511
INFO:root:FL Epoch: 24 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :865
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694274
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679338
INFO:root:FL Epoch: 24 Norm Difference for worker 865 is 0.006513
INFO:root:FL Epoch: 24 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :249
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 249 is 0.264387
INFO:root:FL Epoch: 24 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.693525987512925 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:0.6751424670219421                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1399
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695129
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685391
INFO:root:FL Epoch: 25 Norm Difference for worker 1399 is 0.205222
INFO:root:FL Epoch: 25 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :693
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687861
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694041
INFO:root:FL Epoch: 25 Norm Difference for worker 693 is 0.055088
INFO:root:FL Epoch: 25 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1217
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687861
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707914
INFO:root:FL Epoch: 25 Norm Difference for worker 1217 is 0.362303
INFO:root:FL Epoch: 25 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :70
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 70 is 0.272445
INFO:root:FL Epoch: 25 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :496
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698763
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699262
INFO:root:FL Epoch: 25 Norm Difference for worker 496 is 0.096792
INFO:root:FL Epoch: 25 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :407
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693312
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689367
INFO:root:FL Epoch: 25 Norm Difference for worker 407 is 0.334214
INFO:root:FL Epoch: 25 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :317
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 317 is 0.079892
INFO:root:FL Epoch: 25 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :98
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 98 is 0.149908
INFO:root:FL Epoch: 25 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1286
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687861
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681338
INFO:root:FL Epoch: 25 Norm Difference for worker 1286 is 0.31021
INFO:root:FL Epoch: 25 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1251
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696946
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685033
INFO:root:FL Epoch: 25 Norm Difference for worker 1251 is 0.30475
INFO:root:FL Epoch: 25 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6936784702188828 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:0.7406541705131531                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 26 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :1748
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684939
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689750
INFO:root:FL Epoch: 26 Norm Difference for worker 1748 is 0.060317
INFO:root:FL Epoch: 26 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1403
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675653
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688719
INFO:root:FL Epoch: 26 Norm Difference for worker 1403 is 0.021747
INFO:root:FL Epoch: 26 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1456
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708153
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689595
INFO:root:FL Epoch: 26 Norm Difference for worker 1456 is 0.097259
INFO:root:FL Epoch: 26 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1021
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698868
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 26 Norm Difference for worker 1021 is 0.094403
INFO:root:FL Epoch: 26 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1824
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698868
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704546
INFO:root:FL Epoch: 26 Norm Difference for worker 1824 is 0.030324
INFO:root:FL Epoch: 26 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :311
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 311 is 0.240846
INFO:root:FL Epoch: 26 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :906
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675653
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678774
INFO:root:FL Epoch: 26 Norm Difference for worker 906 is 0.24401
INFO:root:FL Epoch: 26 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1618
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684939
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683261
INFO:root:FL Epoch: 26 Norm Difference for worker 1618 is 0.184526
INFO:root:FL Epoch: 26 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :900
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694225
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692649
INFO:root:FL Epoch: 26 Norm Difference for worker 900 is 0.253463
INFO:root:FL Epoch: 26 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1277
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694225
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685078
INFO:root:FL Epoch: 26 Norm Difference for worker 1277 is 0.124685
INFO:root:FL Epoch: 26 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6931297253159916 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:0.7153254151344299                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 27 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1930
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702163
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694243
INFO:root:FL Epoch: 27 Norm Difference for worker 1930 is 0.167422
INFO:root:FL Epoch: 27 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1641
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697775
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697214
INFO:root:FL Epoch: 27 Norm Difference for worker 1641 is 0.119786
INFO:root:FL Epoch: 27 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :786
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702163
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693762
INFO:root:FL Epoch: 27 Norm Difference for worker 786 is 0.141521
INFO:root:FL Epoch: 27 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1944
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693388
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681953
INFO:root:FL Epoch: 27 Norm Difference for worker 1944 is 0.338424
INFO:root:FL Epoch: 27 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :949
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699969
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694945
INFO:root:FL Epoch: 27 Norm Difference for worker 949 is 0.038733
INFO:root:FL Epoch: 27 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 0.160207
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1024
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702163
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695235
INFO:root:FL Epoch: 27 Norm Difference for worker 1024 is 0.103982
INFO:root:FL Epoch: 27 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :860
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689000
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676510
INFO:root:FL Epoch: 27 Norm Difference for worker 860 is 0.232983
INFO:root:FL Epoch: 27 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :79
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 79 is 0.026159
INFO:root:FL Epoch: 27 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1497
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689000
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690834
INFO:root:FL Epoch: 27 Norm Difference for worker 1497 is 0.221786
INFO:root:FL Epoch: 27 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6953450266052695 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:0.6391095519065857                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :533
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705807
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690065
INFO:root:FL Epoch: 28 Norm Difference for worker 533 is 0.182135
INFO:root:FL Epoch: 28 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1370
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678017
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674231
INFO:root:FL Epoch: 28 Norm Difference for worker 1370 is 0.052006
INFO:root:FL Epoch: 28 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1778
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672459
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708249
INFO:root:FL Epoch: 28 Norm Difference for worker 1778 is 0.119063
INFO:root:FL Epoch: 28 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :376
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689133
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689232
INFO:root:FL Epoch: 28 Norm Difference for worker 376 is 0.012067
INFO:root:FL Epoch: 28 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1688
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700249
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688399
INFO:root:FL Epoch: 28 Norm Difference for worker 1688 is 0.18815
INFO:root:FL Epoch: 28 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1791
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700249
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692250
INFO:root:FL Epoch: 28 Norm Difference for worker 1791 is 0.06512
INFO:root:FL Epoch: 28 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :744
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678017
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696546
INFO:root:FL Epoch: 28 Norm Difference for worker 744 is 0.23337
INFO:root:FL Epoch: 28 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :605
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700249
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690559
INFO:root:FL Epoch: 28 Norm Difference for worker 605 is 6.9e-05
INFO:root:FL Epoch: 28 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1458
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683575
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684394
INFO:root:FL Epoch: 28 Norm Difference for worker 1458 is 0.070432
INFO:root:FL Epoch: 28 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :452
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711366
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693305
INFO:root:FL Epoch: 28 Norm Difference for worker 452 is 0.265902
INFO:root:FL Epoch: 28 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6935882217743817 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:0.6731691956520081                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :173
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 173 is 0.090952
INFO:root:FL Epoch: 29 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1917
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691333
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676656
INFO:root:FL Epoch: 29 Norm Difference for worker 1917 is 0.204792
INFO:root:FL Epoch: 29 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1341
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697387
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686683
INFO:root:FL Epoch: 29 Norm Difference for worker 1341 is 0.144675
INFO:root:FL Epoch: 29 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :789
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689314
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696547
INFO:root:FL Epoch: 29 Norm Difference for worker 789 is 0.137007
INFO:root:FL Epoch: 29 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :961
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691333
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693285
INFO:root:FL Epoch: 29 Norm Difference for worker 961 is 0.18244
INFO:root:FL Epoch: 29 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1601
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693351
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 29 Norm Difference for worker 1601 is 0.044578
INFO:root:FL Epoch: 29 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1755
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693351
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690834
INFO:root:FL Epoch: 29 Norm Difference for worker 1755 is 0.026402
INFO:root:FL Epoch: 29 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1597
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691333
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686667
INFO:root:FL Epoch: 29 Norm Difference for worker 1597 is 0.024446
INFO:root:FL Epoch: 29 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1906
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693351
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 29 Norm Difference for worker 1906 is 0.016437
INFO:root:FL Epoch: 29 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :545
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697387
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689936
INFO:root:FL Epoch: 29 Norm Difference for worker 545 is 0.086923
INFO:root:FL Epoch: 29 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6936681516030255 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.6708098649978638                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :97
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 97 is 0.091845
INFO:root:FL Epoch: 30 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688884
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693647
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 0.089171
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1598
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693402
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680618
INFO:root:FL Epoch: 30 Norm Difference for worker 1598 is 0.202858
INFO:root:FL Epoch: 30 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1172
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693402
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699113
INFO:root:FL Epoch: 30 Norm Difference for worker 1172 is 0.026273
INFO:root:FL Epoch: 30 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :189
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686625
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 189 is 0.343634
INFO:root:FL Epoch: 30 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1585
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697921
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688598
INFO:root:FL Epoch: 30 Norm Difference for worker 1585 is 0.205971
INFO:root:FL Epoch: 30 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1215
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695662
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683194
INFO:root:FL Epoch: 30 Norm Difference for worker 1215 is 0.10103
INFO:root:FL Epoch: 30 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :439
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695662
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681711
INFO:root:FL Epoch: 30 Norm Difference for worker 439 is 0.128519
INFO:root:FL Epoch: 30 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :573
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691143
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694263
INFO:root:FL Epoch: 30 Norm Difference for worker 573 is 0.065269
INFO:root:FL Epoch: 30 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1311
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688884
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699697
INFO:root:FL Epoch: 30 Norm Difference for worker 1311 is 0.087536
INFO:root:FL Epoch: 30 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6933150536873761 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:0.6831846833229065                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [1693, 599, 1613, 1374, 698, 1310, 1539, 786, 1330, 1413]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 31 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :1693
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697202
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698126
INFO:root:FL Epoch: 31 Norm Difference for worker 1693 is 0.000627
INFO:root:FL Epoch: 31 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :599
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693197
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685057
INFO:root:FL Epoch: 31 Norm Difference for worker 599 is 0.113375
INFO:root:FL Epoch: 31 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1613
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695200
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693103
INFO:root:FL Epoch: 31 Norm Difference for worker 1613 is 0.00151
INFO:root:FL Epoch: 31 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1374
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689192
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693572
INFO:root:FL Epoch: 31 Norm Difference for worker 1374 is 0.04304
INFO:root:FL Epoch: 31 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :698
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693197
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690191
INFO:root:FL Epoch: 31 Norm Difference for worker 698 is 0.025595
INFO:root:FL Epoch: 31 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1310
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694198
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693335
INFO:root:FL Epoch: 31 Norm Difference for worker 1310 is 0.105014
INFO:root:FL Epoch: 31 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1539
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692196
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693855
INFO:root:FL Epoch: 31 Norm Difference for worker 1539 is 0.048887
INFO:root:FL Epoch: 31 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :786
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691195
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708782
INFO:root:FL Epoch: 31 Norm Difference for worker 786 is 0.111552
INFO:root:FL Epoch: 31 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1330
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696201
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697243
INFO:root:FL Epoch: 31 Norm Difference for worker 1330 is 0.314644
INFO:root:FL Epoch: 31 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1413
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694198
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693272
INFO:root:FL Epoch: 31 Norm Difference for worker 1413 is 0.020279
INFO:root:FL Epoch: 31 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6931034607045791 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:0.6977882385253906                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :1528
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692232
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683570
INFO:root:FL Epoch: 32 Norm Difference for worker 1528 is 0.234264
INFO:root:FL Epoch: 32 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :546
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692232
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688021
INFO:root:FL Epoch: 32 Norm Difference for worker 546 is 0.130261
INFO:root:FL Epoch: 32 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1315
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694547
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689348
INFO:root:FL Epoch: 32 Norm Difference for worker 1315 is 0.137682
INFO:root:FL Epoch: 32 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693621
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 0.017006
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :504
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692695
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679838
INFO:root:FL Epoch: 32 Norm Difference for worker 504 is 0.145793
INFO:root:FL Epoch: 32 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :250
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680261
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 250 is 0.218535
INFO:root:FL Epoch: 32 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :655
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694547
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695502
INFO:root:FL Epoch: 32 Norm Difference for worker 655 is 0.238539
INFO:root:FL Epoch: 32 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1640
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681412
INFO:root:FL Epoch: 32 Norm Difference for worker 1640 is 0.264872
INFO:root:FL Epoch: 32 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1386
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692232
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689358
INFO:root:FL Epoch: 32 Norm Difference for worker 1386 is 0.15413
INFO:root:FL Epoch: 32 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :46
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693634
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 46 is 0.138426
INFO:root:FL Epoch: 32 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6930784758399514 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:0.7060428857803345                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1149
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691948
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694669
INFO:root:FL Epoch: 33 Norm Difference for worker 1149 is 0.14241
INFO:root:FL Epoch: 33 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :529
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694511
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708829
INFO:root:FL Epoch: 33 Norm Difference for worker 529 is 0.009796
INFO:root:FL Epoch: 33 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :986
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694511
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696310
INFO:root:FL Epoch: 33 Norm Difference for worker 986 is 0.255387
INFO:root:FL Epoch: 33 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :911
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695792
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696743
INFO:root:FL Epoch: 33 Norm Difference for worker 911 is 0.022787
INFO:root:FL Epoch: 33 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :260
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 260 is 0.102169
INFO:root:FL Epoch: 33 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :855
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691948
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699854
INFO:root:FL Epoch: 33 Norm Difference for worker 855 is 0.046997
INFO:root:FL Epoch: 33 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :478
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694511
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716852
INFO:root:FL Epoch: 33 Norm Difference for worker 478 is 0.185245
INFO:root:FL Epoch: 33 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1001
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690667
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693993
INFO:root:FL Epoch: 33 Norm Difference for worker 1001 is 0.265378
INFO:root:FL Epoch: 33 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :407
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688104
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679880
INFO:root:FL Epoch: 33 Norm Difference for worker 407 is 0.291722
INFO:root:FL Epoch: 33 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1886
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689385
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694815
INFO:root:FL Epoch: 33 Norm Difference for worker 1886 is 0.07784
INFO:root:FL Epoch: 33 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.6931338941349703 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:0.6943332552909851                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1640
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692437
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711883
INFO:root:FL Epoch: 34 Norm Difference for worker 1640 is 0.282181
INFO:root:FL Epoch: 34 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :942
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685962
INFO:root:FL Epoch: 34 Norm Difference for worker 942 is 0.168351
INFO:root:FL Epoch: 34 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :389
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696665
INFO:root:FL Epoch: 34 Norm Difference for worker 389 is 0.057628
INFO:root:FL Epoch: 34 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :907
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693385
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693581
INFO:root:FL Epoch: 34 Norm Difference for worker 907 is 0.01011
INFO:root:FL Epoch: 34 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1081
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692674
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693370
INFO:root:FL Epoch: 34 Norm Difference for worker 1081 is 0.018672
INFO:root:FL Epoch: 34 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1797
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680727
INFO:root:FL Epoch: 34 Norm Difference for worker 1797 is 0.388499
INFO:root:FL Epoch: 34 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1890
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692555
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689444
INFO:root:FL Epoch: 34 Norm Difference for worker 1890 is 0.153432
INFO:root:FL Epoch: 34 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :922
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693741
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661437
INFO:root:FL Epoch: 34 Norm Difference for worker 922 is 0.232859
INFO:root:FL Epoch: 34 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1593
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689623
INFO:root:FL Epoch: 34 Norm Difference for worker 1593 is 0.124965
INFO:root:FL Epoch: 34 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1411
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693805
INFO:root:FL Epoch: 34 Norm Difference for worker 1411 is 0.076013
INFO:root:FL Epoch: 34 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6931411553831661 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:0.6936646103858948                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1678
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693044
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690143
INFO:root:FL Epoch: 35 Norm Difference for worker 1678 is 0.006758
INFO:root:FL Epoch: 35 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1654
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693199
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680654
INFO:root:FL Epoch: 35 Norm Difference for worker 1654 is 0.133061
INFO:root:FL Epoch: 35 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1413
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693096
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686590
INFO:root:FL Epoch: 35 Norm Difference for worker 1413 is 0.060233
INFO:root:FL Epoch: 35 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :547
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693199
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 35 Norm Difference for worker 547 is 0.006232
INFO:root:FL Epoch: 35 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1443
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693096
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684930
INFO:root:FL Epoch: 35 Norm Difference for worker 1443 is 0.232133
INFO:root:FL Epoch: 35 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :144
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 144 is 0.072681
INFO:root:FL Epoch: 35 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :892
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693185
INFO:root:FL Epoch: 35 Norm Difference for worker 892 is 0.030198
INFO:root:FL Epoch: 35 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :191
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 191 is 0.031003
INFO:root:FL Epoch: 35 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :340
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689531
INFO:root:FL Epoch: 35 Norm Difference for worker 340 is 0.213362
INFO:root:FL Epoch: 35 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1558
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693199
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693272
INFO:root:FL Epoch: 35 Norm Difference for worker 1558 is 0.026569
INFO:root:FL Epoch: 35 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6930847904261421 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:0.7087245583534241                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1323
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693267
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699728
INFO:root:FL Epoch: 36 Norm Difference for worker 1323 is 0.113995
INFO:root:FL Epoch: 36 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1216
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697904
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689348
INFO:root:FL Epoch: 36 Norm Difference for worker 1216 is 0.148253
INFO:root:FL Epoch: 36 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697904
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686596
INFO:root:FL Epoch: 36 Norm Difference for worker 1937 is 0.155519
INFO:root:FL Epoch: 36 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :432
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691721
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689982
INFO:root:FL Epoch: 36 Norm Difference for worker 432 is 0.103795
INFO:root:FL Epoch: 36 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1511
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693267
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690679
INFO:root:FL Epoch: 36 Norm Difference for worker 1511 is 0.026086
INFO:root:FL Epoch: 36 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :669
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690175
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693204
INFO:root:FL Epoch: 36 Norm Difference for worker 669 is 0.042082
INFO:root:FL Epoch: 36 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1891
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691721
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 36 Norm Difference for worker 1891 is 0.131734
INFO:root:FL Epoch: 36 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1824
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691721
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699144
INFO:root:FL Epoch: 36 Norm Difference for worker 1824 is 0.118741
INFO:root:FL Epoch: 36 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :228
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 228 is 0.083367
INFO:root:FL Epoch: 36 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :447
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691721
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688631
INFO:root:FL Epoch: 36 Norm Difference for worker 447 is 0.033793
INFO:root:FL Epoch: 36 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6931297779083252 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:0.6947354674339294                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 37 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :400
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686269
INFO:root:FL Epoch: 37 Norm Difference for worker 400 is 0.094936
INFO:root:FL Epoch: 37 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :3
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.709406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 3 is 0.163105
INFO:root:FL Epoch: 37 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1265
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689235
INFO:root:FL Epoch: 37 Norm Difference for worker 1265 is 0.030867
INFO:root:FL Epoch: 37 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :532
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693466
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693075
INFO:root:FL Epoch: 37 Norm Difference for worker 532 is 0.115724
INFO:root:FL Epoch: 37 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1836
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698568
INFO:root:FL Epoch: 37 Norm Difference for worker 1836 is 0.117582
INFO:root:FL Epoch: 37 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :270
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 270 is 0.114177
INFO:root:FL Epoch: 37 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1792
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700098
INFO:root:FL Epoch: 37 Norm Difference for worker 1792 is 0.310554
INFO:root:FL Epoch: 37 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1318
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693307
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702990
INFO:root:FL Epoch: 37 Norm Difference for worker 1318 is 0.157441
INFO:root:FL Epoch: 37 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :159
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 159 is 0.045614
INFO:root:FL Epoch: 37 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :894
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693625
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693286
INFO:root:FL Epoch: 37 Norm Difference for worker 894 is 0.027703
INFO:root:FL Epoch: 37 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.6938465412925271 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:0.7454315423965454                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 38 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :91
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 91 is 0.165907
INFO:root:FL Epoch: 38 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :406
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699545
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693210
INFO:root:FL Epoch: 38 Norm Difference for worker 406 is 0.25106
INFO:root:FL Epoch: 38 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1341
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679151
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688109
INFO:root:FL Epoch: 38 Norm Difference for worker 1341 is 0.276849
INFO:root:FL Epoch: 38 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1142
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704643
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654221
INFO:root:FL Epoch: 38 Norm Difference for worker 1142 is 0.140008
INFO:root:FL Epoch: 38 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :961
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694446
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703291
INFO:root:FL Epoch: 38 Norm Difference for worker 961 is 0.108552
INFO:root:FL Epoch: 38 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1634
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694446
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701171
INFO:root:FL Epoch: 38 Norm Difference for worker 1634 is 0.113842
INFO:root:FL Epoch: 38 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :278
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693280
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 278 is 0.175662
INFO:root:FL Epoch: 38 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1725
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694446
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693571
INFO:root:FL Epoch: 38 Norm Difference for worker 1725 is 0.021787
INFO:root:FL Epoch: 38 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1426
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704643
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686219
INFO:root:FL Epoch: 38 Norm Difference for worker 1426 is 0.046635
INFO:root:FL Epoch: 38 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :171
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704643
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 171 is 0.284981
INFO:root:FL Epoch: 38 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6931636403588688 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:0.6918256878852844                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :793
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692884
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696726
INFO:root:FL Epoch: 39 Norm Difference for worker 793 is 0.041947
INFO:root:FL Epoch: 39 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1430
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692751
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696977
INFO:root:FL Epoch: 39 Norm Difference for worker 1430 is 0.080694
INFO:root:FL Epoch: 39 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1259
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 39 Norm Difference for worker 1259 is 0.012842
INFO:root:FL Epoch: 39 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :83
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693413
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 83 is 0.073472
INFO:root:FL Epoch: 39 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :963
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693545
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690692
INFO:root:FL Epoch: 39 Norm Difference for worker 963 is 0.123629
INFO:root:FL Epoch: 39 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :727
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679319
INFO:root:FL Epoch: 39 Norm Difference for worker 727 is 0.198734
INFO:root:FL Epoch: 39 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1798
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692751
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679082
INFO:root:FL Epoch: 39 Norm Difference for worker 1798 is 0.222825
INFO:root:FL Epoch: 39 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1045
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693016
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684457
INFO:root:FL Epoch: 39 Norm Difference for worker 1045 is 0.268616
INFO:root:FL Epoch: 39 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :795
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693413
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701032
INFO:root:FL Epoch: 39 Norm Difference for worker 795 is 0.093082
INFO:root:FL Epoch: 39 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693016
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687498
INFO:root:FL Epoch: 39 Norm Difference for worker 1544 is 0.148545
INFO:root:FL Epoch: 39 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6936651468276978 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:0.670895516872406                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :1876
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693400
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681369
INFO:root:FL Epoch: 40 Norm Difference for worker 1876 is 0.152523
INFO:root:FL Epoch: 40 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1511
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695651
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693753
INFO:root:FL Epoch: 40 Norm Difference for worker 1511 is 0.008008
INFO:root:FL Epoch: 40 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1817
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691150
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691991
INFO:root:FL Epoch: 40 Norm Difference for worker 1817 is 0.133344
INFO:root:FL Epoch: 40 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :696
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693400
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694238
INFO:root:FL Epoch: 40 Norm Difference for worker 696 is 0.128893
INFO:root:FL Epoch: 40 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :514
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693400
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693591
INFO:root:FL Epoch: 40 Norm Difference for worker 514 is 0.157046
INFO:root:FL Epoch: 40 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :724
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695651
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683728
INFO:root:FL Epoch: 40 Norm Difference for worker 724 is 0.204605
INFO:root:FL Epoch: 40 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :71
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 71 is 0.16369
INFO:root:FL Epoch: 40 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1627
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688899
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691666
INFO:root:FL Epoch: 40 Norm Difference for worker 1627 is 0.094145
INFO:root:FL Epoch: 40 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1036
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688899
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703824
INFO:root:FL Epoch: 40 Norm Difference for worker 1036 is 0.17831
INFO:root:FL Epoch: 40 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1139
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693400
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696782
INFO:root:FL Epoch: 40 Norm Difference for worker 1139 is 0.216498
INFO:root:FL Epoch: 40 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.6932244581334731 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:0.6878089308738708                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [431, 1920, 659, 855, 1679, 48, 359, 1794, 466, 1659]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :431
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692626
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693210
INFO:root:FL Epoch: 41 Norm Difference for worker 431 is 0.069532
INFO:root:FL Epoch: 41 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1920
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691556
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694080
INFO:root:FL Epoch: 41 Norm Difference for worker 1920 is 0.010983
INFO:root:FL Epoch: 41 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693546
INFO:root:FL Epoch: 41 Norm Difference for worker 659 is 0.007105
INFO:root:FL Epoch: 41 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :855
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694767
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689294
INFO:root:FL Epoch: 41 Norm Difference for worker 855 is 0.161137
INFO:root:FL Epoch: 41 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1679
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694232
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685966
INFO:root:FL Epoch: 41 Norm Difference for worker 1679 is 0.131681
INFO:root:FL Epoch: 41 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :48
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691556
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 48 is 0.011489
INFO:root:FL Epoch: 41 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :359
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692626
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697174
INFO:root:FL Epoch: 41 Norm Difference for worker 359 is 0.165523
INFO:root:FL Epoch: 41 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1794
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686486
INFO:root:FL Epoch: 41 Norm Difference for worker 1794 is 0.075186
INFO:root:FL Epoch: 41 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :466
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700204
INFO:root:FL Epoch: 41 Norm Difference for worker 466 is 0.085969
INFO:root:FL Epoch: 41 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691556
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703358
INFO:root:FL Epoch: 41 Norm Difference for worker 1659 is 0.02109
INFO:root:FL Epoch: 41 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.693368631250718 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:0.6808788180351257                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1016
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693223
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682790
INFO:root:FL Epoch: 42 Norm Difference for worker 1016 is 0.210889
INFO:root:FL Epoch: 42 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :758
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693223
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693580
INFO:root:FL Epoch: 42 Norm Difference for worker 758 is 0.013176
INFO:root:FL Epoch: 42 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1919
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690755
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698437
INFO:root:FL Epoch: 42 Norm Difference for worker 1919 is 0.021062
INFO:root:FL Epoch: 42 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1693
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693223
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693162
INFO:root:FL Epoch: 42 Norm Difference for worker 1693 is 0.036231
INFO:root:FL Epoch: 42 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1465
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691989
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688338
INFO:root:FL Epoch: 42 Norm Difference for worker 1465 is 0.268688
INFO:root:FL Epoch: 42 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :882
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695692
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694574
INFO:root:FL Epoch: 42 Norm Difference for worker 882 is 0.008114
INFO:root:FL Epoch: 42 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :176
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 176 is 0.200213
INFO:root:FL Epoch: 42 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1854
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689520
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693192
INFO:root:FL Epoch: 42 Norm Difference for worker 1854 is 0.127932
INFO:root:FL Epoch: 42 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :107
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 107 is 0.172411
INFO:root:FL Epoch: 42 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :77
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695130
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 77 is 0.046463
INFO:root:FL Epoch: 42 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6934109435361975 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:0.6792058944702148                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 43 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :301
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 301 is 0.219195
INFO:root:FL Epoch: 43 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :961
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691842
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693664
INFO:root:FL Epoch: 43 Norm Difference for worker 961 is 0.233111
INFO:root:FL Epoch: 43 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1081
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693246
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688199
INFO:root:FL Epoch: 43 Norm Difference for worker 1081 is 0.041906
INFO:root:FL Epoch: 43 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :165
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 165 is 0.045969
INFO:root:FL Epoch: 43 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1765
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689034
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678463
INFO:root:FL Epoch: 43 Norm Difference for worker 1765 is 0.171517
INFO:root:FL Epoch: 43 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 0.210425
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :21
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 21 is 0.145416
INFO:root:FL Epoch: 43 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :425
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687630
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676670
INFO:root:FL Epoch: 43 Norm Difference for worker 425 is 0.213595
INFO:root:FL Epoch: 43 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1827
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693246
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692506
INFO:root:FL Epoch: 43 Norm Difference for worker 1827 is 0.06417
INFO:root:FL Epoch: 43 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1721
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690438
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698935
INFO:root:FL Epoch: 43 Norm Difference for worker 1721 is 0.084011
INFO:root:FL Epoch: 43 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6938965285525602 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.6648612022399902                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :617
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687819
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688208
INFO:root:FL Epoch: 44 Norm Difference for worker 617 is 0.254173
INFO:root:FL Epoch: 44 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :842
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687819
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691046
INFO:root:FL Epoch: 44 Norm Difference for worker 842 is 0.26048
INFO:root:FL Epoch: 44 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :851
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693559
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694944
INFO:root:FL Epoch: 44 Norm Difference for worker 851 is 0.075887
INFO:root:FL Epoch: 44 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :604
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693559
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688250
INFO:root:FL Epoch: 44 Norm Difference for worker 604 is 0.04166
INFO:root:FL Epoch: 44 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1478
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693559
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695299
INFO:root:FL Epoch: 44 Norm Difference for worker 1478 is 0.130774
INFO:root:FL Epoch: 44 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1239
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699298
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693376
INFO:root:FL Epoch: 44 Norm Difference for worker 1239 is 0.019345
INFO:root:FL Epoch: 44 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1744
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693559
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692610
INFO:root:FL Epoch: 44 Norm Difference for worker 1744 is 0.103895
INFO:root:FL Epoch: 44 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1946
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696429
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691175
INFO:root:FL Epoch: 44 Norm Difference for worker 1946 is 0.071073
INFO:root:FL Epoch: 44 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1499
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690689
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693754
INFO:root:FL Epoch: 44 Norm Difference for worker 1499 is 0.044734
INFO:root:FL Epoch: 44 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1072
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699299
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693507
INFO:root:FL Epoch: 44 Norm Difference for worker 1072 is 0.050746
INFO:root:FL Epoch: 44 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6937805834938499 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:0.6677573919296265                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :284
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693609
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 284 is 0.046118
INFO:root:FL Epoch: 45 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :629
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696050
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694332
INFO:root:FL Epoch: 45 Norm Difference for worker 629 is 0.073437
INFO:root:FL Epoch: 45 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1483
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696050
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690893
INFO:root:FL Epoch: 45 Norm Difference for worker 1483 is 0.048642
INFO:root:FL Epoch: 45 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :496
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698622
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689167
INFO:root:FL Epoch: 45 Norm Difference for worker 496 is 0.110431
INFO:root:FL Epoch: 45 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1902
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685762
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690669
INFO:root:FL Epoch: 45 Norm Difference for worker 1902 is 0.043603
INFO:root:FL Epoch: 45 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :261
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686338
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 261 is 0.093084
INFO:root:FL Epoch: 45 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1691
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690028
INFO:root:FL Epoch: 45 Norm Difference for worker 1691 is 0.040562
INFO:root:FL Epoch: 45 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :309
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706338
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 309 is 0.047036
INFO:root:FL Epoch: 45 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :195
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 195 is 0.203472
INFO:root:FL Epoch: 45 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :346
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703766
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690814
INFO:root:FL Epoch: 45 Norm Difference for worker 346 is 0.203707
INFO:root:FL Epoch: 45 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6937098187558791 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:0.6696444153785706                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1012
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688673
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693974
INFO:root:FL Epoch: 46 Norm Difference for worker 1012 is 0.018636
INFO:root:FL Epoch: 46 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1287
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686294
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695676
INFO:root:FL Epoch: 46 Norm Difference for worker 1287 is 0.048845
INFO:root:FL Epoch: 46 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1772
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686294
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693166
INFO:root:FL Epoch: 46 Norm Difference for worker 1772 is 0.255919
INFO:root:FL Epoch: 46 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :973
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698187
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689096
INFO:root:FL Epoch: 46 Norm Difference for worker 973 is 0.257116
INFO:root:FL Epoch: 46 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :355
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686294
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692984
INFO:root:FL Epoch: 46 Norm Difference for worker 355 is 0.260151
INFO:root:FL Epoch: 46 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :15
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683916
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 15 is 0.062036
INFO:root:FL Epoch: 46 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1335
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686294
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697459
INFO:root:FL Epoch: 46 Norm Difference for worker 1335 is 0.273625
INFO:root:FL Epoch: 46 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :859
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691051
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687286
INFO:root:FL Epoch: 46 Norm Difference for worker 859 is 0.136925
INFO:root:FL Epoch: 46 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1060
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693430
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698952
INFO:root:FL Epoch: 46 Norm Difference for worker 1060 is 0.350129
INFO:root:FL Epoch: 46 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1175
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688673
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693376
INFO:root:FL Epoch: 46 Norm Difference for worker 1175 is 0.23645
INFO:root:FL Epoch: 46 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6933649953673867 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:0.7295164465904236                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1026
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683066
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673885
INFO:root:FL Epoch: 47 Norm Difference for worker 1026 is 0.1201
INFO:root:FL Epoch: 47 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1386
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683066
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688880
INFO:root:FL Epoch: 47 Norm Difference for worker 1386 is 0.082426
INFO:root:FL Epoch: 47 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :370
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697358
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697831
INFO:root:FL Epoch: 47 Norm Difference for worker 370 is 0.164741
INFO:root:FL Epoch: 47 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1316
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704505
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692934
INFO:root:FL Epoch: 47 Norm Difference for worker 1316 is 0.125066
INFO:root:FL Epoch: 47 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1423
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697358
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688911
INFO:root:FL Epoch: 47 Norm Difference for worker 1423 is 0.047457
INFO:root:FL Epoch: 47 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1323
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700932
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694106
INFO:root:FL Epoch: 47 Norm Difference for worker 1323 is 0.176356
INFO:root:FL Epoch: 47 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1440
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686639
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689411
INFO:root:FL Epoch: 47 Norm Difference for worker 1440 is 0.085176
INFO:root:FL Epoch: 47 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :374
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693785
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 47 Norm Difference for worker 374 is 0.318087
INFO:root:FL Epoch: 47 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :641
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693785
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698895
INFO:root:FL Epoch: 47 Norm Difference for worker 641 is 0.018802
INFO:root:FL Epoch: 47 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :685
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708078
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692854
INFO:root:FL Epoch: 47 Norm Difference for worker 685 is 0.153067
INFO:root:FL Epoch: 47 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.6931030469782212 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:0.6978411078453064                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :742
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694095
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692967
INFO:root:FL Epoch: 48 Norm Difference for worker 742 is 0.055304
INFO:root:FL Epoch: 48 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :885
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692690
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682532
INFO:root:FL Epoch: 48 Norm Difference for worker 885 is 0.298937
INFO:root:FL Epoch: 48 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :169
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 169 is 0.090208
INFO:root:FL Epoch: 48 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694095
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682941
INFO:root:FL Epoch: 48 Norm Difference for worker 1527 is 0.183577
INFO:root:FL Epoch: 48 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :884
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694095
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698567
INFO:root:FL Epoch: 48 Norm Difference for worker 884 is 0.115319
INFO:root:FL Epoch: 48 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1072
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692690
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695371
INFO:root:FL Epoch: 48 Norm Difference for worker 1072 is 0.078282
INFO:root:FL Epoch: 48 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :458
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692222
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699887
INFO:root:FL Epoch: 48 Norm Difference for worker 458 is 0.096964
INFO:root:FL Epoch: 48 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1623
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693626
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690660
INFO:root:FL Epoch: 48 Norm Difference for worker 1623 is 0.033318
INFO:root:FL Epoch: 48 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1318
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693626
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697899
INFO:root:FL Epoch: 48 Norm Difference for worker 1318 is 0.147653
INFO:root:FL Epoch: 48 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1808
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691753
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690824
INFO:root:FL Epoch: 48 Norm Difference for worker 1808 is 0.058388
INFO:root:FL Epoch: 48 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.693125868544859 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:0.7149242162704468                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :1089
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693379
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700803
INFO:root:FL Epoch: 49 Norm Difference for worker 1089 is 0.114401
INFO:root:FL Epoch: 49 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1220
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693379
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 49 Norm Difference for worker 1220 is 0.064464
INFO:root:FL Epoch: 49 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :832
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693379
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697192
INFO:root:FL Epoch: 49 Norm Difference for worker 832 is 0.080498
INFO:root:FL Epoch: 49 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :348
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684761
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689760
INFO:root:FL Epoch: 49 Norm Difference for worker 348 is 0.021475
INFO:root:FL Epoch: 49 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1483
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697688
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686119
INFO:root:FL Epoch: 49 Norm Difference for worker 1483 is 0.144128
INFO:root:FL Epoch: 49 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1709
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697688
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691535
INFO:root:FL Epoch: 49 Norm Difference for worker 1709 is 0.047758
INFO:root:FL Epoch: 49 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :170
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699843
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 170 is 0.317061
INFO:root:FL Epoch: 49 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701997
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695315
INFO:root:FL Epoch: 49 Norm Difference for worker 862 is 0.147987
INFO:root:FL Epoch: 49 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1619
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691225
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686045
INFO:root:FL Epoch: 49 Norm Difference for worker 1619 is 0.102227
INFO:root:FL Epoch: 49 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :52
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 52 is 0.070455
INFO:root:FL Epoch: 49 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.6937114982043996 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:0.6695991158485413                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :1159
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691556
INFO:root:FL Epoch: 50 Norm Difference for worker 1159 is 0.105188
INFO:root:FL Epoch: 50 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :973
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698197
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695844
INFO:root:FL Epoch: 50 Norm Difference for worker 973 is 0.200526
INFO:root:FL Epoch: 50 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :918
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700581
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688722
INFO:root:FL Epoch: 50 Norm Difference for worker 918 is 0.132149
INFO:root:FL Epoch: 50 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :978
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693177
INFO:root:FL Epoch: 50 Norm Difference for worker 978 is 0.035431
INFO:root:FL Epoch: 50 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1454
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694416
INFO:root:FL Epoch: 50 Norm Difference for worker 1454 is 0.073942
INFO:root:FL Epoch: 50 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1102
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691048
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694850
INFO:root:FL Epoch: 50 Norm Difference for worker 1102 is 0.222474
INFO:root:FL Epoch: 50 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :762
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686282
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685361
INFO:root:FL Epoch: 50 Norm Difference for worker 762 is 0.115797
INFO:root:FL Epoch: 50 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :302
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 302 is 0.142766
INFO:root:FL Epoch: 50 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1871
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698198
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693403
INFO:root:FL Epoch: 50 Norm Difference for worker 1871 is 0.087415
INFO:root:FL Epoch: 50 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :580
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686282
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682657
INFO:root:FL Epoch: 50 Norm Difference for worker 580 is 0.30842
INFO:root:FL Epoch: 50 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6930794540573569 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:0.7032194137573242                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [1942, 848, 888, 1807, 655, 164, 302, 119, 1277, 1553]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 200 200 200 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :1942
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693197
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693156
INFO:root:FL Epoch: 51 Norm Difference for worker 1942 is 0.033976
INFO:root:FL Epoch: 51 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :848
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694200
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683932
INFO:root:FL Epoch: 51 Norm Difference for worker 848 is 0.181019
INFO:root:FL Epoch: 51 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :888
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691193
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692470
INFO:root:FL Epoch: 51 Norm Difference for worker 888 is 0.006939
INFO:root:FL Epoch: 51 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1807
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694200
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680750
INFO:root:FL Epoch: 51 Norm Difference for worker 1807 is 0.365091
INFO:root:FL Epoch: 51 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :655
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694200
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678839
INFO:root:FL Epoch: 51 Norm Difference for worker 655 is 0.288191
INFO:root:FL Epoch: 51 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :164
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 164 is 0.056467
INFO:root:FL Epoch: 51 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :302
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 302 is 0.073021
INFO:root:FL Epoch: 51 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :119
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692195
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675039
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 119 is 0.308037
INFO:root:FL Epoch: 51 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1277
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697206
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691871
INFO:root:FL Epoch: 51 Norm Difference for worker 1277 is 0.072007
INFO:root:FL Epoch: 51 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1553
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691193
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698089
INFO:root:FL Epoch: 51 Norm Difference for worker 1553 is 0.11521
INFO:root:FL Epoch: 51 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.6933120489120483 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:0.6833246946334839                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :410
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691222
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695665
INFO:root:FL Epoch: 52 Norm Difference for worker 410 is 0.096048
INFO:root:FL Epoch: 52 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :710
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696157
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693338
INFO:root:FL Epoch: 52 Norm Difference for worker 710 is 0.041428
INFO:root:FL Epoch: 52 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1013
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694183
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691052
INFO:root:FL Epoch: 52 Norm Difference for worker 1013 is 0.096432
INFO:root:FL Epoch: 52 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :60
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690235
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 60 is 0.033176
INFO:root:FL Epoch: 52 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :109
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692209
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 109 is 0.131138
INFO:root:FL Epoch: 52 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1576
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695170
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690270
INFO:root:FL Epoch: 52 Norm Difference for worker 1576 is 0.110757
INFO:root:FL Epoch: 52 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :931
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691222
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697812
INFO:root:FL Epoch: 52 Norm Difference for worker 931 is 0.007281
INFO:root:FL Epoch: 52 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :407
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695170
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675118
INFO:root:FL Epoch: 52 Norm Difference for worker 407 is 0.363172
INFO:root:FL Epoch: 52 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :697
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693196
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696962
INFO:root:FL Epoch: 52 Norm Difference for worker 697 is 0.109485
INFO:root:FL Epoch: 52 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1217
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691222
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669791
INFO:root:FL Epoch: 52 Norm Difference for worker 1217 is 0.323792
INFO:root:FL Epoch: 52 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.6935154830708223 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:0.6754921674728394                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1299
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689743
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692783
INFO:root:FL Epoch: 53 Norm Difference for worker 1299 is 0.12111
INFO:root:FL Epoch: 53 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :593
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696869
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695835
INFO:root:FL Epoch: 53 Norm Difference for worker 593 is 0.021042
INFO:root:FL Epoch: 53 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1438
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693306
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693405
INFO:root:FL Epoch: 53 Norm Difference for worker 1438 is 0.030149
INFO:root:FL Epoch: 53 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1891
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684399
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700246
INFO:root:FL Epoch: 53 Norm Difference for worker 1891 is 0.049545
INFO:root:FL Epoch: 53 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1705
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691525
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692890
INFO:root:FL Epoch: 53 Norm Difference for worker 1705 is 0.005878
INFO:root:FL Epoch: 53 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1052
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695087
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692570
INFO:root:FL Epoch: 53 Norm Difference for worker 1052 is 0.0157
INFO:root:FL Epoch: 53 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1474
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700431
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696651
INFO:root:FL Epoch: 53 Norm Difference for worker 1474 is 0.076583
INFO:root:FL Epoch: 53 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :550
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689743
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693580
INFO:root:FL Epoch: 53 Norm Difference for worker 550 is 0.071591
INFO:root:FL Epoch: 53 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :475
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691525
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692967
INFO:root:FL Epoch: 53 Norm Difference for worker 475 is 0.075246
INFO:root:FL Epoch: 53 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1925
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686180
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685528
INFO:root:FL Epoch: 53 Norm Difference for worker 1925 is 0.115414
INFO:root:FL Epoch: 53 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.6935708066996407 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:0.6737070679664612                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 54 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :1628
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693340
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669909
INFO:root:FL Epoch: 54 Norm Difference for worker 1628 is 0.32358
INFO:root:FL Epoch: 54 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :165
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691377
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 165 is 0.020487
INFO:root:FL Epoch: 54 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :671
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695303
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693096
INFO:root:FL Epoch: 54 Norm Difference for worker 671 is 0.053625
INFO:root:FL Epoch: 54 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :216
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 216 is 0.003566
INFO:root:FL Epoch: 54 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :620
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689413
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694291
INFO:root:FL Epoch: 54 Norm Difference for worker 620 is 0.21966
INFO:root:FL Epoch: 54 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :465
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697266
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693532
INFO:root:FL Epoch: 54 Norm Difference for worker 465 is 0.082906
INFO:root:FL Epoch: 54 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :72
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695303
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 72 is 0.021943
INFO:root:FL Epoch: 54 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :559
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697266
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693288
INFO:root:FL Epoch: 54 Norm Difference for worker 559 is 0.020296
INFO:root:FL Epoch: 54 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :886
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693340
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693619
INFO:root:FL Epoch: 54 Norm Difference for worker 886 is 0.055685
INFO:root:FL Epoch: 54 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1530
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695303
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660647
INFO:root:FL Epoch: 54 Norm Difference for worker 1530 is 0.50044
INFO:root:FL Epoch: 54 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.6933934793752783 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:0.679880678653717                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1536
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689230
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690790
INFO:root:FL Epoch: 55 Norm Difference for worker 1536 is 0.089526
INFO:root:FL Epoch: 55 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1204
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694572
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686250
INFO:root:FL Epoch: 55 Norm Difference for worker 1204 is 0.257851
INFO:root:FL Epoch: 55 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1550
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687894
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690138
INFO:root:FL Epoch: 55 Norm Difference for worker 1550 is 0.037376
INFO:root:FL Epoch: 55 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1139
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691901
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695525
INFO:root:FL Epoch: 55 Norm Difference for worker 1139 is 0.164534
INFO:root:FL Epoch: 55 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :735
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693204
INFO:root:FL Epoch: 55 Norm Difference for worker 735 is 0.123647
INFO:root:FL Epoch: 55 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1804
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694572
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690282
INFO:root:FL Epoch: 55 Norm Difference for worker 1804 is 0.01312
INFO:root:FL Epoch: 55 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1303
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695907
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688168
INFO:root:FL Epoch: 55 Norm Difference for worker 1303 is 0.130153
INFO:root:FL Epoch: 55 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :856
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689230
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682167
INFO:root:FL Epoch: 55 Norm Difference for worker 856 is 0.250965
INFO:root:FL Epoch: 55 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1587
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693420
INFO:root:FL Epoch: 55 Norm Difference for worker 1587 is 0.055275
INFO:root:FL Epoch: 55 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :124
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679353
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 124 is 0.252238
INFO:root:FL Epoch: 55 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6937704787534826 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:0.6680165529251099                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 56 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :103
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 103 is 0.114765
INFO:root:FL Epoch: 56 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :47
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 47 is 0.162732
INFO:root:FL Epoch: 56 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1805
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683289
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696342
INFO:root:FL Epoch: 56 Norm Difference for worker 1805 is 0.108155
INFO:root:FL Epoch: 56 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1280
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685835
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694841
INFO:root:FL Epoch: 56 Norm Difference for worker 1280 is 0.086689
INFO:root:FL Epoch: 56 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1599
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693471
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696097
INFO:root:FL Epoch: 56 Norm Difference for worker 1599 is 0.024744
INFO:root:FL Epoch: 56 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1088
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696016
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692563
INFO:root:FL Epoch: 56 Norm Difference for worker 1088 is 0.12216
INFO:root:FL Epoch: 56 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1092
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701107
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692358
INFO:root:FL Epoch: 56 Norm Difference for worker 1092 is 0.008139
INFO:root:FL Epoch: 56 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1468
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685835
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696352
INFO:root:FL Epoch: 56 Norm Difference for worker 1468 is 0.179305
INFO:root:FL Epoch: 56 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :962
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698562
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697554
INFO:root:FL Epoch: 56 Norm Difference for worker 962 is 0.132361
INFO:root:FL Epoch: 56 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1742
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685835
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690873
INFO:root:FL Epoch: 56 Norm Difference for worker 1742 is 0.220205
INFO:root:FL Epoch: 56 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.6931997642797583 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:0.6893113851547241                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :1087
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692770
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689341
INFO:root:FL Epoch: 57 Norm Difference for worker 1087 is 0.157323
INFO:root:FL Epoch: 57 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :51
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 51 is 0.149479
INFO:root:FL Epoch: 57 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :352
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693539
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688320
INFO:root:FL Epoch: 57 Norm Difference for worker 352 is 0.0739
INFO:root:FL Epoch: 57 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1760
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693923
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692817
INFO:root:FL Epoch: 57 Norm Difference for worker 1760 is 0.008129
INFO:root:FL Epoch: 57 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1518
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694692
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699072
INFO:root:FL Epoch: 57 Norm Difference for worker 1518 is 0.075626
INFO:root:FL Epoch: 57 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1886
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692386
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693284
INFO:root:FL Epoch: 57 Norm Difference for worker 1886 is 0.022434
INFO:root:FL Epoch: 57 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1418
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693923
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693813
INFO:root:FL Epoch: 57 Norm Difference for worker 1418 is 0.137871
INFO:root:FL Epoch: 57 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :593
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692770
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693238
INFO:root:FL Epoch: 57 Norm Difference for worker 593 is 0.058989
INFO:root:FL Epoch: 57 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :803
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692386
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687474
INFO:root:FL Epoch: 57 Norm Difference for worker 803 is 0.105475
INFO:root:FL Epoch: 57 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1360
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691617
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693235
INFO:root:FL Epoch: 57 Norm Difference for worker 1360 is 0.026954
INFO:root:FL Epoch: 57 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6930788019124199 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:0.7062487602233887                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1472
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693232
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695569
INFO:root:FL Epoch: 58 Norm Difference for worker 1472 is 0.216778
INFO:root:FL Epoch: 58 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :142
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 142 is 0.196158
INFO:root:FL Epoch: 58 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :686
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695835
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692435
INFO:root:FL Epoch: 58 Norm Difference for worker 686 is 0.031896
INFO:root:FL Epoch: 58 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1238
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694410
INFO:root:FL Epoch: 58 Norm Difference for worker 1238 is 0.039063
INFO:root:FL Epoch: 58 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :610
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693931
INFO:root:FL Epoch: 58 Norm Difference for worker 610 is 0.12965
INFO:root:FL Epoch: 58 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :438
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688025
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686060
INFO:root:FL Epoch: 58 Norm Difference for worker 438 is 0.403666
INFO:root:FL Epoch: 58 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1853
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695835
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693718
INFO:root:FL Epoch: 58 Norm Difference for worker 1853 is 0.017193
INFO:root:FL Epoch: 58 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1371
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692163
INFO:root:FL Epoch: 58 Norm Difference for worker 1371 is 0.074328
INFO:root:FL Epoch: 58 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :839
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695259
INFO:root:FL Epoch: 58 Norm Difference for worker 839 is 0.066816
INFO:root:FL Epoch: 58 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1439
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694816
INFO:root:FL Epoch: 58 Norm Difference for worker 1439 is 0.052655
INFO:root:FL Epoch: 58 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6942883274134468 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:0.6564087867736816                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1354
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693848
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701396
INFO:root:FL Epoch: 59 Norm Difference for worker 1354 is 0.10385
INFO:root:FL Epoch: 59 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :228
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 228 is 0.144044
INFO:root:FL Epoch: 59 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :462
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693848
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698623
INFO:root:FL Epoch: 59 Norm Difference for worker 462 is 0.056014
INFO:root:FL Epoch: 59 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1636
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686360
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682732
INFO:root:FL Epoch: 59 Norm Difference for worker 1636 is 0.37141
INFO:root:FL Epoch: 59 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1046
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690104
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693382
INFO:root:FL Epoch: 59 Norm Difference for worker 1046 is 0.241129
INFO:root:FL Epoch: 59 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1188
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705080
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695387
INFO:root:FL Epoch: 59 Norm Difference for worker 1188 is 0.026816
INFO:root:FL Epoch: 59 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1882
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686360
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679608
INFO:root:FL Epoch: 59 Norm Difference for worker 1882 is 0.04863
INFO:root:FL Epoch: 59 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1003
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690104
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691872
INFO:root:FL Epoch: 59 Norm Difference for worker 1003 is 0.076959
INFO:root:FL Epoch: 59 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1658
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693848
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696079
INFO:root:FL Epoch: 59 Norm Difference for worker 1658 is 0.334162
INFO:root:FL Epoch: 59 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1075
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678872
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703037
INFO:root:FL Epoch: 59 Norm Difference for worker 1075 is 0.018455
INFO:root:FL Epoch: 59 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6931558987673592 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:0.7176905274391174                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :160
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683741
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 160 is 0.001245
INFO:root:FL Epoch: 60 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1460
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695866
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690883
INFO:root:FL Epoch: 60 Norm Difference for worker 1460 is 0.033109
INFO:root:FL Epoch: 60 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1369
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683741
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693837
INFO:root:FL Epoch: 60 Norm Difference for worker 1369 is 0.019836
INFO:root:FL Epoch: 60 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1465
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691016
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697395
INFO:root:FL Epoch: 60 Norm Difference for worker 1465 is 0.320152
INFO:root:FL Epoch: 60 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :920
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681316
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699603
INFO:root:FL Epoch: 60 Norm Difference for worker 920 is 0.045499
INFO:root:FL Epoch: 60 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :167
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 167 is 0.146949
INFO:root:FL Epoch: 60 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :434
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693441
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694406
INFO:root:FL Epoch: 60 Norm Difference for worker 434 is 0.038189
INFO:root:FL Epoch: 60 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :908
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700716
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675876
INFO:root:FL Epoch: 60 Norm Difference for worker 908 is 0.336099
INFO:root:FL Epoch: 60 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1014
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691016
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693236
INFO:root:FL Epoch: 60 Norm Difference for worker 1014 is 0.113427
INFO:root:FL Epoch: 60 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1614
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691016
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681082
INFO:root:FL Epoch: 60 Norm Difference for worker 1614 is 0.022069
INFO:root:FL Epoch: 60 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.6937676387674668 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:0.6680927872657776                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [1377, 126, 1194, 362, 1279, 1826, 1404, 1802, 128, 1290]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 61 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :1377
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701082
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688148
INFO:root:FL Epoch: 61 Norm Difference for worker 1377 is 0.254378
INFO:root:FL Epoch: 61 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :126
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 126 is 0.001073
INFO:root:FL Epoch: 61 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1194
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683319
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685276
INFO:root:FL Epoch: 61 Norm Difference for worker 1194 is 0.066895
INFO:root:FL Epoch: 61 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :362
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693469
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699506
INFO:root:FL Epoch: 61 Norm Difference for worker 362 is 0.153064
INFO:root:FL Epoch: 61 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1279
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696007
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692211
INFO:root:FL Epoch: 61 Norm Difference for worker 1279 is 0.133265
INFO:root:FL Epoch: 61 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1826
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688394
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 61 Norm Difference for worker 1826 is 0.124561
INFO:root:FL Epoch: 61 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1404
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688394
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697863
INFO:root:FL Epoch: 61 Norm Difference for worker 1404 is 0.087149
INFO:root:FL Epoch: 61 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1802
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698544
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691392
INFO:root:FL Epoch: 61 Norm Difference for worker 1802 is 0.003216
INFO:root:FL Epoch: 61 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :128
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693294
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 128 is 0.042756
INFO:root:FL Epoch: 61 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1290
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696007
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690526
INFO:root:FL Epoch: 61 Norm Difference for worker 1290 is 0.102381
INFO:root:FL Epoch: 61 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.693127411253312 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:0.6949687600135803                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :228
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 228 is 0.162193
INFO:root:FL Epoch: 62 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :380
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692967
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688752
INFO:root:FL Epoch: 62 Norm Difference for worker 380 is 0.141423
INFO:root:FL Epoch: 62 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1593
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692967
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687918
INFO:root:FL Epoch: 62 Norm Difference for worker 1593 is 0.125382
INFO:root:FL Epoch: 62 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1340
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692319
INFO:root:FL Epoch: 62 Norm Difference for worker 1340 is 0.094081
INFO:root:FL Epoch: 62 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :838
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692603
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686594
INFO:root:FL Epoch: 62 Norm Difference for worker 838 is 0.030775
INFO:root:FL Epoch: 62 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :117
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686841
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 117 is 0.070143
INFO:root:FL Epoch: 62 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :48
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 48 is 0.036802
INFO:root:FL Epoch: 62 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :793
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693331
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689380
INFO:root:FL Epoch: 62 Norm Difference for worker 793 is 0.003734
INFO:root:FL Epoch: 62 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1118
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692813
INFO:root:FL Epoch: 62 Norm Difference for worker 1118 is 0.022339
INFO:root:FL Epoch: 62 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1657
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693513
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687539
INFO:root:FL Epoch: 62 Norm Difference for worker 1657 is 0.129638
INFO:root:FL Epoch: 62 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.6931326634743634 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:0.7156282067298889                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1234
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686724
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682304
INFO:root:FL Epoch: 63 Norm Difference for worker 1234 is 0.092515
INFO:root:FL Epoch: 63 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :729
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702288
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 63 Norm Difference for worker 729 is 0.098609
INFO:root:FL Epoch: 63 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :469
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695618
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680551
INFO:root:FL Epoch: 63 Norm Difference for worker 469 is 0.114953
INFO:root:FL Epoch: 63 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :846
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688947
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691873
INFO:root:FL Epoch: 63 Norm Difference for worker 846 is 0.054194
INFO:root:FL Epoch: 63 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1600
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697841
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692178
INFO:root:FL Epoch: 63 Norm Difference for worker 1600 is 0.029611
INFO:root:FL Epoch: 63 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :157
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686724
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 157 is 0.08294
INFO:root:FL Epoch: 63 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1182
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684501
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693246
INFO:root:FL Epoch: 63 Norm Difference for worker 1182 is 0.052835
INFO:root:FL Epoch: 63 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1061
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691171
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676511
INFO:root:FL Epoch: 63 Norm Difference for worker 1061 is 0.200806
INFO:root:FL Epoch: 63 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1408
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688947
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696243
INFO:root:FL Epoch: 63 Norm Difference for worker 1408 is 0.17313
INFO:root:FL Epoch: 63 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :650
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700064
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677649
INFO:root:FL Epoch: 63 Norm Difference for worker 650 is 0.225205
INFO:root:FL Epoch: 63 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.6931165807387408 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:0.7139149308204651                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :207
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 207 is 0.109849
INFO:root:FL Epoch: 64 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :542
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699525
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696312
INFO:root:FL Epoch: 64 Norm Difference for worker 542 is 0.230707
INFO:root:FL Epoch: 64 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1793
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693358
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684659
INFO:root:FL Epoch: 64 Norm Difference for worker 1793 is 0.209898
INFO:root:FL Epoch: 64 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1161
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693358
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688667
INFO:root:FL Epoch: 64 Norm Difference for worker 1161 is 0.019632
INFO:root:FL Epoch: 64 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1832
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697470
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693178
INFO:root:FL Epoch: 64 Norm Difference for worker 1832 is 0.106245
INFO:root:FL Epoch: 64 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1180
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695414
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696260
INFO:root:FL Epoch: 64 Norm Difference for worker 1180 is 0.013027
INFO:root:FL Epoch: 64 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1370
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691303
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689726
INFO:root:FL Epoch: 64 Norm Difference for worker 1370 is 0.185425
INFO:root:FL Epoch: 64 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :679
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699525
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689036
INFO:root:FL Epoch: 64 Norm Difference for worker 679 is 0.306859
INFO:root:FL Epoch: 64 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1235
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699525
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694879
INFO:root:FL Epoch: 64 Norm Difference for worker 1235 is 0.090725
INFO:root:FL Epoch: 64 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :562
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693358
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693362
INFO:root:FL Epoch: 64 Norm Difference for worker 562 is 0.153249
INFO:root:FL Epoch: 64 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.6939387356533724 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:0.6638621687889099                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 65 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :7
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 7 is 0.104751
INFO:root:FL Epoch: 65 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :806
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687644
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696234
INFO:root:FL Epoch: 65 Norm Difference for worker 806 is 0.023241
INFO:root:FL Epoch: 65 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :172
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 172 is 0.081642
INFO:root:FL Epoch: 65 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :751
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693589
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689855
INFO:root:FL Epoch: 65 Norm Difference for worker 751 is 0.019358
INFO:root:FL Epoch: 65 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :922
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684671
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672817
INFO:root:FL Epoch: 65 Norm Difference for worker 922 is 0.135937
INFO:root:FL Epoch: 65 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1606
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684671
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697586
INFO:root:FL Epoch: 65 Norm Difference for worker 1606 is 0.064419
INFO:root:FL Epoch: 65 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :904
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684671
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688697
INFO:root:FL Epoch: 65 Norm Difference for worker 904 is 0.05438
INFO:root:FL Epoch: 65 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1023
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690616
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699816
INFO:root:FL Epoch: 65 Norm Difference for worker 1023 is 0.058928
INFO:root:FL Epoch: 65 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :451
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690616
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689719
INFO:root:FL Epoch: 65 Norm Difference for worker 451 is 0.106866
INFO:root:FL Epoch: 65 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :871
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684671
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684267
INFO:root:FL Epoch: 65 Norm Difference for worker 871 is 0.10694
INFO:root:FL Epoch: 65 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.6943237255601322 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:0.6557210683822632                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1824
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697690
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691674
INFO:root:FL Epoch: 66 Norm Difference for worker 1824 is 0.253529
INFO:root:FL Epoch: 66 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :776
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693875
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688103
INFO:root:FL Epoch: 66 Norm Difference for worker 776 is 0.007897
INFO:root:FL Epoch: 66 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :679
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690060
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680745
INFO:root:FL Epoch: 66 Norm Difference for worker 679 is 0.219483
INFO:root:FL Epoch: 66 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1263
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693875
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691066
INFO:root:FL Epoch: 66 Norm Difference for worker 1263 is 0.159475
INFO:root:FL Epoch: 66 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1658
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697690
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691557
INFO:root:FL Epoch: 66 Norm Difference for worker 1658 is 0.298902
INFO:root:FL Epoch: 66 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :161
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 161 is 0.069088
INFO:root:FL Epoch: 66 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :623
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705321
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687314
INFO:root:FL Epoch: 66 Norm Difference for worker 623 is 0.117545
INFO:root:FL Epoch: 66 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1308
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686244
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696726
INFO:root:FL Epoch: 66 Norm Difference for worker 1308 is 0.093398
INFO:root:FL Epoch: 66 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :248
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 248 is 0.307564
INFO:root:FL Epoch: 66 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :692
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690059
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690688
INFO:root:FL Epoch: 66 Norm Difference for worker 692 is 0.061471
INFO:root:FL Epoch: 66 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.6930781813228831 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:0.7056398987770081                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :1855
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693224
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693672
INFO:root:FL Epoch: 67 Norm Difference for worker 1855 is 0.086403
INFO:root:FL Epoch: 67 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :447
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689500
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694342
INFO:root:FL Epoch: 67 Norm Difference for worker 447 is 0.008921
INFO:root:FL Epoch: 67 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :860
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693224
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693955
INFO:root:FL Epoch: 67 Norm Difference for worker 860 is 0.25576
INFO:root:FL Epoch: 67 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694466
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691062
INFO:root:FL Epoch: 67 Norm Difference for worker 1575 is 0.151989
INFO:root:FL Epoch: 67 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :818
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693224
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674922
INFO:root:FL Epoch: 67 Norm Difference for worker 818 is 0.227395
INFO:root:FL Epoch: 67 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1745
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694466
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688039
INFO:root:FL Epoch: 67 Norm Difference for worker 1745 is 0.090053
INFO:root:FL Epoch: 67 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :201
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690741
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 201 is 0.151589
INFO:root:FL Epoch: 67 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :82
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 82 is 0.163503
INFO:root:FL Epoch: 67 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :907
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694466
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692744
INFO:root:FL Epoch: 67 Norm Difference for worker 907 is 0.060291
INFO:root:FL Epoch: 67 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1068
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691983
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691517
INFO:root:FL Epoch: 67 Norm Difference for worker 1068 is 0.138774
INFO:root:FL Epoch: 67 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.6930804042255178 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:0.7027372717857361                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1385
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695102
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689466
INFO:root:FL Epoch: 68 Norm Difference for worker 1385 is 0.019165
INFO:root:FL Epoch: 68 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1108
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690329
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693253
INFO:root:FL Epoch: 68 Norm Difference for worker 1108 is 0.101701
INFO:root:FL Epoch: 68 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1575
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694147
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693605
INFO:root:FL Epoch: 68 Norm Difference for worker 1575 is 0.120118
INFO:root:FL Epoch: 68 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :567
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690164
INFO:root:FL Epoch: 68 Norm Difference for worker 567 is 0.12088
INFO:root:FL Epoch: 68 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1334
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694448
INFO:root:FL Epoch: 68 Norm Difference for worker 1334 is 0.090731
INFO:root:FL Epoch: 68 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :186
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690329
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 186 is 0.070412
INFO:root:FL Epoch: 68 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :589
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689252
INFO:root:FL Epoch: 68 Norm Difference for worker 589 is 0.1593
INFO:root:FL Epoch: 68 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :861
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694147
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690260
INFO:root:FL Epoch: 68 Norm Difference for worker 861 is 0.15481
INFO:root:FL Epoch: 68 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :249
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690372
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 249 is 0.140161
INFO:root:FL Epoch: 68 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :363
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698919
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663106
INFO:root:FL Epoch: 68 Norm Difference for worker 363 is 0.351403
INFO:root:FL Epoch: 68 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.6939042070332695 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:0.6646785140037537                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :1792
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705119
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672900
INFO:root:FL Epoch: 69 Norm Difference for worker 1792 is 0.376282
INFO:root:FL Epoch: 69 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1931
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684899
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711305
INFO:root:FL Epoch: 69 Norm Difference for worker 1931 is 0.000781
INFO:root:FL Epoch: 69 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1446
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690676
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686181
INFO:root:FL Epoch: 69 Norm Difference for worker 1446 is 0.047617
INFO:root:FL Epoch: 69 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1658
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702230
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685584
INFO:root:FL Epoch: 69 Norm Difference for worker 1658 is 0.282578
INFO:root:FL Epoch: 69 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1501
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699342
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693807
INFO:root:FL Epoch: 69 Norm Difference for worker 1501 is 0.05368
INFO:root:FL Epoch: 69 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :633
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693564
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692964
INFO:root:FL Epoch: 69 Norm Difference for worker 633 is 0.080974
INFO:root:FL Epoch: 69 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :191
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 191 is 0.081544
INFO:root:FL Epoch: 69 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :365
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696453
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692085
INFO:root:FL Epoch: 69 Norm Difference for worker 365 is 0.147308
INFO:root:FL Epoch: 69 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :539
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687787
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694931
INFO:root:FL Epoch: 69 Norm Difference for worker 539 is 0.153932
INFO:root:FL Epoch: 69 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1151
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702230
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691684
INFO:root:FL Epoch: 69 Norm Difference for worker 1151 is 0.15982
INFO:root:FL Epoch: 69 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.6933468720492195 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:0.7287187576293945                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1947
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693758
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690041
INFO:root:FL Epoch: 70 Norm Difference for worker 1947 is 0.056015
INFO:root:FL Epoch: 70 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :708
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700750
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690838
INFO:root:FL Epoch: 70 Norm Difference for worker 708 is 0.007841
INFO:root:FL Epoch: 70 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1032
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700750
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660159
INFO:root:FL Epoch: 70 Norm Difference for worker 1032 is 0.384006
INFO:root:FL Epoch: 70 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1835
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690262
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 70 Norm Difference for worker 1835 is 0.114109
INFO:root:FL Epoch: 70 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1097
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679774
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693287
INFO:root:FL Epoch: 70 Norm Difference for worker 1097 is 0.253389
INFO:root:FL Epoch: 70 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1636
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683270
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679856
INFO:root:FL Epoch: 70 Norm Difference for worker 1636 is 0.27678
INFO:root:FL Epoch: 70 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :104
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 104 is 0.017417
INFO:root:FL Epoch: 70 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1018
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693758
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675389
INFO:root:FL Epoch: 70 Norm Difference for worker 1018 is 0.179481
INFO:root:FL Epoch: 70 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :783
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693758
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697179
INFO:root:FL Epoch: 70 Norm Difference for worker 783 is 0.091415
INFO:root:FL Epoch: 70 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1165
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683270
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693505
INFO:root:FL Epoch: 70 Norm Difference for worker 1165 is 0.036289
INFO:root:FL Epoch: 70 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.6931174116976121 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:0.7140045762062073                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [62, 1637, 492, 467, 439, 1788, 1531, 1101, 1372, 1289]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :62
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695425
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 62 is 0.036064
INFO:root:FL Epoch: 71 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1637
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695425
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694859
INFO:root:FL Epoch: 71 Norm Difference for worker 1637 is 0.068827
INFO:root:FL Epoch: 71 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :492
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695425
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686355
INFO:root:FL Epoch: 71 Norm Difference for worker 492 is 0.028085
INFO:root:FL Epoch: 71 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :467
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689231
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684048
INFO:root:FL Epoch: 71 Norm Difference for worker 467 is 0.101262
INFO:root:FL Epoch: 71 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :439
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689232
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 71 Norm Difference for worker 439 is 0.157546
INFO:root:FL Epoch: 71 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1788
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695425
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705111
INFO:root:FL Epoch: 71 Norm Difference for worker 1788 is 0.101828
INFO:root:FL Epoch: 71 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1531
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693360
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694433
INFO:root:FL Epoch: 71 Norm Difference for worker 1531 is 0.011406
INFO:root:FL Epoch: 71 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1101
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699554
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696525
INFO:root:FL Epoch: 71 Norm Difference for worker 1101 is 0.139237
INFO:root:FL Epoch: 71 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1372
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693360
INFO:root:Worker: 1372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692552
INFO:root:FL Epoch: 71 Norm Difference for worker 1372 is 0.039833
INFO:root:FL Epoch: 71 Done on worker:1372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1289
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693360
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700451
INFO:root:FL Epoch: 71 Norm Difference for worker 1289 is 0.064737
INFO:root:FL Epoch: 71 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.69308761288138 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:0.7005483508110046                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1808
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692437
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701931
INFO:root:FL Epoch: 72 Norm Difference for worker 1808 is 0.059928
INFO:root:FL Epoch: 72 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :988
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692437
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675471
INFO:root:FL Epoch: 72 Norm Difference for worker 988 is 0.227942
INFO:root:FL Epoch: 72 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1871
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690225
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688544
INFO:root:FL Epoch: 72 Norm Difference for worker 1871 is 0.046703
INFO:root:FL Epoch: 72 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :246
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 246 is 0.042643
INFO:root:FL Epoch: 72 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :578
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693912
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669068
INFO:root:FL Epoch: 72 Norm Difference for worker 578 is 0.264641
INFO:root:FL Epoch: 72 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1167
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693745
INFO:root:FL Epoch: 72 Norm Difference for worker 1167 is 0.199659
INFO:root:FL Epoch: 72 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1905
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690225
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690291
INFO:root:FL Epoch: 72 Norm Difference for worker 1905 is 0.088929
INFO:root:FL Epoch: 72 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :161
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691867
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 161 is 0.098159
INFO:root:FL Epoch: 72 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :115
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694284
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 115 is 0.16145
INFO:root:FL Epoch: 72 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :918
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693912
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696211
INFO:root:FL Epoch: 72 Norm Difference for worker 918 is 0.06594
INFO:root:FL Epoch: 72 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.6933544698883506 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:0.6814647912979126                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 73 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1190
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687341
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688474
INFO:root:FL Epoch: 73 Norm Difference for worker 1190 is 0.223524
INFO:root:FL Epoch: 73 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :534
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689691
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696332
INFO:root:FL Epoch: 73 Norm Difference for worker 534 is 0.081458
INFO:root:FL Epoch: 73 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1482
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693216
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693247
INFO:root:FL Epoch: 73 Norm Difference for worker 1482 is 0.055805
INFO:root:FL Epoch: 73 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :854
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695566
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694705
INFO:root:FL Epoch: 73 Norm Difference for worker 854 is 0.039654
INFO:root:FL Epoch: 73 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1711
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695566
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700776
INFO:root:FL Epoch: 73 Norm Difference for worker 1711 is 0.123038
INFO:root:FL Epoch: 73 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :834
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696742
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690180
INFO:root:FL Epoch: 73 Norm Difference for worker 834 is 0.199292
INFO:root:FL Epoch: 73 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :816
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692041
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702596
INFO:root:FL Epoch: 73 Norm Difference for worker 816 is 0.109
INFO:root:FL Epoch: 73 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1421
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692041
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693228
INFO:root:FL Epoch: 73 Norm Difference for worker 1421 is 0.008527
INFO:root:FL Epoch: 73 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1353
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695567
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694802
INFO:root:FL Epoch: 73 Norm Difference for worker 1353 is 0.036774
INFO:root:FL Epoch: 73 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :991
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694391
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683043
INFO:root:FL Epoch: 73 Norm Difference for worker 991 is 0.123321
INFO:root:FL Epoch: 73 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.6932766682961408 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:0.6850118041038513                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :906
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693181
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700549
INFO:root:FL Epoch: 74 Norm Difference for worker 906 is 0.269264
INFO:root:FL Epoch: 74 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :572
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695631
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691662
INFO:root:FL Epoch: 74 Norm Difference for worker 572 is 0.068483
INFO:root:FL Epoch: 74 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1804
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693181
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693213
INFO:root:FL Epoch: 74 Norm Difference for worker 1804 is 0.045198
INFO:root:FL Epoch: 74 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :98
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 98 is 0.145029
INFO:root:FL Epoch: 74 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1645
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693997
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663863
INFO:root:FL Epoch: 74 Norm Difference for worker 1645 is 0.219461
INFO:root:FL Epoch: 74 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :583
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690730
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693192
INFO:root:FL Epoch: 74 Norm Difference for worker 583 is 0.003241
INFO:root:FL Epoch: 74 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :100
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699456
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 100 is 0.221918
INFO:root:FL Epoch: 74 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1709
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693997
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698558
INFO:root:FL Epoch: 74 Norm Difference for worker 1709 is 0.001979
INFO:root:FL Epoch: 74 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :278
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675266
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 278 is 0.045019
INFO:root:FL Epoch: 74 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :942
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692364
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695138
INFO:root:FL Epoch: 74 Norm Difference for worker 942 is 0.171783
INFO:root:FL Epoch: 74 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.6931114372085122 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:0.713294506072998                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :978
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695341
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693167
INFO:root:FL Epoch: 75 Norm Difference for worker 978 is 0.085274
INFO:root:FL Epoch: 75 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :410
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687362
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689977
INFO:root:FL Epoch: 75 Norm Difference for worker 410 is 0.031743
INFO:root:FL Epoch: 75 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :848
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697336
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682336
INFO:root:FL Epoch: 75 Norm Difference for worker 848 is 0.194968
INFO:root:FL Epoch: 75 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1023
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695341
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695237
INFO:root:FL Epoch: 75 Norm Difference for worker 1023 is 0.221048
INFO:root:FL Epoch: 75 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :197
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 197 is 0.100146
INFO:root:FL Epoch: 75 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1535
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701325
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694779
INFO:root:FL Epoch: 75 Norm Difference for worker 1535 is 0.099314
INFO:root:FL Epoch: 75 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :786
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691351
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698882
INFO:root:FL Epoch: 75 Norm Difference for worker 786 is 0.142219
INFO:root:FL Epoch: 75 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1486
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697336
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680681
INFO:root:FL Epoch: 75 Norm Difference for worker 1486 is 0.181519
INFO:root:FL Epoch: 75 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1128
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699331
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692910
INFO:root:FL Epoch: 75 Norm Difference for worker 1128 is 0.078045
INFO:root:FL Epoch: 75 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1761
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693346
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686421
INFO:root:FL Epoch: 75 Norm Difference for worker 1761 is 0.113205
INFO:root:FL Epoch: 75 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.6935171730378095 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:0.6754345297813416                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 76 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1548
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696881
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700801
INFO:root:FL Epoch: 76 Norm Difference for worker 1548 is 0.236085
INFO:root:FL Epoch: 76 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1417
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686158
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689889
INFO:root:FL Epoch: 76 Norm Difference for worker 1417 is 0.000541
INFO:root:FL Epoch: 76 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :840
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689732
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687790
INFO:root:FL Epoch: 76 Norm Difference for worker 840 is 0.049122
INFO:root:FL Epoch: 76 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :570
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693307
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688874
INFO:root:FL Epoch: 76 Norm Difference for worker 570 is 0.188525
INFO:root:FL Epoch: 76 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1300
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691520
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697468
INFO:root:FL Epoch: 76 Norm Difference for worker 1300 is 0.06526
INFO:root:FL Epoch: 76 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1440
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691520
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692849
INFO:root:FL Epoch: 76 Norm Difference for worker 1440 is 0.177927
INFO:root:FL Epoch: 76 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :716
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689732
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689766
INFO:root:FL Epoch: 76 Norm Difference for worker 716 is 0.184383
INFO:root:FL Epoch: 76 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1434
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696881
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693378
INFO:root:FL Epoch: 76 Norm Difference for worker 1434 is 0.01196
INFO:root:FL Epoch: 76 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1090
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693307
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708432
INFO:root:FL Epoch: 76 Norm Difference for worker 1090 is 0.080881
INFO:root:FL Epoch: 76 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :170
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 170 is 0.239928
INFO:root:FL Epoch: 76 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.6943415964350981 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:0.6553792357444763                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :975
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690038
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697164
INFO:root:FL Epoch: 77 Norm Difference for worker 975 is 0.030426
INFO:root:FL Epoch: 77 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :926
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705441
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695994
INFO:root:FL Epoch: 77 Norm Difference for worker 926 is 0.058129
INFO:root:FL Epoch: 77 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693889
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682962
INFO:root:FL Epoch: 77 Norm Difference for worker 1128 is 0.033605
INFO:root:FL Epoch: 77 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 303 is 0.193802
INFO:root:FL Epoch: 77 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1274
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690038
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679445
INFO:root:FL Epoch: 77 Norm Difference for worker 1274 is 0.261366
INFO:root:FL Epoch: 77 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :483
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701590
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698169
INFO:root:FL Epoch: 77 Norm Difference for worker 483 is 0.042562
INFO:root:FL Epoch: 77 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :944
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697739
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703509
INFO:root:FL Epoch: 77 Norm Difference for worker 944 is 0.151239
INFO:root:FL Epoch: 77 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :904
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682336
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681804
INFO:root:FL Epoch: 77 Norm Difference for worker 904 is 0.115686
INFO:root:FL Epoch: 77 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :394
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701590
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694463
INFO:root:FL Epoch: 77 Norm Difference for worker 394 is 0.257942
INFO:root:FL Epoch: 77 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1282
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697739
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695332
INFO:root:FL Epoch: 77 Norm Difference for worker 1282 is 0.197503
INFO:root:FL Epoch: 77 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.6934328464900746 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:0.6783800721168518                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :1205
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694746
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673969
INFO:root:FL Epoch: 78 Norm Difference for worker 1205 is 0.202138
INFO:root:FL Epoch: 78 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :886
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696233
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693462
INFO:root:FL Epoch: 78 Norm Difference for worker 886 is 0.078791
INFO:root:FL Epoch: 78 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :835
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696233
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696807
INFO:root:FL Epoch: 78 Norm Difference for worker 835 is 0.008912
INFO:root:FL Epoch: 78 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1830
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687359
INFO:root:FL Epoch: 78 Norm Difference for worker 1830 is 0.070926
INFO:root:FL Epoch: 78 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :482
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691770
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688991
INFO:root:FL Epoch: 78 Norm Difference for worker 482 is 0.160729
INFO:root:FL Epoch: 78 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1179
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693323
INFO:root:FL Epoch: 78 Norm Difference for worker 1179 is 0.144291
INFO:root:FL Epoch: 78 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1312
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696233
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693176
INFO:root:FL Epoch: 78 Norm Difference for worker 1312 is 0.10118
INFO:root:FL Epoch: 78 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1592
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694746
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701940
INFO:root:FL Epoch: 78 Norm Difference for worker 1592 is 0.077623
INFO:root:FL Epoch: 78 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :45
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690639
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 45 is 0.178046
INFO:root:FL Epoch: 78 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1934
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690282
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691309
INFO:root:FL Epoch: 78 Norm Difference for worker 1934 is 0.014098
INFO:root:FL Epoch: 78 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.6932506035355961 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:0.6863546967506409                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1712
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693852
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684348
INFO:root:FL Epoch: 79 Norm Difference for worker 1712 is 0.076169
INFO:root:FL Epoch: 79 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :194
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 194 is 0.228098
INFO:root:FL Epoch: 79 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :814
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695897
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695848
INFO:root:FL Epoch: 79 Norm Difference for worker 814 is 0.058366
INFO:root:FL Epoch: 79 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :277
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 277 is 0.005556
INFO:root:FL Epoch: 79 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1810
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694534
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694692
INFO:root:FL Epoch: 79 Norm Difference for worker 1810 is 0.207846
INFO:root:FL Epoch: 79 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :235
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.716085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 235 is 0.197753
INFO:root:FL Epoch: 79 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :487
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692489
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688144
INFO:root:FL Epoch: 79 Norm Difference for worker 487 is 0.137966
INFO:root:FL Epoch: 79 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1274
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693170
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672730
INFO:root:FL Epoch: 79 Norm Difference for worker 1274 is 0.299749
INFO:root:FL Epoch: 79 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :998
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691126
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693181
INFO:root:FL Epoch: 79 Norm Difference for worker 998 is 0.110867
INFO:root:FL Epoch: 79 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1460
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693852
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691225
INFO:root:FL Epoch: 79 Norm Difference for worker 1460 is 0.060891
INFO:root:FL Epoch: 79 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.6931648289456087 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:0.6917343735694885                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 80 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :951
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693431
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693199
INFO:root:FL Epoch: 80 Norm Difference for worker 951 is 0.14487
INFO:root:FL Epoch: 80 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :196
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 196 is 0.076144
INFO:root:FL Epoch: 80 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :695
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692865
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694464
INFO:root:FL Epoch: 80 Norm Difference for worker 695 is 0.178131
INFO:root:FL Epoch: 80 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1847
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685516
INFO:root:FL Epoch: 80 Norm Difference for worker 1847 is 0.12496
INFO:root:FL Epoch: 80 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1670
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692865
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693041
INFO:root:FL Epoch: 80 Norm Difference for worker 1670 is 0.072565
INFO:root:FL Epoch: 80 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1872
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693007
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691227
INFO:root:FL Epoch: 80 Norm Difference for worker 1872 is 0.108856
INFO:root:FL Epoch: 80 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692441
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667397
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 0.296248
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :564
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693431
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694301
INFO:root:FL Epoch: 80 Norm Difference for worker 564 is 0.052735
INFO:root:FL Epoch: 80 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :683
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693572
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690462
INFO:root:FL Epoch: 80 Norm Difference for worker 683 is 0.183353
INFO:root:FL Epoch: 80 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :33
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693855
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 33 is 0.125689
INFO:root:FL Epoch: 80 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.6937954811488881 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:0.6673680543899536                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1552, 722, 895, 1912, 1905, 370, 1295, 616, 579, 1867]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1552
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696100
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693669
INFO:root:FL Epoch: 81 Norm Difference for worker 1552 is 0.14337
INFO:root:FL Epoch: 81 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :722
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677816
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694002
INFO:root:FL Epoch: 81 Norm Difference for worker 722 is 0.055755
INFO:root:FL Epoch: 81 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :895
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696100
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695258
INFO:root:FL Epoch: 81 Norm Difference for worker 895 is 0.035314
INFO:root:FL Epoch: 81 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1912
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683040
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689643
INFO:root:FL Epoch: 81 Norm Difference for worker 1912 is 0.025647
INFO:root:FL Epoch: 81 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1905
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688264
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694385
INFO:root:FL Epoch: 81 Norm Difference for worker 1905 is 0.023581
INFO:root:FL Epoch: 81 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :370
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690876
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685334
INFO:root:FL Epoch: 81 Norm Difference for worker 370 is 0.086838
INFO:root:FL Epoch: 81 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1295
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685652
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694017
INFO:root:FL Epoch: 81 Norm Difference for worker 1295 is 0.062146
INFO:root:FL Epoch: 81 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :616
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690876
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688105
INFO:root:FL Epoch: 81 Norm Difference for worker 616 is 0.273205
INFO:root:FL Epoch: 81 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :579
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698712
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695135
INFO:root:FL Epoch: 81 Norm Difference for worker 579 is 0.188059
INFO:root:FL Epoch: 81 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1867
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693488
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694198
INFO:root:FL Epoch: 81 Norm Difference for worker 1867 is 0.067328
INFO:root:FL Epoch: 81 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.6932018294053919 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:0.6891822218894958                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1016
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693552
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685331
INFO:root:FL Epoch: 82 Norm Difference for worker 1016 is 0.186041
INFO:root:FL Epoch: 82 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1907
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691566
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690498
INFO:root:FL Epoch: 82 Norm Difference for worker 1907 is 0.06107
INFO:root:FL Epoch: 82 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :171
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 171 is 0.200458
INFO:root:FL Epoch: 82 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :180
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693552
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 180 is 0.180319
INFO:root:FL Epoch: 82 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1447
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699254
INFO:root:FL Epoch: 82 Norm Difference for worker 1447 is 0.091711
INFO:root:FL Epoch: 82 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :316
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 316 is 0.208109
INFO:root:FL Epoch: 82 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1107
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691963
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689983
INFO:root:FL Epoch: 82 Norm Difference for worker 1107 is 0.117011
INFO:root:FL Epoch: 82 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :451
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693950
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688265
INFO:root:FL Epoch: 82 Norm Difference for worker 451 is 0.123553
INFO:root:FL Epoch: 82 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1246
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687240
INFO:root:FL Epoch: 82 Norm Difference for worker 1246 is 0.189642
INFO:root:FL Epoch: 82 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :792
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692758
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693801
INFO:root:FL Epoch: 82 Norm Difference for worker 792 is 0.196476
INFO:root:FL Epoch: 82 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.6932243634672726 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:0.6878165602684021                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1537
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691024
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697190
INFO:root:FL Epoch: 83 Norm Difference for worker 1537 is 0.249796
INFO:root:FL Epoch: 83 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :890
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692093
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696608
INFO:root:FL Epoch: 83 Norm Difference for worker 890 is 0.09616
INFO:root:FL Epoch: 83 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1098
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691558
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685148
INFO:root:FL Epoch: 83 Norm Difference for worker 1098 is 0.118423
INFO:root:FL Epoch: 83 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :872
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692627
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694560
INFO:root:FL Epoch: 83 Norm Difference for worker 872 is 0.025942
INFO:root:FL Epoch: 83 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1229
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691024
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693678
INFO:root:FL Epoch: 83 Norm Difference for worker 1229 is 0.105624
INFO:root:FL Epoch: 83 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :169
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 169 is 0.131619
INFO:root:FL Epoch: 83 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1490
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691558
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693616
INFO:root:FL Epoch: 83 Norm Difference for worker 1490 is 0.178667
INFO:root:FL Epoch: 83 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :659
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694230
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693622
INFO:root:FL Epoch: 83 Norm Difference for worker 659 is 0.077135
INFO:root:FL Epoch: 83 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :81
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 81 is 0.121162
INFO:root:FL Epoch: 83 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :873
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693696
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693155
INFO:root:FL Epoch: 83 Norm Difference for worker 873 is 0.025243
INFO:root:FL Epoch: 83 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.6932795994422015 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:0.6848668456077576                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1878
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696508
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674847
INFO:root:FL Epoch: 84 Norm Difference for worker 1878 is 0.280099
INFO:root:FL Epoch: 84 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1224
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694845
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689931
INFO:root:FL Epoch: 84 Norm Difference for worker 1224 is 0.126318
INFO:root:FL Epoch: 84 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :132
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 132 is 0.077643
INFO:root:FL Epoch: 84 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :198
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 198 is 0.096859
INFO:root:FL Epoch: 84 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :140
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694848
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 140 is 0.035244
INFO:root:FL Epoch: 84 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :649
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694013
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691002
INFO:root:FL Epoch: 84 Norm Difference for worker 649 is 0.063029
INFO:root:FL Epoch: 84 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :436
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685230
INFO:root:FL Epoch: 84 Norm Difference for worker 436 is 0.125137
INFO:root:FL Epoch: 84 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :86
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692692
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 86 is 0.107719
INFO:root:FL Epoch: 84 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1238
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694069
INFO:root:FL Epoch: 84 Norm Difference for worker 1238 is 0.083621
INFO:root:FL Epoch: 84 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1616
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692350
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692782
INFO:root:FL Epoch: 84 Norm Difference for worker 1616 is 0.065963
INFO:root:FL Epoch: 84 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.6931958969901589 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:0.7206421494483948                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :376
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698940
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693305
INFO:root:FL Epoch: 85 Norm Difference for worker 376 is 0.119508
INFO:root:FL Epoch: 85 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :587
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696228
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693218
INFO:root:FL Epoch: 85 Norm Difference for worker 587 is 0.167829
INFO:root:FL Epoch: 85 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1674
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690802
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692111
INFO:root:FL Epoch: 85 Norm Difference for worker 1674 is 0.140788
INFO:root:FL Epoch: 85 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1650
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696228
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694995
INFO:root:FL Epoch: 85 Norm Difference for worker 1650 is 0.114999
INFO:root:FL Epoch: 85 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1395
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698940
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693309
INFO:root:FL Epoch: 85 Norm Difference for worker 1395 is 0.054951
INFO:root:FL Epoch: 85 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :747
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685377
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702578
INFO:root:FL Epoch: 85 Norm Difference for worker 747 is 0.029436
INFO:root:FL Epoch: 85 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :841
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696228
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698328
INFO:root:FL Epoch: 85 Norm Difference for worker 841 is 0.075427
INFO:root:FL Epoch: 85 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1713
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688090
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704690
INFO:root:FL Epoch: 85 Norm Difference for worker 1713 is 0.267967
INFO:root:FL Epoch: 85 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :586
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698940
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690172
INFO:root:FL Epoch: 85 Norm Difference for worker 586 is 0.088312
INFO:root:FL Epoch: 85 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :76
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685377
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 76 is 0.152386
INFO:root:FL Epoch: 85 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.6937880936790916 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:0.6675611734390259                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1588
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690891
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691503
INFO:root:FL Epoch: 86 Norm Difference for worker 1588 is 0.090432
INFO:root:FL Epoch: 86 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :653
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685706
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706645
INFO:root:FL Epoch: 86 Norm Difference for worker 653 is 0.017133
INFO:root:FL Epoch: 86 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1926
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690891
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694142
INFO:root:FL Epoch: 86 Norm Difference for worker 1926 is 0.006214
INFO:root:FL Epoch: 86 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1027
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696075
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631790
INFO:root:FL Epoch: 86 Norm Difference for worker 1027 is 0.290776
INFO:root:FL Epoch: 86 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :529
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693483
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690457
INFO:root:FL Epoch: 86 Norm Difference for worker 529 is 0.09611
INFO:root:FL Epoch: 86 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1929
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703852
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691002
INFO:root:FL Epoch: 86 Norm Difference for worker 1929 is 0.027721
INFO:root:FL Epoch: 86 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :184
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 184 is 0.135594
INFO:root:FL Epoch: 86 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1709
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690891
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692591
INFO:root:FL Epoch: 86 Norm Difference for worker 1709 is 0.021282
INFO:root:FL Epoch: 86 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :74
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693239
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 74 is 0.1997
INFO:root:FL Epoch: 86 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1001
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693483
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693959
INFO:root:FL Epoch: 86 Norm Difference for worker 1001 is 0.155471
INFO:root:FL Epoch: 86 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.6942435748436872 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:0.6572932600975037                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1919
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697466
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693492
INFO:root:FL Epoch: 87 Norm Difference for worker 1919 is 0.034228
INFO:root:FL Epoch: 87 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :211
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 211 is 0.14241
INFO:root:FL Epoch: 87 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :692
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699254
INFO:root:FL Epoch: 87 Norm Difference for worker 692 is 0.048246
INFO:root:FL Epoch: 87 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :756
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697466
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691274
INFO:root:FL Epoch: 87 Norm Difference for worker 756 is 0.036672
INFO:root:FL Epoch: 87 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :452
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686090
INFO:root:FL Epoch: 87 Norm Difference for worker 452 is 0.232996
INFO:root:FL Epoch: 87 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1940
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690798
INFO:root:FL Epoch: 87 Norm Difference for worker 1940 is 0.197917
INFO:root:FL Epoch: 87 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1274
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696064
INFO:root:FL Epoch: 87 Norm Difference for worker 1274 is 0.207154
INFO:root:FL Epoch: 87 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :505
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690162
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693057
INFO:root:FL Epoch: 87 Norm Difference for worker 505 is 0.157017
INFO:root:FL Epoch: 87 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1090
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697466
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684523
INFO:root:FL Epoch: 87 Norm Difference for worker 1090 is 0.088704
INFO:root:FL Epoch: 87 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :674
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697874
INFO:root:FL Epoch: 87 Norm Difference for worker 674 is 0.299069
INFO:root:FL Epoch: 87 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.693350869066575 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:0.6816167235374451                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :754
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692055
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686497
INFO:root:FL Epoch: 88 Norm Difference for worker 754 is 0.297567
INFO:root:FL Epoch: 88 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1867
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689735
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696216
INFO:root:FL Epoch: 88 Norm Difference for worker 1867 is 0.076509
INFO:root:FL Epoch: 88 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1196
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696694
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697975
INFO:root:FL Epoch: 88 Norm Difference for worker 1196 is 0.150623
INFO:root:FL Epoch: 88 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1355
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690895
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691551
INFO:root:FL Epoch: 88 Norm Difference for worker 1355 is 0.038073
INFO:root:FL Epoch: 88 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1912
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694374
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700264
INFO:root:FL Epoch: 88 Norm Difference for worker 1912 is 0.055408
INFO:root:FL Epoch: 88 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1919
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693214
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691602
INFO:root:FL Epoch: 88 Norm Difference for worker 1919 is 0.022229
INFO:root:FL Epoch: 88 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1518
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696694
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691451
INFO:root:FL Epoch: 88 Norm Difference for worker 1518 is 0.11269
INFO:root:FL Epoch: 88 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :818
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696694
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703178
INFO:root:FL Epoch: 88 Norm Difference for worker 818 is 0.248981
INFO:root:FL Epoch: 88 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1600
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696694
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692258
INFO:root:FL Epoch: 88 Norm Difference for worker 1600 is 0.010045
INFO:root:FL Epoch: 88 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1594
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701333
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693197
INFO:root:FL Epoch: 88 Norm Difference for worker 1594 is 0.074466
INFO:root:FL Epoch: 88 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.6931356612373801 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:0.7159059643745422                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 89 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1856
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686649
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697091
INFO:root:FL Epoch: 89 Norm Difference for worker 1856 is 0.026396
INFO:root:FL Epoch: 89 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :476
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682148
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685682
INFO:root:FL Epoch: 89 Norm Difference for worker 476 is 0.031143
INFO:root:FL Epoch: 89 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :191
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694640
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 191 is 0.022155
INFO:root:FL Epoch: 89 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :401
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704653
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692685
INFO:root:FL Epoch: 89 Norm Difference for worker 401 is 0.087679
INFO:root:FL Epoch: 89 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :350
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688899
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690600
INFO:root:FL Epoch: 89 Norm Difference for worker 350 is 0.092136
INFO:root:FL Epoch: 89 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :34
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 34 is 0.091221
INFO:root:FL Epoch: 89 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :742
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693400
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693620
INFO:root:FL Epoch: 89 Norm Difference for worker 742 is 0.018467
INFO:root:FL Epoch: 89 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1521
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697901
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689167
INFO:root:FL Epoch: 89 Norm Difference for worker 1521 is 0.234431
INFO:root:FL Epoch: 89 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1275
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686649
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687660
INFO:root:FL Epoch: 89 Norm Difference for worker 1275 is 0.244305
INFO:root:FL Epoch: 89 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :107
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 107 is 0.035229
INFO:root:FL Epoch: 89 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.6933685681399178 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:0.6808801889419556                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1193
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691989
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679176
INFO:root:FL Epoch: 90 Norm Difference for worker 1193 is 0.362013
INFO:root:FL Epoch: 90 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :930
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685817
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707270
INFO:root:FL Epoch: 90 Norm Difference for worker 930 is 0.081562
INFO:root:FL Epoch: 90 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1680
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687052
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690722
INFO:root:FL Epoch: 90 Norm Difference for worker 1680 is 0.042156
INFO:root:FL Epoch: 90 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1543
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695692
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689558
INFO:root:FL Epoch: 90 Norm Difference for worker 1543 is 0.089509
INFO:root:FL Epoch: 90 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :25
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 25 is 0.092204
INFO:root:FL Epoch: 90 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1115
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694458
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693213
INFO:root:FL Epoch: 90 Norm Difference for worker 1115 is 0.113298
INFO:root:FL Epoch: 90 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1856
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696926
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696851
INFO:root:FL Epoch: 90 Norm Difference for worker 1856 is 0.063455
INFO:root:FL Epoch: 90 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :687
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694458
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688696
INFO:root:FL Epoch: 90 Norm Difference for worker 687 is 0.172534
INFO:root:FL Epoch: 90 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :24
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695692
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 24 is 0.00888
INFO:root:FL Epoch: 90 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :850
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696926
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682028
INFO:root:FL Epoch: 90 Norm Difference for worker 850 is 0.267767
INFO:root:FL Epoch: 90 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.6932406986460966 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:0.6868896484375                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [623, 1591, 1404, 853, 1441, 944, 1326, 1243, 1153, 1122]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 91 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :623
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695678
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707885
INFO:root:FL Epoch: 91 Norm Difference for worker 623 is 0.021364
INFO:root:FL Epoch: 91 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1591
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693568
INFO:root:FL Epoch: 91 Norm Difference for worker 1591 is 0.106856
INFO:root:FL Epoch: 91 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1404
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692790
INFO:root:FL Epoch: 91 Norm Difference for worker 1404 is 0.026284
INFO:root:FL Epoch: 91 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :853
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692539
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689792
INFO:root:FL Epoch: 91 Norm Difference for worker 853 is 0.059947
INFO:root:FL Epoch: 91 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1441
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691911
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687044
INFO:root:FL Epoch: 91 Norm Difference for worker 1441 is 0.011633
INFO:root:FL Epoch: 91 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :944
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696306
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693447
INFO:root:FL Epoch: 91 Norm Difference for worker 944 is 0.118835
INFO:root:FL Epoch: 91 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1326
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 91 Norm Difference for worker 1326 is 0.02748
INFO:root:FL Epoch: 91 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1243
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693795
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 91 Norm Difference for worker 1243 is 0.212282
INFO:root:FL Epoch: 91 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1153
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694579
INFO:root:FL Epoch: 91 Norm Difference for worker 1153 is 0.086067
INFO:root:FL Epoch: 91 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1122
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694665
INFO:root:FL Epoch: 91 Norm Difference for worker 1122 is 0.088807
INFO:root:FL Epoch: 91 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.69310102743261 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:0.6981357932090759                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :845
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692662
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691157
INFO:root:FL Epoch: 92 Norm Difference for worker 845 is 0.016615
INFO:root:FL Epoch: 92 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1139
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694652
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694673
INFO:root:FL Epoch: 92 Norm Difference for worker 1139 is 0.240331
INFO:root:FL Epoch: 92 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :844
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692164
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688198
INFO:root:FL Epoch: 92 Norm Difference for worker 844 is 0.0798
INFO:root:FL Epoch: 92 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :540
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693157
INFO:root:FL Epoch: 92 Norm Difference for worker 540 is 0.060855
INFO:root:FL Epoch: 92 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :872
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693657
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693171
INFO:root:FL Epoch: 92 Norm Difference for worker 872 is 0.007257
INFO:root:FL Epoch: 92 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1177
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692219
INFO:root:FL Epoch: 92 Norm Difference for worker 1177 is 0.050564
INFO:root:FL Epoch: 92 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1685
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691667
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689922
INFO:root:FL Epoch: 92 Norm Difference for worker 1685 is 0.053186
INFO:root:FL Epoch: 92 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692164
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 175 is 0.111521
INFO:root:FL Epoch: 92 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :376
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695268
INFO:root:FL Epoch: 92 Norm Difference for worker 376 is 0.05034
INFO:root:FL Epoch: 92 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1367
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 92 Norm Difference for worker 1367 is 0.05569
INFO:root:FL Epoch: 92 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.693237255601322 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:0.6870850324630737                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 93 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :48
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694382
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 48 is 0.021501
INFO:root:FL Epoch: 93 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :872
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692558
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693094
INFO:root:FL Epoch: 93 Norm Difference for worker 872 is 0.007667
INFO:root:FL Epoch: 93 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1196
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694382
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693528
INFO:root:FL Epoch: 93 Norm Difference for worker 1196 is 0.157461
INFO:root:FL Epoch: 93 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1390
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692558
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693864
INFO:root:FL Epoch: 93 Norm Difference for worker 1390 is 0.029675
INFO:root:FL Epoch: 93 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1195
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693166
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694358
INFO:root:FL Epoch: 93 Norm Difference for worker 1195 is 0.020478
INFO:root:FL Epoch: 93 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :341
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693774
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693007
INFO:root:FL Epoch: 93 Norm Difference for worker 341 is 0.019677
INFO:root:FL Epoch: 93 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :279
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 279 is 0.154158
INFO:root:FL Epoch: 93 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :241
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 241 is 0.098451
INFO:root:FL Epoch: 93 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1160
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692558
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692255
INFO:root:FL Epoch: 93 Norm Difference for worker 1160 is 0.065039
INFO:root:FL Epoch: 93 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1421
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693774
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693040
INFO:root:FL Epoch: 93 Norm Difference for worker 1421 is 0.046726
INFO:root:FL Epoch: 93 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.69324029193205 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:0.6869140863418579                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1770
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691916
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692497
INFO:root:FL Epoch: 94 Norm Difference for worker 1770 is 0.016421
INFO:root:FL Epoch: 94 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :149
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 149 is 0.022859
INFO:root:FL Epoch: 94 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1939
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690666
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701114
INFO:root:FL Epoch: 94 Norm Difference for worker 1939 is 0.027873
INFO:root:FL Epoch: 94 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1250
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693330
INFO:root:FL Epoch: 94 Norm Difference for worker 1250 is 0.15021
INFO:root:FL Epoch: 94 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :809
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691291
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685684
INFO:root:FL Epoch: 94 Norm Difference for worker 809 is 0.00727
INFO:root:FL Epoch: 94 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :301
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694417
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.724063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 301 is 0.198353
INFO:root:FL Epoch: 94 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :636
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688046
INFO:root:FL Epoch: 94 Norm Difference for worker 636 is 0.125983
INFO:root:FL Epoch: 94 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1925
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691291
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710318
INFO:root:FL Epoch: 94 Norm Difference for worker 1925 is 0.093873
INFO:root:FL Epoch: 94 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :125
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688837
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 125 is 0.109768
INFO:root:FL Epoch: 94 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1537
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692541
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688895
INFO:root:FL Epoch: 94 Norm Difference for worker 1537 is 0.258542
INFO:root:FL Epoch: 94 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.6933864635579726 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:0.680157482624054                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :1495
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691925
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695580
INFO:root:FL Epoch: 95 Norm Difference for worker 1495 is 0.140021
INFO:root:FL Epoch: 95 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1264
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695848
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715216
INFO:root:FL Epoch: 95 Norm Difference for worker 1264 is 0.38622
INFO:root:FL Epoch: 95 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :469
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694540
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693202
INFO:root:FL Epoch: 95 Norm Difference for worker 469 is 0.171752
INFO:root:FL Epoch: 95 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1275
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693233
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689842
INFO:root:FL Epoch: 95 Norm Difference for worker 1275 is 0.179481
INFO:root:FL Epoch: 95 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :734
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694540
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692285
INFO:root:FL Epoch: 95 Norm Difference for worker 734 is 0.157667
INFO:root:FL Epoch: 95 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1533
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694540
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696195
INFO:root:FL Epoch: 95 Norm Difference for worker 1533 is 0.004759
INFO:root:FL Epoch: 95 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1555
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691925
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691857
INFO:root:FL Epoch: 95 Norm Difference for worker 1555 is 0.029042
INFO:root:FL Epoch: 95 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :94
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 94 is 0.005915
INFO:root:FL Epoch: 95 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :311
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 311 is 0.126312
INFO:root:FL Epoch: 95 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :243
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692912
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 243 is 0.050977
INFO:root:FL Epoch: 95 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.6931193786508897 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:0.6958056688308716                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692354
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675951
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 0.27462
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1172
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691865
INFO:root:FL Epoch: 96 Norm Difference for worker 1172 is 0.100358
INFO:root:FL Epoch: 96 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :440
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692089
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696608
INFO:root:FL Epoch: 96 Norm Difference for worker 440 is 0.139553
INFO:root:FL Epoch: 96 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :207
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 207 is 0.033354
INFO:root:FL Epoch: 96 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :205
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 205 is 0.129154
INFO:root:FL Epoch: 96 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :542
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693416
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664610
INFO:root:FL Epoch: 96 Norm Difference for worker 542 is 0.213772
INFO:root:FL Epoch: 96 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1428
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689980
INFO:root:FL Epoch: 96 Norm Difference for worker 1428 is 0.176617
INFO:root:FL Epoch: 96 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1348
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692354
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697423
INFO:root:FL Epoch: 96 Norm Difference for worker 1348 is 0.014697
INFO:root:FL Epoch: 96 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1135
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692620
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681932
INFO:root:FL Epoch: 96 Norm Difference for worker 1135 is 0.221435
INFO:root:FL Epoch: 96 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :308
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 308 is 0.099401
INFO:root:FL Epoch: 96 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.6932722084662494 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:0.6852313280105591                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 97 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :848
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694768
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693573
INFO:root:FL Epoch: 97 Norm Difference for worker 848 is 0.132402
INFO:root:FL Epoch: 97 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :769
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693973
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692546
INFO:root:FL Epoch: 97 Norm Difference for worker 769 is 0.078624
INFO:root:FL Epoch: 97 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :627
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692384
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681934
INFO:root:FL Epoch: 97 Norm Difference for worker 627 is 0.162788
INFO:root:FL Epoch: 97 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :413
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693179
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697188
INFO:root:FL Epoch: 97 Norm Difference for worker 413 is 0.127509
INFO:root:FL Epoch: 97 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1061
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693179
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687696
INFO:root:FL Epoch: 97 Norm Difference for worker 1061 is 0.231801
INFO:root:FL Epoch: 97 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1302
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693973
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681529
INFO:root:FL Epoch: 97 Norm Difference for worker 1302 is 0.1649
INFO:root:FL Epoch: 97 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1445
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692384
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682619
INFO:root:FL Epoch: 97 Norm Difference for worker 1445 is 0.263706
INFO:root:FL Epoch: 97 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :973
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691589
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690132
INFO:root:FL Epoch: 97 Norm Difference for worker 973 is 0.231234
INFO:root:FL Epoch: 97 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :110
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693973
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 110 is 0.199673
INFO:root:FL Epoch: 97 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :15
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693179
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 15 is 0.110039
INFO:root:FL Epoch: 97 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.6938203362857595 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:0.6667365431785583                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 98 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :633
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698859
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691791
INFO:root:FL Epoch: 98 Norm Difference for worker 633 is 0.103529
INFO:root:FL Epoch: 98 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :77
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690829
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 77 is 0.00523
INFO:root:FL Epoch: 98 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1548
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693505
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673992
INFO:root:FL Epoch: 98 Norm Difference for worker 1548 is 0.181721
INFO:root:FL Epoch: 98 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :734
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690829
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676674
INFO:root:FL Epoch: 98 Norm Difference for worker 734 is 0.080662
INFO:root:FL Epoch: 98 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1609
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693505
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693195
INFO:root:FL Epoch: 98 Norm Difference for worker 1609 is 0.150389
INFO:root:FL Epoch: 98 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1375
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698859
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685583
INFO:root:FL Epoch: 98 Norm Difference for worker 1375 is 0.260601
INFO:root:FL Epoch: 98 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1209
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688152
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695787
INFO:root:FL Epoch: 98 Norm Difference for worker 1209 is 0.115889
INFO:root:FL Epoch: 98 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1751
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696182
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698310
INFO:root:FL Epoch: 98 Norm Difference for worker 1751 is 0.018174
INFO:root:FL Epoch: 98 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1773
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693505
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692149
INFO:root:FL Epoch: 98 Norm Difference for worker 1773 is 0.123243
INFO:root:FL Epoch: 98 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1238
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696182
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691540
INFO:root:FL Epoch: 98 Norm Difference for worker 1238 is 0.024284
INFO:root:FL Epoch: 98 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.6933467563460854 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:0.6817959547042847                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 99 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1854
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690929
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683546
INFO:root:FL Epoch: 99 Norm Difference for worker 1854 is 0.123781
INFO:root:FL Epoch: 99 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1767
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693212
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697995
INFO:root:FL Epoch: 99 Norm Difference for worker 1767 is 0.162156
INFO:root:FL Epoch: 99 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1325
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697779
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698825
INFO:root:FL Epoch: 99 Norm Difference for worker 1325 is 0.035774
INFO:root:FL Epoch: 99 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :857
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695496
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703819
INFO:root:FL Epoch: 99 Norm Difference for worker 857 is 0.134123
INFO:root:FL Epoch: 99 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :918
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692071
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690108
INFO:root:FL Epoch: 99 Norm Difference for worker 918 is 0.141966
INFO:root:FL Epoch: 99 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :86
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 86 is 0.080721
INFO:root:FL Epoch: 99 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :420
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692071
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694861
INFO:root:FL Epoch: 99 Norm Difference for worker 420 is 0.055528
INFO:root:FL Epoch: 99 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :564
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693212
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693189
INFO:root:FL Epoch: 99 Norm Difference for worker 564 is 0.126246
INFO:root:FL Epoch: 99 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :958
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694354
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690952
INFO:root:FL Epoch: 99 Norm Difference for worker 958 is 0.013647
INFO:root:FL Epoch: 99 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :800
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694354
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696273
INFO:root:FL Epoch: 99 Norm Difference for worker 800 is 0.053884
INFO:root:FL Epoch: 99 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.6930826095973744 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:0.7080734372138977                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1823
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693257
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696566
INFO:root:FL Epoch: 100 Norm Difference for worker 1823 is 0.010996
INFO:root:FL Epoch: 100 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1049
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693257
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693231
INFO:root:FL Epoch: 100 Norm Difference for worker 1049 is 0.099576
INFO:root:FL Epoch: 100 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1864
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691775
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697860
INFO:root:FL Epoch: 100 Norm Difference for worker 1864 is 0.098474
INFO:root:FL Epoch: 100 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1066
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694739
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693835
INFO:root:FL Epoch: 100 Norm Difference for worker 1066 is 0.051736
INFO:root:FL Epoch: 100 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1740
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699184
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693509
INFO:root:FL Epoch: 100 Norm Difference for worker 1740 is 0.10624
INFO:root:FL Epoch: 100 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1716
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696220
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701117
INFO:root:FL Epoch: 100 Norm Difference for worker 1716 is 0.046552
INFO:root:FL Epoch: 100 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :840
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697702
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693016
INFO:root:FL Epoch: 100 Norm Difference for worker 840 is 0.041352
INFO:root:FL Epoch: 100 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :11
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691264
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 11 is 0.044256
INFO:root:FL Epoch: 100 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1887
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694739
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694844
INFO:root:FL Epoch: 100 Norm Difference for worker 1887 is 0.016923
INFO:root:FL Epoch: 100 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :845
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696220
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693404
INFO:root:FL Epoch: 100 Norm Difference for worker 845 is 0.005812
INFO:root:FL Epoch: 100 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.6930802359300501 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:0.7028169631958008                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697043
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687612
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.6432905197143555 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.6811526477336883 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.121577
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694156
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692011
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.6431951522827148 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.6811316847801209 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 0.121778
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696081
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690157
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.6405410170555115 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.6805507063865661 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 0.127381
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697043
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693412
INFO:root:FL Epoch: 101 Norm Difference for worker 1526 is 0.112285
INFO:root:FL Epoch: 101 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1322
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693256
INFO:root:FL Epoch: 101 Norm Difference for worker 1322 is 0.046108
INFO:root:FL Epoch: 101 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :862
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698604
INFO:root:FL Epoch: 101 Norm Difference for worker 862 is 0.062655
INFO:root:FL Epoch: 101 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :701
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691269
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693515
INFO:root:FL Epoch: 101 Norm Difference for worker 701 is 0.001821
INFO:root:FL Epoch: 101 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1726
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691269
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693425
INFO:root:FL Epoch: 101 Norm Difference for worker 1726 is 0.104817
INFO:root:FL Epoch: 101 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692231
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696109
INFO:root:FL Epoch: 101 Norm Difference for worker 526 is 0.070248
INFO:root:FL Epoch: 101 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1267
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691269
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699889
INFO:root:FL Epoch: 101 Norm Difference for worker 1267 is 0.055738
INFO:root:FL Epoch: 101 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.6936124878771165 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.6724330186843872                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1911
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690120
INFO:root:FL Epoch: 102 Norm Difference for worker 1911 is 0.185641
INFO:root:FL Epoch: 102 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :427
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689180
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694077
INFO:root:FL Epoch: 102 Norm Difference for worker 427 is 0.062577
INFO:root:FL Epoch: 102 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1354
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696637
INFO:root:FL Epoch: 102 Norm Difference for worker 1354 is 0.0681
INFO:root:FL Epoch: 102 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :10
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 10 is 0.003338
INFO:root:FL Epoch: 102 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1326
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687086
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691316
INFO:root:FL Epoch: 102 Norm Difference for worker 1326 is 0.055189
INFO:root:FL Epoch: 102 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1947
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696318
INFO:root:FL Epoch: 102 Norm Difference for worker 1947 is 0.012418
INFO:root:FL Epoch: 102 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1506
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695460
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692744
INFO:root:FL Epoch: 102 Norm Difference for worker 1506 is 0.084359
INFO:root:FL Epoch: 102 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1248
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695460
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678351
INFO:root:FL Epoch: 102 Norm Difference for worker 1248 is 0.093036
INFO:root:FL Epoch: 102 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :887
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687361
INFO:root:FL Epoch: 102 Norm Difference for worker 887 is 0.249223
INFO:root:FL Epoch: 102 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1077
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686359
INFO:root:FL Epoch: 102 Norm Difference for worker 1077 is 0.038037
INFO:root:FL Epoch: 102 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.693083149545333 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.7017251253128052                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1424
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692330
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693159
INFO:root:FL Epoch: 103 Norm Difference for worker 1424 is 0.063525
INFO:root:FL Epoch: 103 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :869
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694892
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687451
INFO:root:FL Epoch: 103 Norm Difference for worker 869 is 0.145722
INFO:root:FL Epoch: 103 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1947
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694892
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692694
INFO:root:FL Epoch: 103 Norm Difference for worker 1947 is 0.05028
INFO:root:FL Epoch: 103 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1218
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688913
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683576
INFO:root:FL Epoch: 103 Norm Difference for worker 1218 is 0.263138
INFO:root:FL Epoch: 103 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :731
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694586
INFO:root:FL Epoch: 103 Norm Difference for worker 731 is 0.157183
INFO:root:FL Epoch: 103 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :391
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692008
INFO:root:FL Epoch: 103 Norm Difference for worker 391 is 0.048579
INFO:root:FL Epoch: 103 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1873
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692329
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692076
INFO:root:FL Epoch: 103 Norm Difference for worker 1873 is 0.047939
INFO:root:FL Epoch: 103 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :163
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697615
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 163 is 0.048532
INFO:root:FL Epoch: 103 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1175
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693647
INFO:root:FL Epoch: 103 Norm Difference for worker 1175 is 0.078205
INFO:root:FL Epoch: 103 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1457
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693371
INFO:root:FL Epoch: 103 Norm Difference for worker 1457 is 0.027454
INFO:root:FL Epoch: 103 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.6934457316118128 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:0.732795238494873                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :612
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705571
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686614
INFO:root:FL Epoch: 104 Norm Difference for worker 612 is 0.282205
INFO:root:FL Epoch: 104 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1157
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686125
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693317
INFO:root:FL Epoch: 104 Norm Difference for worker 1157 is 0.076654
INFO:root:FL Epoch: 104 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1471
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705571
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682855
INFO:root:FL Epoch: 104 Norm Difference for worker 1471 is 0.039872
INFO:root:FL Epoch: 104 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :128
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 128 is 0.176627
INFO:root:FL Epoch: 104 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :66
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 66 is 0.037045
INFO:root:FL Epoch: 104 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :879
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690014
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695033
INFO:root:FL Epoch: 104 Norm Difference for worker 879 is 0.208393
INFO:root:FL Epoch: 104 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1042
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697792
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708401
INFO:root:FL Epoch: 104 Norm Difference for worker 1042 is 0.093522
INFO:root:FL Epoch: 104 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1632
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686125
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691082
INFO:root:FL Epoch: 104 Norm Difference for worker 1632 is 0.150343
INFO:root:FL Epoch: 104 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :150
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 150 is 0.238339
INFO:root:FL Epoch: 104 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1712
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686125
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691347
INFO:root:FL Epoch: 104 Norm Difference for worker 1712 is 0.198685
INFO:root:FL Epoch: 104 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.6935560212415808 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:0.6741748452186584                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1124
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697162
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695534
INFO:root:FL Epoch: 105 Norm Difference for worker 1124 is 0.181595
INFO:root:FL Epoch: 105 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :766
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700993
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693828
INFO:root:FL Epoch: 105 Norm Difference for worker 766 is 0.004955
INFO:root:FL Epoch: 105 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :284
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 284 is 0.027281
INFO:root:FL Epoch: 105 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1589
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695246
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693234
INFO:root:FL Epoch: 105 Norm Difference for worker 1589 is 0.068085
INFO:root:FL Epoch: 105 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1409
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691415
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693064
INFO:root:FL Epoch: 105 Norm Difference for worker 1409 is 0.118028
INFO:root:FL Epoch: 105 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1883
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697162
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693434
INFO:root:FL Epoch: 105 Norm Difference for worker 1883 is 0.014782
INFO:root:FL Epoch: 105 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :833
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697162
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692836
INFO:root:FL Epoch: 105 Norm Difference for worker 833 is 0.019179
INFO:root:FL Epoch: 105 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1441
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700993
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 105 Norm Difference for worker 1441 is 0.031921
INFO:root:FL Epoch: 105 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :847
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695246
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691671
INFO:root:FL Epoch: 105 Norm Difference for worker 847 is 0.146945
INFO:root:FL Epoch: 105 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1423
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685668
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691409
INFO:root:FL Epoch: 105 Norm Difference for worker 1423 is 0.181505
INFO:root:FL Epoch: 105 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.6930927704362309 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:0.6994989514350891                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :534
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694434
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688809
INFO:root:FL Epoch: 106 Norm Difference for worker 534 is 0.064288
INFO:root:FL Epoch: 106 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :186
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 186 is 0.058106
INFO:root:FL Epoch: 106 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :452
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691901
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693692
INFO:root:FL Epoch: 106 Norm Difference for worker 452 is 0.12697
INFO:root:FL Epoch: 106 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :985
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694434
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696319
INFO:root:FL Epoch: 106 Norm Difference for worker 985 is 0.103438
INFO:root:FL Epoch: 106 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1302
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695067
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693699
INFO:root:FL Epoch: 106 Norm Difference for worker 1302 is 0.175001
INFO:root:FL Epoch: 106 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1826
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691132
INFO:root:FL Epoch: 106 Norm Difference for worker 1826 is 0.057343
INFO:root:FL Epoch: 106 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :274
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 274 is 0.012093
INFO:root:FL Epoch: 106 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1833
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692534
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693404
INFO:root:FL Epoch: 106 Norm Difference for worker 1833 is 0.095379
INFO:root:FL Epoch: 106 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :626
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692534
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687476
INFO:root:FL Epoch: 106 Norm Difference for worker 626 is 0.153057
INFO:root:FL Epoch: 106 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694434
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694848
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 0.041095
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.6930916905403137 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:0.7102851867675781                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1731
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691592
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704517
INFO:root:FL Epoch: 107 Norm Difference for worker 1731 is 0.011993
INFO:root:FL Epoch: 107 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1909
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691592
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689945
INFO:root:FL Epoch: 107 Norm Difference for worker 1909 is 0.19552
INFO:root:FL Epoch: 107 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1927
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691592
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693889
INFO:root:FL Epoch: 107 Norm Difference for worker 1927 is 0.079733
INFO:root:FL Epoch: 107 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1664
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698390
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689463
INFO:root:FL Epoch: 107 Norm Difference for worker 1664 is 0.143012
INFO:root:FL Epoch: 107 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :392
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679465
INFO:root:FL Epoch: 107 Norm Difference for worker 392 is 0.084932
INFO:root:FL Epoch: 107 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :575
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689893
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695177
INFO:root:FL Epoch: 107 Norm Difference for worker 575 is 0.031071
INFO:root:FL Epoch: 107 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1365
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688194
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694125
INFO:root:FL Epoch: 107 Norm Difference for worker 1365 is 0.045127
INFO:root:FL Epoch: 107 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :308
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 308 is 0.096597
INFO:root:FL Epoch: 107 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1329
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682308
INFO:root:FL Epoch: 107 Norm Difference for worker 1329 is 0.212263
INFO:root:FL Epoch: 107 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :142
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688194
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 142 is 0.163955
INFO:root:FL Epoch: 107 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.6930982400389278 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:0.6985668540000916                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 108 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :65
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 65 is 0.14719
INFO:root:FL Epoch: 108 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :163
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 163 is 0.02642
INFO:root:FL Epoch: 108 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :504
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694783
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697335
INFO:root:FL Epoch: 108 Norm Difference for worker 504 is 0.146901
INFO:root:FL Epoch: 108 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :120
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 120 is 0.004158
INFO:root:FL Epoch: 108 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1859
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692081
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689723
INFO:root:FL Epoch: 108 Norm Difference for worker 1859 is 0.187188
INFO:root:FL Epoch: 108 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1651
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691540
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690980
INFO:root:FL Epoch: 108 Norm Difference for worker 1651 is 0.071205
INFO:root:FL Epoch: 108 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1272
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692081
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687919
INFO:root:FL Epoch: 108 Norm Difference for worker 1272 is 0.025245
INFO:root:FL Epoch: 108 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :595
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693162
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687978
INFO:root:FL Epoch: 108 Norm Difference for worker 595 is 0.085083
INFO:root:FL Epoch: 108 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :487
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691540
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693544
INFO:root:FL Epoch: 108 Norm Difference for worker 487 is 0.067975
INFO:root:FL Epoch: 108 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1181
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694783
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690568
INFO:root:FL Epoch: 108 Norm Difference for worker 1181 is 0.12218
INFO:root:FL Epoch: 108 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.6930799904991599 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:0.7070218324661255                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :659
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689108
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694785
INFO:root:FL Epoch: 109 Norm Difference for worker 659 is 0.034808
INFO:root:FL Epoch: 109 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1630
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691864
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694159
INFO:root:FL Epoch: 109 Norm Difference for worker 1630 is 0.094242
INFO:root:FL Epoch: 109 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :147
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 147 is 0.073487
INFO:root:FL Epoch: 109 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1704
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694560
INFO:root:FL Epoch: 109 Norm Difference for worker 1704 is 0.080808
INFO:root:FL Epoch: 109 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1338
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695998
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697711
INFO:root:FL Epoch: 109 Norm Difference for worker 1338 is 0.172969
INFO:root:FL Epoch: 109 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :376
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691864
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690802
INFO:root:FL Epoch: 109 Norm Difference for worker 376 is 0.097786
INFO:root:FL Epoch: 109 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :790
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689108
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685378
INFO:root:FL Epoch: 109 Norm Difference for worker 790 is 0.07551
INFO:root:FL Epoch: 109 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1004
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698754
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694677
INFO:root:FL Epoch: 109 Norm Difference for worker 1004 is 0.115696
INFO:root:FL Epoch: 109 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1131
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691864
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694672
INFO:root:FL Epoch: 109 Norm Difference for worker 1131 is 0.176033
INFO:root:FL Epoch: 109 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :172
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695128
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 172 is 0.037517
INFO:root:FL Epoch: 109 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.6931424947345958 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:0.693548321723938                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :191
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 191 is 0.001679
INFO:root:FL Epoch: 110 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :844
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693067
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690679
INFO:root:FL Epoch: 110 Norm Difference for worker 844 is 0.050703
INFO:root:FL Epoch: 110 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1062
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692874
INFO:root:FL Epoch: 110 Norm Difference for worker 1062 is 0.064656
INFO:root:FL Epoch: 110 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1182
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693107
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693503
INFO:root:FL Epoch: 110 Norm Difference for worker 1182 is 0.022618
INFO:root:FL Epoch: 110 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1038
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690382
INFO:root:FL Epoch: 110 Norm Difference for worker 1038 is 0.120513
INFO:root:FL Epoch: 110 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :791
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693027
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696713
INFO:root:FL Epoch: 110 Norm Difference for worker 791 is 0.071146
INFO:root:FL Epoch: 110 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1015
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693227
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686967
INFO:root:FL Epoch: 110 Norm Difference for worker 1015 is 0.202659
INFO:root:FL Epoch: 110 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :160
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 160 is 0.053128
INFO:root:FL Epoch: 110 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :803
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693067
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701902
INFO:root:FL Epoch: 110 Norm Difference for worker 803 is 0.044266
INFO:root:FL Epoch: 110 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :902
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692987
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695142
INFO:root:FL Epoch: 110 Norm Difference for worker 902 is 0.009456
INFO:root:FL Epoch: 110 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.6930972548092112 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:0.6987132430076599                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690408
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.6403951048851013 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.6805189073085784 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.119544
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692052
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690287
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.6435779929161072 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.6812159478664398 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 0.112825
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694273
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679797
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.6350916028022766 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.6793770849704742 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 0.130792
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :212
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 212 is 0.185927
INFO:root:FL Epoch: 111 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :603
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695383
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693251
INFO:root:FL Epoch: 111 Norm Difference for worker 603 is 0.08462
INFO:root:FL Epoch: 111 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1485
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693718
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696323
INFO:root:FL Epoch: 111 Norm Difference for worker 1485 is 0.109242
INFO:root:FL Epoch: 111 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1334
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690140
INFO:root:FL Epoch: 111 Norm Difference for worker 1334 is 0.065878
INFO:root:FL Epoch: 111 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :260
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694566
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 260 is 0.12496
INFO:root:FL Epoch: 111 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1352
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694273
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683527
INFO:root:FL Epoch: 111 Norm Difference for worker 1352 is 0.208187
INFO:root:FL Epoch: 111 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1619
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694273
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688881
INFO:root:FL Epoch: 111 Norm Difference for worker 1619 is 0.10512
INFO:root:FL Epoch: 111 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.6936989321428186 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.66994708776474                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 112 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :254
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694021
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 254 is 0.026786
INFO:root:FL Epoch: 112 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :253
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 253 is 0.012635
INFO:root:FL Epoch: 112 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :267
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688728
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 267 is 0.035613
INFO:root:FL Epoch: 112 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1281
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695770
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682937
INFO:root:FL Epoch: 112 Norm Difference for worker 1281 is 0.19946
INFO:root:FL Epoch: 112 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :552
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705161
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696677
INFO:root:FL Epoch: 112 Norm Difference for worker 552 is 0.028388
INFO:root:FL Epoch: 112 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1889
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693423
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688817
INFO:root:FL Epoch: 112 Norm Difference for worker 1889 is 0.238282
INFO:root:FL Epoch: 112 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1555
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688728
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689969
INFO:root:FL Epoch: 112 Norm Difference for worker 1555 is 0.049152
INFO:root:FL Epoch: 112 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1475
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691075
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686574
INFO:root:FL Epoch: 112 Norm Difference for worker 1475 is 0.028757
INFO:root:FL Epoch: 112 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :334
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 334 is 0.13483
INFO:root:FL Epoch: 112 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :202
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 202 is 0.1836
INFO:root:FL Epoch: 112 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.6930864032577065 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.7091314196586609                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 113 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :173
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 173 is 0.028049
INFO:root:FL Epoch: 113 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1677
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693273
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691430
INFO:root:FL Epoch: 113 Norm Difference for worker 1677 is 0.015136
INFO:root:FL Epoch: 113 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1063
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696445
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694462
INFO:root:FL Epoch: 113 Norm Difference for worker 1063 is 0.011702
INFO:root:FL Epoch: 113 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :828
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698030
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690763
INFO:root:FL Epoch: 113 Norm Difference for worker 828 is 0.075082
INFO:root:FL Epoch: 113 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1243
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691687
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698979
INFO:root:FL Epoch: 113 Norm Difference for worker 1243 is 0.100664
INFO:root:FL Epoch: 113 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1645
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690101
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696797
INFO:root:FL Epoch: 113 Norm Difference for worker 1645 is 0.183852
INFO:root:FL Epoch: 113 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :701
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696445
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693568
INFO:root:FL Epoch: 113 Norm Difference for worker 701 is 0.045202
INFO:root:FL Epoch: 113 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :511
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693273
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682691
INFO:root:FL Epoch: 113 Norm Difference for worker 511 is 0.122258
INFO:root:FL Epoch: 113 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1769
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699616
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689467
INFO:root:FL Epoch: 113 Norm Difference for worker 1769 is 0.2333
INFO:root:FL Epoch: 113 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :539
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691687
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688881
INFO:root:FL Epoch: 113 Norm Difference for worker 539 is 0.044928
INFO:root:FL Epoch: 113 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.6930783250752617 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.7058677077293396                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1682
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694491
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690995
INFO:root:FL Epoch: 114 Norm Difference for worker 1682 is 0.147965
INFO:root:FL Epoch: 114 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :817
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693227
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690724
INFO:root:FL Epoch: 114 Norm Difference for worker 817 is 0.099715
INFO:root:FL Epoch: 114 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :747
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694491
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689851
INFO:root:FL Epoch: 114 Norm Difference for worker 747 is 0.022774
INFO:root:FL Epoch: 114 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1065
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689435
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689020
INFO:root:FL Epoch: 114 Norm Difference for worker 1065 is 0.00127
INFO:root:FL Epoch: 114 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :615
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695755
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701580
INFO:root:FL Epoch: 114 Norm Difference for worker 615 is 0.137209
INFO:root:FL Epoch: 114 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :439
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697019
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693584
INFO:root:FL Epoch: 114 Norm Difference for worker 439 is 0.11393
INFO:root:FL Epoch: 114 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :501
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694491
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691612
INFO:root:FL Epoch: 114 Norm Difference for worker 501 is 0.099661
INFO:root:FL Epoch: 114 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1941
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691963
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695449
INFO:root:FL Epoch: 114 Norm Difference for worker 1941 is 0.021542
INFO:root:FL Epoch: 114 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :729
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697019
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699275
INFO:root:FL Epoch: 114 Norm Difference for worker 729 is 0.058441
INFO:root:FL Epoch: 114 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1621
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694491
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687381
INFO:root:FL Epoch: 114 Norm Difference for worker 1621 is 0.101786
INFO:root:FL Epoch: 114 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.6931868405903087 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.6901593208312988                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1247
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694349
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686511
INFO:root:FL Epoch: 115 Norm Difference for worker 1247 is 0.186019
INFO:root:FL Epoch: 115 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1891
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694049
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692083
INFO:root:FL Epoch: 115 Norm Difference for worker 1891 is 0.1001
INFO:root:FL Epoch: 115 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1092
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692852
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696561
INFO:root:FL Epoch: 115 Norm Difference for worker 1092 is 0.012225
INFO:root:FL Epoch: 115 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1160
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693451
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693350
INFO:root:FL Epoch: 115 Norm Difference for worker 1160 is 0.006239
INFO:root:FL Epoch: 115 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1542
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693750
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692127
INFO:root:FL Epoch: 115 Norm Difference for worker 1542 is 0.029799
INFO:root:FL Epoch: 115 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691955
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693979
INFO:root:FL Epoch: 115 Norm Difference for worker 1248 is 0.111243
INFO:root:FL Epoch: 115 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1758
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692254
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688076
INFO:root:FL Epoch: 115 Norm Difference for worker 1758 is 0.216828
INFO:root:FL Epoch: 115 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :206
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692254
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693319
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 206 is 0.059059
INFO:root:FL Epoch: 115 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :881
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692852
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690750
INFO:root:FL Epoch: 115 Norm Difference for worker 881 is 0.05955
INFO:root:FL Epoch: 115 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1311
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692852
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694242
INFO:root:FL Epoch: 115 Norm Difference for worker 1311 is 0.122116
INFO:root:FL Epoch: 115 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.6932363299762502 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:0.687131941318512                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :670
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696785
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675084
INFO:root:FL Epoch: 116 Norm Difference for worker 670 is 0.259165
INFO:root:FL Epoch: 116 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :77
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 77 is 0.035438
INFO:root:FL Epoch: 116 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :14
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 14 is 0.041011
INFO:root:FL Epoch: 116 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :831
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 116 Norm Difference for worker 831 is 0.056951
INFO:root:FL Epoch: 116 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :557
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692562
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 116 Norm Difference for worker 557 is 0.015342
INFO:root:FL Epoch: 116 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1196
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691355
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690984
INFO:root:FL Epoch: 116 Norm Difference for worker 1196 is 0.174892
INFO:root:FL Epoch: 116 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1519
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694372
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690416
INFO:root:FL Epoch: 116 Norm Difference for worker 1519 is 0.138556
INFO:root:FL Epoch: 116 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :237
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693769
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 237 is 0.18288
INFO:root:FL Epoch: 116 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1512
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690342
INFO:root:FL Epoch: 116 Norm Difference for worker 1512 is 0.092164
INFO:root:FL Epoch: 116 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :592
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690431
INFO:root:FL Epoch: 116 Norm Difference for worker 592 is 0.039198
INFO:root:FL Epoch: 116 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.6931089373195872 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.6970468759536743                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 117 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :300
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693193
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 300 is 0.081837
INFO:root:FL Epoch: 117 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :251
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686175
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 251 is 0.082571
INFO:root:FL Epoch: 117 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :562
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686878
INFO:root:FL Epoch: 117 Norm Difference for worker 562 is 0.095348
INFO:root:FL Epoch: 117 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1356
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691598
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686733
INFO:root:FL Epoch: 117 Norm Difference for worker 1356 is 0.11773
INFO:root:FL Epoch: 117 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :204
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 204 is 0.096632
INFO:root:FL Epoch: 117 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :809
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691987
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691454
INFO:root:FL Epoch: 117 Norm Difference for worker 809 is 0.007513
INFO:root:FL Epoch: 117 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :968
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693933
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692800
INFO:root:FL Epoch: 117 Norm Difference for worker 968 is 0.002294
INFO:root:FL Epoch: 117 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1645
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694712
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682177
INFO:root:FL Epoch: 117 Norm Difference for worker 1645 is 0.2023
INFO:root:FL Epoch: 117 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1482
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691987
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693737
INFO:root:FL Epoch: 117 Norm Difference for worker 1482 is 0.003272
INFO:root:FL Epoch: 117 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :844
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693933
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695123
INFO:root:FL Epoch: 117 Norm Difference for worker 844 is 0.049121
INFO:root:FL Epoch: 117 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.6932545374421513 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.6861462593078613                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 118 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :191
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691048
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 191 is 0.008749
INFO:root:FL Epoch: 118 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1890
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693172
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688151
INFO:root:FL Epoch: 118 Norm Difference for worker 1890 is 0.180781
INFO:root:FL Epoch: 118 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :999
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693172
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697388
INFO:root:FL Epoch: 118 Norm Difference for worker 999 is 0.059925
INFO:root:FL Epoch: 118 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1404
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691064
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693763
INFO:root:FL Epoch: 118 Norm Difference for worker 1404 is 0.03352
INFO:root:FL Epoch: 118 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :725
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693874
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696609
INFO:root:FL Epoch: 118 Norm Difference for worker 725 is 0.066515
INFO:root:FL Epoch: 118 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1853
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695280
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693227
INFO:root:FL Epoch: 118 Norm Difference for worker 1853 is 0.001696
INFO:root:FL Epoch: 118 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1315
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691064
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701730
INFO:root:FL Epoch: 118 Norm Difference for worker 1315 is 0.067778
INFO:root:FL Epoch: 118 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1082
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693874
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692096
INFO:root:FL Epoch: 118 Norm Difference for worker 1082 is 0.060695
INFO:root:FL Epoch: 118 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :862
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691767
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692757
INFO:root:FL Epoch: 118 Norm Difference for worker 862 is 0.069736
INFO:root:FL Epoch: 118 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :84
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 84 is 0.105784
INFO:root:FL Epoch: 118 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.6930782689767725 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:0.7041507363319397                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :917
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696490
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692099
INFO:root:FL Epoch: 119 Norm Difference for worker 917 is 0.070297
INFO:root:FL Epoch: 119 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :474
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696490
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693081
INFO:root:FL Epoch: 119 Norm Difference for worker 474 is 0.015005
INFO:root:FL Epoch: 119 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693207
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697412
INFO:root:FL Epoch: 119 Norm Difference for worker 748 is 0.01296
INFO:root:FL Epoch: 119 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1071
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694301
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691938
INFO:root:FL Epoch: 119 Norm Difference for worker 1071 is 0.015778
INFO:root:FL Epoch: 119 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :436
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692113
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684766
INFO:root:FL Epoch: 119 Norm Difference for worker 436 is 0.108202
INFO:root:FL Epoch: 119 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1413
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696490
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695150
INFO:root:FL Epoch: 119 Norm Difference for worker 1413 is 0.004253
INFO:root:FL Epoch: 119 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :141
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 141 is 0.213502
INFO:root:FL Epoch: 119 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :439
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692113
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694791
INFO:root:FL Epoch: 119 Norm Difference for worker 439 is 0.163189
INFO:root:FL Epoch: 119 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :281
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693207
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 281 is 0.096164
INFO:root:FL Epoch: 119 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1415
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694301
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690668
INFO:root:FL Epoch: 119 Norm Difference for worker 1415 is 0.036908
INFO:root:FL Epoch: 119 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.6932220529107487 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:0.6879539489746094                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :672
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692119
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676541
INFO:root:FL Epoch: 120 Norm Difference for worker 672 is 0.092699
INFO:root:FL Epoch: 120 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1130
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692640
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707070
INFO:root:FL Epoch: 120 Norm Difference for worker 1130 is 0.191003
INFO:root:FL Epoch: 120 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :89
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 89 is 0.335939
INFO:root:FL Epoch: 120 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :766
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691078
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692527
INFO:root:FL Epoch: 120 Norm Difference for worker 766 is 0.004251
INFO:root:FL Epoch: 120 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :604
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692119
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693736
INFO:root:FL Epoch: 120 Norm Difference for worker 604 is 0.04788
INFO:root:FL Epoch: 120 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1934
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693682
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691705
INFO:root:FL Epoch: 120 Norm Difference for worker 1934 is 0.017139
INFO:root:FL Epoch: 120 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1085
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692119
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690788
INFO:root:FL Epoch: 120 Norm Difference for worker 1085 is 0.006016
INFO:root:FL Epoch: 120 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1785
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691599
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688350
INFO:root:FL Epoch: 120 Norm Difference for worker 1785 is 0.079304
INFO:root:FL Epoch: 120 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :799
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703909
INFO:root:FL Epoch: 120 Norm Difference for worker 799 is 0.104108
INFO:root:FL Epoch: 120 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :394
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693681
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682729
INFO:root:FL Epoch: 120 Norm Difference for worker 394 is 0.194894
INFO:root:FL Epoch: 120 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.6936664756606606 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:0.670859694480896                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679876
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652516
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.6212591528892517 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.6765175104141236 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.104264
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679876
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672491
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.6204724311828613 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.6763601720333099 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 0.105965
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688893
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682001
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.6201176047325134 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.6762893617153167 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 0.106732
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1516
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700164
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694454
INFO:root:FL Epoch: 121 Norm Difference for worker 1516 is 0.011121
INFO:root:FL Epoch: 121 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1691
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693401
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691646
INFO:root:FL Epoch: 121 Norm Difference for worker 1691 is 0.012563
INFO:root:FL Epoch: 121 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1534
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691147
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639129
INFO:root:FL Epoch: 121 Norm Difference for worker 1534 is 0.313383
INFO:root:FL Epoch: 121 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1245
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693401
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693442
INFO:root:FL Epoch: 121 Norm Difference for worker 1245 is 0.111112
INFO:root:FL Epoch: 121 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1693
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691147
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693545
INFO:root:FL Epoch: 121 Norm Difference for worker 1693 is 0.019827
INFO:root:FL Epoch: 121 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :520
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691147
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687806
INFO:root:FL Epoch: 121 Norm Difference for worker 520 is 0.014694
INFO:root:FL Epoch: 121 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693401
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696648
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 0.036796
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.6949485365082236 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.6449598670005798                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 122 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :847
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689427
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689595
INFO:root:FL Epoch: 122 Norm Difference for worker 847 is 0.161798
INFO:root:FL Epoch: 122 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :302
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693222
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 302 is 0.157619
INFO:root:FL Epoch: 122 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1156
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689427
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698513
INFO:root:FL Epoch: 122 Norm Difference for worker 1156 is 0.186378
INFO:root:FL Epoch: 122 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1187
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709190
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693178
INFO:root:FL Epoch: 122 Norm Difference for worker 1187 is 0.080225
INFO:root:FL Epoch: 122 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :252
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 252 is 0.021122
INFO:root:FL Epoch: 122 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :460
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704249
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694714
INFO:root:FL Epoch: 122 Norm Difference for worker 460 is 0.230231
INFO:root:FL Epoch: 122 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1246
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699308
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688516
INFO:root:FL Epoch: 122 Norm Difference for worker 1246 is 0.093541
INFO:root:FL Epoch: 122 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :151
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 151 is 0.098462
INFO:root:FL Epoch: 122 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :556
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709189
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695412
INFO:root:FL Epoch: 122 Norm Difference for worker 556 is 0.142278
INFO:root:FL Epoch: 122 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1367
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699308
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709834
INFO:root:FL Epoch: 122 Norm Difference for worker 1367 is 0.066581
INFO:root:FL Epoch: 122 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.6931151572395774 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.6962928175926208                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :900
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692838
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693690
INFO:root:FL Epoch: 123 Norm Difference for worker 900 is 0.125257
INFO:root:FL Epoch: 123 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :614
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690504
INFO:root:FL Epoch: 123 Norm Difference for worker 614 is 0.014751
INFO:root:FL Epoch: 123 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1916
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691579
INFO:root:FL Epoch: 123 Norm Difference for worker 1916 is 0.125237
INFO:root:FL Epoch: 123 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1149
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690032
INFO:root:FL Epoch: 123 Norm Difference for worker 1149 is 0.148416
INFO:root:FL Epoch: 123 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1225
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692838
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692556
INFO:root:FL Epoch: 123 Norm Difference for worker 1225 is 0.101823
INFO:root:FL Epoch: 123 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :315
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692186
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 315 is 0.003897
INFO:root:FL Epoch: 123 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :66
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 66 is 0.117728
INFO:root:FL Epoch: 123 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :959
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691582
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710596
INFO:root:FL Epoch: 123 Norm Difference for worker 959 is 0.191477
INFO:root:FL Epoch: 123 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :938
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692524
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693243
INFO:root:FL Epoch: 123 Norm Difference for worker 938 is 0.076003
INFO:root:FL Epoch: 123 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1349
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693466
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688226
INFO:root:FL Epoch: 123 Norm Difference for worker 1349 is 0.057788
INFO:root:FL Epoch: 123 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.6930834896424237 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.701635479927063                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :1329
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694873
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671532
INFO:root:FL Epoch: 124 Norm Difference for worker 1329 is 0.225605
INFO:root:FL Epoch: 124 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1737
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694028
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691006
INFO:root:FL Epoch: 124 Norm Difference for worker 1737 is 0.113904
INFO:root:FL Epoch: 124 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :570
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695719
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685005
INFO:root:FL Epoch: 124 Norm Difference for worker 570 is 0.185536
INFO:root:FL Epoch: 124 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1802
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693183
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693459
INFO:root:FL Epoch: 124 Norm Difference for worker 1802 is 0.007281
INFO:root:FL Epoch: 124 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1438
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695719
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693262
INFO:root:FL Epoch: 124 Norm Difference for worker 1438 is 0.07027
INFO:root:FL Epoch: 124 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :725
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692338
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695210
INFO:root:FL Epoch: 124 Norm Difference for worker 725 is 0.051085
INFO:root:FL Epoch: 124 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :394
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691492
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695873
INFO:root:FL Epoch: 124 Norm Difference for worker 394 is 0.137148
INFO:root:FL Epoch: 124 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :456
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695719
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700787
INFO:root:FL Epoch: 124 Norm Difference for worker 456 is 0.078735
INFO:root:FL Epoch: 124 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1801
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694028
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688255
INFO:root:FL Epoch: 124 Norm Difference for worker 1801 is 0.088765
INFO:root:FL Epoch: 124 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1221
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694873
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693157
INFO:root:FL Epoch: 124 Norm Difference for worker 1221 is 0.058142
INFO:root:FL Epoch: 124 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.6934084015734056 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.679301381111145                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :371
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693244
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690299
INFO:root:FL Epoch: 125 Norm Difference for worker 371 is 0.24098
INFO:root:FL Epoch: 125 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :455
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690456
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693594
INFO:root:FL Epoch: 125 Norm Difference for worker 455 is 0.357401
INFO:root:FL Epoch: 125 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :747
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691850
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694237
INFO:root:FL Epoch: 125 Norm Difference for worker 747 is 0.054907
INFO:root:FL Epoch: 125 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :106
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 106 is 0.087896
INFO:root:FL Epoch: 125 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1722
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693244
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693281
INFO:root:FL Epoch: 125 Norm Difference for worker 1722 is 0.056474
INFO:root:FL Epoch: 125 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :631
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697427
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658897
INFO:root:FL Epoch: 125 Norm Difference for worker 631 is 0.405773
INFO:root:FL Epoch: 125 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :374
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687667
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678111
INFO:root:FL Epoch: 125 Norm Difference for worker 374 is 0.219216
INFO:root:FL Epoch: 125 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1617
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696033
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691480
INFO:root:FL Epoch: 125 Norm Difference for worker 1617 is 0.059175
INFO:root:FL Epoch: 125 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :513
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694639
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693290
INFO:root:FL Epoch: 125 Norm Difference for worker 513 is 0.177718
INFO:root:FL Epoch: 125 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1270
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696033
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690945
INFO:root:FL Epoch: 125 Norm Difference for worker 1270 is 0.091921
INFO:root:FL Epoch: 125 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.6932092028505662 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.7215071320533752                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 126 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1262
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696335
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684533
INFO:root:FL Epoch: 126 Norm Difference for worker 1262 is 0.077058
INFO:root:FL Epoch: 126 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :808
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693538
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692195
INFO:root:FL Epoch: 126 Norm Difference for worker 808 is 0.037918
INFO:root:FL Epoch: 126 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :93
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 93 is 0.051433
INFO:root:FL Epoch: 126 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1323
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690741
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694879
INFO:root:FL Epoch: 126 Norm Difference for worker 1323 is 0.167972
INFO:root:FL Epoch: 126 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1090
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696335
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696860
INFO:root:FL Epoch: 126 Norm Difference for worker 1090 is 0.191565
INFO:root:FL Epoch: 126 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :844
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696335
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690555
INFO:root:FL Epoch: 126 Norm Difference for worker 844 is 0.039414
INFO:root:FL Epoch: 126 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :915
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690741
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685970
INFO:root:FL Epoch: 126 Norm Difference for worker 915 is 0.349943
INFO:root:FL Epoch: 126 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :433
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696335
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689435
INFO:root:FL Epoch: 126 Norm Difference for worker 433 is 0.148007
INFO:root:FL Epoch: 126 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :605
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690741
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694399
INFO:root:FL Epoch: 126 Norm Difference for worker 605 is 0.125106
INFO:root:FL Epoch: 126 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :416
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687944
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690929
INFO:root:FL Epoch: 126 Norm Difference for worker 416 is 0.097608
INFO:root:FL Epoch: 126 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.693213701248169 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.6884464621543884                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :857
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692216
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700461
INFO:root:FL Epoch: 127 Norm Difference for worker 857 is 0.134139
INFO:root:FL Epoch: 127 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1514
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692687
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691282
INFO:root:FL Epoch: 127 Norm Difference for worker 1514 is 0.006817
INFO:root:FL Epoch: 127 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :267
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 267 is 0.058871
INFO:root:FL Epoch: 127 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1586
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694572
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687813
INFO:root:FL Epoch: 127 Norm Difference for worker 1586 is 0.132673
INFO:root:FL Epoch: 127 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :889
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692687
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693883
INFO:root:FL Epoch: 127 Norm Difference for worker 889 is 0.022165
INFO:root:FL Epoch: 127 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1059
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694572
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683024
INFO:root:FL Epoch: 127 Norm Difference for worker 1059 is 0.318621
INFO:root:FL Epoch: 127 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1388
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694572
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691575
INFO:root:FL Epoch: 127 Norm Difference for worker 1388 is 0.05324
INFO:root:FL Epoch: 127 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1617
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691745
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690343
INFO:root:FL Epoch: 127 Norm Difference for worker 1617 is 0.038531
INFO:root:FL Epoch: 127 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1454
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693629
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695217
INFO:root:FL Epoch: 127 Norm Difference for worker 1454 is 0.038197
INFO:root:FL Epoch: 127 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1616
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692687
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693686
INFO:root:FL Epoch: 127 Norm Difference for worker 1616 is 0.063463
INFO:root:FL Epoch: 127 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.6930791209725773 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.7065290808677673                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 128 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :310
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 310 is 0.040167
INFO:root:FL Epoch: 128 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :104
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695894
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 104 is 0.067451
INFO:root:FL Epoch: 128 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :160
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 160 is 0.05388
INFO:root:FL Epoch: 128 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :498
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694144
INFO:root:FL Epoch: 128 Norm Difference for worker 498 is 0.0626
INFO:root:FL Epoch: 128 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :577
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697224
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693329
INFO:root:FL Epoch: 128 Norm Difference for worker 577 is 0.059491
INFO:root:FL Epoch: 128 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1023
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682904
INFO:root:FL Epoch: 128 Norm Difference for worker 1023 is 0.199748
INFO:root:FL Epoch: 128 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :911
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691906
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695707
INFO:root:FL Epoch: 128 Norm Difference for worker 911 is 0.033152
INFO:root:FL Epoch: 128 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :823
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695894
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694924
INFO:root:FL Epoch: 128 Norm Difference for worker 823 is 0.032149
INFO:root:FL Epoch: 128 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1667
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690957
INFO:root:FL Epoch: 128 Norm Difference for worker 1667 is 0.019186
INFO:root:FL Epoch: 128 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :754
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689247
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688613
INFO:root:FL Epoch: 128 Norm Difference for worker 754 is 0.25221
INFO:root:FL Epoch: 128 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.6930945585755741 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.7108283638954163                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1492
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693301
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689687
INFO:root:FL Epoch: 129 Norm Difference for worker 1492 is 0.078806
INFO:root:FL Epoch: 129 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :354
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698559
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688447
INFO:root:FL Epoch: 129 Norm Difference for worker 354 is 0.100843
INFO:root:FL Epoch: 129 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :33
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 33 is 0.116561
INFO:root:FL Epoch: 129 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1440
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693301
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696236
INFO:root:FL Epoch: 129 Norm Difference for worker 1440 is 0.093445
INFO:root:FL Epoch: 129 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :773
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689795
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689467
INFO:root:FL Epoch: 129 Norm Difference for worker 773 is 0.103248
INFO:root:FL Epoch: 129 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1028
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695054
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696099
INFO:root:FL Epoch: 129 Norm Difference for worker 1028 is 0.214884
INFO:root:FL Epoch: 129 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :863
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693301
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693263
INFO:root:FL Epoch: 129 Norm Difference for worker 863 is 0.105149
INFO:root:FL Epoch: 129 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :755
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695054
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691982
INFO:root:FL Epoch: 129 Norm Difference for worker 755 is 0.09643
INFO:root:FL Epoch: 129 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1307
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698559
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679560
INFO:root:FL Epoch: 129 Norm Difference for worker 1307 is 0.114775
INFO:root:FL Epoch: 129 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1724
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688043
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694892
INFO:root:FL Epoch: 129 Norm Difference for worker 1724 is 0.040098
INFO:root:FL Epoch: 129 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.6931669606881983 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.718571126461029                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 130 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :324
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 324 is 0.153764
INFO:root:FL Epoch: 130 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :145
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695973
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683313
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 145 is 0.271583
INFO:root:FL Epoch: 130 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :544
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690951
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691978
INFO:root:FL Epoch: 130 Norm Difference for worker 544 is 0.107669
INFO:root:FL Epoch: 130 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :970
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685930
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690918
INFO:root:FL Epoch: 130 Norm Difference for worker 970 is 0.076285
INFO:root:FL Epoch: 130 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1423
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698484
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699027
INFO:root:FL Epoch: 130 Norm Difference for worker 1423 is 0.069297
INFO:root:FL Epoch: 130 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1402
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697800
INFO:root:FL Epoch: 130 Norm Difference for worker 1402 is 0.039607
INFO:root:FL Epoch: 130 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :689
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691147
INFO:root:FL Epoch: 130 Norm Difference for worker 689 is 0.012391
INFO:root:FL Epoch: 130 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1486
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696117
INFO:root:FL Epoch: 130 Norm Difference for worker 1486 is 0.122296
INFO:root:FL Epoch: 130 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :765
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685930
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696208
INFO:root:FL Epoch: 130 Norm Difference for worker 765 is 0.134443
INFO:root:FL Epoch: 130 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :11
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686002
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 11 is 0.006085
INFO:root:FL Epoch: 130 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.6934027145890629 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.679519772529602                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690497
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690559
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.631060004234314 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.6785257637500763 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.100843
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694613
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690296
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.6317681670188904 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.6786742508411407 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 0.099331
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686381
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671975
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.6277347207069397 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.6778346300125122 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 0.107962
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1513
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693241
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691016
INFO:root:FL Epoch: 131 Norm Difference for worker 1513 is 0.138479
INFO:root:FL Epoch: 131 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1131
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691869
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690218
INFO:root:FL Epoch: 131 Norm Difference for worker 1131 is 0.231351
INFO:root:FL Epoch: 131 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :516
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691869
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689467
INFO:root:FL Epoch: 131 Norm Difference for worker 516 is 0.104327
INFO:root:FL Epoch: 131 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :950
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689125
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689745
INFO:root:FL Epoch: 131 Norm Difference for worker 950 is 0.235676
INFO:root:FL Epoch: 131 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :910
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697358
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695188
INFO:root:FL Epoch: 131 Norm Difference for worker 910 is 0.090324
INFO:root:FL Epoch: 131 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :386
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691869
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692571
INFO:root:FL Epoch: 131 Norm Difference for worker 386 is 0.054668
INFO:root:FL Epoch: 131 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :240
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 240 is 0.219094
INFO:root:FL Epoch: 131 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.6930809722227209 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.7074236273765564                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 132 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :1511
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697501
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693379
INFO:root:FL Epoch: 132 Norm Difference for worker 1511 is 0.079166
INFO:root:FL Epoch: 132 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1912
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690413
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692429
INFO:root:FL Epoch: 132 Norm Difference for worker 1912 is 0.091861
INFO:root:FL Epoch: 132 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :355
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694665
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702480
INFO:root:FL Epoch: 132 Norm Difference for worker 355 is 0.148483
INFO:root:FL Epoch: 132 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :961
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686160
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688502
INFO:root:FL Epoch: 132 Norm Difference for worker 961 is 0.145313
INFO:root:FL Epoch: 132 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :352
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694665
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699191
INFO:root:FL Epoch: 132 Norm Difference for worker 352 is 0.007038
INFO:root:FL Epoch: 132 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :366
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687577
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691764
INFO:root:FL Epoch: 132 Norm Difference for worker 366 is 0.117041
INFO:root:FL Epoch: 132 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :136
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696083
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 136 is 0.385693
INFO:root:FL Epoch: 132 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :335
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 335 is 0.21084
INFO:root:FL Epoch: 132 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1156
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690413
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693582
INFO:root:FL Epoch: 132 Norm Difference for worker 1156 is 0.056409
INFO:root:FL Epoch: 132 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1522
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698918
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691561
INFO:root:FL Epoch: 132 Norm Difference for worker 1522 is 0.162486
INFO:root:FL Epoch: 132 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.6936190408818862 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.6722365617752075                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1447
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689144
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683487
INFO:root:FL Epoch: 133 Norm Difference for worker 1447 is 0.072417
INFO:root:FL Epoch: 133 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1313
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687030
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686984
INFO:root:FL Epoch: 133 Norm Difference for worker 1313 is 0.062759
INFO:root:FL Epoch: 133 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1892
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687030
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690216
INFO:root:FL Epoch: 133 Norm Difference for worker 1892 is 0.045983
INFO:root:FL Epoch: 133 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695484
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682920
INFO:root:FL Epoch: 133 Norm Difference for worker 700 is 0.103347
INFO:root:FL Epoch: 133 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1180
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689144
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696196
INFO:root:FL Epoch: 133 Norm Difference for worker 1180 is 0.081973
INFO:root:FL Epoch: 133 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :208
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695484
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 208 is 0.045195
INFO:root:FL Epoch: 133 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1366
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691257
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689518
INFO:root:FL Epoch: 133 Norm Difference for worker 1366 is 0.020596
INFO:root:FL Epoch: 133 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1174
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691257
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701404
INFO:root:FL Epoch: 133 Norm Difference for worker 1174 is 0.024504
INFO:root:FL Epoch: 133 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :968
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695484
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696382
INFO:root:FL Epoch: 133 Norm Difference for worker 968 is 0.075382
INFO:root:FL Epoch: 133 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693370
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691028
INFO:root:FL Epoch: 133 Norm Difference for worker 869 is 0.163835
INFO:root:FL Epoch: 133 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.6934965568430284 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.6761247515678406                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1137
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691578
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692384
INFO:root:FL Epoch: 134 Norm Difference for worker 1137 is 0.069273
INFO:root:FL Epoch: 134 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1389
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695011
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695179
INFO:root:FL Epoch: 134 Norm Difference for worker 1389 is 0.013442
INFO:root:FL Epoch: 134 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :158
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694034
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 158 is 0.125691
INFO:root:FL Epoch: 134 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :892
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696729
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690002
INFO:root:FL Epoch: 134 Norm Difference for worker 892 is 0.018323
INFO:root:FL Epoch: 134 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :314
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 314 is 0.198988
INFO:root:FL Epoch: 134 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :737
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689861
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689783
INFO:root:FL Epoch: 134 Norm Difference for worker 737 is 0.022966
INFO:root:FL Epoch: 134 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1206
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693295
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693175
INFO:root:FL Epoch: 134 Norm Difference for worker 1206 is 0.046125
INFO:root:FL Epoch: 134 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :362
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693295
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692902
INFO:root:FL Epoch: 134 Norm Difference for worker 362 is 0.146535
INFO:root:FL Epoch: 134 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1354
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701880
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690852
INFO:root:FL Epoch: 134 Norm Difference for worker 1354 is 0.030143
INFO:root:FL Epoch: 134 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :650
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689861
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670261
INFO:root:FL Epoch: 134 Norm Difference for worker 650 is 0.118746
INFO:root:FL Epoch: 134 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.6930787563323975 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.7037233114242554                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1702
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697411
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693893
INFO:root:FL Epoch: 135 Norm Difference for worker 1702 is 0.065178
INFO:root:FL Epoch: 135 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :19
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 19 is 0.049585
INFO:root:FL Epoch: 135 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :779
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687942
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688786
INFO:root:FL Epoch: 135 Norm Difference for worker 779 is 0.168484
INFO:root:FL Epoch: 135 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1874
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694255
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696734
INFO:root:FL Epoch: 135 Norm Difference for worker 1874 is 0.183821
INFO:root:FL Epoch: 135 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :153
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 153 is 0.146816
INFO:root:FL Epoch: 135 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :751
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692150
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691273
INFO:root:FL Epoch: 135 Norm Difference for worker 751 is 0.040515
INFO:root:FL Epoch: 135 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1409
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695307
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693232
INFO:root:FL Epoch: 135 Norm Difference for worker 1409 is 0.04489
INFO:root:FL Epoch: 135 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1891
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690046
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693696
INFO:root:FL Epoch: 135 Norm Difference for worker 1891 is 0.143813
INFO:root:FL Epoch: 135 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1327
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695307
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688049
INFO:root:FL Epoch: 135 Norm Difference for worker 1327 is 0.098271
INFO:root:FL Epoch: 135 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :312
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692627
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 312 is 0.122007
INFO:root:FL Epoch: 135 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.6931483780636507 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.693045437335968                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :950
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693198
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678629
INFO:root:FL Epoch: 136 Norm Difference for worker 950 is 0.192492
INFO:root:FL Epoch: 136 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1614
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693178
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 136 Norm Difference for worker 1614 is 0.001794
INFO:root:FL Epoch: 136 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1069
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693127
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684734
INFO:root:FL Epoch: 136 Norm Difference for worker 1069 is 0.115091
INFO:root:FL Epoch: 136 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1082
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688198
INFO:root:FL Epoch: 136 Norm Difference for worker 1082 is 0.055995
INFO:root:FL Epoch: 136 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :755
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693188
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692474
INFO:root:FL Epoch: 136 Norm Difference for worker 755 is 0.12554
INFO:root:FL Epoch: 136 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :211
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693137
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 211 is 0.133337
INFO:root:FL Epoch: 136 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :626
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687499
INFO:root:FL Epoch: 136 Norm Difference for worker 626 is 0.161436
INFO:root:FL Epoch: 136 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1801
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687407
INFO:root:FL Epoch: 136 Norm Difference for worker 1801 is 0.040829
INFO:root:FL Epoch: 136 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :592
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693117
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696757
INFO:root:FL Epoch: 136 Norm Difference for worker 592 is 0.014374
INFO:root:FL Epoch: 136 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :113
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 113 is 0.029543
INFO:root:FL Epoch: 136 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.6931298269945032 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.6947373151779175                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :935
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693466
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693163
INFO:root:FL Epoch: 137 Norm Difference for worker 935 is 0.003296
INFO:root:FL Epoch: 137 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1785
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692990
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696726
INFO:root:FL Epoch: 137 Norm Difference for worker 1785 is 0.037336
INFO:root:FL Epoch: 137 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :769
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692990
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697189
INFO:root:FL Epoch: 137 Norm Difference for worker 769 is 0.086614
INFO:root:FL Epoch: 137 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :514
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692354
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693810
INFO:root:FL Epoch: 137 Norm Difference for worker 514 is 0.115221
INFO:root:FL Epoch: 137 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :59
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692513
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 59 is 0.193329
INFO:root:FL Epoch: 137 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1601
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693466
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695642
INFO:root:FL Epoch: 137 Norm Difference for worker 1601 is 0.005595
INFO:root:FL Epoch: 137 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1554
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679736
INFO:root:FL Epoch: 137 Norm Difference for worker 1554 is 0.347626
INFO:root:FL Epoch: 137 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1492
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693466
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691841
INFO:root:FL Epoch: 137 Norm Difference for worker 1492 is 0.111783
INFO:root:FL Epoch: 137 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :393
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693307
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693621
INFO:root:FL Epoch: 137 Norm Difference for worker 393 is 0.018559
INFO:root:FL Epoch: 137 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1921
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692831
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693393
INFO:root:FL Epoch: 137 Norm Difference for worker 1921 is 0.106948
INFO:root:FL Epoch: 137 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.6931112443699556 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.6967620253562927                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :589
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693534
INFO:root:FL Epoch: 138 Norm Difference for worker 589 is 0.191888
INFO:root:FL Epoch: 138 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1143
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693515
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695667
INFO:root:FL Epoch: 138 Norm Difference for worker 1143 is 0.037921
INFO:root:FL Epoch: 138 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1020
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692793
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692740
INFO:root:FL Epoch: 138 Norm Difference for worker 1020 is 0.016606
INFO:root:FL Epoch: 138 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1022
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701991
INFO:root:FL Epoch: 138 Norm Difference for worker 1022 is 0.244175
INFO:root:FL Epoch: 138 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :730
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696007
INFO:root:FL Epoch: 138 Norm Difference for worker 730 is 0.112128
INFO:root:FL Epoch: 138 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :346
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692793
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682243
INFO:root:FL Epoch: 138 Norm Difference for worker 346 is 0.152515
INFO:root:FL Epoch: 138 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 0.305271
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :139
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694597
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 139 is 0.080633
INFO:root:FL Epoch: 138 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1469
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692432
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692619
INFO:root:FL Epoch: 138 Norm Difference for worker 1469 is 0.042368
INFO:root:FL Epoch: 138 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1364
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693155
INFO:root:FL Epoch: 138 Norm Difference for worker 1364 is 0.074943
INFO:root:FL Epoch: 138 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.6935293288791881 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.7358413338661194                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 139 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :545
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677293
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691558
INFO:root:FL Epoch: 139 Norm Difference for worker 545 is 0.143151
INFO:root:FL Epoch: 139 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :55
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673797
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 55 is 0.05382
INFO:root:FL Epoch: 139 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :702
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698203
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692176
INFO:root:FL Epoch: 139 Norm Difference for worker 702 is 0.268335
INFO:root:FL Epoch: 139 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1861
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698203
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700317
INFO:root:FL Epoch: 139 Norm Difference for worker 1861 is 0.081066
INFO:root:FL Epoch: 139 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1745
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702385
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693175
INFO:root:FL Epoch: 139 Norm Difference for worker 1745 is 0.118055
INFO:root:FL Epoch: 139 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :524
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685657
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691120
INFO:root:FL Epoch: 139 Norm Difference for worker 524 is 0.128304
INFO:root:FL Epoch: 139 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :900
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685657
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694533
INFO:root:FL Epoch: 139 Norm Difference for worker 900 is 0.223416
INFO:root:FL Epoch: 139 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :492
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706567
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694536
INFO:root:FL Epoch: 139 Norm Difference for worker 492 is 0.02755
INFO:root:FL Epoch: 139 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1013
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702385
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694901
INFO:root:FL Epoch: 139 Norm Difference for worker 1013 is 0.210966
INFO:root:FL Epoch: 139 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1556
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694021
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694744
INFO:root:FL Epoch: 139 Norm Difference for worker 1556 is 0.058671
INFO:root:FL Epoch: 139 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.6933106113882626 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.6833919286727905                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :1834
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692215
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697017
INFO:root:FL Epoch: 140 Norm Difference for worker 1834 is 0.102875
INFO:root:FL Epoch: 140 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :946
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691235
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677231
INFO:root:FL Epoch: 140 Norm Difference for worker 946 is 0.074208
INFO:root:FL Epoch: 140 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :646
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688294
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683492
INFO:root:FL Epoch: 140 Norm Difference for worker 646 is 0.048442
INFO:root:FL Epoch: 140 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1428
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693195
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687341
INFO:root:FL Epoch: 140 Norm Difference for worker 1428 is 0.11491
INFO:root:FL Epoch: 140 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :50
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.651709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 50 is 0.325001
INFO:root:FL Epoch: 140 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1198
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694176
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693332
INFO:root:FL Epoch: 140 Norm Difference for worker 1198 is 0.168774
INFO:root:FL Epoch: 140 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1355
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692215
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693445
INFO:root:FL Epoch: 140 Norm Difference for worker 1355 is 0.022844
INFO:root:FL Epoch: 140 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :222
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 222 is 0.193698
INFO:root:FL Epoch: 140 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1642
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692215
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685920
INFO:root:FL Epoch: 140 Norm Difference for worker 1642 is 0.14029
INFO:root:FL Epoch: 140 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1223
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692215
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694235
INFO:root:FL Epoch: 140 Norm Difference for worker 1223 is 0.130675
INFO:root:FL Epoch: 140 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.694207208998063 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.6580258011817932                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693787
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678464
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.6117306351661682 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.6746505975723267 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.098533
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693787
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684307
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.6129851341247559 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.6748915135860443 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 0.095793
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683058
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694441
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.6139938235282898 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.6750863194465637 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 0.093593
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1878
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711667
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669158
INFO:root:FL Epoch: 141 Norm Difference for worker 1878 is 0.313858
INFO:root:FL Epoch: 141 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :962
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675906
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669103
INFO:root:FL Epoch: 141 Norm Difference for worker 962 is 0.099987
INFO:root:FL Epoch: 141 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693787
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693538
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 0.056301
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :976
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690210
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695506
INFO:root:FL Epoch: 141 Norm Difference for worker 976 is 0.090197
INFO:root:FL Epoch: 141 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :769
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693787
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687494
INFO:root:FL Epoch: 141 Norm Difference for worker 769 is 0.037238
INFO:root:FL Epoch: 141 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :465
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690210
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696272
INFO:root:FL Epoch: 141 Norm Difference for worker 465 is 0.128889
INFO:root:FL Epoch: 141 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1750
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704515
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693379
INFO:root:FL Epoch: 141 Norm Difference for worker 1750 is 0.034223
INFO:root:FL Epoch: 141 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.6937851309776306 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.6676366925239563                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1841
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688312
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693754
INFO:root:FL Epoch: 142 Norm Difference for worker 1841 is 0.139606
INFO:root:FL Epoch: 142 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1522
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685728
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680924
INFO:root:FL Epoch: 142 Norm Difference for worker 1522 is 0.080397
INFO:root:FL Epoch: 142 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :23
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 23 is 0.121697
INFO:root:FL Epoch: 142 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1157
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693481
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698013
INFO:root:FL Epoch: 142 Norm Difference for worker 1157 is 0.0405
INFO:root:FL Epoch: 142 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :56
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685728
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 56 is 0.132798
INFO:root:FL Epoch: 142 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1269
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688312
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690072
INFO:root:FL Epoch: 142 Norm Difference for worker 1269 is 0.030833
INFO:root:FL Epoch: 142 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :442
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698650
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693655
INFO:root:FL Epoch: 142 Norm Difference for worker 442 is 0.002506
INFO:root:FL Epoch: 142 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :577
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693481
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699298
INFO:root:FL Epoch: 142 Norm Difference for worker 577 is 0.133635
INFO:root:FL Epoch: 142 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :219
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693668
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 219 is 0.010798
INFO:root:FL Epoch: 142 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1614
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690897
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697149
INFO:root:FL Epoch: 142 Norm Difference for worker 1614 is 0.083498
INFO:root:FL Epoch: 142 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.6933733470299664 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.6806868314743042                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1520
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689464
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692027
INFO:root:FL Epoch: 143 Norm Difference for worker 1520 is 0.032051
INFO:root:FL Epoch: 143 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1151
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694480
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690341
INFO:root:FL Epoch: 143 Norm Difference for worker 1151 is 0.140986
INFO:root:FL Epoch: 143 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :182
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 182 is 0.254146
INFO:root:FL Epoch: 143 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :755
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698241
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688989
INFO:root:FL Epoch: 143 Norm Difference for worker 755 is 0.054058
INFO:root:FL Epoch: 143 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :86
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 86 is 0.063763
INFO:root:FL Epoch: 143 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1828
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691972
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693544
INFO:root:FL Epoch: 143 Norm Difference for worker 1828 is 0.254272
INFO:root:FL Epoch: 143 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1417
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694480
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692481
INFO:root:FL Epoch: 143 Norm Difference for worker 1417 is 0.030234
INFO:root:FL Epoch: 143 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :504
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693226
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680244
INFO:root:FL Epoch: 143 Norm Difference for worker 504 is 0.089761
INFO:root:FL Epoch: 143 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :250
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690718
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 250 is 0.12491
INFO:root:FL Epoch: 143 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :634
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695734
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693507
INFO:root:FL Epoch: 143 Norm Difference for worker 634 is 0.147985
INFO:root:FL Epoch: 143 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.6930804252624512 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.7072212100028992                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1753
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690450
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699878
INFO:root:FL Epoch: 144 Norm Difference for worker 1753 is 0.060536
INFO:root:FL Epoch: 144 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1838
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691847
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682731
INFO:root:FL Epoch: 144 Norm Difference for worker 1838 is 0.022284
INFO:root:FL Epoch: 144 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :71
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 71 is 0.042041
INFO:root:FL Epoch: 144 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :711
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694642
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702210
INFO:root:FL Epoch: 144 Norm Difference for worker 711 is 0.008386
INFO:root:FL Epoch: 144 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :960
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689052
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689765
INFO:root:FL Epoch: 144 Norm Difference for worker 960 is 0.066852
INFO:root:FL Epoch: 144 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :665
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696040
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694079
INFO:root:FL Epoch: 144 Norm Difference for worker 665 is 0.022894
INFO:root:FL Epoch: 144 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1500
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697438
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693280
INFO:root:FL Epoch: 144 Norm Difference for worker 1500 is 0.122063
INFO:root:FL Epoch: 144 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1467
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694642
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686930
INFO:root:FL Epoch: 144 Norm Difference for worker 1467 is 0.088136
INFO:root:FL Epoch: 144 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :800
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697438
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697093
INFO:root:FL Epoch: 144 Norm Difference for worker 800 is 0.091379
INFO:root:FL Epoch: 144 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :787
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694642
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681086
INFO:root:FL Epoch: 144 Norm Difference for worker 787 is 0.265838
INFO:root:FL Epoch: 144 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.6931212299010333 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.6956073045730591                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :380
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693396
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695279
INFO:root:FL Epoch: 145 Norm Difference for worker 380 is 0.076489
INFO:root:FL Epoch: 145 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :95
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 95 is 0.087968
INFO:root:FL Epoch: 145 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :818
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692904
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684539
INFO:root:FL Epoch: 145 Norm Difference for worker 818 is 0.224827
INFO:root:FL Epoch: 145 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1766
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693642
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695121
INFO:root:FL Epoch: 145 Norm Difference for worker 1766 is 0.119104
INFO:root:FL Epoch: 145 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1585
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694379
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690007
INFO:root:FL Epoch: 145 Norm Difference for worker 1585 is 0.123785
INFO:root:FL Epoch: 145 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1927
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692659
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681558
INFO:root:FL Epoch: 145 Norm Difference for worker 1927 is 0.129627
INFO:root:FL Epoch: 145 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1721
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692659
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692396
INFO:root:FL Epoch: 145 Norm Difference for worker 1721 is 0.017113
INFO:root:FL Epoch: 145 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693396
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697817
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 0.202613
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1393
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692167
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694236
INFO:root:FL Epoch: 145 Norm Difference for worker 1393 is 0.007258
INFO:root:FL Epoch: 145 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1170
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698131
INFO:root:FL Epoch: 145 Norm Difference for worker 1170 is 0.066969
INFO:root:FL Epoch: 145 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.693188232534072 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.7201200127601624                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :968
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685516
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688191
INFO:root:FL Epoch: 146 Norm Difference for worker 968 is 0.012493
INFO:root:FL Epoch: 146 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :715
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696163
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692666
INFO:root:FL Epoch: 146 Norm Difference for worker 715 is 0.121389
INFO:root:FL Epoch: 146 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :798
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693501
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697405
INFO:root:FL Epoch: 146 Norm Difference for worker 798 is 0.002193
INFO:root:FL Epoch: 146 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1158
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706811
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694029
INFO:root:FL Epoch: 146 Norm Difference for worker 1158 is 0.245777
INFO:root:FL Epoch: 146 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1312
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690839
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693512
INFO:root:FL Epoch: 146 Norm Difference for worker 1312 is 0.002724
INFO:root:FL Epoch: 146 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :656
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696163
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669193
INFO:root:FL Epoch: 146 Norm Difference for worker 656 is 0.138676
INFO:root:FL Epoch: 146 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :911
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698825
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694122
INFO:root:FL Epoch: 146 Norm Difference for worker 911 is 0.049635
INFO:root:FL Epoch: 146 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :391
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696163
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 146 Norm Difference for worker 391 is 0.01893
INFO:root:FL Epoch: 146 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685516
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695086
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 0.062942
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :800
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698825
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692784
INFO:root:FL Epoch: 146 Norm Difference for worker 800 is 0.115521
INFO:root:FL Epoch: 146 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.6931054276578567 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.6975089311599731                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1230
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694027
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682841
INFO:root:FL Epoch: 147 Norm Difference for worker 1230 is 0.190035
INFO:root:FL Epoch: 147 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1810
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692286
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689103
INFO:root:FL Epoch: 147 Norm Difference for worker 1810 is 0.222328
INFO:root:FL Epoch: 147 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :202
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 202 is 0.117891
INFO:root:FL Epoch: 147 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :692
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692721
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693501
INFO:root:FL Epoch: 147 Norm Difference for worker 692 is 0.021127
INFO:root:FL Epoch: 147 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1869
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691851
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692264
INFO:root:FL Epoch: 147 Norm Difference for worker 1869 is 0.045038
INFO:root:FL Epoch: 147 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1931
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692286
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693253
INFO:root:FL Epoch: 147 Norm Difference for worker 1931 is 0.094664
INFO:root:FL Epoch: 147 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1058
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693592
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691617
INFO:root:FL Epoch: 147 Norm Difference for worker 1058 is 0.030069
INFO:root:FL Epoch: 147 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :783
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691851
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686998
INFO:root:FL Epoch: 147 Norm Difference for worker 783 is 0.09224
INFO:root:FL Epoch: 147 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :536
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695333
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691002
INFO:root:FL Epoch: 147 Norm Difference for worker 536 is 0.047807
INFO:root:FL Epoch: 147 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :950
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694898
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693388
INFO:root:FL Epoch: 147 Norm Difference for worker 950 is 0.155304
INFO:root:FL Epoch: 147 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.6930843521566952 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.7085991501808167                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :376
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699398
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690222
INFO:root:FL Epoch: 148 Norm Difference for worker 376 is 0.088161
INFO:root:FL Epoch: 148 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :932
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693265
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693233
INFO:root:FL Epoch: 148 Norm Difference for worker 932 is 0.150746
INFO:root:FL Epoch: 148 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :206
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699399
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 206 is 0.063317
INFO:root:FL Epoch: 148 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :532
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690198
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695096
INFO:root:FL Epoch: 148 Norm Difference for worker 532 is 0.026237
INFO:root:FL Epoch: 148 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1088
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688664
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684246
INFO:root:FL Epoch: 148 Norm Difference for worker 1088 is 0.03224
INFO:root:FL Epoch: 148 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :339
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 339 is 0.068606
INFO:root:FL Epoch: 148 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1682
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693265
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693419
INFO:root:FL Epoch: 148 Norm Difference for worker 1682 is 0.153121
INFO:root:FL Epoch: 148 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :436
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690198
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690318
INFO:root:FL Epoch: 148 Norm Difference for worker 436 is 0.107357
INFO:root:FL Epoch: 148 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1295
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694798
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693178
INFO:root:FL Epoch: 148 Norm Difference for worker 1295 is 0.033606
INFO:root:FL Epoch: 148 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1789
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693265
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693071
INFO:root:FL Epoch: 148 Norm Difference for worker 1789 is 0.076362
INFO:root:FL Epoch: 148 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.6932138485067031 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.6884360909461975                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :648
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691269
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693167
INFO:root:FL Epoch: 149 Norm Difference for worker 648 is 0.08468
INFO:root:FL Epoch: 149 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1268
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693630
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696828
INFO:root:FL Epoch: 149 Norm Difference for worker 1268 is 0.017259
INFO:root:FL Epoch: 149 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :337
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697924
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 337 is 0.216305
INFO:root:FL Epoch: 149 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1086
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695519
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697958
INFO:root:FL Epoch: 149 Norm Difference for worker 1086 is 0.181675
INFO:root:FL Epoch: 149 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1112
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694575
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678974
INFO:root:FL Epoch: 149 Norm Difference for worker 1112 is 0.196262
INFO:root:FL Epoch: 149 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :725
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692214
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693174
INFO:root:FL Epoch: 149 Norm Difference for worker 725 is 0.050683
INFO:root:FL Epoch: 149 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :610
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692214
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679766
INFO:root:FL Epoch: 149 Norm Difference for worker 610 is 0.103366
INFO:root:FL Epoch: 149 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1600
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691269
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693169
INFO:root:FL Epoch: 149 Norm Difference for worker 1600 is 0.036025
INFO:root:FL Epoch: 149 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :335
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691742
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 335 is 0.140549
INFO:root:FL Epoch: 149 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :996
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694575
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693726
INFO:root:FL Epoch: 149 Norm Difference for worker 996 is 0.049093
INFO:root:FL Epoch: 149 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.6931100172155044 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.7131089568138123                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :969
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697296
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695150
INFO:root:FL Epoch: 150 Norm Difference for worker 969 is 0.085286
INFO:root:FL Epoch: 150 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :73
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691366
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696546
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 73 is 0.22267
INFO:root:FL Epoch: 150 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1089
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705202
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693209
INFO:root:FL Epoch: 150 Norm Difference for worker 1089 is 0.063382
INFO:root:FL Epoch: 150 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1428
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691366
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691416
INFO:root:FL Epoch: 150 Norm Difference for worker 1428 is 0.149356
INFO:root:FL Epoch: 150 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :306
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687413
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 306 is 0.187458
INFO:root:FL Epoch: 150 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :424
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691366
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696168
INFO:root:FL Epoch: 150 Norm Difference for worker 424 is 0.027991
INFO:root:FL Epoch: 150 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1357
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695319
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693172
INFO:root:FL Epoch: 150 Norm Difference for worker 1357 is 0.128417
INFO:root:FL Epoch: 150 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :441
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697296
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 150 Norm Difference for worker 441 is 0.02565
INFO:root:FL Epoch: 150 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :62
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697296
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691815
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 62 is 0.022197
INFO:root:FL Epoch: 150 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :459
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693343
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689963
INFO:root:FL Epoch: 150 Norm Difference for worker 459 is 0.0384
INFO:root:FL Epoch: 150 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.6931341290473938 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.6943110823631287                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693031
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691545
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.6374975442886353 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.6798919975757599 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.116906
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693264
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689652
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.6418144106864929 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.6808286011219025 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 0.10777
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693497
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689788
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.6401411294937134 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.6804636359214783 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 0.111306
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :954
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692915
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694494
INFO:root:FL Epoch: 151 Norm Difference for worker 954 is 0.095916
INFO:root:FL Epoch: 151 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1013
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692915
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693425
INFO:root:FL Epoch: 151 Norm Difference for worker 1013 is 0.12088
INFO:root:FL Epoch: 151 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :183
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692343
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 183 is 0.035961
INFO:root:FL Epoch: 151 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :593
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694387
INFO:root:FL Epoch: 151 Norm Difference for worker 593 is 0.047618
INFO:root:FL Epoch: 151 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1646
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692799
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693811
INFO:root:FL Epoch: 151 Norm Difference for worker 1646 is 0.207817
INFO:root:FL Epoch: 151 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :153
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 153 is 0.173095
INFO:root:FL Epoch: 151 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :653
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693264
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693311
INFO:root:FL Epoch: 151 Norm Difference for worker 653 is 0.085491
INFO:root:FL Epoch: 151 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.6936962253907147 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.6700202226638794                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1082
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688741
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 152 Norm Difference for worker 1082 is 0.091547
INFO:root:FL Epoch: 152 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :949
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698101
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693689
INFO:root:FL Epoch: 152 Norm Difference for worker 949 is 0.022212
INFO:root:FL Epoch: 152 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1688
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688741
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704081
INFO:root:FL Epoch: 152 Norm Difference for worker 1688 is 0.170083
INFO:root:FL Epoch: 152 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :734
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686401
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685541
INFO:root:FL Epoch: 152 Norm Difference for worker 734 is 0.087882
INFO:root:FL Epoch: 152 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :277
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 277 is 0.029149
INFO:root:FL Epoch: 152 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :966
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702781
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700444
INFO:root:FL Epoch: 152 Norm Difference for worker 966 is 0.144758
INFO:root:FL Epoch: 152 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :748
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693421
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693593
INFO:root:FL Epoch: 152 Norm Difference for worker 748 is 0.110942
INFO:root:FL Epoch: 152 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :886
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698101
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695307
INFO:root:FL Epoch: 152 Norm Difference for worker 886 is 0.063066
INFO:root:FL Epoch: 152 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :918
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688741
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692322
INFO:root:FL Epoch: 152 Norm Difference for worker 918 is 0.134642
INFO:root:FL Epoch: 152 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :418
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702781
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685321
INFO:root:FL Epoch: 152 Norm Difference for worker 418 is 0.194415
INFO:root:FL Epoch: 152 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.6931358470636255 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.6941593885421753                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :115
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 115 is 0.16082
INFO:root:FL Epoch: 153 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :899
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692945
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693621
INFO:root:FL Epoch: 153 Norm Difference for worker 899 is 0.059838
INFO:root:FL Epoch: 153 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1476
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692844
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683941
INFO:root:FL Epoch: 153 Norm Difference for worker 1476 is 0.124798
INFO:root:FL Epoch: 153 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :185
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 185 is 0.059307
INFO:root:FL Epoch: 153 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :482
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692945
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691085
INFO:root:FL Epoch: 153 Norm Difference for worker 482 is 0.106951
INFO:root:FL Epoch: 153 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1640
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692844
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699755
INFO:root:FL Epoch: 153 Norm Difference for worker 1640 is 0.238457
INFO:root:FL Epoch: 153 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1042
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687245
INFO:root:FL Epoch: 153 Norm Difference for worker 1042 is 0.171436
INFO:root:FL Epoch: 153 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :354
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692945
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693408
INFO:root:FL Epoch: 153 Norm Difference for worker 354 is 0.078251
INFO:root:FL Epoch: 153 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :626
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696487
INFO:root:FL Epoch: 153 Norm Difference for worker 626 is 0.134732
INFO:root:FL Epoch: 153 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :922
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690783
INFO:root:FL Epoch: 153 Norm Difference for worker 922 is 0.167214
INFO:root:FL Epoch: 153 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.693082265994128 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.7020273804664612                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :1534
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694070
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669249
INFO:root:FL Epoch: 154 Norm Difference for worker 1534 is 0.330727
INFO:root:FL Epoch: 154 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1285
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692302
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679464
INFO:root:FL Epoch: 154 Norm Difference for worker 1285 is 0.100662
INFO:root:FL Epoch: 154 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :791
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689650
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693589
INFO:root:FL Epoch: 154 Norm Difference for worker 791 is 0.047685
INFO:root:FL Epoch: 154 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :829
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694282
INFO:root:FL Epoch: 154 Norm Difference for worker 829 is 0.046221
INFO:root:FL Epoch: 154 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1852
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696723
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693170
INFO:root:FL Epoch: 154 Norm Difference for worker 1852 is 0.040393
INFO:root:FL Epoch: 154 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1002
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683510
INFO:root:FL Epoch: 154 Norm Difference for worker 1002 is 0.079345
INFO:root:FL Epoch: 154 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :160
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 160 is 0.056541
INFO:root:FL Epoch: 154 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1586
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687882
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684011
INFO:root:FL Epoch: 154 Norm Difference for worker 1586 is 0.08553
INFO:root:FL Epoch: 154 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1575
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692859
INFO:root:FL Epoch: 154 Norm Difference for worker 1575 is 0.155571
INFO:root:FL Epoch: 154 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :545
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691659
INFO:root:FL Epoch: 154 Norm Difference for worker 545 is 0.105549
INFO:root:FL Epoch: 154 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.6931247886489419 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.695234477519989                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 155 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1219
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692941
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684026
INFO:root:FL Epoch: 155 Norm Difference for worker 1219 is 0.28456
INFO:root:FL Epoch: 155 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :334
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 334 is 0.044018
INFO:root:FL Epoch: 155 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :82
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 82 is 0.137561
INFO:root:FL Epoch: 155 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :426
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692941
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691627
INFO:root:FL Epoch: 155 Norm Difference for worker 426 is 0.045115
INFO:root:FL Epoch: 155 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :457
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693566
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691611
INFO:root:FL Epoch: 155 Norm Difference for worker 457 is 0.093927
INFO:root:FL Epoch: 155 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :687
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692941
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691777
INFO:root:FL Epoch: 155 Norm Difference for worker 687 is 0.173816
INFO:root:FL Epoch: 155 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :836
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693566
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692714
INFO:root:FL Epoch: 155 Norm Difference for worker 836 is 0.047307
INFO:root:FL Epoch: 155 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1157
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693031
INFO:root:FL Epoch: 155 Norm Difference for worker 1157 is 0.058386
INFO:root:FL Epoch: 155 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :845
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 155 Norm Difference for worker 845 is 0.029628
INFO:root:FL Epoch: 155 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :422
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693358
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679218
INFO:root:FL Epoch: 155 Norm Difference for worker 422 is 0.14816
INFO:root:FL Epoch: 155 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.6936181012321921 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.7387859225273132                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :1330
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689679
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648757
INFO:root:FL Epoch: 156 Norm Difference for worker 1330 is 0.182271
INFO:root:FL Epoch: 156 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1035
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698608
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695087
INFO:root:FL Epoch: 156 Norm Difference for worker 1035 is 0.012091
INFO:root:FL Epoch: 156 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :774
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703072
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682330
INFO:root:FL Epoch: 156 Norm Difference for worker 774 is 0.082252
INFO:root:FL Epoch: 156 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1736
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694143
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698515
INFO:root:FL Epoch: 156 Norm Difference for worker 1736 is 0.005225
INFO:root:FL Epoch: 156 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1439
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707536
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688798
INFO:root:FL Epoch: 156 Norm Difference for worker 1439 is 0.027344
INFO:root:FL Epoch: 156 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :824
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703072
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696264
INFO:root:FL Epoch: 156 Norm Difference for worker 824 is 0.119857
INFO:root:FL Epoch: 156 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :957
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689679
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694558
INFO:root:FL Epoch: 156 Norm Difference for worker 957 is 0.183975
INFO:root:FL Epoch: 156 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :80
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.714298
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 80 is 0.053196
INFO:root:FL Epoch: 156 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :952
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685215
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693491
INFO:root:FL Epoch: 156 Norm Difference for worker 952 is 0.04326
INFO:root:FL Epoch: 156 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :703
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694143
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687521
INFO:root:FL Epoch: 156 Norm Difference for worker 703 is 0.022157
INFO:root:FL Epoch: 156 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.6934899898136363 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.7344446778297424                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :1090
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718253
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693354
INFO:root:FL Epoch: 157 Norm Difference for worker 1090 is 0.137261
INFO:root:FL Epoch: 157 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1884
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693966
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697054
INFO:root:FL Epoch: 157 Norm Difference for worker 1884 is 0.043953
INFO:root:FL Epoch: 157 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1139
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685871
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693324
INFO:root:FL Epoch: 157 Norm Difference for worker 1139 is 0.271003
INFO:root:FL Epoch: 157 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :349
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706110
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699042
INFO:root:FL Epoch: 157 Norm Difference for worker 349 is 0.17359
INFO:root:FL Epoch: 157 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :877
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689918
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701256
INFO:root:FL Epoch: 157 Norm Difference for worker 877 is 0.000522
INFO:root:FL Epoch: 157 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :538
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693966
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693839
INFO:root:FL Epoch: 157 Norm Difference for worker 538 is 0.176073
INFO:root:FL Epoch: 157 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :147
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 147 is 0.09278
INFO:root:FL Epoch: 157 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1085
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706110
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693460
INFO:root:FL Epoch: 157 Norm Difference for worker 1085 is 0.045077
INFO:root:FL Epoch: 157 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1142
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677775
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683611
INFO:root:FL Epoch: 157 Norm Difference for worker 1142 is 0.121352
INFO:root:FL Epoch: 157 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :98
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689994
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 98 is 0.046851
INFO:root:FL Epoch: 157 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.6931260859265047 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.6951040625572205                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 158 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :527
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693931
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693355
INFO:root:FL Epoch: 158 Norm Difference for worker 527 is 0.098461
INFO:root:FL Epoch: 158 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :126
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 126 is 0.003938
INFO:root:FL Epoch: 158 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1253
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692954
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690486
INFO:root:FL Epoch: 158 Norm Difference for worker 1253 is 0.162089
INFO:root:FL Epoch: 158 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :917
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692954
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692591
INFO:root:FL Epoch: 158 Norm Difference for worker 917 is 0.053359
INFO:root:FL Epoch: 158 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1316
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692832
INFO:root:FL Epoch: 158 Norm Difference for worker 1316 is 0.04355
INFO:root:FL Epoch: 158 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693540
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690965
INFO:root:FL Epoch: 158 Norm Difference for worker 1311 is 0.105243
INFO:root:FL Epoch: 158 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 311 is 0.120569
INFO:root:FL Epoch: 158 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :779
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690708
INFO:root:FL Epoch: 158 Norm Difference for worker 779 is 0.211115
INFO:root:FL Epoch: 158 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1872
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694127
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697488
INFO:root:FL Epoch: 158 Norm Difference for worker 1872 is 0.076444
INFO:root:FL Epoch: 158 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :900
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693736
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696501
INFO:root:FL Epoch: 158 Norm Difference for worker 900 is 0.119368
INFO:root:FL Epoch: 158 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.693624966284808 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.6720619201660156                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :757
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697637
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693165
INFO:root:FL Epoch: 159 Norm Difference for worker 757 is 0.040243
INFO:root:FL Epoch: 159 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1832
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697637
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690856
INFO:root:FL Epoch: 159 Norm Difference for worker 1832 is 0.12585
INFO:root:FL Epoch: 159 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :439
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704030
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701340
INFO:root:FL Epoch: 159 Norm Difference for worker 439 is 0.070313
INFO:root:FL Epoch: 159 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :689
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684849
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689779
INFO:root:FL Epoch: 159 Norm Difference for worker 689 is 0.074708
INFO:root:FL Epoch: 159 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :232
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692021
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 232 is 0.07413
INFO:root:FL Epoch: 159 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1446
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695505
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694925
INFO:root:FL Epoch: 159 Norm Difference for worker 1446 is 0.007696
INFO:root:FL Epoch: 159 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1516
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691243
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697019
INFO:root:FL Epoch: 159 Norm Difference for worker 1516 is 0.002725
INFO:root:FL Epoch: 159 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :603
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689112
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688724
INFO:root:FL Epoch: 159 Norm Difference for worker 603 is 0.08464
INFO:root:FL Epoch: 159 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1899
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695505
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682666
INFO:root:FL Epoch: 159 Norm Difference for worker 1899 is 0.052846
INFO:root:FL Epoch: 159 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1913
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691243
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694032
INFO:root:FL Epoch: 159 Norm Difference for worker 1913 is 0.172324
INFO:root:FL Epoch: 159 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.6933332436224994 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.6823763251304626                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 160 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :492
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694289
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695443
INFO:root:FL Epoch: 160 Norm Difference for worker 492 is 0.067192
INFO:root:FL Epoch: 160 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :665
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694289
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689527
INFO:root:FL Epoch: 160 Norm Difference for worker 665 is 0.073252
INFO:root:FL Epoch: 160 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1803
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694289
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694377
INFO:root:FL Epoch: 160 Norm Difference for worker 1803 is 0.023575
INFO:root:FL Epoch: 160 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1792
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695372
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678335
INFO:root:FL Epoch: 160 Norm Difference for worker 1792 is 0.325488
INFO:root:FL Epoch: 160 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1299
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693206
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697540
INFO:root:FL Epoch: 160 Norm Difference for worker 1299 is 0.116933
INFO:root:FL Epoch: 160 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :384
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697538
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688040
INFO:root:FL Epoch: 160 Norm Difference for worker 384 is 0.067864
INFO:root:FL Epoch: 160 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1039
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697538
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695808
INFO:root:FL Epoch: 160 Norm Difference for worker 1039 is 0.059586
INFO:root:FL Epoch: 160 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :603
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693206
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687173
INFO:root:FL Epoch: 160 Norm Difference for worker 603 is 0.071573
INFO:root:FL Epoch: 160 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :159
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694289
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 159 is 0.082639
INFO:root:FL Epoch: 160 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :209
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 209 is 0.106407
INFO:root:FL Epoch: 160 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.6930835211978239 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.7083687782287598                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700815
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693723
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.6524568200111389 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.6832063674926758 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.113322
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697793
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689604
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.6510534882545471 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.68288733959198 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 0.116252
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702326
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691042
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.6527356505393982 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.6832700073719025 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 0.11274
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :906
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693261
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688753
INFO:root:FL Epoch: 161 Norm Difference for worker 906 is 0.243272
INFO:root:FL Epoch: 161 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1144
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687218
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690396
INFO:root:FL Epoch: 161 Norm Difference for worker 1144 is 0.121068
INFO:root:FL Epoch: 161 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1064
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691751
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697693
INFO:root:FL Epoch: 161 Norm Difference for worker 1064 is 0.043993
INFO:root:FL Epoch: 161 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :596
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693261
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691855
INFO:root:FL Epoch: 161 Norm Difference for worker 596 is 0.006191
INFO:root:FL Epoch: 161 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1021
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694772
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691475
INFO:root:FL Epoch: 161 Norm Difference for worker 1021 is 0.077372
INFO:root:FL Epoch: 161 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :234
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690939
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 234 is 0.006857
INFO:root:FL Epoch: 161 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1844
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693261
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691883
INFO:root:FL Epoch: 161 Norm Difference for worker 1844 is 0.123381
INFO:root:FL Epoch: 161 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.6931880852755379 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.6900791525840759                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692537
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707320
INFO:root:FL Epoch: 162 Norm Difference for worker 941 is 0.09665
INFO:root:FL Epoch: 162 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1390
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693766
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688827
INFO:root:FL Epoch: 162 Norm Difference for worker 1390 is 0.019697
INFO:root:FL Epoch: 162 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694074
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693276
INFO:root:FL Epoch: 162 Norm Difference for worker 1941 is 0.024021
INFO:root:FL Epoch: 162 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :884
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692537
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690257
INFO:root:FL Epoch: 162 Norm Difference for worker 884 is 0.096306
INFO:root:FL Epoch: 162 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :44
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 44 is 0.05754
INFO:root:FL Epoch: 162 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1585
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692537
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688227
INFO:root:FL Epoch: 162 Norm Difference for worker 1585 is 0.103571
INFO:root:FL Epoch: 162 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1081
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694381
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694813
INFO:root:FL Epoch: 162 Norm Difference for worker 1081 is 0.04221
INFO:root:FL Epoch: 162 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1024
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693766
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695500
INFO:root:FL Epoch: 162 Norm Difference for worker 1024 is 0.115889
INFO:root:FL Epoch: 162 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1886
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693766
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692478
INFO:root:FL Epoch: 162 Norm Difference for worker 1886 is 0.022085
INFO:root:FL Epoch: 162 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1439
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693766
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687624
INFO:root:FL Epoch: 162 Norm Difference for worker 1439 is 0.065938
INFO:root:FL Epoch: 162 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.693234426133773 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.6872401833534241                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1559
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694350
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696085
INFO:root:FL Epoch: 163 Norm Difference for worker 1559 is 0.044404
INFO:root:FL Epoch: 163 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1487
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692572
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692387
INFO:root:FL Epoch: 163 Norm Difference for worker 1487 is 0.024869
INFO:root:FL Epoch: 163 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :359
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693757
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696573
INFO:root:FL Epoch: 163 Norm Difference for worker 359 is 0.10084
INFO:root:FL Epoch: 163 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1586
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694350
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697693
INFO:root:FL Epoch: 163 Norm Difference for worker 1586 is 0.079736
INFO:root:FL Epoch: 163 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1338
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691387
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700259
INFO:root:FL Epoch: 163 Norm Difference for worker 1338 is 0.140002
INFO:root:FL Epoch: 163 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1840
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691387
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688707
INFO:root:FL Epoch: 163 Norm Difference for worker 1840 is 0.204307
INFO:root:FL Epoch: 163 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :901
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693757
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694668
INFO:root:FL Epoch: 163 Norm Difference for worker 901 is 0.075781
INFO:root:FL Epoch: 163 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :711
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694350
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693202
INFO:root:FL Epoch: 163 Norm Difference for worker 711 is 0.037277
INFO:root:FL Epoch: 163 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1413
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693757
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693165
INFO:root:FL Epoch: 163 Norm Difference for worker 1413 is 0.007235
INFO:root:FL Epoch: 163 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :431
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694350
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693594
INFO:root:FL Epoch: 163 Norm Difference for worker 431 is 0.013699
INFO:root:FL Epoch: 163 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.693148763740764 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.6930121779441833                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 164 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1316
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692988
INFO:root:FL Epoch: 164 Norm Difference for worker 1316 is 0.081548
INFO:root:FL Epoch: 164 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :898
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692661
INFO:root:FL Epoch: 164 Norm Difference for worker 898 is 0.099798
INFO:root:FL Epoch: 164 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :465
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691826
INFO:root:FL Epoch: 164 Norm Difference for worker 465 is 0.026079
INFO:root:FL Epoch: 164 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :599
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693377
INFO:root:FL Epoch: 164 Norm Difference for worker 599 is 0.078609
INFO:root:FL Epoch: 164 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1822
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690156
INFO:root:FL Epoch: 164 Norm Difference for worker 1822 is 0.005421
INFO:root:FL Epoch: 164 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1634
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694900
INFO:root:FL Epoch: 164 Norm Difference for worker 1634 is 0.021838
INFO:root:FL Epoch: 164 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1455
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693480
INFO:root:FL Epoch: 164 Norm Difference for worker 1455 is 0.072217
INFO:root:FL Epoch: 164 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :250
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693093
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 250 is 0.12478
INFO:root:FL Epoch: 164 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :791
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693215
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698608
INFO:root:FL Epoch: 164 Norm Difference for worker 791 is 0.103633
INFO:root:FL Epoch: 164 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1388
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691435
INFO:root:FL Epoch: 164 Norm Difference for worker 1388 is 0.048808
INFO:root:FL Epoch: 164 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.6931809537550983 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.6905637979507446                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 165 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :1295
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692633
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692830
INFO:root:FL Epoch: 165 Norm Difference for worker 1295 is 0.000992
INFO:root:FL Epoch: 165 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1294
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693409
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691038
INFO:root:FL Epoch: 165 Norm Difference for worker 1294 is 0.094389
INFO:root:FL Epoch: 165 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1754
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693409
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693495
INFO:root:FL Epoch: 165 Norm Difference for worker 1754 is 0.121719
INFO:root:FL Epoch: 165 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :782
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697506
INFO:root:FL Epoch: 165 Norm Difference for worker 782 is 0.061458
INFO:root:FL Epoch: 165 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :108
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 108 is 0.076684
INFO:root:FL Epoch: 165 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1018
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693927
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685639
INFO:root:FL Epoch: 165 Norm Difference for worker 1018 is 0.195749
INFO:root:FL Epoch: 165 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :832
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692633
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693191
INFO:root:FL Epoch: 165 Norm Difference for worker 832 is 0.114648
INFO:root:FL Epoch: 165 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :133
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704245
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 133 is 0.21819
INFO:root:FL Epoch: 165 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :12
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 12 is 0.233092
INFO:root:FL Epoch: 165 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :34
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 34 is 0.072551
INFO:root:FL Epoch: 165 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.6935501414186814 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.6743608117103577                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 166 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :319
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693386
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 319 is 0.006661
INFO:root:FL Epoch: 166 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :958
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691430
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692026
INFO:root:FL Epoch: 166 Norm Difference for worker 958 is 0.016366
INFO:root:FL Epoch: 166 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1164
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699017
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694682
INFO:root:FL Epoch: 166 Norm Difference for worker 1164 is 0.146328
INFO:root:FL Epoch: 166 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :515
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695224
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691814
INFO:root:FL Epoch: 166 Norm Difference for worker 515 is 0.219557
INFO:root:FL Epoch: 166 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :688
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693327
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692277
INFO:root:FL Epoch: 166 Norm Difference for worker 688 is 0.077678
INFO:root:FL Epoch: 166 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1693
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689534
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686581
INFO:root:FL Epoch: 166 Norm Difference for worker 1693 is 0.010484
INFO:root:FL Epoch: 166 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1070
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697120
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692204
INFO:root:FL Epoch: 166 Norm Difference for worker 1070 is 0.118868
INFO:root:FL Epoch: 166 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1237
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689534
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680603
INFO:root:FL Epoch: 166 Norm Difference for worker 1237 is 0.128621
INFO:root:FL Epoch: 166 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1365
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685741
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699901
INFO:root:FL Epoch: 166 Norm Difference for worker 1365 is 0.039624
INFO:root:FL Epoch: 166 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :936
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689534
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667576
INFO:root:FL Epoch: 166 Norm Difference for worker 936 is 0.163122
INFO:root:FL Epoch: 166 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.6932035824831795 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.6890688538551331                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :106
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682848
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 106 is 0.110596
INFO:root:FL Epoch: 167 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693564
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696670
INFO:root:FL Epoch: 167 Norm Difference for worker 755 is 0.069166
INFO:root:FL Epoch: 167 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :81
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 81 is 0.117754
INFO:root:FL Epoch: 167 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1241
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694790
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696302
INFO:root:FL Epoch: 167 Norm Difference for worker 1241 is 0.086967
INFO:root:FL Epoch: 167 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :665
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692074
INFO:root:FL Epoch: 167 Norm Difference for worker 665 is 0.017559
INFO:root:FL Epoch: 167 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1244
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692338
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692180
INFO:root:FL Epoch: 167 Norm Difference for worker 1244 is 0.047951
INFO:root:FL Epoch: 167 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693973
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693350
INFO:root:FL Epoch: 167 Norm Difference for worker 1755 is 0.047748
INFO:root:FL Epoch: 167 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1189
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693564
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684929
INFO:root:FL Epoch: 167 Norm Difference for worker 1189 is 0.186148
INFO:root:FL Epoch: 167 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :785
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691930
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696814
INFO:root:FL Epoch: 167 Norm Difference for worker 785 is 0.090625
INFO:root:FL Epoch: 167 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1463
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691521
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683864
INFO:root:FL Epoch: 167 Norm Difference for worker 1463 is 0.154881
INFO:root:FL Epoch: 167 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.6933084656210506 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.6834879517555237                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1872
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692224
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693487
INFO:root:FL Epoch: 168 Norm Difference for worker 1872 is 0.086684
INFO:root:FL Epoch: 168 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1711
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692224
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689381
INFO:root:FL Epoch: 168 Norm Difference for worker 1711 is 0.141533
INFO:root:FL Epoch: 168 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :18
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 18 is 0.050966
INFO:root:FL Epoch: 168 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :202
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 202 is 0.118963
INFO:root:FL Epoch: 168 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 0.050207
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1782
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695136
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691428
INFO:root:FL Epoch: 168 Norm Difference for worker 1782 is 0.161327
INFO:root:FL Epoch: 168 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1869
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696106
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693686
INFO:root:FL Epoch: 168 Norm Difference for worker 1869 is 0.059687
INFO:root:FL Epoch: 168 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1830
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692224
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691947
INFO:root:FL Epoch: 168 Norm Difference for worker 1830 is 0.01542
INFO:root:FL Epoch: 168 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1197
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693194
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688451
INFO:root:FL Epoch: 168 Norm Difference for worker 1197 is 0.375102
INFO:root:FL Epoch: 168 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1476
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694165
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697402
INFO:root:FL Epoch: 168 Norm Difference for worker 1476 is 0.09118
INFO:root:FL Epoch: 168 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.6935314711402444 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.67496258020401                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 169 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :945
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691480
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691712
INFO:root:FL Epoch: 169 Norm Difference for worker 945 is 0.083047
INFO:root:FL Epoch: 169 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :273
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694037
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 273 is 0.056036
INFO:root:FL Epoch: 169 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1442
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695151
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684082
INFO:root:FL Epoch: 169 Norm Difference for worker 1442 is 0.074791
INFO:root:FL Epoch: 169 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :952
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695151
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692832
INFO:root:FL Epoch: 169 Norm Difference for worker 952 is 0.053735
INFO:root:FL Epoch: 169 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1360
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693316
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690984
INFO:root:FL Epoch: 169 Norm Difference for worker 1360 is 0.057479
INFO:root:FL Epoch: 169 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :854
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695151
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695606
INFO:root:FL Epoch: 169 Norm Difference for worker 854 is 0.056998
INFO:root:FL Epoch: 169 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :821
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685974
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693910
INFO:root:FL Epoch: 169 Norm Difference for worker 821 is 0.043473
INFO:root:FL Epoch: 169 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1782
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693316
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682800
INFO:root:FL Epoch: 169 Norm Difference for worker 1782 is 0.191461
INFO:root:FL Epoch: 169 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :807
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691480
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693076
INFO:root:FL Epoch: 169 Norm Difference for worker 807 is 0.037607
INFO:root:FL Epoch: 169 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :24
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691480
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 24 is 0.038429
INFO:root:FL Epoch: 169 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.6931045686497408 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.6976313591003418                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :603
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688105
INFO:root:FL Epoch: 170 Norm Difference for worker 603 is 0.117612
INFO:root:FL Epoch: 170 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :40
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 40 is 0.069302
INFO:root:FL Epoch: 170 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1838
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692710
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701976
INFO:root:FL Epoch: 170 Norm Difference for worker 1838 is 0.012472
INFO:root:FL Epoch: 170 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :467
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692262
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693681
INFO:root:FL Epoch: 170 Norm Difference for worker 467 is 0.105166
INFO:root:FL Epoch: 170 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :350
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693182
INFO:root:FL Epoch: 170 Norm Difference for worker 350 is 0.048975
INFO:root:FL Epoch: 170 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :263
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 263 is 0.047581
INFO:root:FL Epoch: 170 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1301
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 170 Norm Difference for worker 1301 is 0.007155
INFO:root:FL Epoch: 170 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :833
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694499
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691647
INFO:root:FL Epoch: 170 Norm Difference for worker 833 is 0.016512
INFO:root:FL Epoch: 170 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :465
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691466
INFO:root:FL Epoch: 170 Norm Difference for worker 465 is 0.041619
INFO:root:FL Epoch: 170 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :863
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693605
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693600
INFO:root:FL Epoch: 170 Norm Difference for worker 863 is 0.07635
INFO:root:FL Epoch: 170 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.6930911330615773 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.699798583984375                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695158
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688156
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.6459416747093201 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.6817392706871033 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.110009
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695821
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685398
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.6406885385513306 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.6805827796459198 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 0.121081
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694495
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696104
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.647402286529541 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.68206507563591 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 0.106942
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :694
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690517
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694907
INFO:root:FL Epoch: 171 Norm Difference for worker 694 is 0.004236
INFO:root:FL Epoch: 171 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1305
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693169
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686138
INFO:root:FL Epoch: 171 Norm Difference for worker 1305 is 0.234018
INFO:root:FL Epoch: 171 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1063
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691843
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699281
INFO:root:FL Epoch: 171 Norm Difference for worker 1063 is 0.018298
INFO:root:FL Epoch: 171 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1767
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695821
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691502
INFO:root:FL Epoch: 171 Norm Difference for worker 1767 is 0.099437
INFO:root:FL Epoch: 171 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :318
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696484
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 318 is 0.08312
INFO:root:FL Epoch: 171 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :760
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694495
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693188
INFO:root:FL Epoch: 171 Norm Difference for worker 760 is 0.006773
INFO:root:FL Epoch: 171 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1876
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694495
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687796
INFO:root:FL Epoch: 171 Norm Difference for worker 1876 is 0.136107
INFO:root:FL Epoch: 171 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.6936174035072327 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.6722880005836487                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1003
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693369
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696806
INFO:root:FL Epoch: 172 Norm Difference for worker 1003 is 0.048622
INFO:root:FL Epoch: 172 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :375
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689153
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687697
INFO:root:FL Epoch: 172 Norm Difference for worker 375 is 0.301265
INFO:root:FL Epoch: 172 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :966
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695478
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693979
INFO:root:FL Epoch: 172 Norm Difference for worker 966 is 0.148448
INFO:root:FL Epoch: 172 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :334
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 334 is 0.123419
INFO:root:FL Epoch: 172 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :312
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 312 is 0.053819
INFO:root:FL Epoch: 172 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1747
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691261
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688955
INFO:root:FL Epoch: 172 Norm Difference for worker 1747 is 0.030669
INFO:root:FL Epoch: 172 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1294
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693369
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689894
INFO:root:FL Epoch: 172 Norm Difference for worker 1294 is 0.064045
INFO:root:FL Epoch: 172 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :737
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689153
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693491
INFO:root:FL Epoch: 172 Norm Difference for worker 737 is 0.012238
INFO:root:FL Epoch: 172 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1064
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691261
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692180
INFO:root:FL Epoch: 172 Norm Difference for worker 1064 is 0.140306
INFO:root:FL Epoch: 172 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1392
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695478
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690140
INFO:root:FL Epoch: 172 Norm Difference for worker 1392 is 0.042038
INFO:root:FL Epoch: 172 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.6930843942305621 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.7086217999458313                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1721
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694801
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691108
INFO:root:FL Epoch: 173 Norm Difference for worker 1721 is 0.017892
INFO:root:FL Epoch: 173 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1093
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696336
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691795
INFO:root:FL Epoch: 173 Norm Difference for worker 1093 is 0.073214
INFO:root:FL Epoch: 173 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1173
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694801
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 173 Norm Difference for worker 1173 is 0.082398
INFO:root:FL Epoch: 173 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :968
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691729
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695537
INFO:root:FL Epoch: 173 Norm Difference for worker 968 is 0.004949
INFO:root:FL Epoch: 173 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :270
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 270 is 0.114163
INFO:root:FL Epoch: 173 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :894
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690194
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689479
INFO:root:FL Epoch: 173 Norm Difference for worker 894 is 0.022497
INFO:root:FL Epoch: 173 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :594
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691729
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683378
INFO:root:FL Epoch: 173 Norm Difference for worker 594 is 0.069658
INFO:root:FL Epoch: 173 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1009
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690194
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694065
INFO:root:FL Epoch: 173 Norm Difference for worker 1009 is 0.052699
INFO:root:FL Epoch: 173 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1378
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688658
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690881
INFO:root:FL Epoch: 173 Norm Difference for worker 1378 is 0.089603
INFO:root:FL Epoch: 173 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :906
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693265
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682688
INFO:root:FL Epoch: 173 Norm Difference for worker 906 is 0.243245
INFO:root:FL Epoch: 173 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.6932592532213997 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.7244343757629395                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 174 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :1667
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690540
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690193
INFO:root:FL Epoch: 174 Norm Difference for worker 1667 is 0.044519
INFO:root:FL Epoch: 174 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :907
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699784
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695379
INFO:root:FL Epoch: 174 Norm Difference for worker 907 is 0.04212
INFO:root:FL Epoch: 174 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1313
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696703
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692736
INFO:root:FL Epoch: 174 Norm Difference for worker 1313 is 0.176864
INFO:root:FL Epoch: 174 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :522
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702865
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679329
INFO:root:FL Epoch: 174 Norm Difference for worker 522 is 0.019858
INFO:root:FL Epoch: 174 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :913
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690540
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684932
INFO:root:FL Epoch: 174 Norm Difference for worker 913 is 0.07038
INFO:root:FL Epoch: 174 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1260
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696703
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692060
INFO:root:FL Epoch: 174 Norm Difference for worker 1260 is 0.0963
INFO:root:FL Epoch: 174 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1683
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693622
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694887
INFO:root:FL Epoch: 174 Norm Difference for worker 1683 is 0.141761
INFO:root:FL Epoch: 174 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :925
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687459
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688517
INFO:root:FL Epoch: 174 Norm Difference for worker 925 is 0.122992
INFO:root:FL Epoch: 174 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1459
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690540
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693236
INFO:root:FL Epoch: 174 Norm Difference for worker 1459 is 0.109191
INFO:root:FL Epoch: 174 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1264
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687459
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688416
INFO:root:FL Epoch: 174 Norm Difference for worker 1264 is 0.300208
INFO:root:FL Epoch: 174 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.6931035238153794 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.7122339010238647                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689544
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688744
INFO:root:FL Epoch: 175 Norm Difference for worker 850 is 0.147468
INFO:root:FL Epoch: 175 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698998
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701201
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 0.218966
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1212
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695217
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679681
INFO:root:FL Epoch: 175 Norm Difference for worker 1212 is 0.141338
INFO:root:FL Epoch: 175 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1570
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689544
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690550
INFO:root:FL Epoch: 175 Norm Difference for worker 1570 is 0.016425
INFO:root:FL Epoch: 175 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :305
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 305 is 0.171225
INFO:root:FL Epoch: 175 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1197
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697108
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651567
INFO:root:FL Epoch: 175 Norm Difference for worker 1197 is 0.44341
INFO:root:FL Epoch: 175 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1169
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695217
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693843
INFO:root:FL Epoch: 175 Norm Difference for worker 1169 is 0.151251
INFO:root:FL Epoch: 175 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1057
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691435
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680230
INFO:root:FL Epoch: 175 Norm Difference for worker 1057 is 0.007824
INFO:root:FL Epoch: 175 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1584
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695217
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690592
INFO:root:FL Epoch: 175 Norm Difference for worker 1584 is 0.199686
INFO:root:FL Epoch: 175 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1528
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695217
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689591
INFO:root:FL Epoch: 175 Norm Difference for worker 1528 is 0.159149
INFO:root:FL Epoch: 175 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.6939800136229571 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.6629084944725037                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :637
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687477
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682116
INFO:root:FL Epoch: 176 Norm Difference for worker 637 is 0.091862
INFO:root:FL Epoch: 176 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1889
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693619
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688858
INFO:root:FL Epoch: 176 Norm Difference for worker 1889 is 0.238528
INFO:root:FL Epoch: 176 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :528
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693619
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689742
INFO:root:FL Epoch: 176 Norm Difference for worker 528 is 0.036932
INFO:root:FL Epoch: 176 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1101
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696690
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701187
INFO:root:FL Epoch: 176 Norm Difference for worker 1101 is 0.038798
INFO:root:FL Epoch: 176 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1673
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684406
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693425
INFO:root:FL Epoch: 176 Norm Difference for worker 1673 is 0.001006
INFO:root:FL Epoch: 176 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :974
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699761
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691505
INFO:root:FL Epoch: 176 Norm Difference for worker 974 is 0.21522
INFO:root:FL Epoch: 176 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1233
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705903
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695891
INFO:root:FL Epoch: 176 Norm Difference for worker 1233 is 0.071106
INFO:root:FL Epoch: 176 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :787
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684406
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688246
INFO:root:FL Epoch: 176 Norm Difference for worker 787 is 0.149205
INFO:root:FL Epoch: 176 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :977
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696690
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683620
INFO:root:FL Epoch: 176 Norm Difference for worker 977 is 0.023391
INFO:root:FL Epoch: 176 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :516
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684406
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688828
INFO:root:FL Epoch: 176 Norm Difference for worker 516 is 0.058503
INFO:root:FL Epoch: 176 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.693651837461135 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.6712784767150879                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :313
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 313 is 0.004445
INFO:root:FL Epoch: 177 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :908
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693392
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707988
INFO:root:FL Epoch: 177 Norm Difference for worker 908 is 0.206733
INFO:root:FL Epoch: 177 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :557
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695603
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691083
INFO:root:FL Epoch: 177 Norm Difference for worker 557 is 0.046481
INFO:root:FL Epoch: 177 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :881
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693392
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698665
INFO:root:FL Epoch: 177 Norm Difference for worker 881 is 0.029661
INFO:root:FL Epoch: 177 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1256
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686758
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693856
INFO:root:FL Epoch: 177 Norm Difference for worker 1256 is 0.028399
INFO:root:FL Epoch: 177 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :539
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693392
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693286
INFO:root:FL Epoch: 177 Norm Difference for worker 539 is 0.112672
INFO:root:FL Epoch: 177 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.706942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 0.064183
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :220
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 220 is 0.042947
INFO:root:FL Epoch: 177 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :342
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693392
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693163
INFO:root:FL Epoch: 177 Norm Difference for worker 342 is 0.028823
INFO:root:FL Epoch: 177 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1936
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693392
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682982
INFO:root:FL Epoch: 177 Norm Difference for worker 1936 is 0.093848
INFO:root:FL Epoch: 177 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.6940128487699172 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.6621665358543396                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :1855
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696790
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693531
INFO:root:FL Epoch: 178 Norm Difference for worker 1855 is 0.125566
INFO:root:FL Epoch: 178 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :418
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703085
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694602
INFO:root:FL Epoch: 178 Norm Difference for worker 418 is 0.223734
INFO:root:FL Epoch: 178 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1550
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696790
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693627
INFO:root:FL Epoch: 178 Norm Difference for worker 1550 is 0.016893
INFO:root:FL Epoch: 178 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1800
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699938
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693153
INFO:root:FL Epoch: 178 Norm Difference for worker 1800 is 0.250218
INFO:root:FL Epoch: 178 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1189
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699938
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692626
INFO:root:FL Epoch: 178 Norm Difference for worker 1189 is 0.235745
INFO:root:FL Epoch: 178 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :611
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690495
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698249
INFO:root:FL Epoch: 178 Norm Difference for worker 611 is 0.051715
INFO:root:FL Epoch: 178 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :325
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 325 is 0.237055
INFO:root:FL Epoch: 178 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :983
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690495
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680027
INFO:root:FL Epoch: 178 Norm Difference for worker 983 is 0.069392
INFO:root:FL Epoch: 178 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693642
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643927
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 0.252032
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693643
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 0.22241
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.6931040918125826 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.7123221755027771                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1226
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687629
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696621
INFO:root:FL Epoch: 179 Norm Difference for worker 1226 is 0.021404
INFO:root:FL Epoch: 179 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1285
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700925
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699940
INFO:root:FL Epoch: 179 Norm Difference for worker 1285 is 0.092964
INFO:root:FL Epoch: 179 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :972
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695227
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691576
INFO:root:FL Epoch: 179 Norm Difference for worker 972 is 0.044386
INFO:root:FL Epoch: 179 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :393
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693328
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693216
INFO:root:FL Epoch: 179 Norm Difference for worker 393 is 0.051644
INFO:root:FL Epoch: 179 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :977
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691428
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695747
INFO:root:FL Epoch: 179 Norm Difference for worker 977 is 0.076806
INFO:root:FL Epoch: 179 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :59
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 59 is 0.133692
INFO:root:FL Epoch: 179 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :575
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689529
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695340
INFO:root:FL Epoch: 179 Norm Difference for worker 575 is 0.008142
INFO:root:FL Epoch: 179 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :472
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695227
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691713
INFO:root:FL Epoch: 179 Norm Difference for worker 472 is 0.012003
INFO:root:FL Epoch: 179 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1689
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693328
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691523
INFO:root:FL Epoch: 179 Norm Difference for worker 1689 is 0.008585
INFO:root:FL Epoch: 179 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :565
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695227
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688395
INFO:root:FL Epoch: 179 Norm Difference for worker 565 is 0.155018
INFO:root:FL Epoch: 179 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.6931024894994848 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.7120965719223022                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1850
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697078
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689232
INFO:root:FL Epoch: 180 Norm Difference for worker 1850 is 0.162312
INFO:root:FL Epoch: 180 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :989
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695201
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691528
INFO:root:FL Epoch: 180 Norm Difference for worker 989 is 0.010868
INFO:root:FL Epoch: 180 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :611
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697078
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694965
INFO:root:FL Epoch: 180 Norm Difference for worker 611 is 0.04328
INFO:root:FL Epoch: 180 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :637
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689569
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687017
INFO:root:FL Epoch: 180 Norm Difference for worker 637 is 0.145891
INFO:root:FL Epoch: 180 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1690
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689569
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693464
INFO:root:FL Epoch: 180 Norm Difference for worker 1690 is 0.040781
INFO:root:FL Epoch: 180 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1250
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693323
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676483
INFO:root:FL Epoch: 180 Norm Difference for worker 1250 is 0.087667
INFO:root:FL Epoch: 180 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :844
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689569
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695394
INFO:root:FL Epoch: 180 Norm Difference for worker 844 is 0.017192
INFO:root:FL Epoch: 180 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1444
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695201
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690619
INFO:root:FL Epoch: 180 Norm Difference for worker 1444 is 0.027482
INFO:root:FL Epoch: 180 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :120
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 120 is 0.050993
INFO:root:FL Epoch: 180 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :134
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 134 is 0.128548
INFO:root:FL Epoch: 180 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.6930790543556213 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.7064489722251892                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694556
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690136
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.6526912450790405 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.6832598686218262 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.109047
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693235
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692825
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.6528668999671936 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.6832999229431153 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.10868
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697199
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689678
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.6497368812561035 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.6825895190238953 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.11522
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :869
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690592
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678823
INFO:root:FL Epoch: 181 Norm Difference for worker 869 is 0.06954
INFO:root:FL Epoch: 181 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :716
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691913
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679855
INFO:root:FL Epoch: 181 Norm Difference for worker 716 is 0.125676
INFO:root:FL Epoch: 181 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1560
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695877
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688759
INFO:root:FL Epoch: 181 Norm Difference for worker 1560 is 0.149741
INFO:root:FL Epoch: 181 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :623
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691913
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695434
INFO:root:FL Epoch: 181 Norm Difference for worker 623 is 0.022643
INFO:root:FL Epoch: 181 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1018
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689270
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694479
INFO:root:FL Epoch: 181 Norm Difference for worker 1018 is 0.163664
INFO:root:FL Epoch: 181 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :195
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693235
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 195 is 0.261018
INFO:root:FL Epoch: 181 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1034
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699842
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693627
INFO:root:FL Epoch: 181 Norm Difference for worker 1034 is 0.167663
INFO:root:FL Epoch: 181 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.6933927851564744 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.6799060702323914                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1201
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698824
INFO:root:FL Epoch: 182 Norm Difference for worker 1201 is 0.09627
INFO:root:FL Epoch: 182 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1052
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690993
INFO:root:FL Epoch: 182 Norm Difference for worker 1052 is 0.044196
INFO:root:FL Epoch: 182 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :959
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698568
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706189
INFO:root:FL Epoch: 182 Norm Difference for worker 959 is 0.17473
INFO:root:FL Epoch: 182 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1624
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689237
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693151
INFO:root:FL Epoch: 182 Norm Difference for worker 1624 is 0.1147
INFO:root:FL Epoch: 182 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :825
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694569
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693418
INFO:root:FL Epoch: 182 Norm Difference for worker 825 is 0.056878
INFO:root:FL Epoch: 182 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1782
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697235
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692370
INFO:root:FL Epoch: 182 Norm Difference for worker 1782 is 0.154545
INFO:root:FL Epoch: 182 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :488
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694569
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688082
INFO:root:FL Epoch: 182 Norm Difference for worker 488 is 0.036543
INFO:root:FL Epoch: 182 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :507
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690570
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709054
INFO:root:FL Epoch: 182 Norm Difference for worker 507 is 0.250389
INFO:root:FL Epoch: 182 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1078
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693236
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693611
INFO:root:FL Epoch: 182 Norm Difference for worker 1078 is 0.037006
INFO:root:FL Epoch: 182 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1849
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690570
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682405
INFO:root:FL Epoch: 182 Norm Difference for worker 1849 is 0.100836
INFO:root:FL Epoch: 182 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.693325004156898 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.6827393174171448                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1215
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691109
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676575
INFO:root:FL Epoch: 183 Norm Difference for worker 1215 is 0.073436
INFO:root:FL Epoch: 183 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1520
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691109
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693231
INFO:root:FL Epoch: 183 Norm Difference for worker 1520 is 0.036413
INFO:root:FL Epoch: 183 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :630
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692156
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692314
INFO:root:FL Epoch: 183 Norm Difference for worker 630 is 0.040588
INFO:root:FL Epoch: 183 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :563
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695294
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693684
INFO:root:FL Epoch: 183 Norm Difference for worker 563 is 0.143135
INFO:root:FL Epoch: 183 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694218
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 0.088055
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1104
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693193
INFO:root:FL Epoch: 183 Norm Difference for worker 1104 is 0.030121
INFO:root:FL Epoch: 183 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1522
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692156
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693758
INFO:root:FL Epoch: 183 Norm Difference for worker 1522 is 0.097162
INFO:root:FL Epoch: 183 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1754
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690926
INFO:root:FL Epoch: 183 Norm Difference for worker 1754 is 0.135785
INFO:root:FL Epoch: 183 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :48
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 48 is 0.01937
INFO:root:FL Epoch: 183 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1604
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689180
INFO:root:FL Epoch: 183 Norm Difference for worker 1604 is 0.042206
INFO:root:FL Epoch: 183 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.6934717542984906 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.6769818663597107                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1775
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696540
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675087
INFO:root:FL Epoch: 184 Norm Difference for worker 1775 is 0.319698
INFO:root:FL Epoch: 184 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1560
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688391
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667764
INFO:root:FL Epoch: 184 Norm Difference for worker 1560 is 0.110414
INFO:root:FL Epoch: 184 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1234
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694910
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691731
INFO:root:FL Epoch: 184 Norm Difference for worker 1234 is 0.177164
INFO:root:FL Epoch: 184 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1381
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694731
INFO:root:FL Epoch: 184 Norm Difference for worker 1381 is 0.023035
INFO:root:FL Epoch: 184 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1244
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688391
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687159
INFO:root:FL Epoch: 184 Norm Difference for worker 1244 is 0.027612
INFO:root:FL Epoch: 184 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1478
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692236
INFO:root:FL Epoch: 184 Norm Difference for worker 1478 is 0.095008
INFO:root:FL Epoch: 184 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1887
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696540
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693862
INFO:root:FL Epoch: 184 Norm Difference for worker 1887 is 0.045037
INFO:root:FL Epoch: 184 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :825
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693267
INFO:root:FL Epoch: 184 Norm Difference for worker 825 is 0.013084
INFO:root:FL Epoch: 184 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :202
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701429
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703578
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 202 is 0.113457
INFO:root:FL Epoch: 184 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :471
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694339
INFO:root:FL Epoch: 184 Norm Difference for worker 471 is 0.113164
INFO:root:FL Epoch: 184 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.6933715133106008 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.6807607412338257                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1656
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696964
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692732
INFO:root:FL Epoch: 185 Norm Difference for worker 1656 is 0.077852
INFO:root:FL Epoch: 185 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1518
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686993
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690813
INFO:root:FL Epoch: 185 Norm Difference for worker 1518 is 0.094724
INFO:root:FL Epoch: 185 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1088
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698210
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693134
INFO:root:FL Epoch: 185 Norm Difference for worker 1088 is 0.078496
INFO:root:FL Epoch: 185 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :559
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691978
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693449
INFO:root:FL Epoch: 185 Norm Difference for worker 559 is 0.010824
INFO:root:FL Epoch: 185 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :487
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693225
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696028
INFO:root:FL Epoch: 185 Norm Difference for worker 487 is 0.142668
INFO:root:FL Epoch: 185 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :317
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693596
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 317 is 0.026422
INFO:root:FL Epoch: 185 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1080
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694471
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696306
INFO:root:FL Epoch: 185 Norm Difference for worker 1080 is 0.018427
INFO:root:FL Epoch: 185 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695718
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696329
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 0.139811
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1146
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688239
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700507
INFO:root:FL Epoch: 185 Norm Difference for worker 1146 is 0.067116
INFO:root:FL Epoch: 185 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698210
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 0.145732
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.6931385643341962 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.6939069032669067                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693072
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699298
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 0.009617
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :785
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693299
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690618
INFO:root:FL Epoch: 186 Norm Difference for worker 785 is 0.107073
INFO:root:FL Epoch: 186 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :663
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692996
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690374
INFO:root:FL Epoch: 186 Norm Difference for worker 663 is 0.069344
INFO:root:FL Epoch: 186 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1530
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693072
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683199
INFO:root:FL Epoch: 186 Norm Difference for worker 1530 is 0.354741
INFO:root:FL Epoch: 186 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :738
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689305
INFO:root:FL Epoch: 186 Norm Difference for worker 738 is 0.053735
INFO:root:FL Epoch: 186 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :128
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 128 is 0.082578
INFO:root:FL Epoch: 186 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1070
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692996
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691623
INFO:root:FL Epoch: 186 Norm Difference for worker 1070 is 0.110037
INFO:root:FL Epoch: 186 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :823
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693223
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690495
INFO:root:FL Epoch: 186 Norm Difference for worker 823 is 0.04345
INFO:root:FL Epoch: 186 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :385
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693299
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693939
INFO:root:FL Epoch: 186 Norm Difference for worker 385 is 0.014967
INFO:root:FL Epoch: 186 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :503
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692996
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694430
INFO:root:FL Epoch: 186 Norm Difference for worker 503 is 0.067774
INFO:root:FL Epoch: 186 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.6930840576396269 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.708518922328949                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 187 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :301
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 301 is 0.229122
INFO:root:FL Epoch: 187 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :277
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694789
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 277 is 0.062751
INFO:root:FL Epoch: 187 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :269
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691738
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.708759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 269 is 0.035447
INFO:root:FL Epoch: 187 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1198
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690212
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715438
INFO:root:FL Epoch: 187 Norm Difference for worker 1198 is 0.082355
INFO:root:FL Epoch: 187 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :545
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696315
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691697
INFO:root:FL Epoch: 187 Norm Difference for worker 545 is 0.114825
INFO:root:FL Epoch: 187 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1043
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693264
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689802
INFO:root:FL Epoch: 187 Norm Difference for worker 1043 is 0.062904
INFO:root:FL Epoch: 187 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :766
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694789
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692093
INFO:root:FL Epoch: 187 Norm Difference for worker 766 is 0.025044
INFO:root:FL Epoch: 187 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :736
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694789
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694583
INFO:root:FL Epoch: 187 Norm Difference for worker 736 is 0.085294
INFO:root:FL Epoch: 187 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :458
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696315
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683949
INFO:root:FL Epoch: 187 Norm Difference for worker 458 is 0.102188
INFO:root:FL Epoch: 187 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1218
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687161
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679007
INFO:root:FL Epoch: 187 Norm Difference for worker 1218 is 0.209588
INFO:root:FL Epoch: 187 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.6930862945668838 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.7008611559867859                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 188 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :1848
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693945
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691381
INFO:root:FL Epoch: 188 Norm Difference for worker 1848 is 0.157247
INFO:root:FL Epoch: 188 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :77
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 77 is 0.065501
INFO:root:FL Epoch: 188 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1719
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691640
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691038
INFO:root:FL Epoch: 188 Norm Difference for worker 1719 is 0.021404
INFO:root:FL Epoch: 188 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :49
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 49 is 0.035208
INFO:root:FL Epoch: 188 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :382
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693177
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690919
INFO:root:FL Epoch: 188 Norm Difference for worker 382 is 0.090891
INFO:root:FL Epoch: 188 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :721
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691640
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693232
INFO:root:FL Epoch: 188 Norm Difference for worker 721 is 0.029129
INFO:root:FL Epoch: 188 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1690
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693177
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694852
INFO:root:FL Epoch: 188 Norm Difference for worker 1690 is 0.002924
INFO:root:FL Epoch: 188 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1774
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694714
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693206
INFO:root:FL Epoch: 188 Norm Difference for worker 1774 is 0.033664
INFO:root:FL Epoch: 188 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1927
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691640
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682106
INFO:root:FL Epoch: 188 Norm Difference for worker 1927 is 0.09441
INFO:root:FL Epoch: 188 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :433
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692408
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681969
INFO:root:FL Epoch: 188 Norm Difference for worker 433 is 0.174314
INFO:root:FL Epoch: 188 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.6931311803705552 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.6945919394493103                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :486
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693293
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 189 Norm Difference for worker 486 is 0.007506
INFO:root:FL Epoch: 189 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1170
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693004
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700138
INFO:root:FL Epoch: 189 Norm Difference for worker 1170 is 0.049211
INFO:root:FL Epoch: 189 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1606
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693293
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692302
INFO:root:FL Epoch: 189 Norm Difference for worker 1606 is 0.042303
INFO:root:FL Epoch: 189 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1307
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692571
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693429
INFO:root:FL Epoch: 189 Norm Difference for worker 1307 is 0.13426
INFO:root:FL Epoch: 189 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :901
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693437
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693956
INFO:root:FL Epoch: 189 Norm Difference for worker 901 is 0.071674
INFO:root:FL Epoch: 189 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :556
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693437
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692427
INFO:root:FL Epoch: 189 Norm Difference for worker 556 is 0.061257
INFO:root:FL Epoch: 189 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :740
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692412
INFO:root:FL Epoch: 189 Norm Difference for worker 740 is 0.066517
INFO:root:FL Epoch: 189 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :927
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692859
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694992
INFO:root:FL Epoch: 189 Norm Difference for worker 927 is 0.036183
INFO:root:FL Epoch: 189 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :270
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693426
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 270 is 0.119294
INFO:root:FL Epoch: 189 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :488
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693293
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687300
INFO:root:FL Epoch: 189 Norm Difference for worker 488 is 0.033202
INFO:root:FL Epoch: 189 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.693230085513171 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.722783625125885                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :256
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684811
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 256 is 0.168603
INFO:root:FL Epoch: 190 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :751
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693574
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695335
INFO:root:FL Epoch: 190 Norm Difference for worker 751 is 0.034801
INFO:root:FL Epoch: 190 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1156
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696495
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693723
INFO:root:FL Epoch: 190 Norm Difference for worker 1156 is 0.059345
INFO:root:FL Epoch: 190 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1330
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699416
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688775
INFO:root:FL Epoch: 190 Norm Difference for worker 1330 is 0.210771
INFO:root:FL Epoch: 190 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :859
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690653
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694023
INFO:root:FL Epoch: 190 Norm Difference for worker 859 is 0.03943
INFO:root:FL Epoch: 190 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :257
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 257 is 0.070446
INFO:root:FL Epoch: 190 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1432
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678969
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684251
INFO:root:FL Epoch: 190 Norm Difference for worker 1432 is 0.043122
INFO:root:FL Epoch: 190 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696495
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689473
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 0.112083
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1730
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696495
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698008
INFO:root:FL Epoch: 190 Norm Difference for worker 1730 is 0.067431
INFO:root:FL Epoch: 190 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :608
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699416
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 190 Norm Difference for worker 608 is 0.083619
INFO:root:FL Epoch: 190 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.6940180168432348 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.7498078942298889                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727751
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704013
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.6877003312110901 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.6917419791221618 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.121206
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716723
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703785
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.6900767683982849 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.6923523843288422 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.116433
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733266
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714455
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.6830273866653442 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.6905543386936188 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.130625
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1898
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694667
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694921
INFO:root:FL Epoch: 191 Norm Difference for worker 1898 is 0.018535
INFO:root:FL Epoch: 191 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694667
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703800
INFO:root:FL Epoch: 191 Norm Difference for worker 555 is 0.124501
INFO:root:FL Epoch: 191 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :925
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678124
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660044
INFO:root:FL Epoch: 191 Norm Difference for worker 925 is 0.114451
INFO:root:FL Epoch: 191 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :113
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693338
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 113 is 0.136563
INFO:root:FL Epoch: 191 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1363
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694667
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682765
INFO:root:FL Epoch: 191 Norm Difference for worker 1363 is 0.039521
INFO:root:FL Epoch: 191 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1837
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689153
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704503
INFO:root:FL Epoch: 191 Norm Difference for worker 1837 is 0.016974
INFO:root:FL Epoch: 191 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :781
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678124
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680831
INFO:root:FL Epoch: 191 Norm Difference for worker 781 is 0.088066
INFO:root:FL Epoch: 191 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.6932801744517159 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.7255353331565857                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :562
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700031
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693838
INFO:root:FL Epoch: 192 Norm Difference for worker 562 is 0.108334
INFO:root:FL Epoch: 192 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1742
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684091
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689876
INFO:root:FL Epoch: 192 Norm Difference for worker 1742 is 0.047081
INFO:root:FL Epoch: 192 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :947
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690467
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694034
INFO:root:FL Epoch: 192 Norm Difference for worker 947 is 0.125029
INFO:root:FL Epoch: 192 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :406
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684091
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693592
INFO:root:FL Epoch: 192 Norm Difference for worker 406 is 0.171082
INFO:root:FL Epoch: 192 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1259
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684091
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693985
INFO:root:FL Epoch: 192 Norm Difference for worker 1259 is 0.015373
INFO:root:FL Epoch: 192 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :390
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700031
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689263
INFO:root:FL Epoch: 192 Norm Difference for worker 390 is 0.012637
INFO:root:FL Epoch: 192 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1140
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693655
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694822
INFO:root:FL Epoch: 192 Norm Difference for worker 1140 is 0.080521
INFO:root:FL Epoch: 192 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1411
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703219
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 192 Norm Difference for worker 1411 is 0.100182
INFO:root:FL Epoch: 192 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :66
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690467
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 66 is 0.024242
INFO:root:FL Epoch: 192 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :468
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690467
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697550
INFO:root:FL Epoch: 192 Norm Difference for worker 468 is 0.08448
INFO:root:FL Epoch: 192 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.6930828515221091 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.701818585395813                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1614
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690594
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694348
INFO:root:FL Epoch: 193 Norm Difference for worker 1614 is 0.001982
INFO:root:FL Epoch: 193 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :504
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694048
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690982
INFO:root:FL Epoch: 193 Norm Difference for worker 504 is 0.13681
INFO:root:FL Epoch: 193 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1022
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695775
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675505
INFO:root:FL Epoch: 193 Norm Difference for worker 1022 is 0.219618
INFO:root:FL Epoch: 193 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :580
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689768
INFO:root:FL Epoch: 193 Norm Difference for worker 580 is 0.168637
INFO:root:FL Epoch: 193 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1730
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694911
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695245
INFO:root:FL Epoch: 193 Norm Difference for worker 1730 is 0.039389
INFO:root:FL Epoch: 193 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :828
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694911
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693644
INFO:root:FL Epoch: 193 Norm Difference for worker 828 is 0.086276
INFO:root:FL Epoch: 193 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1619
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691458
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694652
INFO:root:FL Epoch: 193 Norm Difference for worker 1619 is 0.11716
INFO:root:FL Epoch: 193 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1205
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692321
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687967
INFO:root:FL Epoch: 193 Norm Difference for worker 1205 is 0.178167
INFO:root:FL Epoch: 193 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :511
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691458
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694287
INFO:root:FL Epoch: 193 Norm Difference for worker 511 is 0.074556
INFO:root:FL Epoch: 193 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1270
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698365
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696029
INFO:root:FL Epoch: 193 Norm Difference for worker 1270 is 0.096559
INFO:root:FL Epoch: 193 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.6930858878528371 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.7009607553482056                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 135 is 0.062461
INFO:root:FL Epoch: 194 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1532
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695512
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689747
INFO:root:FL Epoch: 194 Norm Difference for worker 1532 is 5e-05
INFO:root:FL Epoch: 194 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1525
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693177
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690331
INFO:root:FL Epoch: 194 Norm Difference for worker 1525 is 0.061224
INFO:root:FL Epoch: 194 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :103
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695408
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 103 is 0.150955
INFO:root:FL Epoch: 194 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1790
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691621
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691602
INFO:root:FL Epoch: 194 Norm Difference for worker 1790 is 0.077358
INFO:root:FL Epoch: 194 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :752
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690064
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694898
INFO:root:FL Epoch: 194 Norm Difference for worker 752 is 0.099033
INFO:root:FL Epoch: 194 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :784
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690843
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694822
INFO:root:FL Epoch: 194 Norm Difference for worker 784 is 0.059228
INFO:root:FL Epoch: 194 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :630
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690064
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696604
INFO:root:FL Epoch: 194 Norm Difference for worker 630 is 0.027207
INFO:root:FL Epoch: 194 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1283
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693956
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686064
INFO:root:FL Epoch: 194 Norm Difference for worker 1283 is 0.025858
INFO:root:FL Epoch: 194 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1290
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691621
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693742
INFO:root:FL Epoch: 194 Norm Difference for worker 1290 is 0.146026
INFO:root:FL Epoch: 194 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.693176714813008 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.6908621191978455                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :926
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692692
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708218
INFO:root:FL Epoch: 195 Norm Difference for worker 926 is 0.058108
INFO:root:FL Epoch: 195 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :191
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 191 is 0.005442
INFO:root:FL Epoch: 195 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1426
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692921
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694564
INFO:root:FL Epoch: 195 Norm Difference for worker 1426 is 0.045353
INFO:root:FL Epoch: 195 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :261
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 261 is 0.100147
INFO:root:FL Epoch: 195 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :874
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693437
INFO:root:FL Epoch: 195 Norm Difference for worker 874 is 0.130273
INFO:root:FL Epoch: 195 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :700
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692235
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690987
INFO:root:FL Epoch: 195 Norm Difference for worker 700 is 0.132829
INFO:root:FL Epoch: 195 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :7
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694065
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 7 is 0.045806
INFO:root:FL Epoch: 195 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :301
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 301 is 0.216225
INFO:root:FL Epoch: 195 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :502
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692921
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690520
INFO:root:FL Epoch: 195 Norm Difference for worker 502 is 0.062341
INFO:root:FL Epoch: 195 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1471
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693657
INFO:root:FL Epoch: 195 Norm Difference for worker 1471 is 0.103538
INFO:root:FL Epoch: 195 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.6938406790004057 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.666226327419281                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :437
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693520
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687196
INFO:root:FL Epoch: 196 Norm Difference for worker 437 is 0.03765
INFO:root:FL Epoch: 196 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698978
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 0.01708
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1524
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693520
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693137
INFO:root:FL Epoch: 196 Norm Difference for worker 1524 is 0.067511
INFO:root:FL Epoch: 196 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :130
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 130 is 0.104622
INFO:root:FL Epoch: 196 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :478
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677144
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668705
INFO:root:FL Epoch: 196 Norm Difference for worker 478 is 0.154808
INFO:root:FL Epoch: 196 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :911
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682602
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684591
INFO:root:FL Epoch: 196 Norm Difference for worker 911 is 0.037706
INFO:root:FL Epoch: 196 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1227
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693520
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685643
INFO:root:FL Epoch: 196 Norm Difference for worker 1227 is 0.210107
INFO:root:FL Epoch: 196 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1529
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685332
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691702
INFO:root:FL Epoch: 196 Norm Difference for worker 1529 is 0.179966
INFO:root:FL Epoch: 196 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1567
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698978
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693499
INFO:root:FL Epoch: 196 Norm Difference for worker 1567 is 0.065699
INFO:root:FL Epoch: 196 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :633
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696249
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 196 Norm Difference for worker 633 is 0.080323
INFO:root:FL Epoch: 196 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.6933367357534521 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.6822251677513123                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1836
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693207
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694851
INFO:root:FL Epoch: 197 Norm Difference for worker 1836 is 0.062889
INFO:root:FL Epoch: 197 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1738
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695404
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693983
INFO:root:FL Epoch: 197 Norm Difference for worker 1738 is 0.064444
INFO:root:FL Epoch: 197 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :552
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693208
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693444
INFO:root:FL Epoch: 197 Norm Difference for worker 552 is 0.049387
INFO:root:FL Epoch: 197 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 0.052486
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1244
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688815
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682996
INFO:root:FL Epoch: 197 Norm Difference for worker 1244 is 0.017133
INFO:root:FL Epoch: 197 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :932
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696502
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696772
INFO:root:FL Epoch: 197 Norm Difference for worker 932 is 0.094073
INFO:root:FL Epoch: 197 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1049
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695404
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692297
INFO:root:FL Epoch: 197 Norm Difference for worker 1049 is 0.029459
INFO:root:FL Epoch: 197 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1589
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691011
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688982
INFO:root:FL Epoch: 197 Norm Difference for worker 1589 is 0.052664
INFO:root:FL Epoch: 197 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :208
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 208 is 0.035996
INFO:root:FL Epoch: 197 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :677
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697600
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682706
INFO:root:FL Epoch: 197 Norm Difference for worker 677 is 0.058624
INFO:root:FL Epoch: 197 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.6934076652807348 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.679331362247467                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :1491
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687679
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701443
INFO:root:FL Epoch: 198 Norm Difference for worker 1491 is 0.022546
INFO:root:FL Epoch: 198 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1790
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696027
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691776
INFO:root:FL Epoch: 198 Norm Difference for worker 1790 is 0.07446
INFO:root:FL Epoch: 198 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1639
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686288
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696869
INFO:root:FL Epoch: 198 Norm Difference for worker 1639 is 0.014013
INFO:root:FL Epoch: 198 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1719
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697418
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694209
INFO:root:FL Epoch: 198 Norm Difference for worker 1719 is 0.065252
INFO:root:FL Epoch: 198 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :448
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691853
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693356
INFO:root:FL Epoch: 198 Norm Difference for worker 448 is 0.033238
INFO:root:FL Epoch: 198 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1768
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694635
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690628
INFO:root:FL Epoch: 198 Norm Difference for worker 1768 is 0.091234
INFO:root:FL Epoch: 198 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1077
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691853
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694704
INFO:root:FL Epoch: 198 Norm Difference for worker 1077 is 0.023563
INFO:root:FL Epoch: 198 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1215
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693244
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679508
INFO:root:FL Epoch: 198 Norm Difference for worker 1215 is 0.110183
INFO:root:FL Epoch: 198 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1640
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693244
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693615
INFO:root:FL Epoch: 198 Norm Difference for worker 1640 is 0.245733
INFO:root:FL Epoch: 198 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1128
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697418
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689748
INFO:root:FL Epoch: 198 Norm Difference for worker 1128 is 0.005808
INFO:root:FL Epoch: 198 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.6931183548534617 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.695928692817688                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :180
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692318
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 180 is 0.131889
INFO:root:FL Epoch: 199 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1879
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695900
INFO:root:FL Epoch: 199 Norm Difference for worker 1879 is 0.051457
INFO:root:FL Epoch: 199 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1185
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693984
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690913
INFO:root:FL Epoch: 199 Norm Difference for worker 1185 is 0.14936
INFO:root:FL Epoch: 199 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :280
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692318
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 280 is 0.047545
INFO:root:FL Epoch: 199 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1055
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692873
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697336
INFO:root:FL Epoch: 199 Norm Difference for worker 1055 is 0.085528
INFO:root:FL Epoch: 199 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1690
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692873
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693824
INFO:root:FL Epoch: 199 Norm Difference for worker 1690 is 0.005495
INFO:root:FL Epoch: 199 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :722
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693429
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693717
INFO:root:FL Epoch: 199 Norm Difference for worker 722 is 0.068883
INFO:root:FL Epoch: 199 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :933
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692595
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694452
INFO:root:FL Epoch: 199 Norm Difference for worker 933 is 0.019859
INFO:root:FL Epoch: 199 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1874
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694262
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693717
INFO:root:FL Epoch: 199 Norm Difference for worker 1874 is 0.146
INFO:root:FL Epoch: 199 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1457
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692595
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699861
INFO:root:FL Epoch: 199 Norm Difference for worker 1457 is 0.017283
INFO:root:FL Epoch: 199 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.6932354043511784 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.6871839761734009                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :487
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693219
INFO:root:FL Epoch: 200 Norm Difference for worker 487 is 0.106113
INFO:root:FL Epoch: 200 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :707
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693763
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693265
INFO:root:FL Epoch: 200 Norm Difference for worker 707 is 0.038017
INFO:root:FL Epoch: 200 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :38
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 38 is 0.198694
INFO:root:FL Epoch: 200 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :996
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692567
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694096
INFO:root:FL Epoch: 200 Norm Difference for worker 996 is 0.031289
INFO:root:FL Epoch: 200 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1140
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696156
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696921
INFO:root:FL Epoch: 200 Norm Difference for worker 1140 is 0.124468
INFO:root:FL Epoch: 200 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1706
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693763
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699088
INFO:root:FL Epoch: 200 Norm Difference for worker 1706 is 0.065007
INFO:root:FL Epoch: 200 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :765
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690773
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680957
INFO:root:FL Epoch: 200 Norm Difference for worker 765 is 0.064618
INFO:root:FL Epoch: 200 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1194
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693782
INFO:root:FL Epoch: 200 Norm Difference for worker 1194 is 0.083579
INFO:root:FL Epoch: 200 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1234
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693763
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693394
INFO:root:FL Epoch: 200 Norm Difference for worker 1234 is 0.170611
INFO:root:FL Epoch: 200 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1892
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694959
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693157
INFO:root:FL Epoch: 200 Norm Difference for worker 1892 is 0.006505
INFO:root:FL Epoch: 200 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.6931403700043174 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.6937404274940491                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693385
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689405
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.6452550292015076 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.681586766242981 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.09938
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693325
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684917
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.6406565308570862 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.6805758059024811 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.109076
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693503
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688212
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.6459841132164001 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.6817487001419067 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.097847
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1449
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693503
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691344
INFO:root:FL Epoch: 201 Norm Difference for worker 1449 is 0.039131
INFO:root:FL Epoch: 201 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1835
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691319
INFO:root:FL Epoch: 201 Norm Difference for worker 1835 is 0.064402
INFO:root:FL Epoch: 201 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1755
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693428
INFO:root:FL Epoch: 201 Norm Difference for worker 1755 is 0.043729
INFO:root:FL Epoch: 201 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :22
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 22 is 0.045478
INFO:root:FL Epoch: 201 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1640
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674675
INFO:root:FL Epoch: 201 Norm Difference for worker 1640 is 0.258512
INFO:root:FL Epoch: 201 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :544
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693207
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692912
INFO:root:FL Epoch: 201 Norm Difference for worker 544 is 0.071808
INFO:root:FL Epoch: 201 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :122
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 122 is 0.013208
INFO:root:FL Epoch: 201 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.6932335986810572 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.6872830986976624                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1483
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692576
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686770
INFO:root:FL Epoch: 202 Norm Difference for worker 1483 is 0.070721
INFO:root:FL Epoch: 202 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :377
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692576
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693346
INFO:root:FL Epoch: 202 Norm Difference for worker 377 is 0.090101
INFO:root:FL Epoch: 202 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :300
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696408
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 300 is 0.046549
INFO:root:FL Epoch: 202 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :982
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690812
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693542
INFO:root:FL Epoch: 202 Norm Difference for worker 982 is 0.076634
INFO:root:FL Epoch: 202 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :93
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 93 is 0.072693
INFO:root:FL Epoch: 202 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1665
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692576
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690599
INFO:root:FL Epoch: 202 Norm Difference for worker 1665 is 0.040903
INFO:root:FL Epoch: 202 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1168
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690812
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690433
INFO:root:FL Epoch: 202 Norm Difference for worker 1168 is 0.104081
INFO:root:FL Epoch: 202 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :351
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693164
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693170
INFO:root:FL Epoch: 202 Norm Difference for worker 351 is 0.040703
INFO:root:FL Epoch: 202 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :124
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 124 is 0.213149
INFO:root:FL Epoch: 202 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1314
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693753
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694237
INFO:root:FL Epoch: 202 Norm Difference for worker 1314 is 0.240907
INFO:root:FL Epoch: 202 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.6935919768670026 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.6730548143386841                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1790
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691323
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692996
INFO:root:FL Epoch: 203 Norm Difference for worker 1790 is 0.119098
INFO:root:FL Epoch: 203 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1275
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695383
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675853
INFO:root:FL Epoch: 203 Norm Difference for worker 1275 is 0.126754
INFO:root:FL Epoch: 203 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1712
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693353
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698629
INFO:root:FL Epoch: 203 Norm Difference for worker 1712 is 0.033798
INFO:root:FL Epoch: 203 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :594
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695383
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687437
INFO:root:FL Epoch: 203 Norm Difference for worker 594 is 0.157
INFO:root:FL Epoch: 203 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :256
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 256 is 0.224316
INFO:root:FL Epoch: 203 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1075
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701473
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693302
INFO:root:FL Epoch: 203 Norm Difference for worker 1075 is 0.079542
INFO:root:FL Epoch: 203 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1770
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695383
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693627
INFO:root:FL Epoch: 203 Norm Difference for worker 1770 is 0.029125
INFO:root:FL Epoch: 203 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1543
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691323
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689772
INFO:root:FL Epoch: 203 Norm Difference for worker 1543 is 0.078852
INFO:root:FL Epoch: 203 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :483
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689294
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691235
INFO:root:FL Epoch: 203 Norm Difference for worker 483 is 0.011709
INFO:root:FL Epoch: 203 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :433
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695383
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702940
INFO:root:FL Epoch: 203 Norm Difference for worker 433 is 0.177527
INFO:root:FL Epoch: 203 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.693086589083952 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.7007966637611389                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :643
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691652
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691650
INFO:root:FL Epoch: 204 Norm Difference for worker 643 is 0.149425
INFO:root:FL Epoch: 204 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :796
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694700
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690006
INFO:root:FL Epoch: 204 Norm Difference for worker 796 is 0.147666
INFO:root:FL Epoch: 204 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1743
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693938
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695097
INFO:root:FL Epoch: 204 Norm Difference for worker 1743 is 0.057072
INFO:root:FL Epoch: 204 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1572
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694700
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692202
INFO:root:FL Epoch: 204 Norm Difference for worker 1572 is 0.092034
INFO:root:FL Epoch: 204 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :644
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693938
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693220
INFO:root:FL Epoch: 204 Norm Difference for worker 644 is 0.004057
INFO:root:FL Epoch: 204 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :893
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695462
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692444
INFO:root:FL Epoch: 204 Norm Difference for worker 893 is 0.0005
INFO:root:FL Epoch: 204 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :307
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 307 is 0.036084
INFO:root:FL Epoch: 204 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1460
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691652
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688491
INFO:root:FL Epoch: 204 Norm Difference for worker 1460 is 0.047723
INFO:root:FL Epoch: 204 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1890
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693938
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687498
INFO:root:FL Epoch: 204 Norm Difference for worker 1890 is 0.127246
INFO:root:FL Epoch: 204 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :179
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 179 is 0.205393
INFO:root:FL Epoch: 204 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.6931913635310005 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.720332682132721                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1646
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706920
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693615
INFO:root:FL Epoch: 205 Norm Difference for worker 1646 is 0.270272
INFO:root:FL Epoch: 205 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688142
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 0.081746
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :498
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696190
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691320
INFO:root:FL Epoch: 205 Norm Difference for worker 498 is 0.082716
INFO:root:FL Epoch: 205 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :132
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 132 is 0.094177
INFO:root:FL Epoch: 205 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690824
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693377
INFO:root:FL Epoch: 205 Norm Difference for worker 1171 is 0.027482
INFO:root:FL Epoch: 205 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :587
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685459
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693397
INFO:root:FL Epoch: 205 Norm Difference for worker 587 is 0.107443
INFO:root:FL Epoch: 205 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1921
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690824
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690383
INFO:root:FL Epoch: 205 Norm Difference for worker 1921 is 0.031864
INFO:root:FL Epoch: 205 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1482
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693507
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696717
INFO:root:FL Epoch: 205 Norm Difference for worker 1482 is 0.020446
INFO:root:FL Epoch: 205 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :230
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 230 is 0.155375
INFO:root:FL Epoch: 205 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1399
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693507
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685356
INFO:root:FL Epoch: 205 Norm Difference for worker 1399 is 0.066227
INFO:root:FL Epoch: 205 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.6931737486053916 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.6910726428031921                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 206 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :118
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 118 is 0.020334
INFO:root:FL Epoch: 206 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1272
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692942
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694220
INFO:root:FL Epoch: 206 Norm Difference for worker 1272 is 0.030824
INFO:root:FL Epoch: 206 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1114
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693867
INFO:root:FL Epoch: 206 Norm Difference for worker 1114 is 0.01767
INFO:root:FL Epoch: 206 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :236
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 236 is 0.094325
INFO:root:FL Epoch: 206 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693565
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690800
INFO:root:FL Epoch: 206 Norm Difference for worker 1838 is 0.058127
INFO:root:FL Epoch: 206 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1835
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692526
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695472
INFO:root:FL Epoch: 206 Norm Difference for worker 1835 is 0.034595
INFO:root:FL Epoch: 206 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :460
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693980
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693660
INFO:root:FL Epoch: 206 Norm Difference for worker 460 is 0.136959
INFO:root:FL Epoch: 206 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1482
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692449
INFO:root:FL Epoch: 206 Norm Difference for worker 1482 is 0.049586
INFO:root:FL Epoch: 206 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :289
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 289 is 0.01905
INFO:root:FL Epoch: 206 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :329
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 329 is 0.02636
INFO:root:FL Epoch: 206 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.6930787458139307 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.7036982178688049                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1442
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694252
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695964
INFO:root:FL Epoch: 207 Norm Difference for worker 1442 is 0.113119
INFO:root:FL Epoch: 207 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1664
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690053
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683888
INFO:root:FL Epoch: 207 Norm Difference for worker 1664 is 0.104629
INFO:root:FL Epoch: 207 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :483
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691103
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691042
INFO:root:FL Epoch: 207 Norm Difference for worker 483 is 0.006674
INFO:root:FL Epoch: 207 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :754
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689004
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688908
INFO:root:FL Epoch: 207 Norm Difference for worker 754 is 0.201883
INFO:root:FL Epoch: 207 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :166
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695301
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 166 is 0.089143
INFO:root:FL Epoch: 207 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1570
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694252
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691099
INFO:root:FL Epoch: 207 Norm Difference for worker 1570 is 0.001171
INFO:root:FL Epoch: 207 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :541
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693202
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692686
INFO:root:FL Epoch: 207 Norm Difference for worker 541 is 0.045903
INFO:root:FL Epoch: 207 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1604
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692153
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 207 Norm Difference for worker 1604 is 0.030572
INFO:root:FL Epoch: 207 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :800
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696351
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690182
INFO:root:FL Epoch: 207 Norm Difference for worker 800 is 0.090492
INFO:root:FL Epoch: 207 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :277
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 277 is 0.008547
INFO:root:FL Epoch: 207 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.6930917220957139 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.6996884942054749                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1406
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688670
INFO:root:FL Epoch: 208 Norm Difference for worker 1406 is 0.137975
INFO:root:FL Epoch: 208 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :774
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696428
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694301
INFO:root:FL Epoch: 208 Norm Difference for worker 774 is 0.017883
INFO:root:FL Epoch: 208 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :854
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694472
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691202
INFO:root:FL Epoch: 208 Norm Difference for worker 854 is 0.019157
INFO:root:FL Epoch: 208 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1449
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694472
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695109
INFO:root:FL Epoch: 208 Norm Difference for worker 1449 is 0.019143
INFO:root:FL Epoch: 208 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :741
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707312
INFO:root:FL Epoch: 208 Norm Difference for worker 741 is 0.166919
INFO:root:FL Epoch: 208 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :740
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693820
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692214
INFO:root:FL Epoch: 208 Norm Difference for worker 740 is 0.029035
INFO:root:FL Epoch: 208 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1869
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693820
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694149
INFO:root:FL Epoch: 208 Norm Difference for worker 1869 is 0.039532
INFO:root:FL Epoch: 208 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1080
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692044
INFO:root:FL Epoch: 208 Norm Difference for worker 1080 is 0.055536
INFO:root:FL Epoch: 208 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1637
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694472
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693825
INFO:root:FL Epoch: 208 Norm Difference for worker 1637 is 0.005377
INFO:root:FL Epoch: 208 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1546
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692516
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693675
INFO:root:FL Epoch: 208 Norm Difference for worker 1546 is 0.096971
INFO:root:FL Epoch: 208 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.6931346865261302 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.694254457950592                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1904
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694977
INFO:root:FL Epoch: 209 Norm Difference for worker 1904 is 0.161318
INFO:root:FL Epoch: 209 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1753
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704066
INFO:root:FL Epoch: 209 Norm Difference for worker 1753 is 0.080987
INFO:root:FL Epoch: 209 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1821
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693480
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690743
INFO:root:FL Epoch: 209 Norm Difference for worker 1821 is 0.10126
INFO:root:FL Epoch: 209 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1207
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689137
INFO:root:FL Epoch: 209 Norm Difference for worker 1207 is 0.061181
INFO:root:FL Epoch: 209 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :9
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 9 is 0.015966
INFO:root:FL Epoch: 209 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1378
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692926
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698793
INFO:root:FL Epoch: 209 Norm Difference for worker 1378 is 0.084045
INFO:root:FL Epoch: 209 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :211
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 211 is 0.118712
INFO:root:FL Epoch: 209 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :883
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692816
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685261
INFO:root:FL Epoch: 209 Norm Difference for worker 883 is 0.198482
INFO:root:FL Epoch: 209 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :876
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693037
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691355
INFO:root:FL Epoch: 209 Norm Difference for worker 876 is 0.046953
INFO:root:FL Epoch: 209 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :812
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689892
INFO:root:FL Epoch: 209 Norm Difference for worker 812 is 0.044289
INFO:root:FL Epoch: 209 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.6931087865548975 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.6970683336257935                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :321
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 321 is 0.081244
INFO:root:FL Epoch: 210 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :758
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694329
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693373
INFO:root:FL Epoch: 210 Norm Difference for worker 758 is 0.01298
INFO:root:FL Epoch: 210 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :550
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692763
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 210 Norm Difference for worker 550 is 0.074579
INFO:root:FL Epoch: 210 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1387
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696669
INFO:root:FL Epoch: 210 Norm Difference for worker 1387 is 0.04875
INFO:root:FL Epoch: 210 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1806
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692763
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693710
INFO:root:FL Epoch: 210 Norm Difference for worker 1806 is 0.076838
INFO:root:FL Epoch: 210 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693546
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693223
INFO:root:FL Epoch: 210 Norm Difference for worker 760 is 0.015573
INFO:root:FL Epoch: 210 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :316
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 316 is 0.173419
INFO:root:FL Epoch: 210 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1694
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690971
INFO:root:FL Epoch: 210 Norm Difference for worker 1694 is 0.130618
INFO:root:FL Epoch: 210 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :937
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693938
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693153
INFO:root:FL Epoch: 210 Norm Difference for worker 937 is 0.098774
INFO:root:FL Epoch: 210 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1178
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692372
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693870
INFO:root:FL Epoch: 210 Norm Difference for worker 1178 is 0.143341
INFO:root:FL Epoch: 210 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.6932525214026956 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.6862519979476929                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688328
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682603
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.6375637650489807 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.6799061894416809 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.100601
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682936
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.6368980407714844 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.679763263463974 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.102013
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689020
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693429
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.6398783922195435 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.6804065883159638 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.095697
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1428
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690403
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686126
INFO:root:FL Epoch: 211 Norm Difference for worker 1428 is 0.150262
INFO:root:FL Epoch: 211 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :391
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693863
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695769
INFO:root:FL Epoch: 211 Norm Difference for worker 391 is 0.079491
INFO:root:FL Epoch: 211 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1560
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694555
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690526
INFO:root:FL Epoch: 211 Norm Difference for worker 1560 is 0.097434
INFO:root:FL Epoch: 211 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1489
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697323
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692855
INFO:root:FL Epoch: 211 Norm Difference for worker 1489 is 0.040817
INFO:root:FL Epoch: 211 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :106
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693353
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 106 is 0.053995
INFO:root:FL Epoch: 211 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :729
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693337
INFO:root:FL Epoch: 211 Norm Difference for worker 729 is 0.053624
INFO:root:FL Epoch: 211 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1080
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687935
INFO:root:FL Epoch: 211 Norm Difference for worker 1080 is 0.085448
INFO:root:FL Epoch: 211 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.6945195723982418 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.6520909667015076                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :850
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698220
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691515
INFO:root:FL Epoch: 212 Norm Difference for worker 850 is 0.239229
INFO:root:FL Epoch: 212 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1190
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677252
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713731
INFO:root:FL Epoch: 212 Norm Difference for worker 1190 is 0.124129
INFO:root:FL Epoch: 212 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :991
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694026
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674990
INFO:root:FL Epoch: 212 Norm Difference for worker 991 is 0.05621
INFO:root:FL Epoch: 212 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :137
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 137 is 0.007399
INFO:root:FL Epoch: 212 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1175
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694026
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693883
INFO:root:FL Epoch: 212 Norm Difference for worker 1175 is 0.201663
INFO:root:FL Epoch: 212 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1765
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677252
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694767
INFO:root:FL Epoch: 212 Norm Difference for worker 1765 is 0.060561
INFO:root:FL Epoch: 212 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1107
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689833
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697284
INFO:root:FL Epoch: 212 Norm Difference for worker 1107 is 0.146089
INFO:root:FL Epoch: 212 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :415
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698220
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680918
INFO:root:FL Epoch: 212 Norm Difference for worker 415 is 0.059828
INFO:root:FL Epoch: 212 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1168
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681446
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684200
INFO:root:FL Epoch: 212 Norm Difference for worker 1168 is 0.059846
INFO:root:FL Epoch: 212 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :123
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 123 is 0.058299
INFO:root:FL Epoch: 212 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.6936511958346647 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.671297013759613                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1125
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695601
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693289
INFO:root:FL Epoch: 213 Norm Difference for worker 1125 is 0.014854
INFO:root:FL Epoch: 213 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :873
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702229
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693570
INFO:root:FL Epoch: 213 Norm Difference for worker 873 is 0.002594
INFO:root:FL Epoch: 213 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1501
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688972
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693285
INFO:root:FL Epoch: 213 Norm Difference for worker 1501 is 0.046864
INFO:root:FL Epoch: 213 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1370
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695601
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693730
INFO:root:FL Epoch: 213 Norm Difference for worker 1370 is 0.084321
INFO:root:FL Epoch: 213 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1513
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700020
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693695
INFO:root:FL Epoch: 213 Norm Difference for worker 1513 is 0.135273
INFO:root:FL Epoch: 213 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :744
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693391
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693244
INFO:root:FL Epoch: 213 Norm Difference for worker 744 is 0.120563
INFO:root:FL Epoch: 213 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :533
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700020
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693223
INFO:root:FL Epoch: 213 Norm Difference for worker 533 is 0.088542
INFO:root:FL Epoch: 213 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1237
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686763
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682493
INFO:root:FL Epoch: 213 Norm Difference for worker 1237 is 0.096701
INFO:root:FL Epoch: 213 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1929
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695601
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694996
INFO:root:FL Epoch: 213 Norm Difference for worker 1929 is 0.062881
INFO:root:FL Epoch: 213 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1117
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693391
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691433
INFO:root:FL Epoch: 213 Norm Difference for worker 1117 is 0.069542
INFO:root:FL Epoch: 213 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.6932889363344978 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.6844096779823303                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1192
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683007
INFO:root:FL Epoch: 214 Norm Difference for worker 1192 is 0.178699
INFO:root:FL Epoch: 214 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1056
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692308
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696456
INFO:root:FL Epoch: 214 Norm Difference for worker 1056 is 0.010607
INFO:root:FL Epoch: 214 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :257
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694941
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 257 is 0.087864
INFO:root:FL Epoch: 214 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :852
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694941
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688816
INFO:root:FL Epoch: 214 Norm Difference for worker 852 is 0.075038
INFO:root:FL Epoch: 214 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1024
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693330
INFO:root:FL Epoch: 214 Norm Difference for worker 1024 is 0.068725
INFO:root:FL Epoch: 214 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1453
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695818
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692721
INFO:root:FL Epoch: 214 Norm Difference for worker 1453 is 0.017117
INFO:root:FL Epoch: 214 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1392
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692308
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690991
INFO:root:FL Epoch: 214 Norm Difference for worker 1392 is 0.007063
INFO:root:FL Epoch: 214 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1700
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691430
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694870
INFO:root:FL Epoch: 214 Norm Difference for worker 1700 is 0.028223
INFO:root:FL Epoch: 214 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :203
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 203 is 0.005988
INFO:root:FL Epoch: 214 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :661
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695414
INFO:root:FL Epoch: 214 Norm Difference for worker 661 is 0.009742
INFO:root:FL Epoch: 214 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.6931194873417125 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.6958021521568298                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :408
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692886
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693187
INFO:root:FL Epoch: 215 Norm Difference for worker 408 is 0.081348
INFO:root:FL Epoch: 215 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1362
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693416
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692598
INFO:root:FL Epoch: 215 Norm Difference for worker 1362 is 0.012795
INFO:root:FL Epoch: 215 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :158
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 158 is 0.127164
INFO:root:FL Epoch: 215 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :368
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693416
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693216
INFO:root:FL Epoch: 215 Norm Difference for worker 368 is 0.010109
INFO:root:FL Epoch: 215 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :468
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692886
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694874
INFO:root:FL Epoch: 215 Norm Difference for worker 468 is 0.010434
INFO:root:FL Epoch: 215 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1463
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692886
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693960
INFO:root:FL Epoch: 215 Norm Difference for worker 1463 is 0.171591
INFO:root:FL Epoch: 215 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :341
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692614
INFO:root:FL Epoch: 215 Norm Difference for worker 341 is 0.031005
INFO:root:FL Epoch: 215 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1793
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693681
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685409
INFO:root:FL Epoch: 215 Norm Difference for worker 1793 is 0.13686
INFO:root:FL Epoch: 215 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :609
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694977
INFO:root:FL Epoch: 215 Norm Difference for worker 609 is 0.106778
INFO:root:FL Epoch: 215 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :594
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696085
INFO:root:FL Epoch: 215 Norm Difference for worker 594 is 0.114654
INFO:root:FL Epoch: 215 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.6932911907925325 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.6843005418777466                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1256
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696741
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698127
INFO:root:FL Epoch: 216 Norm Difference for worker 1256 is 0.085663
INFO:root:FL Epoch: 216 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1698
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693639
INFO:root:FL Epoch: 216 Norm Difference for worker 1698 is 0.073188
INFO:root:FL Epoch: 216 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :318
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696741
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 318 is 0.107803
INFO:root:FL Epoch: 216 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1075
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689208
INFO:root:FL Epoch: 216 Norm Difference for worker 1075 is 0.095317
INFO:root:FL Epoch: 216 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :427
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695852
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697436
INFO:root:FL Epoch: 216 Norm Difference for worker 427 is 0.009845
INFO:root:FL Epoch: 216 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :895
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697630
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693262
INFO:root:FL Epoch: 216 Norm Difference for worker 895 is 0.017916
INFO:root:FL Epoch: 216 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1686
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694075
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 216 Norm Difference for worker 1686 is 0.057186
INFO:root:FL Epoch: 216 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :939
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692298
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694969
INFO:root:FL Epoch: 216 Norm Difference for worker 939 is 0.066754
INFO:root:FL Epoch: 216 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1008
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691409
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693836
INFO:root:FL Epoch: 216 Norm Difference for worker 1008 is 0.114745
INFO:root:FL Epoch: 216 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1785
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691409
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693375
INFO:root:FL Epoch: 216 Norm Difference for worker 1785 is 0.024787
INFO:root:FL Epoch: 216 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.6932226314264185 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.6879163384437561                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :795
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692636
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692745
INFO:root:FL Epoch: 217 Norm Difference for worker 795 is 0.11151
INFO:root:FL Epoch: 217 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1488
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693685
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700403
INFO:root:FL Epoch: 217 Norm Difference for worker 1488 is 0.039021
INFO:root:FL Epoch: 217 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :830
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691588
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700128
INFO:root:FL Epoch: 217 Norm Difference for worker 830 is 0.261334
INFO:root:FL Epoch: 217 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1412
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694210
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689692
INFO:root:FL Epoch: 217 Norm Difference for worker 1412 is 0.054785
INFO:root:FL Epoch: 217 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1025
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694210
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692899
INFO:root:FL Epoch: 217 Norm Difference for worker 1025 is 0.066487
INFO:root:FL Epoch: 217 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691588
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693894
INFO:root:FL Epoch: 217 Norm Difference for worker 1652 is 0.036763
INFO:root:FL Epoch: 217 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :631
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696832
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672814
INFO:root:FL Epoch: 217 Norm Difference for worker 631 is 0.365537
INFO:root:FL Epoch: 217 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1898
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692112
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683434
INFO:root:FL Epoch: 217 Norm Difference for worker 1898 is 0.11867
INFO:root:FL Epoch: 217 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :872
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693685
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 217 Norm Difference for worker 872 is 0.023823
INFO:root:FL Epoch: 217 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :698
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691588
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692163
INFO:root:FL Epoch: 217 Norm Difference for worker 698 is 0.042231
INFO:root:FL Epoch: 217 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.6930799940053154 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.7070002555847168                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1823
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695994
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698120
INFO:root:FL Epoch: 218 Norm Difference for worker 1823 is 0.033649
INFO:root:FL Epoch: 218 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :16
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 16 is 0.008509
INFO:root:FL Epoch: 218 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1683
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694618
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689293
INFO:root:FL Epoch: 218 Norm Difference for worker 1683 is 0.135466
INFO:root:FL Epoch: 218 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1802
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696802
INFO:root:FL Epoch: 218 Norm Difference for worker 1802 is 0.079452
INFO:root:FL Epoch: 218 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :663
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695705
INFO:root:FL Epoch: 218 Norm Difference for worker 663 is 0.086125
INFO:root:FL Epoch: 218 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1406
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695993
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694636
INFO:root:FL Epoch: 218 Norm Difference for worker 1406 is 0.127995
INFO:root:FL Epoch: 218 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1358
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691866
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696766
INFO:root:FL Epoch: 218 Norm Difference for worker 1358 is 0.198588
INFO:root:FL Epoch: 218 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :240
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684780
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 240 is 0.108761
INFO:root:FL Epoch: 218 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :101
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 101 is 0.202866
INFO:root:FL Epoch: 218 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1363
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693242
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692198
INFO:root:FL Epoch: 218 Norm Difference for worker 1363 is 0.009958
INFO:root:FL Epoch: 218 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.6934718454585356 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.6769780516624451                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 219 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :185
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693280
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 185 is 0.048868
INFO:root:FL Epoch: 219 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1693
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690020
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698551
INFO:root:FL Epoch: 219 Norm Difference for worker 1693 is 0.00749
INFO:root:FL Epoch: 219 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :737
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696540
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 219 Norm Difference for worker 737 is 0.006022
INFO:root:FL Epoch: 219 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1553
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698171
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693521
INFO:root:FL Epoch: 219 Norm Difference for worker 1553 is 0.13307
INFO:root:FL Epoch: 219 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :560
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690020
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690925
INFO:root:FL Epoch: 219 Norm Difference for worker 560 is 0.031444
INFO:root:FL Epoch: 219 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1190
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693280
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689302
INFO:root:FL Epoch: 219 Norm Difference for worker 1190 is 0.163952
INFO:root:FL Epoch: 219 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :926
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701431
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693168
INFO:root:FL Epoch: 219 Norm Difference for worker 926 is 0.063086
INFO:root:FL Epoch: 219 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :912
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691650
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691301
INFO:root:FL Epoch: 219 Norm Difference for worker 912 is 0.192942
INFO:root:FL Epoch: 219 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696540
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698911
INFO:root:FL Epoch: 219 Norm Difference for worker 1477 is 0.042221
INFO:root:FL Epoch: 219 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :173
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688389
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697843
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 173 is 0.096471
INFO:root:FL Epoch: 219 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.6933026278720182 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.6837581396102905                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1326
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693192
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693325
INFO:root:FL Epoch: 220 Norm Difference for worker 1326 is 0.022863
INFO:root:FL Epoch: 220 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :919
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695078
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693974
INFO:root:FL Epoch: 220 Norm Difference for worker 919 is 0.084006
INFO:root:FL Epoch: 220 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1829
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692248
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698523
INFO:root:FL Epoch: 220 Norm Difference for worker 1829 is 0.169093
INFO:root:FL Epoch: 220 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1536
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694135
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690007
INFO:root:FL Epoch: 220 Norm Difference for worker 1536 is 0.087344
INFO:root:FL Epoch: 220 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1533
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693192
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691172
INFO:root:FL Epoch: 220 Norm Difference for worker 1533 is 0.022438
INFO:root:FL Epoch: 220 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1562
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692248
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693905
INFO:root:FL Epoch: 220 Norm Difference for worker 1562 is 0.147216
INFO:root:FL Epoch: 220 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :524
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692248
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693224
INFO:root:FL Epoch: 220 Norm Difference for worker 524 is 0.036095
INFO:root:FL Epoch: 220 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :652
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696022
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693285
INFO:root:FL Epoch: 220 Norm Difference for worker 652 is 0.049349
INFO:root:FL Epoch: 220 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1778
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693192
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 220 Norm Difference for worker 1778 is 0.012325
INFO:root:FL Epoch: 220 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :59
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698382
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 59 is 0.149224
INFO:root:FL Epoch: 220 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.6936327850117403 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.6718332171440125                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682606
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685953
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.6298050284385681 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.6782637298107147 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.087877
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686916
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686995
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.6287795901298523 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.6780506789684295 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.090073
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689070
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668534
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.6282397508621216 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.6779388844966888 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.09123
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :316
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697688
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 316 is 0.215862
INFO:root:FL Epoch: 221 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1143
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695534
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 221 Norm Difference for worker 1143 is 0.037327
INFO:root:FL Epoch: 221 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :39
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689070
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 39 is 0.149796
INFO:root:FL Epoch: 221 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :451
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691225
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688276
INFO:root:FL Epoch: 221 Norm Difference for worker 451 is 0.103258
INFO:root:FL Epoch: 221 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1522
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684761
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699008
INFO:root:FL Epoch: 221 Norm Difference for worker 1522 is 0.0413
INFO:root:FL Epoch: 221 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1199
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701998
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686298
INFO:root:FL Epoch: 221 Norm Difference for worker 1199 is 0.283839
INFO:root:FL Epoch: 221 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1403
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695534
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693698
INFO:root:FL Epoch: 221 Norm Difference for worker 1403 is 0.094733
INFO:root:FL Epoch: 221 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.6931882079909829 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.6900696754455566                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1432
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685882
INFO:root:FL Epoch: 222 Norm Difference for worker 1432 is 0.104698
INFO:root:FL Epoch: 222 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1879
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693768
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693210
INFO:root:FL Epoch: 222 Norm Difference for worker 1879 is 0.072463
INFO:root:FL Epoch: 222 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1374
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694077
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696634
INFO:root:FL Epoch: 222 Norm Difference for worker 1374 is 0.007874
INFO:root:FL Epoch: 222 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :138
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 138 is 0.024707
INFO:root:FL Epoch: 222 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1818
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692455
INFO:root:FL Epoch: 222 Norm Difference for worker 1818 is 0.010039
INFO:root:FL Epoch: 222 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1897
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694077
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693753
INFO:root:FL Epoch: 222 Norm Difference for worker 1897 is 0.006944
INFO:root:FL Epoch: 222 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1713
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693460
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686485
INFO:root:FL Epoch: 222 Norm Difference for worker 1713 is 0.203329
INFO:root:FL Epoch: 222 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1190
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692536
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679464
INFO:root:FL Epoch: 222 Norm Difference for worker 1190 is 0.238534
INFO:root:FL Epoch: 222 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 0.033712
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1704
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692536
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699518
INFO:root:FL Epoch: 222 Norm Difference for worker 1704 is 0.015758
INFO:root:FL Epoch: 222 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.6935235822902006 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.6752204895019531                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 270 is 0.129472
INFO:root:FL Epoch: 223 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :754
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696929
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689918
INFO:root:FL Epoch: 223 Norm Difference for worker 754 is 0.237205
INFO:root:FL Epoch: 223 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :153
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687210
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 153 is 0.209114
INFO:root:FL Epoch: 223 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :729
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687884
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683852
INFO:root:FL Epoch: 223 Norm Difference for worker 729 is 0.060353
INFO:root:FL Epoch: 223 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691502
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696318
INFO:root:FL Epoch: 223 Norm Difference for worker 1270 is 0.069419
INFO:root:FL Epoch: 223 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :198
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 198 is 0.093353
INFO:root:FL Epoch: 223 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :422
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693311
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695089
INFO:root:FL Epoch: 223 Norm Difference for worker 422 is 0.183478
INFO:root:FL Epoch: 223 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :357
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693311
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693156
INFO:root:FL Epoch: 223 Norm Difference for worker 357 is 0.085985
INFO:root:FL Epoch: 223 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1197
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691502
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660674
INFO:root:FL Epoch: 223 Norm Difference for worker 1197 is 0.334979
INFO:root:FL Epoch: 223 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1215
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695120
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678456
INFO:root:FL Epoch: 223 Norm Difference for worker 1215 is 0.081767
INFO:root:FL Epoch: 223 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.693129606106702 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.6947572827339172                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :1695
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687873
INFO:root:FL Epoch: 224 Norm Difference for worker 1695 is 0.180839
INFO:root:FL Epoch: 224 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689441
INFO:root:FL Epoch: 224 Norm Difference for worker 1865 is 0.024718
INFO:root:FL Epoch: 224 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1713
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675467
INFO:root:FL Epoch: 224 Norm Difference for worker 1713 is 0.25893
INFO:root:FL Epoch: 224 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :297
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 297 is 0.04795
INFO:root:FL Epoch: 224 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1928
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692988
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691268
INFO:root:FL Epoch: 224 Norm Difference for worker 1928 is 0.072633
INFO:root:FL Epoch: 224 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1649
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688919
INFO:root:FL Epoch: 224 Norm Difference for worker 1649 is 0.063988
INFO:root:FL Epoch: 224 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :866
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692505
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694103
INFO:root:FL Epoch: 224 Norm Difference for worker 866 is 0.113523
INFO:root:FL Epoch: 224 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1522
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693470
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689252
INFO:root:FL Epoch: 224 Norm Difference for worker 1522 is 0.131108
INFO:root:FL Epoch: 224 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :950
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692827
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696654
INFO:root:FL Epoch: 224 Norm Difference for worker 950 is 0.136516
INFO:root:FL Epoch: 224 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1672
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693470
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701869
INFO:root:FL Epoch: 224 Norm Difference for worker 1672 is 0.073134
INFO:root:FL Epoch: 224 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.6931146593654857 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.6963586211204529                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :772
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694435
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693553
INFO:root:FL Epoch: 225 Norm Difference for worker 772 is 0.183678
INFO:root:FL Epoch: 225 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :146
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702737
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 146 is 0.145898
INFO:root:FL Epoch: 225 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :483
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693473
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693969
INFO:root:FL Epoch: 225 Norm Difference for worker 483 is 0.013638
INFO:root:FL Epoch: 225 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :630
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694114
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696594
INFO:root:FL Epoch: 225 Norm Difference for worker 630 is 0.006617
INFO:root:FL Epoch: 225 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1459
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693794
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693215
INFO:root:FL Epoch: 225 Norm Difference for worker 1459 is 0.10244
INFO:root:FL Epoch: 225 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1607
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693794
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683004
INFO:root:FL Epoch: 225 Norm Difference for worker 1607 is 0.106158
INFO:root:FL Epoch: 225 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1636
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693794
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686207
INFO:root:FL Epoch: 225 Norm Difference for worker 1636 is 0.226584
INFO:root:FL Epoch: 225 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1906
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694114
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 225 Norm Difference for worker 1906 is 0.003593
INFO:root:FL Epoch: 225 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1540
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693794
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694047
INFO:root:FL Epoch: 225 Norm Difference for worker 1540 is 0.281967
INFO:root:FL Epoch: 225 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :320
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 320 is 0.064012
INFO:root:FL Epoch: 225 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.6932891957900104 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.6843976378440857                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :607
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694943
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687641
INFO:root:FL Epoch: 226 Norm Difference for worker 607 is 0.151833
INFO:root:FL Epoch: 226 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1256
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688792
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691366
INFO:root:FL Epoch: 226 Norm Difference for worker 1256 is 0.095273
INFO:root:FL Epoch: 226 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :305
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 305 is 0.105082
INFO:root:FL Epoch: 226 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1249
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692307
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684555
INFO:root:FL Epoch: 226 Norm Difference for worker 1249 is 0.271799
INFO:root:FL Epoch: 226 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1338
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692307
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688360
INFO:root:FL Epoch: 226 Norm Difference for worker 1338 is 0.12996
INFO:root:FL Epoch: 226 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :942
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692307
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689714
INFO:root:FL Epoch: 226 Norm Difference for worker 942 is 0.134354
INFO:root:FL Epoch: 226 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1340
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695822
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694113
INFO:root:FL Epoch: 226 Norm Difference for worker 1340 is 0.033643
INFO:root:FL Epoch: 226 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :822
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694065
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688905
INFO:root:FL Epoch: 226 Norm Difference for worker 822 is 0.130491
INFO:root:FL Epoch: 226 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :41
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 41 is 0.034178
INFO:root:FL Epoch: 226 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1770
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693186
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694874
INFO:root:FL Epoch: 226 Norm Difference for worker 1770 is 0.019292
INFO:root:FL Epoch: 226 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.6932178209809696 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.6882005333900452                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 227 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :77
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 77 is 0.042741
INFO:root:FL Epoch: 227 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :907
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691672
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689715
INFO:root:FL Epoch: 227 Norm Difference for worker 907 is 0.020899
INFO:root:FL Epoch: 227 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :431
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691176
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688447
INFO:root:FL Epoch: 227 Norm Difference for worker 431 is 0.009541
INFO:root:FL Epoch: 227 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1546
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693159
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693323
INFO:root:FL Epoch: 227 Norm Difference for worker 1546 is 0.046153
INFO:root:FL Epoch: 227 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1892
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693655
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688314
INFO:root:FL Epoch: 227 Norm Difference for worker 1892 is 0.019766
INFO:root:FL Epoch: 227 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :70
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697001
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 70 is 0.160934
INFO:root:FL Epoch: 227 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1513
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693655
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692369
INFO:root:FL Epoch: 227 Norm Difference for worker 1513 is 0.095613
INFO:root:FL Epoch: 227 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :959
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695639
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690291
INFO:root:FL Epoch: 227 Norm Difference for worker 959 is 0.177041
INFO:root:FL Epoch: 227 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :274
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 274 is 0.070538
INFO:root:FL Epoch: 227 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :157
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 157 is 0.116431
INFO:root:FL Epoch: 227 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.6931433291996226 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.7166165709495544                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :683
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688776
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687120
INFO:root:FL Epoch: 228 Norm Difference for worker 683 is 0.120211
INFO:root:FL Epoch: 228 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1670
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688776
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693326
INFO:root:FL Epoch: 228 Norm Difference for worker 1670 is 0.02432
INFO:root:FL Epoch: 228 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1846
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691096
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690430
INFO:root:FL Epoch: 228 Norm Difference for worker 1846 is 0.018213
INFO:root:FL Epoch: 228 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :949
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695736
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690032
INFO:root:FL Epoch: 228 Norm Difference for worker 949 is 0.056333
INFO:root:FL Epoch: 228 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1749
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700376
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694806
INFO:root:FL Epoch: 228 Norm Difference for worker 1749 is 0.037377
INFO:root:FL Epoch: 228 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1722
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688776
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696555
INFO:root:FL Epoch: 228 Norm Difference for worker 1722 is 0.112754
INFO:root:FL Epoch: 228 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :993
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700376
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675574
INFO:root:FL Epoch: 228 Norm Difference for worker 993 is 0.300507
INFO:root:FL Epoch: 228 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1085
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691096
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689674
INFO:root:FL Epoch: 228 Norm Difference for worker 1085 is 0.007114
INFO:root:FL Epoch: 228 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :948
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700376
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686079
INFO:root:FL Epoch: 228 Norm Difference for worker 948 is 0.176241
INFO:root:FL Epoch: 228 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1414
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688776
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692044
INFO:root:FL Epoch: 228 Norm Difference for worker 1414 is 0.183177
INFO:root:FL Epoch: 228 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.6933683717952055 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.6808854341506958                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :958
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696925
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693361
INFO:root:FL Epoch: 229 Norm Difference for worker 958 is 0.009498
INFO:root:FL Epoch: 229 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :924
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687054
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695352
INFO:root:FL Epoch: 229 Norm Difference for worker 924 is 0.134702
INFO:root:FL Epoch: 229 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :923
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691989
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696967
INFO:root:FL Epoch: 229 Norm Difference for worker 923 is 0.063033
INFO:root:FL Epoch: 229 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :170
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 170 is 0.188217
INFO:root:FL Epoch: 229 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1886
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690756
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690627
INFO:root:FL Epoch: 229 Norm Difference for worker 1886 is 0.018675
INFO:root:FL Epoch: 229 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :71
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 71 is 0.108115
INFO:root:FL Epoch: 229 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :912
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690756
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691493
INFO:root:FL Epoch: 229 Norm Difference for worker 912 is 0.19271
INFO:root:FL Epoch: 229 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1134
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691989
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694222
INFO:root:FL Epoch: 229 Norm Difference for worker 1134 is 0.093529
INFO:root:FL Epoch: 229 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1808
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690756
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692743
INFO:root:FL Epoch: 229 Norm Difference for worker 1808 is 0.048853
INFO:root:FL Epoch: 229 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1870
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689522
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690019
INFO:root:FL Epoch: 229 Norm Difference for worker 1870 is 0.115865
INFO:root:FL Epoch: 229 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.6934828547870412 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.6765939593315125                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :1469
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699963
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692288
INFO:root:FL Epoch: 230 Norm Difference for worker 1469 is 0.027259
INFO:root:FL Epoch: 230 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :582
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694956
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692852
INFO:root:FL Epoch: 230 Norm Difference for worker 582 is 0.023141
INFO:root:FL Epoch: 230 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :963
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691617
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693825
INFO:root:FL Epoch: 230 Norm Difference for worker 963 is 0.042673
INFO:root:FL Epoch: 230 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :936
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689948
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694338
INFO:root:FL Epoch: 230 Norm Difference for worker 936 is 0.140535
INFO:root:FL Epoch: 230 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1610
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688279
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692511
INFO:root:FL Epoch: 230 Norm Difference for worker 1610 is 0.13266
INFO:root:FL Epoch: 230 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1285
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693286
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693158
INFO:root:FL Epoch: 230 Norm Difference for worker 1285 is 0.130019
INFO:root:FL Epoch: 230 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :954
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688279
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693401
INFO:root:FL Epoch: 230 Norm Difference for worker 954 is 0.139716
INFO:root:FL Epoch: 230 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :660
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698294
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 230 Norm Difference for worker 660 is 0.123403
INFO:root:FL Epoch: 230 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :200
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698294
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693836
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 200 is 0.120201
INFO:root:FL Epoch: 230 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :238
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696625
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 238 is 0.21867
INFO:root:FL Epoch: 230 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.6931727809064528 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.6911435127258301                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692949
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680856
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.6423510909080505 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.6809462189674378 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.1003
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692146
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688118
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.6462888121604919 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.6818165242671966 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.092009
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692347
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691381
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.645510733127594 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.6816434919834137 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.093644
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :182
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692949
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 182 is 0.173026
INFO:root:FL Epoch: 231 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :207
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690196
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 207 is 0.056839
INFO:root:FL Epoch: 231 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1332
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693350
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696171
INFO:root:FL Epoch: 231 Norm Difference for worker 1332 is 0.079468
INFO:root:FL Epoch: 231 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :956
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693503
INFO:root:FL Epoch: 231 Norm Difference for worker 956 is 0.027351
INFO:root:FL Epoch: 231 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693350
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693036
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 0.027703
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1364
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693350
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695265
INFO:root:FL Epoch: 231 Norm Difference for worker 1364 is 0.06337
INFO:root:FL Epoch: 231 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :648
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693550
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687402
INFO:root:FL Epoch: 231 Norm Difference for worker 648 is 0.042796
INFO:root:FL Epoch: 231 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.6931300864500158 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.6947144269943237                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1755
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693618
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695373
INFO:root:FL Epoch: 232 Norm Difference for worker 1755 is 0.037227
INFO:root:FL Epoch: 232 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1533
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693305
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698372
INFO:root:FL Epoch: 232 Norm Difference for worker 1533 is 0.03209
INFO:root:FL Epoch: 232 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1003
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692992
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694385
INFO:root:FL Epoch: 232 Norm Difference for worker 1003 is 0.016071
INFO:root:FL Epoch: 232 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1514
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 232 Norm Difference for worker 1514 is 0.033712
INFO:root:FL Epoch: 232 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :482
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692992
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703062
INFO:root:FL Epoch: 232 Norm Difference for worker 482 is 0.060788
INFO:root:FL Epoch: 232 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :38
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 38 is 0.176139
INFO:root:FL Epoch: 232 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1305
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682209
INFO:root:FL Epoch: 232 Norm Difference for worker 1305 is 0.226296
INFO:root:FL Epoch: 232 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :806
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692992
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693160
INFO:root:FL Epoch: 232 Norm Difference for worker 806 is 0.067697
INFO:root:FL Epoch: 232 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693305
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690149
INFO:root:FL Epoch: 232 Norm Difference for worker 1291 is 0.055544
INFO:root:FL Epoch: 232 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1342
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692679
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694178
INFO:root:FL Epoch: 232 Norm Difference for worker 1342 is 0.023017
INFO:root:FL Epoch: 232 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.6937503919881933 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.6685509085655212                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1736
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698439
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700161
INFO:root:FL Epoch: 233 Norm Difference for worker 1736 is 0.128252
INFO:root:FL Epoch: 233 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1347
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693457
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693426
INFO:root:FL Epoch: 233 Norm Difference for worker 1347 is 0.055808
INFO:root:FL Epoch: 233 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :965
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700929
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691479
INFO:root:FL Epoch: 233 Norm Difference for worker 965 is 0.032551
INFO:root:FL Epoch: 233 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1370
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688476
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686276
INFO:root:FL Epoch: 233 Norm Difference for worker 1370 is 0.085063
INFO:root:FL Epoch: 233 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :121
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698439
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 121 is 0.021796
INFO:root:FL Epoch: 233 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1393
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693457
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694571
INFO:root:FL Epoch: 233 Norm Difference for worker 1393 is 0.028961
INFO:root:FL Epoch: 233 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :456
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693457
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690639
INFO:root:FL Epoch: 233 Norm Difference for worker 456 is 0.011909
INFO:root:FL Epoch: 233 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1814
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693457
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688769
INFO:root:FL Epoch: 233 Norm Difference for worker 1814 is 0.189593
INFO:root:FL Epoch: 233 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1922
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688476
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 233 Norm Difference for worker 1922 is 0.181869
INFO:root:FL Epoch: 233 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :825
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690967
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690387
INFO:root:FL Epoch: 233 Norm Difference for worker 825 is 0.062335
INFO:root:FL Epoch: 233 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.6936871304231531 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.6702746748924255                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1426
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695729
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 234 Norm Difference for worker 1426 is 0.068583
INFO:root:FL Epoch: 234 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1515
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695729
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694520
INFO:root:FL Epoch: 234 Norm Difference for worker 1515 is 0.180251
INFO:root:FL Epoch: 234 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1029
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693415
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689247
INFO:root:FL Epoch: 234 Norm Difference for worker 1029 is 0.144563
INFO:root:FL Epoch: 234 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1283
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693415
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693200
INFO:root:FL Epoch: 234 Norm Difference for worker 1283 is 0.061463
INFO:root:FL Epoch: 234 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :292
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694128
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 292 is 0.097614
INFO:root:FL Epoch: 234 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :988
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686473
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689057
INFO:root:FL Epoch: 234 Norm Difference for worker 988 is 0.117272
INFO:root:FL Epoch: 234 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :434
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686473
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697526
INFO:root:FL Epoch: 234 Norm Difference for worker 434 is 0.033427
INFO:root:FL Epoch: 234 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1197
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679531
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678656
INFO:root:FL Epoch: 234 Norm Difference for worker 1197 is 0.321514
INFO:root:FL Epoch: 234 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1772
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702671
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694244
INFO:root:FL Epoch: 234 Norm Difference for worker 1772 is 0.153665
INFO:root:FL Epoch: 234 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1338
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691101
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702068
INFO:root:FL Epoch: 234 Norm Difference for worker 1338 is 0.087897
INFO:root:FL Epoch: 234 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.693826272207148 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.6665878295898438                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :522
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688125
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693308
INFO:root:FL Epoch: 235 Norm Difference for worker 522 is 0.056901
INFO:root:FL Epoch: 235 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1084
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698894
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696458
INFO:root:FL Epoch: 235 Norm Difference for worker 1084 is 0.266565
INFO:root:FL Epoch: 235 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688125
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683988
INFO:root:FL Epoch: 235 Norm Difference for worker 794 is 0.13719
INFO:root:FL Epoch: 235 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1467
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688125
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693579
INFO:root:FL Epoch: 235 Norm Difference for worker 1467 is 0.131183
INFO:root:FL Epoch: 235 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693510
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686640
INFO:root:FL Epoch: 235 Norm Difference for worker 1794 is 0.009356
INFO:root:FL Epoch: 235 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1935
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685433
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697496
INFO:root:FL Epoch: 235 Norm Difference for worker 1935 is 0.034535
INFO:root:FL Epoch: 235 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698894
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696675
INFO:root:FL Epoch: 235 Norm Difference for worker 1180 is 0.078869
INFO:root:FL Epoch: 235 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1316
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688125
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690323
INFO:root:FL Epoch: 235 Norm Difference for worker 1316 is 0.022262
INFO:root:FL Epoch: 235 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1029
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682741
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670159
INFO:root:FL Epoch: 235 Norm Difference for worker 1029 is 0.131419
INFO:root:FL Epoch: 235 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1087
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704278
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693262
INFO:root:FL Epoch: 235 Norm Difference for worker 1087 is 0.11674
INFO:root:FL Epoch: 235 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.6932672542684218 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.6854833960533142                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1500
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694715
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690844
INFO:root:FL Epoch: 236 Norm Difference for worker 1500 is 0.097268
INFO:root:FL Epoch: 236 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1518
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692407
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692622
INFO:root:FL Epoch: 236 Norm Difference for worker 1518 is 0.066176
INFO:root:FL Epoch: 236 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693946
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696509
INFO:root:FL Epoch: 236 Norm Difference for worker 1356 is 0.126188
INFO:root:FL Epoch: 236 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1009
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693177
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691771
INFO:root:FL Epoch: 236 Norm Difference for worker 1009 is 0.005214
INFO:root:FL Epoch: 236 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :923
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694715
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693929
INFO:root:FL Epoch: 236 Norm Difference for worker 923 is 0.077396
INFO:root:FL Epoch: 236 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1137
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694715
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693332
INFO:root:FL Epoch: 236 Norm Difference for worker 1137 is 0.052523
INFO:root:FL Epoch: 236 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1947
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691638
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692308
INFO:root:FL Epoch: 236 Norm Difference for worker 1947 is 0.005946
INFO:root:FL Epoch: 236 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692407
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688049
INFO:root:FL Epoch: 236 Norm Difference for worker 1178 is 0.152876
INFO:root:FL Epoch: 236 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :44
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693946
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 44 is 0.056874
INFO:root:FL Epoch: 236 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :161
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 161 is 0.070231
INFO:root:FL Epoch: 236 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.6933587719412411 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.6812834143638611                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :312
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 312 is 0.056915
INFO:root:FL Epoch: 237 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1612
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695605
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692329
INFO:root:FL Epoch: 237 Norm Difference for worker 1612 is 0.020493
INFO:root:FL Epoch: 237 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1685
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695605
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699903
INFO:root:FL Epoch: 237 Norm Difference for worker 1685 is 0.017084
INFO:root:FL Epoch: 237 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :582
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690831
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694620
INFO:root:FL Epoch: 237 Norm Difference for worker 582 is 0.023311
INFO:root:FL Epoch: 237 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :797
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692025
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686540
INFO:root:FL Epoch: 237 Norm Difference for worker 797 is 0.149537
INFO:root:FL Epoch: 237 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :600
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687251
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695570
INFO:root:FL Epoch: 237 Norm Difference for worker 600 is 0.18765
INFO:root:FL Epoch: 237 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :237
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 237 is 0.207255
INFO:root:FL Epoch: 237 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1308
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689638
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686663
INFO:root:FL Epoch: 237 Norm Difference for worker 1308 is 0.004447
INFO:root:FL Epoch: 237 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :534
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695605
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692427
INFO:root:FL Epoch: 237 Norm Difference for worker 534 is 0.039119
INFO:root:FL Epoch: 237 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :844
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692025
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692995
INFO:root:FL Epoch: 237 Norm Difference for worker 844 is 0.06768
INFO:root:FL Epoch: 237 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.6935047752716962 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.6758469343185425                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :58
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 58 is 0.050357
INFO:root:FL Epoch: 238 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :859
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689809
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693260
INFO:root:FL Epoch: 238 Norm Difference for worker 859 is 0.135829
INFO:root:FL Epoch: 238 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :433
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689809
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701393
INFO:root:FL Epoch: 238 Norm Difference for worker 433 is 0.170787
INFO:root:FL Epoch: 238 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1026
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691554
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691978
INFO:root:FL Epoch: 238 Norm Difference for worker 1026 is 0.11448
INFO:root:FL Epoch: 238 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :994
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689809
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692754
INFO:root:FL Epoch: 238 Norm Difference for worker 994 is 0.082923
INFO:root:FL Epoch: 238 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1506
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688064
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691987
INFO:root:FL Epoch: 238 Norm Difference for worker 1506 is 0.036058
INFO:root:FL Epoch: 238 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :858
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693299
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690657
INFO:root:FL Epoch: 238 Norm Difference for worker 858 is 0.006018
INFO:root:FL Epoch: 238 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :763
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684573
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694156
INFO:root:FL Epoch: 238 Norm Difference for worker 763 is 0.071093
INFO:root:FL Epoch: 238 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1007
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702026
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703084
INFO:root:FL Epoch: 238 Norm Difference for worker 1007 is 0.234
INFO:root:FL Epoch: 238 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :921
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689809
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701299
INFO:root:FL Epoch: 238 Norm Difference for worker 921 is 0.159683
INFO:root:FL Epoch: 238 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.6932078915483811 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.7214235663414001                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1052
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685170
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688362
INFO:root:FL Epoch: 239 Norm Difference for worker 1052 is 0.009997
INFO:root:FL Epoch: 239 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :845
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687958
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699675
INFO:root:FL Epoch: 239 Norm Difference for worker 845 is 0.068702
INFO:root:FL Epoch: 239 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :221
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694115
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 221 is 0.059048
INFO:root:FL Epoch: 239 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :456
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685170
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694270
INFO:root:FL Epoch: 239 Norm Difference for worker 456 is 0.111807
INFO:root:FL Epoch: 239 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :255
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 255 is 0.185615
INFO:root:FL Epoch: 239 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :587
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687958
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694235
INFO:root:FL Epoch: 239 Norm Difference for worker 587 is 0.109168
INFO:root:FL Epoch: 239 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :86
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 86 is 0.03277
INFO:root:FL Epoch: 239 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1398
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704691
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693411
INFO:root:FL Epoch: 239 Norm Difference for worker 1398 is 0.086153
INFO:root:FL Epoch: 239 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :451
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693536
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694411
INFO:root:FL Epoch: 239 Norm Difference for worker 451 is 0.18885
INFO:root:FL Epoch: 239 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1030
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690747
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693615
INFO:root:FL Epoch: 239 Norm Difference for worker 1030 is 0.049267
INFO:root:FL Epoch: 239 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.6931877732276917 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.6901020407676697                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1503
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691469
INFO:root:FL Epoch: 240 Norm Difference for worker 1503 is 0.095868
INFO:root:FL Epoch: 240 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693318
INFO:root:FL Epoch: 240 Norm Difference for worker 627 is 0.087565
INFO:root:FL Epoch: 240 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1705
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693602
INFO:root:FL Epoch: 240 Norm Difference for worker 1705 is 0.018503
INFO:root:FL Epoch: 240 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1702
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692542
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693653
INFO:root:FL Epoch: 240 Norm Difference for worker 1702 is 0.032111
INFO:root:FL Epoch: 240 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1356
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693457
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685500
INFO:root:FL Epoch: 240 Norm Difference for worker 1356 is 0.100243
INFO:root:FL Epoch: 240 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :22
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 22 is 0.026418
INFO:root:FL Epoch: 240 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1709
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693127
INFO:root:FL Epoch: 240 Norm Difference for worker 1709 is 0.004734
INFO:root:FL Epoch: 240 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :31
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694372
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 31 is 0.135394
INFO:root:FL Epoch: 240 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :42
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 42 is 0.023885
INFO:root:FL Epoch: 240 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :358
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694372
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682012
INFO:root:FL Epoch: 240 Norm Difference for worker 358 is 0.117901
INFO:root:FL Epoch: 240 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.6930942815892837 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.6992120742797852                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686223
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.6500709652900696 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.6826649963855743 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.100185
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694979
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689749
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.6502694487571716 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.6827098429203033 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.09977
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696793
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692171
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.6543422341346741 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.6836376249790191 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.09127
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1593
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692561
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690166
INFO:root:FL Epoch: 241 Norm Difference for worker 1593 is 0.091945
INFO:root:FL Epoch: 241 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1631
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691956
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695850
INFO:root:FL Epoch: 241 Norm Difference for worker 1631 is 0.117767
INFO:root:FL Epoch: 241 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1647
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690747
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692721
INFO:root:FL Epoch: 241 Norm Difference for worker 1647 is 0.107934
INFO:root:FL Epoch: 241 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1726
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697896
INFO:root:FL Epoch: 241 Norm Difference for worker 1726 is 0.066409
INFO:root:FL Epoch: 241 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1002
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695584
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693160
INFO:root:FL Epoch: 241 Norm Difference for worker 1002 is 0.073304
INFO:root:FL Epoch: 241 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1907
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691351
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693167
INFO:root:FL Epoch: 241 Norm Difference for worker 1907 is 0.007218
INFO:root:FL Epoch: 241 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :518
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694375
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688338
INFO:root:FL Epoch: 241 Norm Difference for worker 518 is 0.107629
INFO:root:FL Epoch: 241 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.6931653653874117 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.6916876435279846                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1813
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693440
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689757
INFO:root:FL Epoch: 242 Norm Difference for worker 1813 is 0.0502
INFO:root:FL Epoch: 242 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1657
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693440
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700998
INFO:root:FL Epoch: 242 Norm Difference for worker 1657 is 0.121288
INFO:root:FL Epoch: 242 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1921
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693865
INFO:root:FL Epoch: 242 Norm Difference for worker 1921 is 0.062514
INFO:root:FL Epoch: 242 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :123
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 123 is 0.010029
INFO:root:FL Epoch: 242 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :56
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 56 is 0.114766
INFO:root:FL Epoch: 242 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :975
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693586
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693261
INFO:root:FL Epoch: 242 Norm Difference for worker 975 is 0.048878
INFO:root:FL Epoch: 242 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1165
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693002
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692050
INFO:root:FL Epoch: 242 Norm Difference for worker 1165 is 0.016228
INFO:root:FL Epoch: 242 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :380
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693002
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691624
INFO:root:FL Epoch: 242 Norm Difference for worker 380 is 0.06752
INFO:root:FL Epoch: 242 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :313
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 313 is 0.003764
INFO:root:FL Epoch: 242 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1324
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693002
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685661
INFO:root:FL Epoch: 242 Norm Difference for worker 1324 is 0.132228
INFO:root:FL Epoch: 242 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.6933565315078286 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.6813802123069763                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1593
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688482
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 243 Norm Difference for worker 1593 is 0.112735
INFO:root:FL Epoch: 243 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1300
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695585
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693306
INFO:root:FL Epoch: 243 Norm Difference for worker 1300 is 0.066103
INFO:root:FL Epoch: 243 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :642
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697952
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697573
INFO:root:FL Epoch: 243 Norm Difference for worker 642 is 0.267339
INFO:root:FL Epoch: 243 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1371
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690850
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688765
INFO:root:FL Epoch: 243 Norm Difference for worker 1371 is 0.046333
INFO:root:FL Epoch: 243 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :278
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 278 is 0.032037
INFO:root:FL Epoch: 243 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :562
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694401
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684716
INFO:root:FL Epoch: 243 Norm Difference for worker 562 is 0.086052
INFO:root:FL Epoch: 243 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1220
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694401
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689190
INFO:root:FL Epoch: 243 Norm Difference for worker 1220 is 0.004917
INFO:root:FL Epoch: 243 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :620
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692034
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685325
INFO:root:FL Epoch: 243 Norm Difference for worker 620 is 0.124782
INFO:root:FL Epoch: 243 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :885
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694401
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681200
INFO:root:FL Epoch: 243 Norm Difference for worker 885 is 0.263938
INFO:root:FL Epoch: 243 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1473
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694401
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690052
INFO:root:FL Epoch: 243 Norm Difference for worker 1473 is 0.163141
INFO:root:FL Epoch: 243 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.6930788159370422 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.7036924362182617                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :828
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692153
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700344
INFO:root:FL Epoch: 244 Norm Difference for worker 828 is 0.066813
INFO:root:FL Epoch: 244 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1531
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687957
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695320
INFO:root:FL Epoch: 244 Norm Difference for worker 1531 is 8.7e-05
INFO:root:FL Epoch: 244 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :942
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689006
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695101
INFO:root:FL Epoch: 244 Norm Difference for worker 942 is 0.069536
INFO:root:FL Epoch: 244 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1585
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691104
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685536
INFO:root:FL Epoch: 244 Norm Difference for worker 1585 is 0.084532
INFO:root:FL Epoch: 244 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :214
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 214 is 0.007866
INFO:root:FL Epoch: 244 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1712
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694251
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693282
INFO:root:FL Epoch: 244 Norm Difference for worker 1712 is 0.113242
INFO:root:FL Epoch: 244 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :760
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690055
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693358
INFO:root:FL Epoch: 244 Norm Difference for worker 760 is 0.062081
INFO:root:FL Epoch: 244 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1577
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695300
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693172
INFO:root:FL Epoch: 244 Norm Difference for worker 1577 is 0.011042
INFO:root:FL Epoch: 244 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :161
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691104
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 161 is 0.106449
INFO:root:FL Epoch: 244 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :872
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692153
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693217
INFO:root:FL Epoch: 244 Norm Difference for worker 872 is 0.010065
INFO:root:FL Epoch: 244 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.6930894080330344 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.7001543641090393                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 245 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :42
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 42 is 0.007993
INFO:root:FL Epoch: 245 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 320 is 0.077489
INFO:root:FL Epoch: 245 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1861
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692473
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692418
INFO:root:FL Epoch: 245 Norm Difference for worker 1861 is 0.007785
INFO:root:FL Epoch: 245 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :965
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693870
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696720
INFO:root:FL Epoch: 245 Norm Difference for worker 965 is 0.073246
INFO:root:FL Epoch: 245 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :484
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693172
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686929
INFO:root:FL Epoch: 245 Norm Difference for worker 484 is 0.124386
INFO:root:FL Epoch: 245 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :884
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694568
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693548
INFO:root:FL Epoch: 245 Norm Difference for worker 884 is 0.119747
INFO:root:FL Epoch: 245 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1238
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690378
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695121
INFO:root:FL Epoch: 245 Norm Difference for worker 1238 is 0.010372
INFO:root:FL Epoch: 245 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :214
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 214 is 0.022194
INFO:root:FL Epoch: 245 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1012
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693870
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698776
INFO:root:FL Epoch: 245 Norm Difference for worker 1012 is 0.078308
INFO:root:FL Epoch: 245 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :674
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692473
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698490
INFO:root:FL Epoch: 245 Norm Difference for worker 674 is 0.13812
INFO:root:FL Epoch: 245 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.693151551134446 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.6927780508995056                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :501
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693000
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700769
INFO:root:FL Epoch: 246 Norm Difference for worker 501 is 0.044272
INFO:root:FL Epoch: 246 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1726
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696381
INFO:root:FL Epoch: 246 Norm Difference for worker 1726 is 0.076837
INFO:root:FL Epoch: 246 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1606
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693110
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697319
INFO:root:FL Epoch: 246 Norm Difference for worker 1606 is 0.029636
INFO:root:FL Epoch: 246 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1903
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693110
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694493
INFO:root:FL Epoch: 246 Norm Difference for worker 1903 is 0.066446
INFO:root:FL Epoch: 246 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :59
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693073
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691402
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 59 is 0.178759
INFO:root:FL Epoch: 246 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1152
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693295
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680239
INFO:root:FL Epoch: 246 Norm Difference for worker 1152 is 0.23201
INFO:root:FL Epoch: 246 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :944
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696995
INFO:root:FL Epoch: 246 Norm Difference for worker 944 is 0.083231
INFO:root:FL Epoch: 246 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1138
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693258
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691898
INFO:root:FL Epoch: 246 Norm Difference for worker 1138 is 0.04854
INFO:root:FL Epoch: 246 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :484
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693036
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697949
INFO:root:FL Epoch: 246 Norm Difference for worker 484 is 0.111566
INFO:root:FL Epoch: 246 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1176
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693849
INFO:root:FL Epoch: 246 Norm Difference for worker 1176 is 0.014016
INFO:root:FL Epoch: 246 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.6931313241229338 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.7154817581176758                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1188
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686764
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 247 Norm Difference for worker 1188 is 0.086786
INFO:root:FL Epoch: 247 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1113
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693391
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 247 Norm Difference for worker 1113 is 0.121223
INFO:root:FL Epoch: 247 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1084
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688973
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681980
INFO:root:FL Epoch: 247 Norm Difference for worker 1084 is 0.232212
INFO:root:FL Epoch: 247 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1606
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688973
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700448
INFO:root:FL Epoch: 247 Norm Difference for worker 1606 is 0.025197
INFO:root:FL Epoch: 247 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :769
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695600
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692237
INFO:root:FL Epoch: 247 Norm Difference for worker 769 is 0.093769
INFO:root:FL Epoch: 247 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :829
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688973
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690788
INFO:root:FL Epoch: 247 Norm Difference for worker 829 is 0.025288
INFO:root:FL Epoch: 247 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :116
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 116 is 0.078615
INFO:root:FL Epoch: 247 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :544
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693391
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693524
INFO:root:FL Epoch: 247 Norm Difference for worker 544 is 0.077344
INFO:root:FL Epoch: 247 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1566
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691182
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691381
INFO:root:FL Epoch: 247 Norm Difference for worker 1566 is 0.219762
INFO:root:FL Epoch: 247 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1301
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688973
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690018
INFO:root:FL Epoch: 247 Norm Difference for worker 1301 is 0.000437
INFO:root:FL Epoch: 247 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.6930861999006832 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.7008739113807678                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :36
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 36 is 0.162588
INFO:root:FL Epoch: 248 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1147
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695486
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693377
INFO:root:FL Epoch: 248 Norm Difference for worker 1147 is 0.028587
INFO:root:FL Epoch: 248 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :785
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692407
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693250
INFO:root:FL Epoch: 248 Norm Difference for worker 785 is 0.088348
INFO:root:FL Epoch: 248 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :826
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695486
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 248 Norm Difference for worker 826 is 0.04389
INFO:root:FL Epoch: 248 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :778
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695486
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684970
INFO:root:FL Epoch: 248 Norm Difference for worker 778 is 0.109284
INFO:root:FL Epoch: 248 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :373
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690868
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693925
INFO:root:FL Epoch: 248 Norm Difference for worker 373 is 0.091858
INFO:root:FL Epoch: 248 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1904
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696256
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688302
INFO:root:FL Epoch: 248 Norm Difference for worker 1904 is 0.17832
INFO:root:FL Epoch: 248 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :495
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691637
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698730
INFO:root:FL Epoch: 248 Norm Difference for worker 495 is 0.080514
INFO:root:FL Epoch: 248 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :501
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693946
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689965
INFO:root:FL Epoch: 248 Norm Difference for worker 501 is 0.094541
INFO:root:FL Epoch: 248 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :869
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693177
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693932
INFO:root:FL Epoch: 248 Norm Difference for worker 869 is 0.090265
INFO:root:FL Epoch: 248 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.693111307480756 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.6967488527297974                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :606
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693513
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692667
INFO:root:FL Epoch: 249 Norm Difference for worker 606 is 0.018619
INFO:root:FL Epoch: 249 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1727
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691716
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693349
INFO:root:FL Epoch: 249 Norm Difference for worker 1727 is 0.088972
INFO:root:FL Epoch: 249 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :935
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693873
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692951
INFO:root:FL Epoch: 249 Norm Difference for worker 935 is 0.014807
INFO:root:FL Epoch: 249 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :362
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692794
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693437
INFO:root:FL Epoch: 249 Norm Difference for worker 362 is 0.077706
INFO:root:FL Epoch: 249 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :666
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685293
INFO:root:FL Epoch: 249 Norm Difference for worker 666 is 0.278086
INFO:root:FL Epoch: 249 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :491
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692794
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698629
INFO:root:FL Epoch: 249 Norm Difference for worker 491 is 0.216369
INFO:root:FL Epoch: 249 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :80
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 80 is 0.036064
INFO:root:FL Epoch: 249 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1533
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 249 Norm Difference for worker 1533 is 0.07334
INFO:root:FL Epoch: 249 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :496
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693873
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691697
INFO:root:FL Epoch: 249 Norm Difference for worker 496 is 0.073427
INFO:root:FL Epoch: 249 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :290
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 290 is 0.023407
INFO:root:FL Epoch: 249 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.6930858317543479 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.700985848903656                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 250 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :78
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 78 is 0.083921
INFO:root:FL Epoch: 250 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :296
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 296 is 0.012836
INFO:root:FL Epoch: 250 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1388
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696301
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693158
INFO:root:FL Epoch: 250 Norm Difference for worker 1388 is 0.061603
INFO:root:FL Epoch: 250 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :169
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 169 is 0.052338
INFO:root:FL Epoch: 250 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :351
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695520
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697534
INFO:root:FL Epoch: 250 Norm Difference for worker 351 is 0.008105
INFO:root:FL Epoch: 250 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1200
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693178
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692974
INFO:root:FL Epoch: 250 Norm Difference for worker 1200 is 0.084006
INFO:root:FL Epoch: 250 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1052
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694739
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692623
INFO:root:FL Epoch: 250 Norm Difference for worker 1052 is 0.026251
INFO:root:FL Epoch: 250 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :729
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690835
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690115
INFO:root:FL Epoch: 250 Norm Difference for worker 729 is 0.080279
INFO:root:FL Epoch: 250 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :151
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 151 is 0.020942
INFO:root:FL Epoch: 250 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1317
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693178
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689289
INFO:root:FL Epoch: 250 Norm Difference for worker 1317 is 0.101228
INFO:root:FL Epoch: 250 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.6933165578281179 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.6831194162368774                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690174
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690906
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.6438173055648804 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.6812687814235687 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.081063
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690174
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683070
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.6402721405029297 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.6804921269416809 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.088546
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690174
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680409
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.6417899131774902 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.6808232367038727 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.085339
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :764
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694206
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691130
INFO:root:FL Epoch: 251 Norm Difference for worker 764 is 0.133156
INFO:root:FL Epoch: 251 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1000
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692190
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687677
INFO:root:FL Epoch: 251 Norm Difference for worker 1000 is 0.062368
INFO:root:FL Epoch: 251 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :718
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690174
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690080
INFO:root:FL Epoch: 251 Norm Difference for worker 718 is 0.01829
INFO:root:FL Epoch: 251 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :697
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692190
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682935
INFO:root:FL Epoch: 251 Norm Difference for worker 697 is 0.09701
INFO:root:FL Epoch: 251 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :204
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687657
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 204 is 0.045372
INFO:root:FL Epoch: 251 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1862
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693198
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689265
INFO:root:FL Epoch: 251 Norm Difference for worker 1862 is 0.036775
INFO:root:FL Epoch: 251 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :913
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694206
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690201
INFO:root:FL Epoch: 251 Norm Difference for worker 913 is 0.017384
INFO:root:FL Epoch: 251 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.6939512175672194 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.6635686755180359                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1465
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696601
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694929
INFO:root:FL Epoch: 252 Norm Difference for worker 1465 is 0.136287
INFO:root:FL Epoch: 252 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693598
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689795
INFO:root:FL Epoch: 252 Norm Difference for worker 1481 is 0.002003
INFO:root:FL Epoch: 252 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1390
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699604
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688312
INFO:root:FL Epoch: 252 Norm Difference for worker 1390 is 0.025405
INFO:root:FL Epoch: 252 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1870
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678583
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672922
INFO:root:FL Epoch: 252 Norm Difference for worker 1870 is 0.07925
INFO:root:FL Epoch: 252 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :755
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687592
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690387
INFO:root:FL Epoch: 252 Norm Difference for worker 755 is 0.006273
INFO:root:FL Epoch: 252 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1728
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702607
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693151
INFO:root:FL Epoch: 252 Norm Difference for worker 1728 is 0.026481
INFO:root:FL Epoch: 252 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1074
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693598
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689942
INFO:root:FL Epoch: 252 Norm Difference for worker 1074 is 0.059802
INFO:root:FL Epoch: 252 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681586
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695036
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 0.171871
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1734
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681586
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703665
INFO:root:FL Epoch: 252 Norm Difference for worker 1734 is 0.067799
INFO:root:FL Epoch: 252 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1268
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684589
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690417
INFO:root:FL Epoch: 252 Norm Difference for worker 1268 is 0.031003
INFO:root:FL Epoch: 252 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.6948149414623485 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.6470775008201599                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1274
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694260
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678514
INFO:root:FL Epoch: 253 Norm Difference for worker 1274 is 0.161398
INFO:root:FL Epoch: 253 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1234
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703696
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693241
INFO:root:FL Epoch: 253 Norm Difference for worker 1234 is 0.220382
INFO:root:FL Epoch: 253 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :852
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680105
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690793
INFO:root:FL Epoch: 253 Norm Difference for worker 852 is 0.110615
INFO:root:FL Epoch: 253 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1737
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694260
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683855
INFO:root:FL Epoch: 253 Norm Difference for worker 1737 is 0.023921
INFO:root:FL Epoch: 253 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1163
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698978
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690076
INFO:root:FL Epoch: 253 Norm Difference for worker 1163 is 0.086971
INFO:root:FL Epoch: 253 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :213
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677086
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 213 is 0.035141
INFO:root:FL Epoch: 253 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1350
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689542
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688881
INFO:root:FL Epoch: 253 Norm Difference for worker 1350 is 0.089763
INFO:root:FL Epoch: 253 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :291
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691565
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 291 is 0.279089
INFO:root:FL Epoch: 253 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :800
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694260
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683134
INFO:root:FL Epoch: 253 Norm Difference for worker 800 is 0.011915
INFO:root:FL Epoch: 253 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1016
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689542
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695755
INFO:root:FL Epoch: 253 Norm Difference for worker 1016 is 0.065146
INFO:root:FL Epoch: 253 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.6939193396007314 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.6643165349960327                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 254 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1754
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693575
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696464
INFO:root:FL Epoch: 254 Norm Difference for worker 1754 is 0.182304
INFO:root:FL Epoch: 254 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1163
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690649
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688301
INFO:root:FL Epoch: 254 Norm Difference for worker 1163 is 0.05975
INFO:root:FL Epoch: 254 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :896
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693575
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694084
INFO:root:FL Epoch: 254 Norm Difference for worker 896 is 0.06524
INFO:root:FL Epoch: 254 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :38
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687723
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 38 is 0.121433
INFO:root:FL Epoch: 254 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1431
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696501
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697551
INFO:root:FL Epoch: 254 Norm Difference for worker 1431 is 0.054213
INFO:root:FL Epoch: 254 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :945
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678946
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698063
INFO:root:FL Epoch: 254 Norm Difference for worker 945 is 0.102159
INFO:root:FL Epoch: 254 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1882
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696501
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690340
INFO:root:FL Epoch: 254 Norm Difference for worker 1882 is 0.047975
INFO:root:FL Epoch: 254 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1311
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687723
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689196
INFO:root:FL Epoch: 254 Norm Difference for worker 1311 is 0.058271
INFO:root:FL Epoch: 254 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :721
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690649
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693567
INFO:root:FL Epoch: 254 Norm Difference for worker 721 is 0.011392
INFO:root:FL Epoch: 254 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :844
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699427
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695935
INFO:root:FL Epoch: 254 Norm Difference for worker 844 is 0.080908
INFO:root:FL Epoch: 254 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.693563748808468 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.6739319562911987                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1458
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701097
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691755
INFO:root:FL Epoch: 255 Norm Difference for worker 1458 is 0.022429
INFO:root:FL Epoch: 255 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :415
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697216
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692372
INFO:root:FL Epoch: 255 Norm Difference for worker 415 is 0.01862
INFO:root:FL Epoch: 255 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1593
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701097
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697475
INFO:root:FL Epoch: 255 Norm Difference for worker 1593 is 0.105986
INFO:root:FL Epoch: 255 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1941
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695276
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691285
INFO:root:FL Epoch: 255 Norm Difference for worker 1941 is 0.069785
INFO:root:FL Epoch: 255 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :575
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691395
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688343
INFO:root:FL Epoch: 255 Norm Difference for worker 575 is 0.033599
INFO:root:FL Epoch: 255 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1329
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693335
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693824
INFO:root:FL Epoch: 255 Norm Difference for worker 1329 is 0.124412
INFO:root:FL Epoch: 255 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :88
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 88 is 0.053666
INFO:root:FL Epoch: 255 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1317
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691395
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691401
INFO:root:FL Epoch: 255 Norm Difference for worker 1317 is 0.047337
INFO:root:FL Epoch: 255 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1582
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695276
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 255 Norm Difference for worker 1582 is 0.085648
INFO:root:FL Epoch: 255 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689455
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691315
INFO:root:FL Epoch: 255 Norm Difference for worker 1124 is 0.141731
INFO:root:FL Epoch: 255 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.6932945672203513 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.6841420531272888                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1806
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691379
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691076
INFO:root:FL Epoch: 256 Norm Difference for worker 1806 is 0.063853
INFO:root:FL Epoch: 256 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :864
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690474
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685262
INFO:root:FL Epoch: 256 Norm Difference for worker 864 is 0.139566
INFO:root:FL Epoch: 256 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1226
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694093
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692308
INFO:root:FL Epoch: 256 Norm Difference for worker 1226 is 0.014373
INFO:root:FL Epoch: 256 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :325
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 325 is 0.165589
INFO:root:FL Epoch: 256 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :424
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692284
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692591
INFO:root:FL Epoch: 256 Norm Difference for worker 424 is 0.062513
INFO:root:FL Epoch: 256 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1188
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692284
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690081
INFO:root:FL Epoch: 256 Norm Difference for worker 1188 is 0.042782
INFO:root:FL Epoch: 256 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1760
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689570
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692930
INFO:root:FL Epoch: 256 Norm Difference for worker 1760 is 0.009218
INFO:root:FL Epoch: 256 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :100
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 100 is 0.157607
INFO:root:FL Epoch: 256 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1464
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690474
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691070
INFO:root:FL Epoch: 256 Norm Difference for worker 1464 is 0.083644
INFO:root:FL Epoch: 256 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :887
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694997
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690421
INFO:root:FL Epoch: 256 Norm Difference for worker 887 is 0.147958
INFO:root:FL Epoch: 256 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.6931218750336591 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.6955441832542419                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1443
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682726
INFO:root:FL Epoch: 257 Norm Difference for worker 1443 is 0.177483
INFO:root:FL Epoch: 257 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :3
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699992
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 3 is 0.089743
INFO:root:FL Epoch: 257 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :324
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692911
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 324 is 0.045373
INFO:root:FL Epoch: 257 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :653
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693389
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692649
INFO:root:FL Epoch: 257 Norm Difference for worker 653 is 0.042299
INFO:root:FL Epoch: 257 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :780
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698144
INFO:root:FL Epoch: 257 Norm Difference for worker 780 is 0.11043
INFO:root:FL Epoch: 257 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :610
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694108
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693343
INFO:root:FL Epoch: 257 Norm Difference for worker 610 is 0.091302
INFO:root:FL Epoch: 257 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :309
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 309 is 0.020506
INFO:root:FL Epoch: 257 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :393
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693389
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691440
INFO:root:FL Epoch: 257 Norm Difference for worker 393 is 0.015957
INFO:root:FL Epoch: 257 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1556
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687739
INFO:root:FL Epoch: 257 Norm Difference for worker 1556 is 0.099338
INFO:root:FL Epoch: 257 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :602
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694550
INFO:root:FL Epoch: 257 Norm Difference for worker 602 is 0.062972
INFO:root:FL Epoch: 257 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.6930781252243939 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.7055373787879944                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1162
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691992
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692431
INFO:root:FL Epoch: 258 Norm Difference for worker 1162 is 0.139557
INFO:root:FL Epoch: 258 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1887
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690760
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690447
INFO:root:FL Epoch: 258 Norm Difference for worker 1887 is 0.01839
INFO:root:FL Epoch: 258 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1228
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690760
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693273
INFO:root:FL Epoch: 258 Norm Difference for worker 1228 is 0.083259
INFO:root:FL Epoch: 258 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1028
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696917
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687774
INFO:root:FL Epoch: 258 Norm Difference for worker 1028 is 0.174599
INFO:root:FL Epoch: 258 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1657
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687066
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690623
INFO:root:FL Epoch: 258 Norm Difference for worker 1657 is 0.073936
INFO:root:FL Epoch: 258 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1687
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694454
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691854
INFO:root:FL Epoch: 258 Norm Difference for worker 1687 is 0.133434
INFO:root:FL Epoch: 258 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1086
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695686
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682005
INFO:root:FL Epoch: 258 Norm Difference for worker 1086 is 0.13131
INFO:root:FL Epoch: 258 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :388
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696917
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694286
INFO:root:FL Epoch: 258 Norm Difference for worker 388 is 0.024205
INFO:root:FL Epoch: 258 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :429
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691992
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690993
INFO:root:FL Epoch: 258 Norm Difference for worker 429 is 0.155202
INFO:root:FL Epoch: 258 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :973
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687066
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684333
INFO:root:FL Epoch: 258 Norm Difference for worker 973 is 0.122422
INFO:root:FL Epoch: 258 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.6932339668273926 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.6872690916061401                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 259 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :9
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 9 is 0.040738
INFO:root:FL Epoch: 259 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1195
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692575
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692065
INFO:root:FL Epoch: 259 Norm Difference for worker 1195 is 0.022344
INFO:root:FL Epoch: 259 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :213
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 213 is 0.100755
INFO:root:FL Epoch: 259 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :53
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 53 is 0.052024
INFO:root:FL Epoch: 259 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :147
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 147 is 0.054211
INFO:root:FL Epoch: 259 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1859
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693754
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693604
INFO:root:FL Epoch: 259 Norm Difference for worker 1859 is 0.141387
INFO:root:FL Epoch: 259 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :429
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691985
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689968
INFO:root:FL Epoch: 259 Norm Difference for worker 429 is 0.115687
INFO:root:FL Epoch: 259 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1183
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691985
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678549
INFO:root:FL Epoch: 259 Norm Difference for worker 1183 is 0.162555
INFO:root:FL Epoch: 259 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1225
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690806
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697186
INFO:root:FL Epoch: 259 Norm Difference for worker 1225 is 0.007901
INFO:root:FL Epoch: 259 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1102
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694933
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693951
INFO:root:FL Epoch: 259 Norm Difference for worker 1102 is 0.194958
INFO:root:FL Epoch: 259 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.693748323356404 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.6686040759086609                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1793
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693456
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685319
INFO:root:FL Epoch: 260 Norm Difference for worker 1793 is 0.079869
INFO:root:FL Epoch: 260 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1652
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690971
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694824
INFO:root:FL Epoch: 260 Norm Difference for worker 1652 is 0.070358
INFO:root:FL Epoch: 260 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1184
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683515
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693179
INFO:root:FL Epoch: 260 Norm Difference for worker 1184 is 0.139156
INFO:root:FL Epoch: 260 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1482
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698426
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691429
INFO:root:FL Epoch: 260 Norm Difference for worker 1482 is 0.032465
INFO:root:FL Epoch: 260 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1085
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690971
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697774
INFO:root:FL Epoch: 260 Norm Difference for worker 1085 is 0.049257
INFO:root:FL Epoch: 260 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :257
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695941
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 257 is 0.112334
INFO:root:FL Epoch: 260 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1289
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693456
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693838
INFO:root:FL Epoch: 260 Norm Difference for worker 1289 is 0.111104
INFO:root:FL Epoch: 260 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1365
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700911
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696167
INFO:root:FL Epoch: 260 Norm Difference for worker 1365 is 0.035884
INFO:root:FL Epoch: 260 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :864
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700912
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680707
INFO:root:FL Epoch: 260 Norm Difference for worker 864 is 0.116587
INFO:root:FL Epoch: 260 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1611
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698426
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694280
INFO:root:FL Epoch: 260 Norm Difference for worker 1611 is 0.109869
INFO:root:FL Epoch: 260 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.6931677600916695 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.6915116906166077                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692003
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689283
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.6498693823814392 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.6826194286346435 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.08524
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692985
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685085
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.6467766761779785 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.6819253027439117 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.091723
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692821
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693278
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.650505542755127 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.6827632367610932 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.083909
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :947
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693640
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694827
INFO:root:FL Epoch: 261 Norm Difference for worker 947 is 0.100114
INFO:root:FL Epoch: 261 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1647
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 261 Norm Difference for worker 1647 is 0.088616
INFO:root:FL Epoch: 261 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :422
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693312
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693512
INFO:root:FL Epoch: 261 Norm Difference for worker 422 is 0.116445
INFO:root:FL Epoch: 261 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :127
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694393
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 127 is 0.114179
INFO:root:FL Epoch: 261 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1270
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692657
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684804
INFO:root:FL Epoch: 261 Norm Difference for worker 1270 is 0.096212
INFO:root:FL Epoch: 261 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1475
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692985
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694961
INFO:root:FL Epoch: 261 Norm Difference for worker 1475 is 0.000847
INFO:root:FL Epoch: 261 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1332
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693640
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689915
INFO:root:FL Epoch: 261 Norm Difference for worker 1332 is 0.102185
INFO:root:FL Epoch: 261 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.6933653249460108 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.6810108423233032                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 262 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1712
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696885
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696324
INFO:root:FL Epoch: 262 Norm Difference for worker 1712 is 0.052504
INFO:root:FL Epoch: 262 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :818
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692001
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687172
INFO:root:FL Epoch: 262 Norm Difference for worker 818 is 0.198944
INFO:root:FL Epoch: 262 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :28
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 28 is 0.02589
INFO:root:FL Epoch: 262 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :800
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692001
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676786
INFO:root:FL Epoch: 262 Norm Difference for worker 800 is 0.076774
INFO:root:FL Epoch: 262 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :258
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 258 is 0.006362
INFO:root:FL Epoch: 262 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1584
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688337
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698544
INFO:root:FL Epoch: 262 Norm Difference for worker 1584 is 0.120999
INFO:root:FL Epoch: 262 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1423
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693222
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689400
INFO:root:FL Epoch: 262 Norm Difference for worker 1423 is 0.128699
INFO:root:FL Epoch: 262 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1175
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689558
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691721
INFO:root:FL Epoch: 262 Norm Difference for worker 1175 is 0.149582
INFO:root:FL Epoch: 262 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :625
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692001
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702235
INFO:root:FL Epoch: 262 Norm Difference for worker 625 is 0.184574
INFO:root:FL Epoch: 262 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1520
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695664
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691738
INFO:root:FL Epoch: 262 Norm Difference for worker 1520 is 0.042641
INFO:root:FL Epoch: 262 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.6933281702153823 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.6825982928276062                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :979
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697445
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690826
INFO:root:FL Epoch: 263 Norm Difference for worker 979 is 0.154325
INFO:root:FL Epoch: 263 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1707
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694264
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689931
INFO:root:FL Epoch: 263 Norm Difference for worker 1707 is 0.055986
INFO:root:FL Epoch: 263 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :50
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691082
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689197
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 50 is 0.245011
INFO:root:FL Epoch: 263 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :20
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694354
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 20 is 0.146562
INFO:root:FL Epoch: 263 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :945
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695324
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692603
INFO:root:FL Epoch: 263 Norm Difference for worker 945 is 0.05013
INFO:root:FL Epoch: 263 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :232
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 232 is 0.040475
INFO:root:FL Epoch: 263 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1938
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696385
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695598
INFO:root:FL Epoch: 263 Norm Difference for worker 1938 is 0.040393
INFO:root:FL Epoch: 263 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1500
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692143
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686428
INFO:root:FL Epoch: 263 Norm Difference for worker 1500 is 0.085249
INFO:root:FL Epoch: 263 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :705
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 263 Norm Difference for worker 705 is 0.020937
INFO:root:FL Epoch: 263 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :970
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692143
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692173
INFO:root:FL Epoch: 263 Norm Difference for worker 970 is 0.00115
INFO:root:FL Epoch: 263 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.694118503262015 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.659864604473114                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1333
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686949
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693723
INFO:root:FL Epoch: 264 Norm Difference for worker 1333 is 0.015424
INFO:root:FL Epoch: 264 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1041
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703877
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693617
INFO:root:FL Epoch: 264 Norm Difference for worker 1041 is 0.132083
INFO:root:FL Epoch: 264 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :704
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697106
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690697
INFO:root:FL Epoch: 264 Norm Difference for worker 704 is 0.179721
INFO:root:FL Epoch: 264 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :272
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701722
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 272 is 0.087636
INFO:root:FL Epoch: 264 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1412
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690335
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694809
INFO:root:FL Epoch: 264 Norm Difference for worker 1412 is 0.074644
INFO:root:FL Epoch: 264 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1475
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697106
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697263
INFO:root:FL Epoch: 264 Norm Difference for worker 1475 is 0.038807
INFO:root:FL Epoch: 264 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1352
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703877
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691942
INFO:root:FL Epoch: 264 Norm Difference for worker 1352 is 0.203591
INFO:root:FL Epoch: 264 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1251
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680178
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688316
INFO:root:FL Epoch: 264 Norm Difference for worker 1251 is 0.220355
INFO:root:FL Epoch: 264 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :162
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.715792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 162 is 0.077277
INFO:root:FL Epoch: 264 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :202
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676793
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 202 is 0.171043
INFO:root:FL Epoch: 264 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.6931000492152046 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.7117294669151306                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :1078
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691717
INFO:root:FL Epoch: 265 Norm Difference for worker 1078 is 0.014152
INFO:root:FL Epoch: 265 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :339
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 339 is 0.066105
INFO:root:FL Epoch: 265 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1327
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691478
INFO:root:FL Epoch: 265 Norm Difference for worker 1327 is 0.130129
INFO:root:FL Epoch: 265 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1482
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689634
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690352
INFO:root:FL Epoch: 265 Norm Difference for worker 1482 is 0.003261
INFO:root:FL Epoch: 265 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1713
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698840
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686397
INFO:root:FL Epoch: 265 Norm Difference for worker 1713 is 0.238715
INFO:root:FL Epoch: 265 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1622
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692305
INFO:root:FL Epoch: 265 Norm Difference for worker 1622 is 0.10121
INFO:root:FL Epoch: 265 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1408
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696999
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689250
INFO:root:FL Epoch: 265 Norm Difference for worker 1408 is 0.1403
INFO:root:FL Epoch: 265 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1865
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687793
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696164
INFO:root:FL Epoch: 265 Norm Difference for worker 1865 is 0.016973
INFO:root:FL Epoch: 265 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1421
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696999
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687688
INFO:root:FL Epoch: 265 Norm Difference for worker 1421 is 0.01398
INFO:root:FL Epoch: 265 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :325
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 325 is 0.109971
INFO:root:FL Epoch: 265 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.6933279598460478 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.6826106309890747                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691085
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692688
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 0.107798
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :857
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693443
INFO:root:FL Epoch: 266 Norm Difference for worker 857 is 0.136111
INFO:root:FL Epoch: 266 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :104
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692105
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 104 is 0.097736
INFO:root:FL Epoch: 266 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1713
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691085
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680235
INFO:root:FL Epoch: 266 Norm Difference for worker 1713 is 0.186767
INFO:root:FL Epoch: 266 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1448
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687907
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695816
INFO:root:FL Epoch: 266 Norm Difference for worker 1448 is 0.02627
INFO:root:FL Epoch: 266 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :21
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693203
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 21 is 0.077853
INFO:root:FL Epoch: 266 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :596
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696381
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697865
INFO:root:FL Epoch: 266 Norm Difference for worker 596 is 0.034642
INFO:root:FL Epoch: 266 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :894
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687907
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689068
INFO:root:FL Epoch: 266 Norm Difference for worker 894 is 0.002102
INFO:root:FL Epoch: 266 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1708
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695322
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 266 Norm Difference for worker 1708 is 0.028504
INFO:root:FL Epoch: 266 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1086
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696381
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697307
INFO:root:FL Epoch: 266 Norm Difference for worker 1086 is 0.134657
INFO:root:FL Epoch: 266 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.693165056845721 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.6917144656181335                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692070
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 0.01536
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1281
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688285
INFO:root:FL Epoch: 267 Norm Difference for worker 1281 is 0.106118
INFO:root:FL Epoch: 267 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :462
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694897
INFO:root:FL Epoch: 267 Norm Difference for worker 462 is 0.00941
INFO:root:FL Epoch: 267 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1092
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693435
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693598
INFO:root:FL Epoch: 267 Norm Difference for worker 1092 is 0.004158
INFO:root:FL Epoch: 267 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :606
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692861
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693154
INFO:root:FL Epoch: 267 Norm Difference for worker 606 is 0.020699
INFO:root:FL Epoch: 267 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1605
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693365
INFO:root:FL Epoch: 267 Norm Difference for worker 1605 is 0.006065
INFO:root:FL Epoch: 267 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :925
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693578
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686670
INFO:root:FL Epoch: 267 Norm Difference for worker 925 is 0.125513
INFO:root:FL Epoch: 267 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :434
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690840
INFO:root:FL Epoch: 267 Norm Difference for worker 434 is 0.024018
INFO:root:FL Epoch: 267 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :484
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 267 Norm Difference for worker 484 is 0.080332
INFO:root:FL Epoch: 267 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :348
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691688
INFO:root:FL Epoch: 267 Norm Difference for worker 348 is 0.071594
INFO:root:FL Epoch: 267 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.6930909577537986 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.6998357176780701                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1881
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694503
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693278
INFO:root:FL Epoch: 268 Norm Difference for worker 1881 is 0.099091
INFO:root:FL Epoch: 268 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :711
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692503
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693592
INFO:root:FL Epoch: 268 Norm Difference for worker 711 is 0.013608
INFO:root:FL Epoch: 268 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1677
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693836
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690989
INFO:root:FL Epoch: 268 Norm Difference for worker 1677 is 0.030302
INFO:root:FL Epoch: 268 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :664
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695169
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691783
INFO:root:FL Epoch: 268 Norm Difference for worker 664 is 0.106921
INFO:root:FL Epoch: 268 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :661
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693169
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692102
INFO:root:FL Epoch: 268 Norm Difference for worker 661 is 0.035249
INFO:root:FL Epoch: 268 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1595
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694503
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693315
INFO:root:FL Epoch: 268 Norm Difference for worker 1595 is 0.092097
INFO:root:FL Epoch: 268 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :304
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691170
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 304 is 0.116767
INFO:root:FL Epoch: 268 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1712
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692503
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692836
INFO:root:FL Epoch: 268 Norm Difference for worker 1712 is 0.117102
INFO:root:FL Epoch: 268 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1175
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689170
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689455
INFO:root:FL Epoch: 268 Norm Difference for worker 1175 is 0.089023
INFO:root:FL Epoch: 268 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1844
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695169
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694649
INFO:root:FL Epoch: 268 Norm Difference for worker 1844 is 0.117538
INFO:root:FL Epoch: 268 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.6936128419988296 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.6724256873130798                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1376
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687084
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694885
INFO:root:FL Epoch: 269 Norm Difference for worker 1376 is 0.079155
INFO:root:FL Epoch: 269 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :336
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.660560
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 336 is 0.215544
INFO:root:FL Epoch: 269 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1276
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699818
INFO:root:FL Epoch: 269 Norm Difference for worker 1276 is 0.016835
INFO:root:FL Epoch: 269 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1589
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687084
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696463
INFO:root:FL Epoch: 269 Norm Difference for worker 1589 is 0.003041
INFO:root:FL Epoch: 269 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :673
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690072
INFO:root:FL Epoch: 269 Norm Difference for worker 673 is 0.040746
INFO:root:FL Epoch: 269 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :525
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697051
INFO:root:FL Epoch: 269 Norm Difference for worker 525 is 0.287346
INFO:root:FL Epoch: 269 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :278
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 278 is 0.055592
INFO:root:FL Epoch: 269 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1929
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697555
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693348
INFO:root:FL Epoch: 269 Norm Difference for worker 1929 is 0.045065
INFO:root:FL Epoch: 269 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :883
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684990
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691133
INFO:root:FL Epoch: 269 Norm Difference for worker 883 is 0.210878
INFO:root:FL Epoch: 269 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :602
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693366
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687286
INFO:root:FL Epoch: 269 Norm Difference for worker 602 is 0.021985
INFO:root:FL Epoch: 269 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.6932651575873879 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.6855891942977905                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :642
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696211
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688373
INFO:root:FL Epoch: 270 Norm Difference for worker 642 is 0.229845
INFO:root:FL Epoch: 270 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :292
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 292 is 0.079232
INFO:root:FL Epoch: 270 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1822
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691659
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693232
INFO:root:FL Epoch: 270 Norm Difference for worker 1822 is 0.019694
INFO:root:FL Epoch: 270 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :896
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692417
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686864
INFO:root:FL Epoch: 270 Norm Difference for worker 896 is 0.128923
INFO:root:FL Epoch: 270 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :733
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692417
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691779
INFO:root:FL Epoch: 270 Norm Difference for worker 733 is 0.155526
INFO:root:FL Epoch: 270 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :899
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693176
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691997
INFO:root:FL Epoch: 270 Norm Difference for worker 899 is 0.000288
INFO:root:FL Epoch: 270 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :640
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689383
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692122
INFO:root:FL Epoch: 270 Norm Difference for worker 640 is 0.068711
INFO:root:FL Epoch: 270 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1499
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690900
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685306
INFO:root:FL Epoch: 270 Norm Difference for worker 1499 is 0.07437
INFO:root:FL Epoch: 270 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :203
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 203 is 0.011683
INFO:root:FL Epoch: 270 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :906
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697728
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676656
INFO:root:FL Epoch: 270 Norm Difference for worker 906 is 0.225005
INFO:root:FL Epoch: 270 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.6931274007348454 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.7150953412055969                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706410
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694760
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.6670483350753784 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.6866202890872956 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.096322
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699897
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694013
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.6662465333938599 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.6864281713962554 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.09797
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699897
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695026
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.6644219160079956 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.6859929978847503 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.101725
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1386
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691212
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686966
INFO:root:FL Epoch: 271 Norm Difference for worker 1386 is 0.076804
INFO:root:FL Epoch: 271 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :312
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693273
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 312 is 0.070642
INFO:root:FL Epoch: 271 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :273
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698642
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 273 is 0.007222
INFO:root:FL Epoch: 271 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :324
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 324 is 0.105499
INFO:root:FL Epoch: 271 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :868
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695554
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691898
INFO:root:FL Epoch: 271 Norm Difference for worker 868 is 0.103271
INFO:root:FL Epoch: 271 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :587
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693383
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695886
INFO:root:FL Epoch: 271 Norm Difference for worker 587 is 0.104245
INFO:root:FL Epoch: 271 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1406
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691212
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698787
INFO:root:FL Epoch: 271 Norm Difference for worker 1406 is 0.121263
INFO:root:FL Epoch: 271 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.6934320120250478 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.678411066532135                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1369
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694742
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 272 Norm Difference for worker 1369 is 0.104312
INFO:root:FL Epoch: 272 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1078
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691773
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694338
INFO:root:FL Epoch: 272 Norm Difference for worker 1078 is 0.056336
INFO:root:FL Epoch: 272 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :946
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691773
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690242
INFO:root:FL Epoch: 272 Norm Difference for worker 946 is 0.071068
INFO:root:FL Epoch: 272 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1596
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696227
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692703
INFO:root:FL Epoch: 272 Norm Difference for worker 1596 is 0.014074
INFO:root:FL Epoch: 272 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1754
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691773
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690114
INFO:root:FL Epoch: 272 Norm Difference for worker 1754 is 0.142292
INFO:root:FL Epoch: 272 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1893
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691773
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684520
INFO:root:FL Epoch: 272 Norm Difference for worker 1893 is 0.099711
INFO:root:FL Epoch: 272 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :76
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 76 is 0.079501
INFO:root:FL Epoch: 272 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690216
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 0.044548
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1514
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697711
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695144
INFO:root:FL Epoch: 272 Norm Difference for worker 1514 is 0.004591
INFO:root:FL Epoch: 272 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :134
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690288
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 134 is 0.149277
INFO:root:FL Epoch: 272 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.693236603456385 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.6871148943901062                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1624
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691482
INFO:root:FL Epoch: 273 Norm Difference for worker 1624 is 0.090591
INFO:root:FL Epoch: 273 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1303
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694376
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693922
INFO:root:FL Epoch: 273 Norm Difference for worker 1303 is 0.085249
INFO:root:FL Epoch: 273 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1603
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693771
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694595
INFO:root:FL Epoch: 273 Norm Difference for worker 1603 is 0.040132
INFO:root:FL Epoch: 273 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :789
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694376
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691694
INFO:root:FL Epoch: 273 Norm Difference for worker 789 is 0.101254
INFO:root:FL Epoch: 273 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1461
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687914
INFO:root:FL Epoch: 273 Norm Difference for worker 1461 is 0.15534
INFO:root:FL Epoch: 273 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1439
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694981
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691591
INFO:root:FL Epoch: 273 Norm Difference for worker 1439 is 0.050645
INFO:root:FL Epoch: 273 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :566
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691955
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693558
INFO:root:FL Epoch: 273 Norm Difference for worker 566 is 0.041361
INFO:root:FL Epoch: 273 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :614
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692423
INFO:root:FL Epoch: 273 Norm Difference for worker 614 is 0.01406
INFO:root:FL Epoch: 273 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :747
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693771
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692447
INFO:root:FL Epoch: 273 Norm Difference for worker 747 is 0.035517
INFO:root:FL Epoch: 273 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1857
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688817
INFO:root:FL Epoch: 273 Norm Difference for worker 1857 is 0.08035
INFO:root:FL Epoch: 273 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.6931058343719033 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.712565541267395                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :722
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695255
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693162
INFO:root:FL Epoch: 274 Norm Difference for worker 722 is 0.091921
INFO:root:FL Epoch: 274 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1292
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693332
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691983
INFO:root:FL Epoch: 274 Norm Difference for worker 1292 is 0.012362
INFO:root:FL Epoch: 274 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :200
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691409
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 200 is 0.066808
INFO:root:FL Epoch: 274 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1745
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693332
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692216
INFO:root:FL Epoch: 274 Norm Difference for worker 1745 is 0.094477
INFO:root:FL Epoch: 274 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1317
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693332
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 274 Norm Difference for worker 1317 is 0.100993
INFO:root:FL Epoch: 274 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :888
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693332
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693182
INFO:root:FL Epoch: 274 Norm Difference for worker 888 is 0.01169
INFO:root:FL Epoch: 274 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :600
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697179
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691012
INFO:root:FL Epoch: 274 Norm Difference for worker 600 is 0.250037
INFO:root:FL Epoch: 274 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1582
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693332
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687296
INFO:root:FL Epoch: 274 Norm Difference for worker 1582 is 0.067716
INFO:root:FL Epoch: 274 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :122
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693332
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692375
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 122 is 0.043856
INFO:root:FL Epoch: 274 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1276
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695255
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693190
INFO:root:FL Epoch: 274 Norm Difference for worker 1276 is 0.087586
INFO:root:FL Epoch: 274 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.6932864329394173 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.6845318078994751                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :1037
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695780
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694568
INFO:root:FL Epoch: 275 Norm Difference for worker 1037 is 0.008149
INFO:root:FL Epoch: 275 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1924
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691454
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691648
INFO:root:FL Epoch: 275 Norm Difference for worker 1924 is 0.088425
INFO:root:FL Epoch: 275 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1138
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689723
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685890
INFO:root:FL Epoch: 275 Norm Difference for worker 1138 is 0.035994
INFO:root:FL Epoch: 275 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :939
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691454
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690991
INFO:root:FL Epoch: 275 Norm Difference for worker 939 is 0.073627
INFO:root:FL Epoch: 275 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :622
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692319
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692293
INFO:root:FL Epoch: 275 Norm Difference for worker 622 is 0.101424
INFO:root:FL Epoch: 275 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1818
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690589
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691971
INFO:root:FL Epoch: 275 Norm Difference for worker 1818 is 0.01713
INFO:root:FL Epoch: 275 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :213
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 213 is 0.099935
INFO:root:FL Epoch: 275 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1662
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694050
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693205
INFO:root:FL Epoch: 275 Norm Difference for worker 1662 is 0.017262
INFO:root:FL Epoch: 275 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :829
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693185
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692614
INFO:root:FL Epoch: 275 Norm Difference for worker 829 is 0.054701
INFO:root:FL Epoch: 275 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :968
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691454
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691156
INFO:root:FL Epoch: 275 Norm Difference for worker 968 is 0.018835
INFO:root:FL Epoch: 275 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.6934902142075932 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.6763392090797424                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 276 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :20
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 20 is 0.158297
INFO:root:FL Epoch: 276 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1906
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689900
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690871
INFO:root:FL Epoch: 276 Norm Difference for worker 1906 is 0.002142
INFO:root:FL Epoch: 276 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :168
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686510
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 168 is 0.093485
INFO:root:FL Epoch: 276 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :97
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692887
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 97 is 0.042507
INFO:root:FL Epoch: 276 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :947
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693291
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697217
INFO:root:FL Epoch: 276 Norm Difference for worker 947 is 0.028952
INFO:root:FL Epoch: 276 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :950
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696681
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687178
INFO:root:FL Epoch: 276 Norm Difference for worker 950 is 0.165474
INFO:root:FL Epoch: 276 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1018
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701767
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691680
INFO:root:FL Epoch: 276 Norm Difference for worker 1018 is 0.178372
INFO:root:FL Epoch: 276 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :477
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691596
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693714
INFO:root:FL Epoch: 276 Norm Difference for worker 477 is 0.119438
INFO:root:FL Epoch: 276 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1388
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694986
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689417
INFO:root:FL Epoch: 276 Norm Difference for worker 1388 is 0.03234
INFO:root:FL Epoch: 276 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1776
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689900
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697459
INFO:root:FL Epoch: 276 Norm Difference for worker 1776 is 0.085974
INFO:root:FL Epoch: 276 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.6931752983261558 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.6909628510475159                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :140
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692494
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 140 is 0.009864
INFO:root:FL Epoch: 277 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1142
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693587
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687693
INFO:root:FL Epoch: 277 Norm Difference for worker 1142 is 0.139533
INFO:root:FL Epoch: 277 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :362
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693368
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691283
INFO:root:FL Epoch: 277 Norm Difference for worker 362 is 0.075315
INFO:root:FL Epoch: 277 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :200
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 200 is 0.101065
INFO:root:FL Epoch: 277 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :503
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692494
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693522
INFO:root:FL Epoch: 277 Norm Difference for worker 503 is 0.017458
INFO:root:FL Epoch: 277 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1050
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693806
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694238
INFO:root:FL Epoch: 277 Norm Difference for worker 1050 is 0.008977
INFO:root:FL Epoch: 277 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :405
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692931
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690680
INFO:root:FL Epoch: 277 Norm Difference for worker 405 is 0.101892
INFO:root:FL Epoch: 277 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1577
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692712
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693820
INFO:root:FL Epoch: 277 Norm Difference for worker 1577 is 0.016934
INFO:root:FL Epoch: 277 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1490
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692931
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695651
INFO:root:FL Epoch: 277 Norm Difference for worker 1490 is 0.149462
INFO:root:FL Epoch: 277 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693368
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695241
INFO:root:FL Epoch: 277 Norm Difference for worker 1483 is 0.068677
INFO:root:FL Epoch: 277 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.6931710032855763 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.7188745141029358                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 278 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :103
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 103 is 0.161719
INFO:root:FL Epoch: 278 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :304
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698551
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 304 is 0.153609
INFO:root:FL Epoch: 278 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1032
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701091
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690027
INFO:root:FL Epoch: 278 Norm Difference for worker 1032 is 0.233484
INFO:root:FL Epoch: 278 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :468
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701091
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698060
INFO:root:FL Epoch: 278 Norm Difference for worker 468 is 0.051258
INFO:root:FL Epoch: 278 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1597
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685848
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691465
INFO:root:FL Epoch: 278 Norm Difference for worker 1597 is 0.030227
INFO:root:FL Epoch: 278 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :227
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688389
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694491
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 227 is 0.081772
INFO:root:FL Epoch: 278 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :380
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693470
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693115
INFO:root:FL Epoch: 278 Norm Difference for worker 380 is 0.13814
INFO:root:FL Epoch: 278 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :825
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690929
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694509
INFO:root:FL Epoch: 278 Norm Difference for worker 825 is 0.079865
INFO:root:FL Epoch: 278 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1670
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701091
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690015
INFO:root:FL Epoch: 278 Norm Difference for worker 1670 is 0.0409
INFO:root:FL Epoch: 278 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1007
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688389
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668262
INFO:root:FL Epoch: 278 Norm Difference for worker 1007 is 0.163463
INFO:root:FL Epoch: 278 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.6931829031775979 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.6904308199882507                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1013
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693967
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691150
INFO:root:FL Epoch: 279 Norm Difference for worker 1013 is 0.048348
INFO:root:FL Epoch: 279 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :873
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693423
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689862
INFO:root:FL Epoch: 279 Norm Difference for worker 873 is 0.032344
INFO:root:FL Epoch: 279 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1343
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693423
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693300
INFO:root:FL Epoch: 279 Norm Difference for worker 1343 is 0.138442
INFO:root:FL Epoch: 279 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1746
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694239
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682060
INFO:root:FL Epoch: 279 Norm Difference for worker 1746 is 0.148766
INFO:root:FL Epoch: 279 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :499
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693423
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694717
INFO:root:FL Epoch: 279 Norm Difference for worker 499 is 0.089305
INFO:root:FL Epoch: 279 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1131
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693967
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693622
INFO:root:FL Epoch: 279 Norm Difference for worker 1131 is 0.14477
INFO:root:FL Epoch: 279 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :310
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 310 is 0.03164
INFO:root:FL Epoch: 279 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :223
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 223 is 0.074012
INFO:root:FL Epoch: 279 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1692
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692063
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702078
INFO:root:FL Epoch: 279 Norm Difference for worker 1692 is 0.066856
INFO:root:FL Epoch: 279 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1352
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693695
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696143
INFO:root:FL Epoch: 279 Norm Difference for worker 1352 is 0.148454
INFO:root:FL Epoch: 279 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.6931721182430491 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.718962550163269                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1925
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708766
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693899
INFO:root:FL Epoch: 280 Norm Difference for worker 1925 is 0.14401
INFO:root:FL Epoch: 280 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1145
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693472
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683960
INFO:root:FL Epoch: 280 Norm Difference for worker 1145 is 0.002237
INFO:root:FL Epoch: 280 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :636
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685825
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696275
INFO:root:FL Epoch: 280 Norm Difference for worker 636 is 0.050142
INFO:root:FL Epoch: 280 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1906
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688374
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691783
INFO:root:FL Epoch: 280 Norm Difference for worker 1906 is 0.03746
INFO:root:FL Epoch: 280 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1542
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685825
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690981
INFO:root:FL Epoch: 280 Norm Difference for worker 1542 is 0.018406
INFO:root:FL Epoch: 280 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :348
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698570
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687301
INFO:root:FL Epoch: 280 Norm Difference for worker 348 is 0.032984
INFO:root:FL Epoch: 280 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :704
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693472
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679884
INFO:root:FL Epoch: 280 Norm Difference for worker 704 is 0.10835
INFO:root:FL Epoch: 280 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1809
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685825
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687979
INFO:root:FL Epoch: 280 Norm Difference for worker 1809 is 0.01569
INFO:root:FL Epoch: 280 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1212
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693472
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693564
INFO:root:FL Epoch: 280 Norm Difference for worker 1212 is 0.1696
INFO:root:FL Epoch: 280 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1390
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690923
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693984
INFO:root:FL Epoch: 280 Norm Difference for worker 1390 is 0.103876
INFO:root:FL Epoch: 280 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.6930780901628382 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.7052893042564392                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695634
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691672
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.6607791185379028 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.685132098197937 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.089957
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698048
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692648
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.6609401106834412 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.6851699590682984 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.089625
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696841
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691311
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.6618622541427612 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.6853869318962097 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.087719
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :907
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698048
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693141
INFO:root:FL Epoch: 281 Norm Difference for worker 907 is 0.024684
INFO:root:FL Epoch: 281 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :330
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694427
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693375
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 330 is 0.024516
INFO:root:FL Epoch: 281 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1916
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692013
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693202
INFO:root:FL Epoch: 281 Norm Difference for worker 1916 is 0.090529
INFO:root:FL Epoch: 281 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1435
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689599
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695061
INFO:root:FL Epoch: 281 Norm Difference for worker 1435 is 0.058097
INFO:root:FL Epoch: 281 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1385
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694427
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691357
INFO:root:FL Epoch: 281 Norm Difference for worker 1385 is 0.017174
INFO:root:FL Epoch: 281 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1108
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692013
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694024
INFO:root:FL Epoch: 281 Norm Difference for worker 1108 is 0.107401
INFO:root:FL Epoch: 281 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :449
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689599
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686201
INFO:root:FL Epoch: 281 Norm Difference for worker 449 is 0.032418
INFO:root:FL Epoch: 281 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.6934574667145225 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.6774846315383911                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 282 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :194
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699587
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 194 is 0.176702
INFO:root:FL Epoch: 282 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1670
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691693
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694667
INFO:root:FL Epoch: 282 Norm Difference for worker 1670 is 0.057117
INFO:root:FL Epoch: 282 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :368
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694850
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694867
INFO:root:FL Epoch: 282 Norm Difference for worker 368 is 0.013718
INFO:root:FL Epoch: 282 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1195
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693272
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693714
INFO:root:FL Epoch: 282 Norm Difference for worker 1195 is 0.03338
INFO:root:FL Epoch: 282 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1701
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693272
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693320
INFO:root:FL Epoch: 282 Norm Difference for worker 1701 is 0.029547
INFO:root:FL Epoch: 282 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :24
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690481
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 24 is 0.014704
INFO:root:FL Epoch: 282 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1893
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688536
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680590
INFO:root:FL Epoch: 282 Norm Difference for worker 1893 is 0.101006
INFO:root:FL Epoch: 282 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1109
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698008
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692769
INFO:root:FL Epoch: 282 Norm Difference for worker 1109 is 0.061177
INFO:root:FL Epoch: 282 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1734
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691693
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686564
INFO:root:FL Epoch: 282 Norm Difference for worker 1734 is 0.022912
INFO:root:FL Epoch: 282 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 0.023249
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.6932097357862136 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.6886903047561646                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :177
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 177 is 0.063524
INFO:root:FL Epoch: 283 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :4
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 4 is 0.077336
INFO:root:FL Epoch: 283 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1015
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690924
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690269
INFO:root:FL Epoch: 283 Norm Difference for worker 1015 is 0.151851
INFO:root:FL Epoch: 283 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :346
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686166
INFO:root:FL Epoch: 283 Norm Difference for worker 346 is 0.111112
INFO:root:FL Epoch: 283 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :215
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 215 is 0.049445
INFO:root:FL Epoch: 283 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :938
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692711
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693061
INFO:root:FL Epoch: 283 Norm Difference for worker 938 is 0.001842
INFO:root:FL Epoch: 283 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1805
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691370
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693371
INFO:root:FL Epoch: 283 Norm Difference for worker 1805 is 0.132991
INFO:root:FL Epoch: 283 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :495
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693604
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691051
INFO:root:FL Epoch: 283 Norm Difference for worker 495 is 0.091769
INFO:root:FL Epoch: 283 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :999
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694497
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692543
INFO:root:FL Epoch: 283 Norm Difference for worker 999 is 0.053423
INFO:root:FL Epoch: 283 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1886
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692264
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692950
INFO:root:FL Epoch: 283 Norm Difference for worker 1886 is 0.007763
INFO:root:FL Epoch: 283 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.6931133340386784 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.6965141892433167                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :386
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692817
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693328
INFO:root:FL Epoch: 284 Norm Difference for worker 386 is 0.008419
INFO:root:FL Epoch: 284 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1503
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694161
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687734
INFO:root:FL Epoch: 284 Norm Difference for worker 1503 is 0.07227
INFO:root:FL Epoch: 284 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1701
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694497
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691413
INFO:root:FL Epoch: 284 Norm Difference for worker 1701 is 0.078028
INFO:root:FL Epoch: 284 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :862
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693489
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 284 Norm Difference for worker 862 is 0.054115
INFO:root:FL Epoch: 284 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1169
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692817
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691078
INFO:root:FL Epoch: 284 Norm Difference for worker 1169 is 0.083478
INFO:root:FL Epoch: 284 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :346
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692144
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685633
INFO:root:FL Epoch: 284 Norm Difference for worker 346 is 0.134935
INFO:root:FL Epoch: 284 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693489
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695633
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 0.058341
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1492
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692145
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686669
INFO:root:FL Epoch: 284 Norm Difference for worker 1492 is 0.09138
INFO:root:FL Epoch: 284 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1401
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693489
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688136
INFO:root:FL Epoch: 284 Norm Difference for worker 1401 is 0.070761
INFO:root:FL Epoch: 284 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :424
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693153
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693154
INFO:root:FL Epoch: 284 Norm Difference for worker 424 is 0.022215
INFO:root:FL Epoch: 284 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.693084131268894 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.701450765132904                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :1837
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691527
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687359
INFO:root:FL Epoch: 285 Norm Difference for worker 1837 is 0.068745
INFO:root:FL Epoch: 285 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :824
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692354
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687143
INFO:root:FL Epoch: 285 Norm Difference for worker 824 is 0.160645
INFO:root:FL Epoch: 285 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1007
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692355
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689165
INFO:root:FL Epoch: 285 Norm Difference for worker 1007 is 0.193635
INFO:root:FL Epoch: 285 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :253
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 253 is 0.062848
INFO:root:FL Epoch: 285 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1875
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692355
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704298
INFO:root:FL Epoch: 285 Norm Difference for worker 1875 is 0.22436
INFO:root:FL Epoch: 285 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :985
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694835
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690886
INFO:root:FL Epoch: 285 Norm Difference for worker 985 is 0.072259
INFO:root:FL Epoch: 285 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1657
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694835
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687738
INFO:root:FL Epoch: 285 Norm Difference for worker 1657 is 0.091965
INFO:root:FL Epoch: 285 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :468
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692355
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691765
INFO:root:FL Epoch: 285 Norm Difference for worker 468 is 0.016234
INFO:root:FL Epoch: 285 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1548
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694835
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686330
INFO:root:FL Epoch: 285 Norm Difference for worker 1548 is 0.182285
INFO:root:FL Epoch: 285 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1947
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691527
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692353
INFO:root:FL Epoch: 285 Norm Difference for worker 1947 is 0.056293
INFO:root:FL Epoch: 285 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.693175245733822 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.7191944122314453                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1275
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696049
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692444
INFO:root:FL Epoch: 286 Norm Difference for worker 1275 is 0.179203
INFO:root:FL Epoch: 286 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1599
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690906
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696999
INFO:root:FL Epoch: 286 Norm Difference for worker 1599 is 0.077236
INFO:root:FL Epoch: 286 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :419
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692100
INFO:root:FL Epoch: 286 Norm Difference for worker 419 is 0.101718
INFO:root:FL Epoch: 286 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :900
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693691
INFO:root:FL Epoch: 286 Norm Difference for worker 900 is 0.127259
INFO:root:FL Epoch: 286 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :474
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691310
INFO:root:FL Epoch: 286 Norm Difference for worker 474 is 0.037526
INFO:root:FL Epoch: 286 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :471
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696775
INFO:root:FL Epoch: 286 Norm Difference for worker 471 is 0.017605
INFO:root:FL Epoch: 286 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1727
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698621
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690031
INFO:root:FL Epoch: 286 Norm Difference for worker 1727 is 0.065148
INFO:root:FL Epoch: 286 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :881
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698621
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695966
INFO:root:FL Epoch: 286 Norm Difference for worker 881 is 0.106849
INFO:root:FL Epoch: 286 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :697
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696049
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695018
INFO:root:FL Epoch: 286 Norm Difference for worker 697 is 0.138765
INFO:root:FL Epoch: 286 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :483
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698621
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694749
INFO:root:FL Epoch: 286 Norm Difference for worker 483 is 0.048381
INFO:root:FL Epoch: 286 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.6933369706658756 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.6822149157524109                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1262
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689910
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692939
INFO:root:FL Epoch: 287 Norm Difference for worker 1262 is 0.130898
INFO:root:FL Epoch: 287 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :690
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694307
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693590
INFO:root:FL Epoch: 287 Norm Difference for worker 690 is 0.041113
INFO:root:FL Epoch: 287 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :59
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691009
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697261
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 59 is 0.146247
INFO:root:FL Epoch: 287 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1825
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692108
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689592
INFO:root:FL Epoch: 287 Norm Difference for worker 1825 is 0.176223
INFO:root:FL Epoch: 287 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695406
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 287 Norm Difference for worker 509 is 0.028964
INFO:root:FL Epoch: 287 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :444
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698704
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680924
INFO:root:FL Epoch: 287 Norm Difference for worker 444 is 0.250211
INFO:root:FL Epoch: 287 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :246
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696496
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 246 is 0.008539
INFO:root:FL Epoch: 287 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :841
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692108
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693158
INFO:root:FL Epoch: 287 Norm Difference for worker 841 is 0.102461
INFO:root:FL Epoch: 287 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :417
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688811
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712869
INFO:root:FL Epoch: 287 Norm Difference for worker 417 is 0.05077
INFO:root:FL Epoch: 287 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693208
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691366
INFO:root:FL Epoch: 287 Norm Difference for worker 1509 is 0.052658
INFO:root:FL Epoch: 287 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.6930788685293758 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.7036656737327576                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :893
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693202
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693784
INFO:root:FL Epoch: 288 Norm Difference for worker 893 is 0.00458
INFO:root:FL Epoch: 288 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :133
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 133 is 0.218424
INFO:root:FL Epoch: 288 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :732
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691109
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693240
INFO:root:FL Epoch: 288 Norm Difference for worker 732 is 0.091818
INFO:root:FL Epoch: 288 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689016
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684881
INFO:root:FL Epoch: 288 Norm Difference for worker 912 is 0.126405
INFO:root:FL Epoch: 288 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :831
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696001
INFO:root:FL Epoch: 288 Norm Difference for worker 831 is 0.06584
INFO:root:FL Epoch: 288 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1258
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687384
INFO:root:FL Epoch: 288 Norm Difference for worker 1258 is 0.246623
INFO:root:FL Epoch: 288 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1406
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690063
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689915
INFO:root:FL Epoch: 288 Norm Difference for worker 1406 is 0.122629
INFO:root:FL Epoch: 288 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :510
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694248
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 288 Norm Difference for worker 510 is 0.067425
INFO:root:FL Epoch: 288 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :75
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 75 is 0.148616
INFO:root:FL Epoch: 288 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1065
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689016
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689793
INFO:root:FL Epoch: 288 Norm Difference for worker 1065 is 0.004246
INFO:root:FL Epoch: 288 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.6934745662352618 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.676884651184082                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :444
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699840
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682054
INFO:root:FL Epoch: 289 Norm Difference for worker 444 is 0.243919
INFO:root:FL Epoch: 289 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1645
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691642
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686220
INFO:root:FL Epoch: 289 Norm Difference for worker 1645 is 0.148627
INFO:root:FL Epoch: 289 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :199
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 199 is 0.120228
INFO:root:FL Epoch: 289 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :500
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698201
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693941
INFO:root:FL Epoch: 289 Norm Difference for worker 500 is 0.069558
INFO:root:FL Epoch: 289 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :917
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693282
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692538
INFO:root:FL Epoch: 289 Norm Difference for worker 917 is 0.119248
INFO:root:FL Epoch: 289 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1421
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690002
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694542
INFO:root:FL Epoch: 289 Norm Difference for worker 1421 is 0.019793
INFO:root:FL Epoch: 289 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1485
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688363
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685840
INFO:root:FL Epoch: 289 Norm Difference for worker 1485 is 0.081692
INFO:root:FL Epoch: 289 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :306
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 306 is 0.070171
INFO:root:FL Epoch: 289 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :638
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699840
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693197
INFO:root:FL Epoch: 289 Norm Difference for worker 638 is 0.03493
INFO:root:FL Epoch: 289 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1471
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691642
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693348
INFO:root:FL Epoch: 289 Norm Difference for worker 1471 is 0.108693
INFO:root:FL Epoch: 289 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.6932365929379183 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.6871157288551331                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1328
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697332
INFO:root:FL Epoch: 290 Norm Difference for worker 1328 is 0.040895
INFO:root:FL Epoch: 290 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :498
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692560
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695553
INFO:root:FL Epoch: 290 Norm Difference for worker 498 is 0.022331
INFO:root:FL Epoch: 290 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1566
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685458
INFO:root:FL Epoch: 290 Norm Difference for worker 1566 is 0.170761
INFO:root:FL Epoch: 290 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1908
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694375
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690865
INFO:root:FL Epoch: 290 Norm Difference for worker 1908 is 0.087217
INFO:root:FL Epoch: 290 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1688
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691351
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704037
INFO:root:FL Epoch: 290 Norm Difference for worker 1688 is 0.179358
INFO:root:FL Epoch: 290 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :885
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694375
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684930
INFO:root:FL Epoch: 290 Norm Difference for worker 885 is 0.220193
INFO:root:FL Epoch: 290 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :907
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689536
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683345
INFO:root:FL Epoch: 290 Norm Difference for worker 907 is 0.020646
INFO:root:FL Epoch: 290 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1256
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693165
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690977
INFO:root:FL Epoch: 290 Norm Difference for worker 1256 is 0.074391
INFO:root:FL Epoch: 290 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1058
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693770
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693946
INFO:root:FL Epoch: 290 Norm Difference for worker 1058 is 0.050445
INFO:root:FL Epoch: 290 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1876
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690746
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697700
INFO:root:FL Epoch: 290 Norm Difference for worker 1876 is 0.120851
INFO:root:FL Epoch: 290 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.6938820902039023 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.6652083396911621                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679379
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689921
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.6327857971191406 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.6788883626461029 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.067921
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685047
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689810
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.6295803189277649 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.6782169282436371 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.07477
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685047
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693938
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.6306990385055542 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.6784502625465393 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.072377
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1366
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690715
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689555
INFO:root:FL Epoch: 291 Norm Difference for worker 1366 is 0.047277
INFO:root:FL Epoch: 291 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1025
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699217
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699881
INFO:root:FL Epoch: 291 Norm Difference for worker 1025 is 0.001293
INFO:root:FL Epoch: 291 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1801
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696383
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693965
INFO:root:FL Epoch: 291 Norm Difference for worker 1801 is 0.06511
INFO:root:FL Epoch: 291 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1023
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693549
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686210
INFO:root:FL Epoch: 291 Norm Difference for worker 1023 is 0.099764
INFO:root:FL Epoch: 291 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :476
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693549
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691878
INFO:root:FL Epoch: 291 Norm Difference for worker 476 is 0.09486
INFO:root:FL Epoch: 291 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682213
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699595
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 0.061804
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1114
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690715
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688625
INFO:root:FL Epoch: 291 Norm Difference for worker 1114 is 0.052109
INFO:root:FL Epoch: 291 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.694137362872853 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.6594652533531189                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1472
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683454
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682318
INFO:root:FL Epoch: 292 Norm Difference for worker 1472 is 0.067016
INFO:root:FL Epoch: 292 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1744
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693734
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695875
INFO:root:FL Epoch: 292 Norm Difference for worker 1744 is 0.086999
INFO:root:FL Epoch: 292 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :373
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693734
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709936
INFO:root:FL Epoch: 292 Norm Difference for worker 373 is 0.004957
INFO:root:FL Epoch: 292 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1755
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683454
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693922
INFO:root:FL Epoch: 292 Norm Difference for worker 1755 is 0.007443
INFO:root:FL Epoch: 292 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1251
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707442
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693267
INFO:root:FL Epoch: 292 Norm Difference for worker 1251 is 0.240912
INFO:root:FL Epoch: 292 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :364
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690307
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690486
INFO:root:FL Epoch: 292 Norm Difference for worker 364 is 0.0113
INFO:root:FL Epoch: 292 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :894
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690307
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701569
INFO:root:FL Epoch: 292 Norm Difference for worker 894 is 0.088377
INFO:root:FL Epoch: 292 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1005
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697161
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693611
INFO:root:FL Epoch: 292 Norm Difference for worker 1005 is 0.008443
INFO:root:FL Epoch: 292 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :388
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693734
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703888
INFO:root:FL Epoch: 292 Norm Difference for worker 388 is 0.033833
INFO:root:FL Epoch: 292 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1242
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693734
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693957
INFO:root:FL Epoch: 292 Norm Difference for worker 1242 is 0.026037
INFO:root:FL Epoch: 292 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.6934473795049331 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.6778470277786255                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1224
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690182
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693725
INFO:root:FL Epoch: 293 Norm Difference for worker 1224 is 0.104372
INFO:root:FL Epoch: 293 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :983
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699434
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693669
INFO:root:FL Epoch: 293 Norm Difference for worker 983 is 0.060452
INFO:root:FL Epoch: 293 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1414
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699434
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695314
INFO:root:FL Epoch: 293 Norm Difference for worker 1414 is 0.110832
INFO:root:FL Epoch: 293 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1763
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688640
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 293 Norm Difference for worker 1763 is 0.038766
INFO:root:FL Epoch: 293 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :305
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 305 is 0.096901
INFO:root:FL Epoch: 293 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :650
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694808
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693407
INFO:root:FL Epoch: 293 Norm Difference for worker 650 is 0.086982
INFO:root:FL Epoch: 293 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1660
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687098
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692760
INFO:root:FL Epoch: 293 Norm Difference for worker 1660 is 0.060425
INFO:root:FL Epoch: 293 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1700
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699434
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692286
INFO:root:FL Epoch: 293 Norm Difference for worker 1700 is 0.023308
INFO:root:FL Epoch: 293 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1483
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688640
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690877
INFO:root:FL Epoch: 293 Norm Difference for worker 1483 is 0.061921
INFO:root:FL Epoch: 293 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :860
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666777
INFO:root:FL Epoch: 293 Norm Difference for worker 860 is 0.124641
INFO:root:FL Epoch: 293 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.6941027150434607 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.6602005362510681                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :318
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 318 is 0.108783
INFO:root:FL Epoch: 294 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1700
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680305
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687423
INFO:root:FL Epoch: 294 Norm Difference for worker 1700 is 0.000403
INFO:root:FL Epoch: 294 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :951
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690358
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684942
INFO:root:FL Epoch: 294 Norm Difference for worker 951 is 0.049405
INFO:root:FL Epoch: 294 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1022
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697059
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690233
INFO:root:FL Epoch: 294 Norm Difference for worker 1022 is 0.245346
INFO:root:FL Epoch: 294 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1087
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693708
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695408
INFO:root:FL Epoch: 294 Norm Difference for worker 1087 is 0.1546
INFO:root:FL Epoch: 294 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :931
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687007
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697017
INFO:root:FL Epoch: 294 Norm Difference for worker 931 is 0.004779
INFO:root:FL Epoch: 294 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :653
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693709
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686949
INFO:root:FL Epoch: 294 Norm Difference for worker 653 is 0.040092
INFO:root:FL Epoch: 294 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :272
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697059
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 272 is 0.104999
INFO:root:FL Epoch: 294 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1459
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697059
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690325
INFO:root:FL Epoch: 294 Norm Difference for worker 1459 is 0.003936
INFO:root:FL Epoch: 294 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1399
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697059
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694340
INFO:root:FL Epoch: 294 Norm Difference for worker 1399 is 0.159879
INFO:root:FL Epoch: 294 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.6931387992466197 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.6938862204551697                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :675
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693680
INFO:root:FL Epoch: 295 Norm Difference for worker 675 is 0.006703
INFO:root:FL Epoch: 295 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1942
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 295 Norm Difference for worker 1942 is 0.004588
INFO:root:FL Epoch: 295 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1406
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686282
INFO:root:FL Epoch: 295 Norm Difference for worker 1406 is 0.127367
INFO:root:FL Epoch: 295 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1321
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692926
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679883
INFO:root:FL Epoch: 295 Norm Difference for worker 1321 is 0.159315
INFO:root:FL Epoch: 295 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :443
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693074
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683247
INFO:root:FL Epoch: 295 Norm Difference for worker 443 is 0.161266
INFO:root:FL Epoch: 295 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :427
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693527
INFO:root:FL Epoch: 295 Norm Difference for worker 427 is 0.015706
INFO:root:FL Epoch: 295 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1883
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692926
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692371
INFO:root:FL Epoch: 295 Norm Difference for worker 1883 is 0.056038
INFO:root:FL Epoch: 295 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :918
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700218
INFO:root:FL Epoch: 295 Norm Difference for worker 918 is 0.062542
INFO:root:FL Epoch: 295 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :638
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693074
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693699
INFO:root:FL Epoch: 295 Norm Difference for worker 638 is 0.04517
INFO:root:FL Epoch: 295 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1630
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693074
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684554
INFO:root:FL Epoch: 295 Norm Difference for worker 1630 is 0.115699
INFO:root:FL Epoch: 295 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.693156782318564 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.692358136177063                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1480
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693305
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700719
INFO:root:FL Epoch: 296 Norm Difference for worker 1480 is 0.105859
INFO:root:FL Epoch: 296 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :79
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693069
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 79 is 0.048493
INFO:root:FL Epoch: 296 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1343
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693226
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692201
INFO:root:FL Epoch: 296 Norm Difference for worker 1343 is 0.110043
INFO:root:FL Epoch: 296 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1312
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693069
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692572
INFO:root:FL Epoch: 296 Norm Difference for worker 1312 is 0.040302
INFO:root:FL Epoch: 296 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :198
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693384
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 198 is 0.05375
INFO:root:FL Epoch: 296 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693226
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697603
INFO:root:FL Epoch: 296 Norm Difference for worker 1941 is 0.038921
INFO:root:FL Epoch: 296 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :975
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692911
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690495
INFO:root:FL Epoch: 296 Norm Difference for worker 975 is 0.056656
INFO:root:FL Epoch: 296 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :496
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693305
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693275
INFO:root:FL Epoch: 296 Norm Difference for worker 496 is 0.042846
INFO:root:FL Epoch: 296 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692990
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691565
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 0.109868
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1032
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693305
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694231
INFO:root:FL Epoch: 296 Norm Difference for worker 1032 is 0.184875
INFO:root:FL Epoch: 296 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.6931619363672593 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.6919517517089844                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :1570
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693387
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 297 Norm Difference for worker 1570 is 0.011252
INFO:root:FL Epoch: 297 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1715
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692669
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691818
INFO:root:FL Epoch: 297 Norm Difference for worker 1715 is 0.016688
INFO:root:FL Epoch: 297 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694634
INFO:root:FL Epoch: 297 Norm Difference for worker 1205 is 0.151005
INFO:root:FL Epoch: 297 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1159
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693507
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692383
INFO:root:FL Epoch: 297 Norm Difference for worker 1159 is 0.033613
INFO:root:FL Epoch: 297 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1186
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693267
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688121
INFO:root:FL Epoch: 297 Norm Difference for worker 1186 is 0.044389
INFO:root:FL Epoch: 297 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :734
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693028
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695893
INFO:root:FL Epoch: 297 Norm Difference for worker 734 is 0.090316
INFO:root:FL Epoch: 297 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1461
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693267
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688879
INFO:root:FL Epoch: 297 Norm Difference for worker 1461 is 0.132349
INFO:root:FL Epoch: 297 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :100
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 100 is 0.125545
INFO:root:FL Epoch: 297 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :989
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693387
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691824
INFO:root:FL Epoch: 297 Norm Difference for worker 989 is 0.001744
INFO:root:FL Epoch: 297 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1614
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693267
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696011
INFO:root:FL Epoch: 297 Norm Difference for worker 1614 is 0.025488
INFO:root:FL Epoch: 297 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.6930927669300753 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.6994858384132385                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :535
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693585
INFO:root:FL Epoch: 298 Norm Difference for worker 535 is 0.013817
INFO:root:FL Epoch: 298 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :268
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695063
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 268 is 0.097982
INFO:root:FL Epoch: 298 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :968
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693107
INFO:root:FL Epoch: 298 Norm Difference for worker 968 is 0.0092
INFO:root:FL Epoch: 298 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :728
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693799
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693267
INFO:root:FL Epoch: 298 Norm Difference for worker 728 is 0.111883
INFO:root:FL Epoch: 298 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :188
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 188 is 0.045814
INFO:root:FL Epoch: 298 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1851
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693799
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693510
INFO:root:FL Epoch: 298 Norm Difference for worker 1851 is 0.066899
INFO:root:FL Epoch: 298 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1892
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694431
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697048
INFO:root:FL Epoch: 298 Norm Difference for worker 1892 is 0.004095
INFO:root:FL Epoch: 298 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :580
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691271
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703855
INFO:root:FL Epoch: 298 Norm Difference for worker 580 is 0.134985
INFO:root:FL Epoch: 298 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1226
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690640
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695049
INFO:root:FL Epoch: 298 Norm Difference for worker 1226 is 0.00843
INFO:root:FL Epoch: 298 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1003
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693770
INFO:root:FL Epoch: 298 Norm Difference for worker 1003 is 0.007191
INFO:root:FL Epoch: 298 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.6931997362305137 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.6893129348754883                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1318
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692770
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688561
INFO:root:FL Epoch: 299 Norm Difference for worker 1318 is 0.127788
INFO:root:FL Epoch: 299 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694691
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695000
INFO:root:FL Epoch: 299 Norm Difference for worker 1648 is 0.04235
INFO:root:FL Epoch: 299 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :781
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694307
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698210
INFO:root:FL Epoch: 299 Norm Difference for worker 781 is 0.113158
INFO:root:FL Epoch: 299 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1817
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692386
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693159
INFO:root:FL Epoch: 299 Norm Difference for worker 1817 is 0.035421
INFO:root:FL Epoch: 299 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692386
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693882
INFO:root:FL Epoch: 299 Norm Difference for worker 648 is 0.061073
INFO:root:FL Epoch: 299 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :144
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 144 is 0.038359
INFO:root:FL Epoch: 299 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1139
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675618
INFO:root:FL Epoch: 299 Norm Difference for worker 1139 is 0.152766
INFO:root:FL Epoch: 299 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1156
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692770
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692350
INFO:root:FL Epoch: 299 Norm Difference for worker 1156 is 0.08475
INFO:root:FL Epoch: 299 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :598
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700623
INFO:root:FL Epoch: 299 Norm Difference for worker 598 is 0.128735
INFO:root:FL Epoch: 299 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :650
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693923
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690870
INFO:root:FL Epoch: 299 Norm Difference for worker 650 is 0.109302
INFO:root:FL Epoch: 299 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.6931791831465328 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.6906872391700745                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1467
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692658
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687363
INFO:root:FL Epoch: 300 Norm Difference for worker 1467 is 0.15054
INFO:root:FL Epoch: 300 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1937
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692904
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686060
INFO:root:FL Epoch: 300 Norm Difference for worker 1937 is 0.097393
INFO:root:FL Epoch: 300 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1312
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693397
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692571
INFO:root:FL Epoch: 300 Norm Difference for worker 1312 is 0.054172
INFO:root:FL Epoch: 300 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1780
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693397
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690619
INFO:root:FL Epoch: 300 Norm Difference for worker 1780 is 0.105811
INFO:root:FL Epoch: 300 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :228
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693643
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 228 is 0.118518
INFO:root:FL Epoch: 300 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :852
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694382
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690351
INFO:root:FL Epoch: 300 Norm Difference for worker 852 is 0.056679
INFO:root:FL Epoch: 300 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :941
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692165
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695895
INFO:root:FL Epoch: 300 Norm Difference for worker 941 is 0.10606
INFO:root:FL Epoch: 300 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1896
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693396
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698521
INFO:root:FL Epoch: 300 Norm Difference for worker 1896 is 0.107646
INFO:root:FL Epoch: 300 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :414
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692411
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682048
INFO:root:FL Epoch: 300 Norm Difference for worker 414 is 0.104444
INFO:root:FL Epoch: 300 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1088
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693167
INFO:root:FL Epoch: 300 Norm Difference for worker 1088 is 0.054206
INFO:root:FL Epoch: 300 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.6932501442292157 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.6863770484924316                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 1443, 486, 588, 551, 1025, 195, 320]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689774
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689520
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.6493030786514282 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.6824917376041413 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.076113
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691812
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687427
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.6486287713050842 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.6823399662971497 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.077525
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693850
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701467
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.6529868841171265 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.6833273053169251 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.068415
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1443
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694529
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690671
INFO:root:FL Epoch: 301 Norm Difference for worker 1443 is 0.164479
INFO:root:FL Epoch: 301 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :486
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690453
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695138
INFO:root:FL Epoch: 301 Norm Difference for worker 486 is 0.004245
INFO:root:FL Epoch: 301 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :588
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693850
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692521
INFO:root:FL Epoch: 301 Norm Difference for worker 588 is 0.008952
INFO:root:FL Epoch: 301 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :551
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690453
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693267
INFO:root:FL Epoch: 301 Norm Difference for worker 551 is 0.028584
INFO:root:FL Epoch: 301 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1025
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693170
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689539
INFO:root:FL Epoch: 301 Norm Difference for worker 1025 is 0.058713
INFO:root:FL Epoch: 301 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :195
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688415
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 195 is 0.202132
INFO:root:FL Epoch: 301 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :320
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693170
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 320 is 0.08781
INFO:root:FL Epoch: 301 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.6935545977424172 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.6742205619812012                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [905, 877, 1238, 1840, 1610, 287, 910, 204, 609, 1756]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :905
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683775
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679088
INFO:root:FL Epoch: 302 Norm Difference for worker 905 is 0.111993
INFO:root:FL Epoch: 302 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :877
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695241
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695923
INFO:root:FL Epoch: 302 Norm Difference for worker 877 is 0.111217
INFO:root:FL Epoch: 302 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1238
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695241
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693457
INFO:root:FL Epoch: 302 Norm Difference for worker 1238 is 0.038547
INFO:root:FL Epoch: 302 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1840
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697152
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692278
INFO:root:FL Epoch: 302 Norm Difference for worker 1840 is 0.196991
INFO:root:FL Epoch: 302 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1610
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691419
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696887
INFO:root:FL Epoch: 302 Norm Difference for worker 1610 is 0.082316
INFO:root:FL Epoch: 302 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :287
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 287 is 0.243464
INFO:root:FL Epoch: 302 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :910
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689508
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693302
INFO:root:FL Epoch: 302 Norm Difference for worker 910 is 0.057379
INFO:root:FL Epoch: 302 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :204
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 204 is 0.00746
INFO:root:FL Epoch: 302 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :609
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689508
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689988
INFO:root:FL Epoch: 302 Norm Difference for worker 609 is 0.069043
INFO:root:FL Epoch: 302 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1756
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695241
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694821
INFO:root:FL Epoch: 302 Norm Difference for worker 1756 is 0.017817
INFO:root:FL Epoch: 302 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.6930821608094608 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.7020702362060547                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1753, 1756, 1355, 139, 584, 1564, 174, 1418, 1113, 648]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1753
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693669
INFO:root:FL Epoch: 303 Norm Difference for worker 1753 is 0.060483
INFO:root:FL Epoch: 303 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1756
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694075
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693201
INFO:root:FL Epoch: 303 Norm Difference for worker 1756 is 0.058621
INFO:root:FL Epoch: 303 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1355
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694075
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694600
INFO:root:FL Epoch: 303 Norm Difference for worker 1355 is 0.062103
INFO:root:FL Epoch: 303 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :139
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 139 is 0.050131
INFO:root:FL Epoch: 303 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :584
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694075
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692239
INFO:root:FL Epoch: 303 Norm Difference for worker 584 is 0.10901
INFO:root:FL Epoch: 303 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1564
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694075
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692613
INFO:root:FL Epoch: 303 Norm Difference for worker 1564 is 0.04113
INFO:root:FL Epoch: 303 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :174
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690456
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 174 is 0.122995
INFO:root:FL Epoch: 303 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1418
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690522
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690678
INFO:root:FL Epoch: 303 Norm Difference for worker 1418 is 0.091204
INFO:root:FL Epoch: 303 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1113
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692298
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693290
INFO:root:FL Epoch: 303 Norm Difference for worker 1113 is 0.131694
INFO:root:FL Epoch: 303 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :648
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693116
INFO:root:FL Epoch: 303 Norm Difference for worker 648 is 0.019855
INFO:root:FL Epoch: 303 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.6932585309533512 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.6859355568885803                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [315, 691, 657, 599, 1341, 285, 1303, 1544, 468, 755]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 304 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :315
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 315 is 0.003907
INFO:root:FL Epoch: 304 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :691
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692450
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693435
INFO:root:FL Epoch: 304 Norm Difference for worker 691 is 0.086961
INFO:root:FL Epoch: 304 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :657
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693173
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696852
INFO:root:FL Epoch: 304 Norm Difference for worker 657 is 0.030829
INFO:root:FL Epoch: 304 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :599
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694621
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694386
INFO:root:FL Epoch: 304 Norm Difference for worker 599 is 0.052629
INFO:root:FL Epoch: 304 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1341
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693897
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688346
INFO:root:FL Epoch: 304 Norm Difference for worker 1341 is 0.119936
INFO:root:FL Epoch: 304 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :285
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 285 is 0.045677
INFO:root:FL Epoch: 304 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1303
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692450
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693894
INFO:root:FL Epoch: 304 Norm Difference for worker 1303 is 0.066152
INFO:root:FL Epoch: 304 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1544
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693173
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689761
INFO:root:FL Epoch: 304 Norm Difference for worker 1544 is 0.078394
INFO:root:FL Epoch: 304 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :468
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692450
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695610
INFO:root:FL Epoch: 304 Norm Difference for worker 468 is 0.017688
INFO:root:FL Epoch: 304 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :755
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690278
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697910
INFO:root:FL Epoch: 304 Norm Difference for worker 755 is 0.051208
INFO:root:FL Epoch: 304 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.6937612400335424 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.6682615876197815                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [28, 1394, 832, 101, 1000, 1708, 385, 352, 1307, 941]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 305 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :28
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701026
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 28 is 0.039239
INFO:root:FL Epoch: 305 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1394
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693465
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681985
INFO:root:FL Epoch: 305 Norm Difference for worker 1394 is 0.012734
INFO:root:FL Epoch: 305 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :832
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693465
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 305 Norm Difference for worker 832 is 0.142509
INFO:root:FL Epoch: 305 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :101
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694448
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 101 is 0.114173
INFO:root:FL Epoch: 305 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1000
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693510
INFO:root:FL Epoch: 305 Norm Difference for worker 1000 is 0.044412
INFO:root:FL Epoch: 305 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1708
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695985
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695782
INFO:root:FL Epoch: 305 Norm Difference for worker 1708 is 0.060071
INFO:root:FL Epoch: 305 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :385
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695985
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700782
INFO:root:FL Epoch: 305 Norm Difference for worker 385 is 0.051529
INFO:root:FL Epoch: 305 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :352
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690938
INFO:root:FL Epoch: 305 Norm Difference for worker 352 is 0.051892
INFO:root:FL Epoch: 305 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1307
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691029
INFO:root:FL Epoch: 305 Norm Difference for worker 1307 is 0.161712
INFO:root:FL Epoch: 305 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :941
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693465
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686688
INFO:root:FL Epoch: 305 Norm Difference for worker 941 is 0.065722
INFO:root:FL Epoch: 305 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.6933542244574603 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.6814762353897095                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [1489, 606, 1775, 681, 834, 643, 1374, 711, 1459, 538]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 306 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :1489
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696738
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694874
INFO:root:FL Epoch: 306 Norm Difference for worker 1489 is 0.033378
INFO:root:FL Epoch: 306 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :606
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688520
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691602
INFO:root:FL Epoch: 306 Norm Difference for worker 606 is 0.008261
INFO:root:FL Epoch: 306 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1775
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688520
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694643
INFO:root:FL Epoch: 306 Norm Difference for worker 1775 is 0.224346
INFO:root:FL Epoch: 306 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :681
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689694
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692957
INFO:root:FL Epoch: 306 Norm Difference for worker 681 is 0.095563
INFO:root:FL Epoch: 306 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :834
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690868
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692245
INFO:root:FL Epoch: 306 Norm Difference for worker 834 is 0.155334
INFO:root:FL Epoch: 306 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :643
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692042
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699978
INFO:root:FL Epoch: 306 Norm Difference for worker 643 is 0.065731
INFO:root:FL Epoch: 306 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1374
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690868
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692664
INFO:root:FL Epoch: 306 Norm Difference for worker 1374 is 0.01863
INFO:root:FL Epoch: 306 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :711
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697912
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692539
INFO:root:FL Epoch: 306 Norm Difference for worker 711 is 0.044958
INFO:root:FL Epoch: 306 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1459
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690868
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690927
INFO:root:FL Epoch: 306 Norm Difference for worker 1459 is 0.066259
INFO:root:FL Epoch: 306 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :538
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692042
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695071
INFO:root:FL Epoch: 306 Norm Difference for worker 538 is 0.037034
INFO:root:FL Epoch: 306 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.6934899898136363 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.6763505935668945                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [906, 614, 1894, 1327, 596, 1690, 1186, 1923, 510, 784]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :906
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694985
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682896
INFO:root:FL Epoch: 307 Norm Difference for worker 906 is 0.227682
INFO:root:FL Epoch: 307 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :614
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686515
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693312
INFO:root:FL Epoch: 307 Norm Difference for worker 614 is 0.028013
INFO:root:FL Epoch: 307 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1894
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693291
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693959
INFO:root:FL Epoch: 307 Norm Difference for worker 1894 is 0.074482
INFO:root:FL Epoch: 307 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1327
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689903
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698930
INFO:root:FL Epoch: 307 Norm Difference for worker 1327 is 0.050945
INFO:root:FL Epoch: 307 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :596
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691597
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691290
INFO:root:FL Epoch: 307 Norm Difference for worker 596 is 0.046374
INFO:root:FL Epoch: 307 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1690
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691597
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693904
INFO:root:FL Epoch: 307 Norm Difference for worker 1690 is 0.042923
INFO:root:FL Epoch: 307 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1186
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693291
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693063
INFO:root:FL Epoch: 307 Norm Difference for worker 1186 is 0.066357
INFO:root:FL Epoch: 307 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1923
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693291
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689746
INFO:root:FL Epoch: 307 Norm Difference for worker 1923 is 0.011295
INFO:root:FL Epoch: 307 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :510
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694985
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687211
INFO:root:FL Epoch: 307 Norm Difference for worker 510 is 0.046392
INFO:root:FL Epoch: 307 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :784
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694985
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698848
INFO:root:FL Epoch: 307 Norm Difference for worker 784 is 0.019877
INFO:root:FL Epoch: 307 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.6931367236025193 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.6940736174583435                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [1266, 207, 1584, 252, 1605, 1486, 1617, 525, 1340, 1914]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 308 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :1266
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692308
INFO:root:FL Epoch: 308 Norm Difference for worker 1266 is 0.058971
INFO:root:FL Epoch: 308 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :207
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 207 is 0.018642
INFO:root:FL Epoch: 308 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1584
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693240
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683636
INFO:root:FL Epoch: 308 Norm Difference for worker 1584 is 0.156832
INFO:root:FL Epoch: 308 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :252
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 252 is 0.048883
INFO:root:FL Epoch: 308 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1605
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692870
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693016
INFO:root:FL Epoch: 308 Norm Difference for worker 1605 is 0.028346
INFO:root:FL Epoch: 308 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1486
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692962
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688779
INFO:root:FL Epoch: 308 Norm Difference for worker 1486 is 0.111653
INFO:root:FL Epoch: 308 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1617
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692962
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693199
INFO:root:FL Epoch: 308 Norm Difference for worker 1617 is 0.041338
INFO:root:FL Epoch: 308 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :525
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694547
INFO:root:FL Epoch: 308 Norm Difference for worker 525 is 0.233193
INFO:root:FL Epoch: 308 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1340
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693055
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691948
INFO:root:FL Epoch: 308 Norm Difference for worker 1340 is 0.036627
INFO:root:FL Epoch: 308 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1914
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692962
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692845
INFO:root:FL Epoch: 308 Norm Difference for worker 1914 is 0.03231
INFO:root:FL Epoch: 308 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.6932413613095003 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.6868595480918884                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [21, 1041, 1494, 370, 1006, 19, 1204, 583, 1772, 502]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 309 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :21
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690644
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 21 is 0.095471
INFO:root:FL Epoch: 309 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1041
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692536
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694258
INFO:root:FL Epoch: 309 Norm Difference for worker 1041 is 0.103487
INFO:root:FL Epoch: 309 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1494
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692704
INFO:root:FL Epoch: 309 Norm Difference for worker 1494 is 0.078133
INFO:root:FL Epoch: 309 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :370
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692536
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695503
INFO:root:FL Epoch: 309 Norm Difference for worker 370 is 0.061402
INFO:root:FL Epoch: 309 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1006
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693798
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686362
INFO:root:FL Epoch: 309 Norm Difference for worker 1006 is 0.116545
INFO:root:FL Epoch: 309 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :19
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 19 is 0.009974
INFO:root:FL Epoch: 309 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1204
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685254
INFO:root:FL Epoch: 309 Norm Difference for worker 1204 is 0.202776
INFO:root:FL Epoch: 309 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :583
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693160
INFO:root:FL Epoch: 309 Norm Difference for worker 583 is 0.018949
INFO:root:FL Epoch: 309 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1772
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693798
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695181
INFO:root:FL Epoch: 309 Norm Difference for worker 1772 is 0.120692
INFO:root:FL Epoch: 309 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :502
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692096
INFO:root:FL Epoch: 309 Norm Difference for worker 502 is 0.06096
INFO:root:FL Epoch: 309 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.6930781006813049 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.7045464515686035                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [167, 201, 537, 1676, 1913, 909, 1534, 585, 658, 1332]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 310 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :167
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693211
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 167 is 0.122294
INFO:root:FL Epoch: 310 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :201
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 201 is 0.077626
INFO:root:FL Epoch: 310 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :537
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696612
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692901
INFO:root:FL Epoch: 310 Norm Difference for worker 537 is 0.078887
INFO:root:FL Epoch: 310 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1676
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691239
INFO:root:FL Epoch: 310 Norm Difference for worker 1676 is 0.167422
INFO:root:FL Epoch: 310 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1913
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686410
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686741
INFO:root:FL Epoch: 310 Norm Difference for worker 1913 is 0.102445
INFO:root:FL Epoch: 310 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :909
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689811
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681975
INFO:root:FL Epoch: 310 Norm Difference for worker 909 is 0.062049
INFO:root:FL Epoch: 310 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1534
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697745
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685363
INFO:root:FL Epoch: 310 Norm Difference for worker 1534 is 0.281902
INFO:root:FL Epoch: 310 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :585
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693211
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692520
INFO:root:FL Epoch: 310 Norm Difference for worker 585 is 0.015013
INFO:root:FL Epoch: 310 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :658
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697745
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693567
INFO:root:FL Epoch: 310 Norm Difference for worker 658 is 0.03712
INFO:root:FL Epoch: 310 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1332
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688065
INFO:root:FL Epoch: 310 Norm Difference for worker 1332 is 0.061714
INFO:root:FL Epoch: 310 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.6932852022788104 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.6845875978469849                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 1910, 621, 208, 1255, 860, 680, 1770]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686782
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.6450988054275513 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.6815520823001862 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.081329
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696623
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695434
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.6473112106323242 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.6820446372032165 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.076681
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690605
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695593
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.6472901701927185 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.6820399522781372 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.076726
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1910
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690605
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704882
INFO:root:FL Epoch: 311 Norm Difference for worker 1910 is 0.08091
INFO:root:FL Epoch: 311 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :621
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687167
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693794
INFO:root:FL Epoch: 311 Norm Difference for worker 621 is 0.044482
INFO:root:FL Epoch: 311 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :208
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696022
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 208 is 0.02588
INFO:root:FL Epoch: 311 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1255
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692324
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669655
INFO:root:FL Epoch: 311 Norm Difference for worker 1255 is 0.176877
INFO:root:FL Epoch: 311 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :860
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691465
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681476
INFO:root:FL Epoch: 311 Norm Difference for worker 860 is 0.174726
INFO:root:FL Epoch: 311 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :680
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689746
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699077
INFO:root:FL Epoch: 311 Norm Difference for worker 680 is 0.101804
INFO:root:FL Epoch: 311 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1770
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695763
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692406
INFO:root:FL Epoch: 311 Norm Difference for worker 1770 is 0.016981
INFO:root:FL Epoch: 311 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.6950723388615776 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.6430663466453552                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [682, 445, 1687, 664, 651, 289, 709, 742, 1093, 800]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :682
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689328
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676720
INFO:root:FL Epoch: 312 Norm Difference for worker 682 is 0.112205
INFO:root:FL Epoch: 312 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :445
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689327
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682130
INFO:root:FL Epoch: 312 Norm Difference for worker 445 is 0.004907
INFO:root:FL Epoch: 312 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1687
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689327
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701206
INFO:root:FL Epoch: 312 Norm Difference for worker 1687 is 0.019947
INFO:root:FL Epoch: 312 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :664
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709888
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694157
INFO:root:FL Epoch: 312 Norm Difference for worker 664 is 0.037519
INFO:root:FL Epoch: 312 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :651
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668767
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727140
INFO:root:FL Epoch: 312 Norm Difference for worker 651 is 0.037436
INFO:root:FL Epoch: 312 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :289
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690301
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 289 is 0.07236
INFO:root:FL Epoch: 312 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :709
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679047
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707263
INFO:root:FL Epoch: 312 Norm Difference for worker 709 is 0.029209
INFO:root:FL Epoch: 312 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :742
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684187
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703375
INFO:root:FL Epoch: 312 Norm Difference for worker 742 is 0.102846
INFO:root:FL Epoch: 312 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1093
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694468
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694123
INFO:root:FL Epoch: 312 Norm Difference for worker 1093 is 0.054536
INFO:root:FL Epoch: 312 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :800
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689328
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689948
INFO:root:FL Epoch: 312 Norm Difference for worker 800 is 0.012801
INFO:root:FL Epoch: 312 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.6946418285369873 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.6499565243721008                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [1508, 834, 1190, 29, 1700, 246, 1120, 1788, 578, 729]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :1508
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698539
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701293
INFO:root:FL Epoch: 313 Norm Difference for worker 1508 is 0.039723
INFO:root:FL Epoch: 313 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :834
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716205
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693832
INFO:root:FL Epoch: 313 Norm Difference for worker 834 is 0.179947
INFO:root:FL Epoch: 313 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1190
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672039
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688807
INFO:root:FL Epoch: 313 Norm Difference for worker 1190 is 0.136123
INFO:root:FL Epoch: 313 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :29
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694122
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707109
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 29 is 0.078238
INFO:root:FL Epoch: 313 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1700
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694122
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697763
INFO:root:FL Epoch: 313 Norm Difference for worker 1700 is 0.008069
INFO:root:FL Epoch: 313 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :246
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 246 is 0.058718
INFO:root:FL Epoch: 313 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1120
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698539
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706605
INFO:root:FL Epoch: 313 Norm Difference for worker 1120 is 0.064498
INFO:root:FL Epoch: 313 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1788
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685289
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693962
INFO:root:FL Epoch: 313 Norm Difference for worker 1788 is 0.067148
INFO:root:FL Epoch: 313 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :578
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711788
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695633
INFO:root:FL Epoch: 313 Norm Difference for worker 578 is 0.23324
INFO:root:FL Epoch: 313 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :729
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689706
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689751
INFO:root:FL Epoch: 313 Norm Difference for worker 729 is 0.007894
INFO:root:FL Epoch: 313 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.693412233801449 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.6791526079177856                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [1599, 1102, 743, 1678, 1810, 800, 1839, 750, 1145, 1449]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :1599
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701703
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693158
INFO:root:FL Epoch: 314 Norm Difference for worker 1599 is 0.002825
INFO:root:FL Epoch: 314 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1102
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691837
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679997
INFO:root:FL Epoch: 314 Norm Difference for worker 1102 is 0.145915
INFO:root:FL Epoch: 314 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :743
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693246
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683117
INFO:root:FL Epoch: 314 Norm Difference for worker 743 is 0.010302
INFO:root:FL Epoch: 314 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1678
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697475
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 314 Norm Difference for worker 1678 is 0.021788
INFO:root:FL Epoch: 314 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1810
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693246
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688909
INFO:root:FL Epoch: 314 Norm Difference for worker 1810 is 0.208108
INFO:root:FL Epoch: 314 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :800
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690428
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688714
INFO:root:FL Epoch: 314 Norm Difference for worker 800 is 0.062101
INFO:root:FL Epoch: 314 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1839
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689018
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693830
INFO:root:FL Epoch: 314 Norm Difference for worker 1839 is 0.079532
INFO:root:FL Epoch: 314 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :750
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689018
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686381
INFO:root:FL Epoch: 314 Norm Difference for worker 750 is 0.109463
INFO:root:FL Epoch: 314 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1145
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694656
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695059
INFO:root:FL Epoch: 314 Norm Difference for worker 1145 is 0.052663
INFO:root:FL Epoch: 314 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1449
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693246
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693387
INFO:root:FL Epoch: 314 Norm Difference for worker 1449 is 0.053488
INFO:root:FL Epoch: 314 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.6933053766979891 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.683630108833313                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [984, 720, 1397, 1394, 1003, 1673, 1271, 1114, 1740, 185]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 315 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :984
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685735
INFO:root:FL Epoch: 315 Norm Difference for worker 984 is 0.064815
INFO:root:FL Epoch: 315 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :720
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692237
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693157
INFO:root:FL Epoch: 315 Norm Difference for worker 720 is 0.039728
INFO:root:FL Epoch: 315 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1397
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695105
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679170
INFO:root:FL Epoch: 315 Norm Difference for worker 1397 is 0.236992
INFO:root:FL Epoch: 315 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1394
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693193
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695411
INFO:root:FL Epoch: 315 Norm Difference for worker 1394 is 0.016224
INFO:root:FL Epoch: 315 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1003
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692237
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691340
INFO:root:FL Epoch: 315 Norm Difference for worker 1003 is 0.021306
INFO:root:FL Epoch: 315 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1673
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695105
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689031
INFO:root:FL Epoch: 315 Norm Difference for worker 1673 is 0.020205
INFO:root:FL Epoch: 315 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1271
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692237
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692506
INFO:root:FL Epoch: 315 Norm Difference for worker 1271 is 0.052224
INFO:root:FL Epoch: 315 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1114
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694149
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695330
INFO:root:FL Epoch: 315 Norm Difference for worker 1114 is 0.021104
INFO:root:FL Epoch: 315 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1740
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692237
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696120
INFO:root:FL Epoch: 315 Norm Difference for worker 1740 is 0.061457
INFO:root:FL Epoch: 315 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :185
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 185 is 0.037404
INFO:root:FL Epoch: 315 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.6931401876842275 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.6937550902366638                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [1324, 1278, 397, 409, 691, 951, 145, 665, 1649, 1550]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :1324
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693087
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691486
INFO:root:FL Epoch: 316 Norm Difference for worker 1324 is 0.122752
INFO:root:FL Epoch: 316 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1278
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693208
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696497
INFO:root:FL Epoch: 316 Norm Difference for worker 1278 is 0.025737
INFO:root:FL Epoch: 316 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :397
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693390
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693070
INFO:root:FL Epoch: 316 Norm Difference for worker 397 is 0.057638
INFO:root:FL Epoch: 316 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :409
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688306
INFO:root:FL Epoch: 316 Norm Difference for worker 409 is 0.146302
INFO:root:FL Epoch: 316 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :691
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693330
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688538
INFO:root:FL Epoch: 316 Norm Difference for worker 691 is 0.126391
INFO:root:FL Epoch: 316 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :951
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698427
INFO:root:FL Epoch: 316 Norm Difference for worker 951 is 0.072009
INFO:root:FL Epoch: 316 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :145
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693026
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687730
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 145 is 0.148257
INFO:root:FL Epoch: 316 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :665
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693087
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692671
INFO:root:FL Epoch: 316 Norm Difference for worker 665 is 0.027105
INFO:root:FL Epoch: 316 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1649
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692965
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690549
INFO:root:FL Epoch: 316 Norm Difference for worker 1649 is 0.074374
INFO:root:FL Epoch: 316 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1550
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693451
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692211
INFO:root:FL Epoch: 316 Norm Difference for worker 1550 is 0.044564
INFO:root:FL Epoch: 316 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.6932846412939184 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.684618353843689                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [596, 425, 327, 614, 1586, 1405, 196, 226, 526, 243]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :596
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692327
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694912
INFO:root:FL Epoch: 317 Norm Difference for worker 596 is 0.045891
INFO:root:FL Epoch: 317 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :425
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694040
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669597
INFO:root:FL Epoch: 317 Norm Difference for worker 425 is 0.191619
INFO:root:FL Epoch: 317 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :327
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695644
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 327 is 0.048545
INFO:root:FL Epoch: 317 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :614
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695753
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693983
INFO:root:FL Epoch: 317 Norm Difference for worker 614 is 0.031642
INFO:root:FL Epoch: 317 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1586
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692404
INFO:root:FL Epoch: 317 Norm Difference for worker 1586 is 0.076396
INFO:root:FL Epoch: 317 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1405
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701233
INFO:root:FL Epoch: 317 Norm Difference for worker 1405 is 0.095782
INFO:root:FL Epoch: 317 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :196
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694897
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 196 is 0.000332
INFO:root:FL Epoch: 317 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :226
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 226 is 0.078947
INFO:root:FL Epoch: 317 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :526
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694532
INFO:root:FL Epoch: 317 Norm Difference for worker 526 is 0.041482
INFO:root:FL Epoch: 317 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :243
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 243 is 0.008916
INFO:root:FL Epoch: 317 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.6934244632720947 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.6786923408508301                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [253, 748, 1265, 1438, 1466, 1310, 171, 1495, 820, 920]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :253
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 253 is 0.04833
INFO:root:FL Epoch: 318 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :748
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693253
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689374
INFO:root:FL Epoch: 318 Norm Difference for worker 748 is 0.001115
INFO:root:FL Epoch: 318 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1265
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697621
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 318 Norm Difference for worker 1265 is 0.061367
INFO:root:FL Epoch: 318 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1438
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691797
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693288
INFO:root:FL Epoch: 318 Norm Difference for worker 1438 is 0.037006
INFO:root:FL Epoch: 318 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1466
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696165
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696246
INFO:root:FL Epoch: 318 Norm Difference for worker 1466 is 0.069545
INFO:root:FL Epoch: 318 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1310
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693253
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693676
INFO:root:FL Epoch: 318 Norm Difference for worker 1310 is 0.08733
INFO:root:FL Epoch: 318 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :171
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 171 is 0.131843
INFO:root:FL Epoch: 318 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1495
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697621
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691787
INFO:root:FL Epoch: 318 Norm Difference for worker 1495 is 0.102658
INFO:root:FL Epoch: 318 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :820
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687429
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692964
INFO:root:FL Epoch: 318 Norm Difference for worker 820 is 0.061645
INFO:root:FL Epoch: 318 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :920
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697621
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693172
INFO:root:FL Epoch: 318 Norm Difference for worker 920 is 0.056353
INFO:root:FL Epoch: 318 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.6933265328407288 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.6826685667037964                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1365, 504, 564, 1732, 1905, 1719, 1514, 629, 929, 1382]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1365
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690042
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692314
INFO:root:FL Epoch: 319 Norm Difference for worker 1365 is 0.018256
INFO:root:FL Epoch: 319 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :504
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688989
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701327
INFO:root:FL Epoch: 319 Norm Difference for worker 504 is 0.082854
INFO:root:FL Epoch: 319 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :564
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694256
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694538
INFO:root:FL Epoch: 319 Norm Difference for worker 564 is 0.0656
INFO:root:FL Epoch: 319 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1732
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698573
INFO:root:FL Epoch: 319 Norm Difference for worker 1732 is 0.012993
INFO:root:FL Epoch: 319 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1905
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693326
INFO:root:FL Epoch: 319 Norm Difference for worker 1905 is 0.034179
INFO:root:FL Epoch: 319 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1719
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692149
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696921
INFO:root:FL Epoch: 319 Norm Difference for worker 1719 is 0.03546
INFO:root:FL Epoch: 319 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1514
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691096
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693611
INFO:root:FL Epoch: 319 Norm Difference for worker 1514 is 0.017141
INFO:root:FL Epoch: 319 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :629
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700492
INFO:root:FL Epoch: 319 Norm Difference for worker 629 is 0.032191
INFO:root:FL Epoch: 319 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :929
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691096
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683765
INFO:root:FL Epoch: 319 Norm Difference for worker 929 is 0.072381
INFO:root:FL Epoch: 319 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1382
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694256
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692132
INFO:root:FL Epoch: 319 Norm Difference for worker 1382 is 0.037162
INFO:root:FL Epoch: 319 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.6933228478712194 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.6828367114067078                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [64, 124, 326, 1653, 535, 1504, 1731, 1934, 1210, 1637]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 320 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :64
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 64 is 0.016425
INFO:root:FL Epoch: 320 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :124
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695274
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693806
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 124 is 0.14656
INFO:root:FL Epoch: 320 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :326
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 326 is 0.018873
INFO:root:FL Epoch: 320 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1653
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695274
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687874
INFO:root:FL Epoch: 320 Norm Difference for worker 1653 is 0.17857
INFO:root:FL Epoch: 320 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :535
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694237
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692801
INFO:root:FL Epoch: 320 Norm Difference for worker 535 is 0.033673
INFO:root:FL Epoch: 320 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1504
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693201
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710742
INFO:root:FL Epoch: 320 Norm Difference for worker 1504 is 0.079466
INFO:root:FL Epoch: 320 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1731
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688019
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693581
INFO:root:FL Epoch: 320 Norm Difference for worker 1731 is 0.056791
INFO:root:FL Epoch: 320 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1934
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693201
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697688
INFO:root:FL Epoch: 320 Norm Difference for worker 1934 is 0.003335
INFO:root:FL Epoch: 320 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1210
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695274
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698121
INFO:root:FL Epoch: 320 Norm Difference for worker 1210 is 0.230974
INFO:root:FL Epoch: 320 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1637
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694237
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693953
INFO:root:FL Epoch: 320 Norm Difference for worker 1637 is 0.026702
INFO:root:FL Epoch: 320 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.693103271372178 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.6978126168251038                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 1219, 1730, 471, 792, 1830, 1466, 619]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694089
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692409
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.6580187082290649 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.6844870090484619 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.080845
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695951
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687276
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.6552669405937195 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.683850222826004 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.086562
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694089
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690214
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.656194806098938 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.6840642690658569 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.084632
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1219
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692693
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697460
INFO:root:FL Epoch: 321 Norm Difference for worker 1219 is 0.175199
INFO:root:FL Epoch: 321 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1730
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693623
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693221
INFO:root:FL Epoch: 321 Norm Difference for worker 1730 is 0.034882
INFO:root:FL Epoch: 321 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :471
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691762
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696525
INFO:root:FL Epoch: 321 Norm Difference for worker 471 is 0.056323
INFO:root:FL Epoch: 321 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :792
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694089
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697282
INFO:root:FL Epoch: 321 Norm Difference for worker 792 is 0.11049
INFO:root:FL Epoch: 321 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1830
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691762
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693246
INFO:root:FL Epoch: 321 Norm Difference for worker 1830 is 0.012933
INFO:root:FL Epoch: 321 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1466
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695020
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705913
INFO:root:FL Epoch: 321 Norm Difference for worker 1466 is 0.063684
INFO:root:FL Epoch: 321 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :619
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693624
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695696
INFO:root:FL Epoch: 321 Norm Difference for worker 619 is 0.022753
INFO:root:FL Epoch: 321 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.6931027945350198 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.6978744864463806                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [832, 612, 600, 982, 1725, 1224, 539, 3, 1510, 673]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :832
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690800
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690911
INFO:root:FL Epoch: 322 Norm Difference for worker 832 is 0.079688
INFO:root:FL Epoch: 322 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :612
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694101
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701893
INFO:root:FL Epoch: 322 Norm Difference for worker 612 is 0.135024
INFO:root:FL Epoch: 322 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :600
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696460
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677230
INFO:root:FL Epoch: 322 Norm Difference for worker 600 is 0.208129
INFO:root:FL Epoch: 322 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :982
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691743
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695242
INFO:root:FL Epoch: 322 Norm Difference for worker 982 is 0.077522
INFO:root:FL Epoch: 322 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1725
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695343
INFO:root:FL Epoch: 322 Norm Difference for worker 1725 is 0.026338
INFO:root:FL Epoch: 322 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1224
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695593
INFO:root:FL Epoch: 322 Norm Difference for worker 1224 is 0.068457
INFO:root:FL Epoch: 322 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :539
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692687
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694571
INFO:root:FL Epoch: 322 Norm Difference for worker 539 is 0.033263
INFO:root:FL Epoch: 322 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :3
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690472
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 3 is 0.069761
INFO:root:FL Epoch: 322 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1510
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692687
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696089
INFO:root:FL Epoch: 322 Norm Difference for worker 1510 is 0.062722
INFO:root:FL Epoch: 322 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :673
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694102
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692829
INFO:root:FL Epoch: 322 Norm Difference for worker 673 is 0.053857
INFO:root:FL Epoch: 322 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.6932781303630156 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.6849337220191956                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [888, 344, 814, 1493, 639, 1448, 256, 461, 1908, 337]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :888
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690707
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698761
INFO:root:FL Epoch: 323 Norm Difference for worker 888 is 0.045078
INFO:root:FL Epoch: 323 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :344
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694831
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691249
INFO:root:FL Epoch: 323 Norm Difference for worker 344 is 0.040526
INFO:root:FL Epoch: 323 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :814
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691532
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694849
INFO:root:FL Epoch: 323 Norm Difference for worker 814 is 0.016792
INFO:root:FL Epoch: 323 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1493
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693181
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691759
INFO:root:FL Epoch: 323 Norm Difference for worker 1493 is 0.106357
INFO:root:FL Epoch: 323 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :639
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696480
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693464
INFO:root:FL Epoch: 323 Norm Difference for worker 639 is 0.110257
INFO:root:FL Epoch: 323 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1448
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692356
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 323 Norm Difference for worker 1448 is 0.017691
INFO:root:FL Epoch: 323 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :256
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 256 is 0.177044
INFO:root:FL Epoch: 323 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :461
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694006
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693347
INFO:root:FL Epoch: 323 Norm Difference for worker 461 is 0.108955
INFO:root:FL Epoch: 323 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1908
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694831
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693181
INFO:root:FL Epoch: 323 Norm Difference for worker 1908 is 0.097842
INFO:root:FL Epoch: 323 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :337
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685973
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 337 is 0.161372
INFO:root:FL Epoch: 323 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.6930807934087866 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.7025647163391113                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1471, 1574, 1571, 563, 1944, 1599, 1205, 843, 1897, 1775]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1471
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694128
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687891
INFO:root:FL Epoch: 324 Norm Difference for worker 1471 is 0.06278
INFO:root:FL Epoch: 324 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1574
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693191
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693302
INFO:root:FL Epoch: 324 Norm Difference for worker 1574 is 0.036171
INFO:root:FL Epoch: 324 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1571
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696941
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684736
INFO:root:FL Epoch: 324 Norm Difference for worker 1571 is 0.0928
INFO:root:FL Epoch: 324 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :563
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693191
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693173
INFO:root:FL Epoch: 324 Norm Difference for worker 563 is 0.132833
INFO:root:FL Epoch: 324 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1944
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695066
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690581
INFO:root:FL Epoch: 324 Norm Difference for worker 1944 is 0.203698
INFO:root:FL Epoch: 324 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1599
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692254
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693429
INFO:root:FL Epoch: 324 Norm Difference for worker 1599 is 0.024354
INFO:root:FL Epoch: 324 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1205
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696941
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689765
INFO:root:FL Epoch: 324 Norm Difference for worker 1205 is 0.162081
INFO:root:FL Epoch: 324 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :843
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695066
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693693
INFO:root:FL Epoch: 324 Norm Difference for worker 843 is 0.008745
INFO:root:FL Epoch: 324 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1897
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693191
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695405
INFO:root:FL Epoch: 324 Norm Difference for worker 1897 is 0.049711
INFO:root:FL Epoch: 324 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1775
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693191
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690587
INFO:root:FL Epoch: 324 Norm Difference for worker 1775 is 0.232492
INFO:root:FL Epoch: 324 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.6941541783949908 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.6591152548789978                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [1096, 570, 779, 298, 1125, 1322, 856, 1417, 826, 661]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :1096
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704136
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693608
INFO:root:FL Epoch: 325 Norm Difference for worker 1096 is 0.03687
INFO:root:FL Epoch: 325 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :570
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697210
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689324
INFO:root:FL Epoch: 325 Norm Difference for worker 570 is 0.088494
INFO:root:FL Epoch: 325 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :779
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697210
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693359
INFO:root:FL Epoch: 325 Norm Difference for worker 779 is 0.18035
INFO:root:FL Epoch: 325 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :298
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692968
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 298 is 0.157644
INFO:root:FL Epoch: 325 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1125
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690284
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702446
INFO:root:FL Epoch: 325 Norm Difference for worker 1125 is 0.014818
INFO:root:FL Epoch: 325 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1322
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693747
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690131
INFO:root:FL Epoch: 325 Norm Difference for worker 1322 is 0.047961
INFO:root:FL Epoch: 325 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :856
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693747
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662242
INFO:root:FL Epoch: 325 Norm Difference for worker 856 is 0.105386
INFO:root:FL Epoch: 325 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1417
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686820
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700063
INFO:root:FL Epoch: 325 Norm Difference for worker 1417 is 0.040535
INFO:root:FL Epoch: 325 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :826
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700673
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705042
INFO:root:FL Epoch: 325 Norm Difference for worker 826 is 0.032964
INFO:root:FL Epoch: 325 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :661
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686820
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697480
INFO:root:FL Epoch: 325 Norm Difference for worker 661 is 0.006373
INFO:root:FL Epoch: 325 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.6935335608089671 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.6748981475830078                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [354, 951, 1777, 867, 1140, 1467, 525, 13, 1011, 386]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :354
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693685
INFO:root:FL Epoch: 326 Norm Difference for worker 354 is 0.110392
INFO:root:FL Epoch: 326 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :951
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712704
INFO:root:FL Epoch: 326 Norm Difference for worker 951 is 0.073933
INFO:root:FL Epoch: 326 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1777
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687791
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698661
INFO:root:FL Epoch: 326 Norm Difference for worker 1777 is 0.051357
INFO:root:FL Epoch: 326 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :867
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687791
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693065
INFO:root:FL Epoch: 326 Norm Difference for worker 867 is 0.0703
INFO:root:FL Epoch: 326 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1140
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691475
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692151
INFO:root:FL Epoch: 326 Norm Difference for worker 1140 is 0.159054
INFO:root:FL Epoch: 326 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1467
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689633
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693413
INFO:root:FL Epoch: 326 Norm Difference for worker 1467 is 0.147641
INFO:root:FL Epoch: 326 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :525
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702526
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690019
INFO:root:FL Epoch: 326 Norm Difference for worker 525 is 0.258949
INFO:root:FL Epoch: 326 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :13
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 13 is 0.166253
INFO:root:FL Epoch: 326 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1011
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697001
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696262
INFO:root:FL Epoch: 326 Norm Difference for worker 1011 is 0.11205
INFO:root:FL Epoch: 326 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :386
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693977
INFO:root:FL Epoch: 326 Norm Difference for worker 386 is 0.044706
INFO:root:FL Epoch: 326 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.6931381471016828 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.7161412835121155                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [394, 43, 1946, 202, 357, 879, 365, 105, 548, 1176]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 327 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :394
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691132
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686344
INFO:root:FL Epoch: 327 Norm Difference for worker 394 is 0.094453
INFO:root:FL Epoch: 327 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :43
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 43 is 0.012951
INFO:root:FL Epoch: 327 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1946
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695679
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693635
INFO:root:FL Epoch: 327 Norm Difference for worker 1946 is 0.129212
INFO:root:FL Epoch: 327 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :202
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693406
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 202 is 0.039256
INFO:root:FL Epoch: 327 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :357
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695679
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703487
INFO:root:FL Epoch: 327 Norm Difference for worker 357 is 0.002653
INFO:root:FL Epoch: 327 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :879
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700226
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693644
INFO:root:FL Epoch: 327 Norm Difference for worker 879 is 0.125627
INFO:root:FL Epoch: 327 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :365
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688859
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682716
INFO:root:FL Epoch: 327 Norm Difference for worker 365 is 0.044299
INFO:root:FL Epoch: 327 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :105
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 105 is 0.254941
INFO:root:FL Epoch: 327 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :548
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693406
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685174
INFO:root:FL Epoch: 327 Norm Difference for worker 548 is 0.121925
INFO:root:FL Epoch: 327 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1176
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697953
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694319
INFO:root:FL Epoch: 327 Norm Difference for worker 1176 is 0.049496
INFO:root:FL Epoch: 327 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.6930819294031929 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.7021389603614807                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [1232, 710, 1540, 1486, 1881, 795, 1174, 1718, 1621, 1011]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 328 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :1232
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694082
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695163
INFO:root:FL Epoch: 328 Norm Difference for worker 1232 is 0.061383
INFO:root:FL Epoch: 328 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :710
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693006
INFO:root:FL Epoch: 328 Norm Difference for worker 710 is 0.053534
INFO:root:FL Epoch: 328 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1540
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692292
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704487
INFO:root:FL Epoch: 328 Norm Difference for worker 1540 is 0.243802
INFO:root:FL Epoch: 328 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1486
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694082
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693191
INFO:root:FL Epoch: 328 Norm Difference for worker 1486 is 0.084099
INFO:root:FL Epoch: 328 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1881
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693174
INFO:root:FL Epoch: 328 Norm Difference for worker 1881 is 0.062065
INFO:root:FL Epoch: 328 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :795
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689607
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693613
INFO:root:FL Epoch: 328 Norm Difference for worker 795 is 0.02088
INFO:root:FL Epoch: 328 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1174
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695873
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692578
INFO:root:FL Epoch: 328 Norm Difference for worker 1174 is 0.065173
INFO:root:FL Epoch: 328 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1718
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692292
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690330
INFO:root:FL Epoch: 328 Norm Difference for worker 1718 is 0.019757
INFO:root:FL Epoch: 328 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1621
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691397
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693442
INFO:root:FL Epoch: 328 Norm Difference for worker 1621 is 0.078311
INFO:root:FL Epoch: 328 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1011
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694082
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686419
INFO:root:FL Epoch: 328 Norm Difference for worker 1011 is 0.153816
INFO:root:FL Epoch: 328 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.6934403110952938 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.6781059503555298                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [991, 1293, 318, 707, 1256, 1006, 474, 1060, 1599, 1142]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 329 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :991
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694778
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699884
INFO:root:FL Epoch: 329 Norm Difference for worker 991 is 0.061354
INFO:root:FL Epoch: 329 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1293
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694778
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690148
INFO:root:FL Epoch: 329 Norm Difference for worker 1293 is 0.097681
INFO:root:FL Epoch: 329 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :318
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 318 is 0.098972
INFO:root:FL Epoch: 329 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :707
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693262
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693268
INFO:root:FL Epoch: 329 Norm Difference for worker 707 is 0.005569
INFO:root:FL Epoch: 329 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1256
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694778
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699278
INFO:root:FL Epoch: 329 Norm Difference for worker 1256 is 0.035814
INFO:root:FL Epoch: 329 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1006
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685684
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689747
INFO:root:FL Epoch: 329 Norm Difference for worker 1006 is 0.11928
INFO:root:FL Epoch: 329 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :474
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702356
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 329 Norm Difference for worker 474 is 0.00697
INFO:root:FL Epoch: 329 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1060
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688715
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686119
INFO:root:FL Epoch: 329 Norm Difference for worker 1060 is 0.220112
INFO:root:FL Epoch: 329 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1599
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693262
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687317
INFO:root:FL Epoch: 329 Norm Difference for worker 1599 is 0.007373
INFO:root:FL Epoch: 329 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1142
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699324
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694612
INFO:root:FL Epoch: 329 Norm Difference for worker 1142 is 0.126153
INFO:root:FL Epoch: 329 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.6932939220877254 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.6841701865196228                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [824, 956, 806, 259, 128, 1910, 388, 1464, 189, 1100]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :824
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694090
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698663
INFO:root:FL Epoch: 330 Norm Difference for worker 824 is 0.185336
INFO:root:FL Epoch: 330 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :956
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693188
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692911
INFO:root:FL Epoch: 330 Norm Difference for worker 956 is 0.040325
INFO:root:FL Epoch: 330 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :806
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694090
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694483
INFO:root:FL Epoch: 330 Norm Difference for worker 806 is 0.033417
INFO:root:FL Epoch: 330 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :259
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692286
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693914
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 259 is 0.194984
INFO:root:FL Epoch: 330 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :128
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692286
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 128 is 0.033944
INFO:root:FL Epoch: 330 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1910
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693188
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700474
INFO:root:FL Epoch: 330 Norm Difference for worker 1910 is 0.074522
INFO:root:FL Epoch: 330 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :388
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693188
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693843
INFO:root:FL Epoch: 330 Norm Difference for worker 388 is 0.006102
INFO:root:FL Epoch: 330 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1464
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690483
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701685
INFO:root:FL Epoch: 330 Norm Difference for worker 1464 is 0.041848
INFO:root:FL Epoch: 330 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :189
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686607
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 189 is 0.161523
INFO:root:FL Epoch: 330 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1100
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694090
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692050
INFO:root:FL Epoch: 330 Norm Difference for worker 1100 is 0.003211
INFO:root:FL Epoch: 330 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.6932762405451607 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.6850337386131287                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 218, 858, 782, 846, 1181, 420, 726]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692366
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693323
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.6482376456260681 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.6822522163391114 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.075638
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692366
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681767
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.6501145958900452 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.6826747596263886 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.071707
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688292
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689037
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.64793860912323 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.6821851253509521 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.076265
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :218
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694810
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693191
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 218 is 0.088958
INFO:root:FL Epoch: 331 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :858
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691551
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693343
INFO:root:FL Epoch: 331 Norm Difference for worker 858 is 0.032473
INFO:root:FL Epoch: 331 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :782
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691551
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690438
INFO:root:FL Epoch: 331 Norm Difference for worker 782 is 0.052553
INFO:root:FL Epoch: 331 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :846
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692366
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693023
INFO:root:FL Epoch: 331 Norm Difference for worker 846 is 0.046422
INFO:root:FL Epoch: 331 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1181
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690736
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699301
INFO:root:FL Epoch: 331 Norm Difference for worker 1181 is 0.073193
INFO:root:FL Epoch: 331 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :420
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692366
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693182
INFO:root:FL Epoch: 331 Norm Difference for worker 420 is 0.037465
INFO:root:FL Epoch: 331 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :726
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688726
INFO:root:FL Epoch: 331 Norm Difference for worker 726 is 0.133897
INFO:root:FL Epoch: 331 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.6933574536267448 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.6813408136367798                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1137, 943, 1384, 478, 1853, 836, 1335, 1385, 333, 848]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1137
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690842
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694260
INFO:root:FL Epoch: 332 Norm Difference for worker 1137 is 0.048525
INFO:root:FL Epoch: 332 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :943
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694405
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690715
INFO:root:FL Epoch: 332 Norm Difference for worker 943 is 0.209262
INFO:root:FL Epoch: 332 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1384
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695593
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693654
INFO:root:FL Epoch: 332 Norm Difference for worker 1384 is 0.044499
INFO:root:FL Epoch: 332 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :478
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694405
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685026
INFO:root:FL Epoch: 332 Norm Difference for worker 478 is 0.133093
INFO:root:FL Epoch: 332 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1853
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693218
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692484
INFO:root:FL Epoch: 332 Norm Difference for worker 1853 is 0.010185
INFO:root:FL Epoch: 332 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :836
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695593
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691900
INFO:root:FL Epoch: 332 Norm Difference for worker 836 is 0.020137
INFO:root:FL Epoch: 332 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1335
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689655
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689136
INFO:root:FL Epoch: 332 Norm Difference for worker 1335 is 0.200233
INFO:root:FL Epoch: 332 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1385
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696781
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697433
INFO:root:FL Epoch: 332 Norm Difference for worker 1385 is 0.021325
INFO:root:FL Epoch: 332 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :333
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 333 is 0.109416
INFO:root:FL Epoch: 332 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :848
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690842
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681111
INFO:root:FL Epoch: 332 Norm Difference for worker 848 is 0.089143
INFO:root:FL Epoch: 332 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.6933805837350733 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.680392324924469                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [754, 1821, 539, 906, 684, 557, 1509, 1785, 340, 645]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :754
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699648
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679725
INFO:root:FL Epoch: 333 Norm Difference for worker 754 is 0.204394
INFO:root:FL Epoch: 333 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1821
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690680
INFO:root:FL Epoch: 333 Norm Difference for worker 1821 is 0.021461
INFO:root:FL Epoch: 333 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :539
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692681
INFO:root:FL Epoch: 333 Norm Difference for worker 539 is 0.066219
INFO:root:FL Epoch: 333 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :906
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700932
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672890
INFO:root:FL Epoch: 333 Norm Difference for worker 906 is 0.197446
INFO:root:FL Epoch: 333 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :684
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691996
INFO:root:FL Epoch: 333 Norm Difference for worker 684 is 0.001289
INFO:root:FL Epoch: 333 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :557
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697081
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692247
INFO:root:FL Epoch: 333 Norm Difference for worker 557 is 0.009969
INFO:root:FL Epoch: 333 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1509
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691946
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693375
INFO:root:FL Epoch: 333 Norm Difference for worker 1509 is 0.078063
INFO:root:FL Epoch: 333 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1785
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691271
INFO:root:FL Epoch: 333 Norm Difference for worker 1785 is 0.016828
INFO:root:FL Epoch: 333 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :340
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686811
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693039
INFO:root:FL Epoch: 333 Norm Difference for worker 340 is 0.115575
INFO:root:FL Epoch: 333 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :645
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692613
INFO:root:FL Epoch: 333 Norm Difference for worker 645 is 0.044944
INFO:root:FL Epoch: 333 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.6930782409275279 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.705563485622406                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1885, 480, 103, 583, 1552, 1728, 265, 35, 1513, 218]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1885
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694457
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694239
INFO:root:FL Epoch: 334 Norm Difference for worker 1885 is 0.014207
INFO:root:FL Epoch: 334 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :480
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688287
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690660
INFO:root:FL Epoch: 334 Norm Difference for worker 480 is 0.009461
INFO:root:FL Epoch: 334 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :103
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 103 is 0.119912
INFO:root:FL Epoch: 334 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :583
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687053
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698929
INFO:root:FL Epoch: 334 Norm Difference for worker 583 is 0.035917
INFO:root:FL Epoch: 334 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1552
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694457
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693277
INFO:root:FL Epoch: 334 Norm Difference for worker 1552 is 0.057051
INFO:root:FL Epoch: 334 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1728
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693223
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692056
INFO:root:FL Epoch: 334 Norm Difference for worker 1728 is 0.021184
INFO:root:FL Epoch: 334 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :265
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 265 is 0.130692
INFO:root:FL Epoch: 334 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :35
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 35 is 0.030155
INFO:root:FL Epoch: 334 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1513
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695691
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693360
INFO:root:FL Epoch: 334 Norm Difference for worker 1513 is 0.072105
INFO:root:FL Epoch: 334 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :218
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 218 is 0.077389
INFO:root:FL Epoch: 334 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.6930947093402638 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.6991386413574219                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [1862, 981, 783, 483, 92, 332, 409, 1407, 210, 1936]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 335 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :1862
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694957
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689707
INFO:root:FL Epoch: 335 Norm Difference for worker 1862 is 0.046177
INFO:root:FL Epoch: 335 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :981
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691373
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703237
INFO:root:FL Epoch: 335 Norm Difference for worker 981 is 0.10696
INFO:root:FL Epoch: 335 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :783
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692568
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697760
INFO:root:FL Epoch: 335 Norm Difference for worker 783 is 0.103331
INFO:root:FL Epoch: 335 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :483
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691089
INFO:root:FL Epoch: 335 Norm Difference for worker 483 is 0.006378
INFO:root:FL Epoch: 335 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :92
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 92 is 0.224141
INFO:root:FL Epoch: 335 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :332
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693187
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 332 is 0.058725
INFO:root:FL Epoch: 335 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :409
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698859
INFO:root:FL Epoch: 335 Norm Difference for worker 409 is 0.159996
INFO:root:FL Epoch: 335 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1407
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687538
INFO:root:FL Epoch: 335 Norm Difference for worker 1407 is 0.069533
INFO:root:FL Epoch: 335 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :210
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 210 is 0.003987
INFO:root:FL Epoch: 335 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1936
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693762
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691966
INFO:root:FL Epoch: 335 Norm Difference for worker 1936 is 0.118848
INFO:root:FL Epoch: 335 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.6932181190041935 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.7220644354820251                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [1219, 607, 222, 931, 772, 1596, 769, 484, 896, 852]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 336 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :1219
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687851
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695163
INFO:root:FL Epoch: 336 Norm Difference for worker 1219 is 0.135244
INFO:root:FL Epoch: 336 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :607
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687851
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679773
INFO:root:FL Epoch: 336 Norm Difference for worker 607 is 0.091159
INFO:root:FL Epoch: 336 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :222
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 222 is 0.212488
INFO:root:FL Epoch: 336 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :931
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702107
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693159
INFO:root:FL Epoch: 336 Norm Difference for worker 931 is 0.057997
INFO:root:FL Epoch: 336 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :772
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704958
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694634
INFO:root:FL Epoch: 336 Norm Difference for worker 772 is 0.160584
INFO:root:FL Epoch: 336 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1596
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690702
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699375
INFO:root:FL Epoch: 336 Norm Difference for worker 1596 is 0.007739
INFO:root:FL Epoch: 336 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :769
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685000
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691290
INFO:root:FL Epoch: 336 Norm Difference for worker 769 is 0.091302
INFO:root:FL Epoch: 336 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :484
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699256
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697970
INFO:root:FL Epoch: 336 Norm Difference for worker 484 is 0.141635
INFO:root:FL Epoch: 336 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :896
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696405
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693260
INFO:root:FL Epoch: 336 Norm Difference for worker 896 is 0.125459
INFO:root:FL Epoch: 336 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :852
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699256
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690928
INFO:root:FL Epoch: 336 Norm Difference for worker 852 is 0.037499
INFO:root:FL Epoch: 336 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.6931275199441349 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.6949548125267029                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [1915, 136, 1458, 1617, 113, 225, 258, 144, 640, 920]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 337 Num points on workers: [200 201 200 200 201 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :1915
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693329
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695962
INFO:root:FL Epoch: 337 Norm Difference for worker 1915 is 0.14899
INFO:root:FL Epoch: 337 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :136
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670385
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 136 is 0.25786
INFO:root:FL Epoch: 337 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1458
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692788
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 337 Norm Difference for worker 1458 is 0.05385
INFO:root:FL Epoch: 337 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1617
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692544
INFO:root:FL Epoch: 337 Norm Difference for worker 1617 is 0.02517
INFO:root:FL Epoch: 337 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :113
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694770
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 113 is 0.010764
INFO:root:FL Epoch: 337 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :225
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 225 is 0.008082
INFO:root:FL Epoch: 337 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :258
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693619
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 258 is 0.00217
INFO:root:FL Epoch: 337 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :144
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 144 is 0.036769
INFO:root:FL Epoch: 337 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :640
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692968
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698322
INFO:root:FL Epoch: 337 Norm Difference for worker 640 is 0.00747
INFO:root:FL Epoch: 337 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :920
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694052
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693190
INFO:root:FL Epoch: 337 Norm Difference for worker 920 is 0.023496
INFO:root:FL Epoch: 337 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.6935040845590479 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.6758701205253601                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [483, 1773, 692, 125, 896, 1694, 899, 1396, 1318, 1791]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :483
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695042
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693242
INFO:root:FL Epoch: 338 Norm Difference for worker 483 is 0.024068
INFO:root:FL Epoch: 338 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1773
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696785
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687529
INFO:root:FL Epoch: 338 Norm Difference for worker 1773 is 0.086926
INFO:root:FL Epoch: 338 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :692
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688070
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688490
INFO:root:FL Epoch: 338 Norm Difference for worker 692 is 0.001857
INFO:root:FL Epoch: 338 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :125
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 125 is 0.088738
INFO:root:FL Epoch: 338 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :896
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688070
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675601
INFO:root:FL Epoch: 338 Norm Difference for worker 896 is 0.094453
INFO:root:FL Epoch: 338 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1694
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696785
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693376
INFO:root:FL Epoch: 338 Norm Difference for worker 1694 is 0.066307
INFO:root:FL Epoch: 338 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :899
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695042
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691067
INFO:root:FL Epoch: 338 Norm Difference for worker 899 is 0.006871
INFO:root:FL Epoch: 338 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1396
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698528
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693183
INFO:root:FL Epoch: 338 Norm Difference for worker 1396 is 0.087058
INFO:root:FL Epoch: 338 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1318
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693299
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689794
INFO:root:FL Epoch: 338 Norm Difference for worker 1318 is 0.125061
INFO:root:FL Epoch: 338 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1791
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689813
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694163
INFO:root:FL Epoch: 338 Norm Difference for worker 1791 is 0.022107
INFO:root:FL Epoch: 338 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.6932023272794836 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.6891509890556335                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [1629, 745, 1002, 1359, 619, 1907, 21, 1557, 205, 802]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 339 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :1629
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693956
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694048
INFO:root:FL Epoch: 339 Norm Difference for worker 1629 is 0.033106
INFO:root:FL Epoch: 339 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :745
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693556
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691077
INFO:root:FL Epoch: 339 Norm Difference for worker 745 is 0.161027
INFO:root:FL Epoch: 339 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1002
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692755
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692473
INFO:root:FL Epoch: 339 Norm Difference for worker 1002 is 0.055958
INFO:root:FL Epoch: 339 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1359
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691733
INFO:root:FL Epoch: 339 Norm Difference for worker 1359 is 0.092073
INFO:root:FL Epoch: 339 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :619
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692755
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692202
INFO:root:FL Epoch: 339 Norm Difference for worker 619 is 0.061781
INFO:root:FL Epoch: 339 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1907
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693956
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693393
INFO:root:FL Epoch: 339 Norm Difference for worker 1907 is 0.008148
INFO:root:FL Epoch: 339 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :21
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692354
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694511
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 21 is 0.088393
INFO:root:FL Epoch: 339 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1557
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693155
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691197
INFO:root:FL Epoch: 339 Norm Difference for worker 1557 is 0.105708
INFO:root:FL Epoch: 339 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :205
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 205 is 0.104719
INFO:root:FL Epoch: 339 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :802
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694356
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682555
INFO:root:FL Epoch: 339 Norm Difference for worker 802 is 0.10702
INFO:root:FL Epoch: 339 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.6930802008684944 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.7071241736412048                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [871, 60, 930, 1124, 733, 1016, 689, 214, 319, 1111]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 340 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :871
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690467
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690827
INFO:root:FL Epoch: 340 Norm Difference for worker 871 is 0.153147
INFO:root:FL Epoch: 340 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :60
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692573
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 60 is 0.034986
INFO:root:FL Epoch: 340 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :930
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696020
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691307
INFO:root:FL Epoch: 340 Norm Difference for worker 930 is 0.070959
INFO:root:FL Epoch: 340 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1124
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691855
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688112
INFO:root:FL Epoch: 340 Norm Difference for worker 1124 is 0.074028
INFO:root:FL Epoch: 340 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :733
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697408
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686492
INFO:root:FL Epoch: 340 Norm Difference for worker 733 is 0.109481
INFO:root:FL Epoch: 340 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1016
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696020
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689571
INFO:root:FL Epoch: 340 Norm Difference for worker 1016 is 0.139072
INFO:root:FL Epoch: 340 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :689
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691855
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691940
INFO:root:FL Epoch: 340 Norm Difference for worker 689 is 0.014412
INFO:root:FL Epoch: 340 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :214
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 214 is 0.019925
INFO:root:FL Epoch: 340 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :319
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 319 is 0.025565
INFO:root:FL Epoch: 340 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1111
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694632
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693877
INFO:root:FL Epoch: 340 Norm Difference for worker 1111 is 0.029577
INFO:root:FL Epoch: 340 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.6931394724284902 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.6938233971595764                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 472, 1059, 560, 655, 898, 1664, 1277]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693215
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690577
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.6569629907608032 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.6842420041561127 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.075079
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693283
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686768
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.6529041528701782 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.6833084344863891 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.083526
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693418
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687343
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.657350480556488 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.6843318819999695 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.074275
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :472
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693012
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691517
INFO:root:FL Epoch: 341 Norm Difference for worker 472 is 0.024723
INFO:root:FL Epoch: 341 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1059
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693080
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685274
INFO:root:FL Epoch: 341 Norm Difference for worker 1059 is 0.219829
INFO:root:FL Epoch: 341 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :560
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692945
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690397
INFO:root:FL Epoch: 341 Norm Difference for worker 560 is 0.058724
INFO:root:FL Epoch: 341 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :655
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693350
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681119
INFO:root:FL Epoch: 341 Norm Difference for worker 655 is 0.173049
INFO:root:FL Epoch: 341 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :898
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693012
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695436
INFO:root:FL Epoch: 341 Norm Difference for worker 898 is 0.056919
INFO:root:FL Epoch: 341 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1664
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693215
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690530
INFO:root:FL Epoch: 341 Norm Difference for worker 1664 is 0.122031
INFO:root:FL Epoch: 341 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1277
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693012
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694037
INFO:root:FL Epoch: 341 Norm Difference for worker 1277 is 0.021162
INFO:root:FL Epoch: 341 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.6931126082644743 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.6965857744216919                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1085, 431, 1019, 17, 671, 163, 1750, 1316, 365, 535]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 342 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1085
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692810
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693409
INFO:root:FL Epoch: 342 Norm Difference for worker 1085 is 0.011682
INFO:root:FL Epoch: 342 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :431
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693496
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693873
INFO:root:FL Epoch: 342 Norm Difference for worker 431 is 0.033834
INFO:root:FL Epoch: 342 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1019
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693496
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692643
INFO:root:FL Epoch: 342 Norm Difference for worker 1019 is 0.023672
INFO:root:FL Epoch: 342 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :17
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 17 is 0.185651
INFO:root:FL Epoch: 342 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :671
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694183
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 342 Norm Difference for worker 671 is 0.01116
INFO:root:FL Epoch: 342 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :163
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693985
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 163 is 0.028725
INFO:root:FL Epoch: 342 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1750
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692810
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692607
INFO:root:FL Epoch: 342 Norm Difference for worker 1750 is 0.013092
INFO:root:FL Epoch: 342 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1316
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692810
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690914
INFO:root:FL Epoch: 342 Norm Difference for worker 1316 is 0.080878
INFO:root:FL Epoch: 342 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :365
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694183
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691449
INFO:root:FL Epoch: 342 Norm Difference for worker 365 is 0.070573
INFO:root:FL Epoch: 342 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :535
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691780
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692119
INFO:root:FL Epoch: 342 Norm Difference for worker 535 is 0.002105
INFO:root:FL Epoch: 342 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.6932803848210503 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.6848272681236267                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [807, 1321, 608, 1300, 1732, 245, 865, 1286, 1311, 189]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :807
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693235
INFO:root:FL Epoch: 343 Norm Difference for worker 807 is 0.024387
INFO:root:FL Epoch: 343 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1321
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693981
INFO:root:FL Epoch: 343 Norm Difference for worker 1321 is 0.130348
INFO:root:FL Epoch: 343 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :608
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690676
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693669
INFO:root:FL Epoch: 343 Norm Difference for worker 608 is 0.035171
INFO:root:FL Epoch: 343 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1300
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690676
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698438
INFO:root:FL Epoch: 343 Norm Difference for worker 1300 is 0.050171
INFO:root:FL Epoch: 343 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1732
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689840
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694511
INFO:root:FL Epoch: 343 Norm Difference for worker 1732 is 0.043745
INFO:root:FL Epoch: 343 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :245
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698195
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 245 is 0.059534
INFO:root:FL Epoch: 343 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :865
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695689
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 343 Norm Difference for worker 865 is 0.041231
INFO:root:FL Epoch: 343 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1286
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694018
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690332
INFO:root:FL Epoch: 343 Norm Difference for worker 1286 is 0.181652
INFO:root:FL Epoch: 343 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1311
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693329
INFO:root:FL Epoch: 343 Norm Difference for worker 1311 is 0.094838
INFO:root:FL Epoch: 343 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :189
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 189 is 0.16491
INFO:root:FL Epoch: 343 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.6931787764324862 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.6907176375389099                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1045, 1586, 604, 485, 1560, 43, 1653, 8, 197, 1076]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1045
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692420
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681738
INFO:root:FL Epoch: 344 Norm Difference for worker 1045 is 0.141716
INFO:root:FL Epoch: 344 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1586
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692907
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693820
INFO:root:FL Epoch: 344 Norm Difference for worker 1586 is 0.064232
INFO:root:FL Epoch: 344 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :604
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692664
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693170
INFO:root:FL Epoch: 344 Norm Difference for worker 604 is 0.010281
INFO:root:FL Epoch: 344 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :485
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693393
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691408
INFO:root:FL Epoch: 344 Norm Difference for worker 485 is 0.129316
INFO:root:FL Epoch: 344 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1560
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700945
INFO:root:FL Epoch: 344 Norm Difference for worker 1560 is 0.075298
INFO:root:FL Epoch: 344 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :43
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 43 is 0.003252
INFO:root:FL Epoch: 344 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1653
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693393
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688040
INFO:root:FL Epoch: 344 Norm Difference for worker 1653 is 0.160334
INFO:root:FL Epoch: 344 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :8
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 8 is 0.075845
INFO:root:FL Epoch: 344 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :197
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 197 is 0.091307
INFO:root:FL Epoch: 344 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1076
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691882
INFO:root:FL Epoch: 344 Norm Difference for worker 1076 is 0.06735
INFO:root:FL Epoch: 344 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.6930821467848385 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.7020755410194397                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [1887, 1618, 192, 1922, 853, 409, 37, 1797, 1173, 354]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 345 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :1887
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689631
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691648
INFO:root:FL Epoch: 345 Norm Difference for worker 1887 is 0.011302
INFO:root:FL Epoch: 345 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1618
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690520
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693248
INFO:root:FL Epoch: 345 Norm Difference for worker 1618 is 0.052799
INFO:root:FL Epoch: 345 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :192
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 192 is 0.009075
INFO:root:FL Epoch: 345 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1922
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694076
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697669
INFO:root:FL Epoch: 345 Norm Difference for worker 1922 is 0.094715
INFO:root:FL Epoch: 345 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :853
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690520
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693818
INFO:root:FL Epoch: 345 Norm Difference for worker 853 is 0.030729
INFO:root:FL Epoch: 345 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :409
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692298
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676064
INFO:root:FL Epoch: 345 Norm Difference for worker 409 is 0.130592
INFO:root:FL Epoch: 345 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :37
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 37 is 0.002296
INFO:root:FL Epoch: 345 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1797
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695853
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694054
INFO:root:FL Epoch: 345 Norm Difference for worker 1797 is 0.249912
INFO:root:FL Epoch: 345 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1173
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696742
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694054
INFO:root:FL Epoch: 345 Norm Difference for worker 1173 is 0.04959
INFO:root:FL Epoch: 345 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :354
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691409
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692093
INFO:root:FL Epoch: 345 Norm Difference for worker 354 is 0.055474
INFO:root:FL Epoch: 345 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.6931030259412878 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.6978445649147034                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [1581, 1807, 1605, 445, 1804, 852, 67, 1870, 1033, 1199]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :1581
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684546
INFO:root:FL Epoch: 346 Norm Difference for worker 1581 is 0.191645
INFO:root:FL Epoch: 346 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1807
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689878
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682924
INFO:root:FL Epoch: 346 Norm Difference for worker 1807 is 0.203502
INFO:root:FL Epoch: 346 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1605
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692690
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692414
INFO:root:FL Epoch: 346 Norm Difference for worker 1605 is 0.003069
INFO:root:FL Epoch: 346 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :445
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694095
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694644
INFO:root:FL Epoch: 346 Norm Difference for worker 445 is 0.035839
INFO:root:FL Epoch: 346 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1804
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692221
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693290
INFO:root:FL Epoch: 346 Norm Difference for worker 1804 is 0.029774
INFO:root:FL Epoch: 346 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :852
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693627
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691828
INFO:root:FL Epoch: 346 Norm Difference for worker 852 is 0.090461
INFO:root:FL Epoch: 346 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :67
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690221
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 67 is 0.196294
INFO:root:FL Epoch: 346 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1870
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694564
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694096
INFO:root:FL Epoch: 346 Norm Difference for worker 1870 is 0.092933
INFO:root:FL Epoch: 346 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1033
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693232
INFO:root:FL Epoch: 346 Norm Difference for worker 1033 is 0.074664
INFO:root:FL Epoch: 346 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1199
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691752
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694169
INFO:root:FL Epoch: 346 Norm Difference for worker 1199 is 0.198842
INFO:root:FL Epoch: 346 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.6930928475716535 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.710520327091217                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [623, 1667, 1748, 1473, 484, 422, 1584, 1257, 247, 1862]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :623
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682961
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690570
INFO:root:FL Epoch: 347 Norm Difference for worker 623 is 0.039546
INFO:root:FL Epoch: 347 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1667
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695018
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693357
INFO:root:FL Epoch: 347 Norm Difference for worker 1667 is 0.02196
INFO:root:FL Epoch: 347 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1748
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698463
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697044
INFO:root:FL Epoch: 347 Norm Difference for worker 1748 is 0.050413
INFO:root:FL Epoch: 347 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1473
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691573
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690361
INFO:root:FL Epoch: 347 Norm Difference for worker 1473 is 0.107688
INFO:root:FL Epoch: 347 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :484
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693295
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692618
INFO:root:FL Epoch: 347 Norm Difference for worker 484 is 0.124715
INFO:root:FL Epoch: 347 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :422
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689851
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699070
INFO:root:FL Epoch: 347 Norm Difference for worker 422 is 0.106185
INFO:root:FL Epoch: 347 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1584
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700185
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688903
INFO:root:FL Epoch: 347 Norm Difference for worker 1584 is 0.156848
INFO:root:FL Epoch: 347 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1257
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691573
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692207
INFO:root:FL Epoch: 347 Norm Difference for worker 1257 is 0.046038
INFO:root:FL Epoch: 347 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :247
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 247 is 0.154093
INFO:root:FL Epoch: 347 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1862
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691573
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695025
INFO:root:FL Epoch: 347 Norm Difference for worker 1862 is 0.087498
INFO:root:FL Epoch: 347 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.6931178955470815 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.6959787011146545                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1637, 1052, 976, 1674, 1323, 573, 1785, 1911, 105, 1649]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1637
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692303
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693849
INFO:root:FL Epoch: 348 Norm Difference for worker 1637 is 0.021234
INFO:root:FL Epoch: 348 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1052
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692586
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693268
INFO:root:FL Epoch: 348 Norm Difference for worker 1052 is 0.021021
INFO:root:FL Epoch: 348 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :976
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692868
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693162
INFO:root:FL Epoch: 348 Norm Difference for worker 976 is 0.005794
INFO:root:FL Epoch: 348 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1674
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693717
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691198
INFO:root:FL Epoch: 348 Norm Difference for worker 1674 is 0.063182
INFO:root:FL Epoch: 348 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1323
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694282
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689456
INFO:root:FL Epoch: 348 Norm Difference for worker 1323 is 0.117808
INFO:root:FL Epoch: 348 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :573
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693434
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693365
INFO:root:FL Epoch: 348 Norm Difference for worker 573 is 0.005008
INFO:root:FL Epoch: 348 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1785
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693434
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687691
INFO:root:FL Epoch: 348 Norm Difference for worker 1785 is 0.085735
INFO:root:FL Epoch: 348 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1911
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693717
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693493
INFO:root:FL Epoch: 348 Norm Difference for worker 1911 is 0.071978
INFO:root:FL Epoch: 348 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :105
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 105 is 0.218015
INFO:root:FL Epoch: 348 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1649
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692303
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693403
INFO:root:FL Epoch: 348 Norm Difference for worker 1649 is 0.032326
INFO:root:FL Epoch: 348 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.6935153568492216 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.6754947304725647                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [1916, 646, 69, 999, 995, 1098, 338, 1684, 334, 1847]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :1916
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696868
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696012
INFO:root:FL Epoch: 349 Norm Difference for worker 1916 is 0.067055
INFO:root:FL Epoch: 349 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :646
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687962
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690940
INFO:root:FL Epoch: 349 Norm Difference for worker 646 is 0.016525
INFO:root:FL Epoch: 349 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :69
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691525
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 69 is 0.130935
INFO:root:FL Epoch: 349 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :999
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695087
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693836
INFO:root:FL Epoch: 349 Norm Difference for worker 999 is 0.096901
INFO:root:FL Epoch: 349 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :995
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691525
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697518
INFO:root:FL Epoch: 349 Norm Difference for worker 995 is 0.023964
INFO:root:FL Epoch: 349 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1098
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689744
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689918
INFO:root:FL Epoch: 349 Norm Difference for worker 1098 is 0.065456
INFO:root:FL Epoch: 349 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :338
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691844
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 338 is 0.091537
INFO:root:FL Epoch: 349 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1684
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691525
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699353
INFO:root:FL Epoch: 349 Norm Difference for worker 1684 is 0.048063
INFO:root:FL Epoch: 349 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :334
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 334 is 0.079106
INFO:root:FL Epoch: 349 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1847
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696868
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691340
INFO:root:FL Epoch: 349 Norm Difference for worker 1847 is 0.080999
INFO:root:FL Epoch: 349 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.6933826909345739 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.68030846118927                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1040, 598, 1751, 1280, 1514, 131, 1654, 1021, 35, 475]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 350 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1040
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691938
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682984
INFO:root:FL Epoch: 350 Norm Difference for worker 1040 is 0.045225
INFO:root:FL Epoch: 350 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :598
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693231
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694309
INFO:root:FL Epoch: 350 Norm Difference for worker 598 is 0.158122
INFO:root:FL Epoch: 350 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1751
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694523
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692649
INFO:root:FL Epoch: 350 Norm Difference for worker 1751 is 0.013168
INFO:root:FL Epoch: 350 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1280
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694523
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 350 Norm Difference for worker 1280 is 0.030152
INFO:root:FL Epoch: 350 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1514
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688062
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691068
INFO:root:FL Epoch: 350 Norm Difference for worker 1514 is 0.002801
INFO:root:FL Epoch: 350 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :131
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694523
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 131 is 0.089538
INFO:root:FL Epoch: 350 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1654
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688062
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697097
INFO:root:FL Epoch: 350 Norm Difference for worker 1654 is 0.044998
INFO:root:FL Epoch: 350 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1021
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691938
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693352
INFO:root:FL Epoch: 350 Norm Difference for worker 1021 is 0.002986
INFO:root:FL Epoch: 350 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :35
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697107
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 35 is 0.015889
INFO:root:FL Epoch: 350 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :475
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690646
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699843
INFO:root:FL Epoch: 350 Norm Difference for worker 475 is 0.048579
INFO:root:FL Epoch: 350 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.6938430842231301 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.6661676168441772                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 1925, 712, 218, 1646, 399, 1451, 456]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690786
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686249
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.6347203850746155 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.6792980849742889 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.065773
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688051
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686020
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.6323503851890564 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.6787966907024383 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.070823
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688051
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682051
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.6340476870536804 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.6791552722454071 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.067204
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1925
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696257
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686616
INFO:root:FL Epoch: 351 Norm Difference for worker 1925 is 0.092235
INFO:root:FL Epoch: 351 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :712
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696257
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693260
INFO:root:FL Epoch: 351 Norm Difference for worker 712 is 0.167759
INFO:root:FL Epoch: 351 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :218
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 218 is 0.104899
INFO:root:FL Epoch: 351 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1646
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679844
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670192
INFO:root:FL Epoch: 351 Norm Difference for worker 1646 is 0.150379
INFO:root:FL Epoch: 351 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :399
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693521
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695974
INFO:root:FL Epoch: 351 Norm Difference for worker 399 is 0.037829
INFO:root:FL Epoch: 351 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1451
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698992
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690482
INFO:root:FL Epoch: 351 Norm Difference for worker 1451 is 0.025015
INFO:root:FL Epoch: 351 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :456
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688051
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693600
INFO:root:FL Epoch: 351 Norm Difference for worker 456 is 0.023467
INFO:root:FL Epoch: 351 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.6942446862950045 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.6572713851928711                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [588, 721, 1883, 1861, 358, 1909, 374, 1674, 1237, 72]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :588
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690160
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690678
INFO:root:FL Epoch: 352 Norm Difference for worker 588 is 0.069779
INFO:root:FL Epoch: 352 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :721
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693815
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697303
INFO:root:FL Epoch: 352 Norm Difference for worker 721 is 0.038544
INFO:root:FL Epoch: 352 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1883
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701123
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699815
INFO:root:FL Epoch: 352 Norm Difference for worker 1883 is 0.003454
INFO:root:FL Epoch: 352 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1861
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708432
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693308
INFO:root:FL Epoch: 352 Norm Difference for worker 1861 is 0.039988
INFO:root:FL Epoch: 352 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :358
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693815
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693928
INFO:root:FL Epoch: 352 Norm Difference for worker 358 is 0.156667
INFO:root:FL Epoch: 352 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1909
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690160
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689478
INFO:root:FL Epoch: 352 Norm Difference for worker 1909 is 0.071431
INFO:root:FL Epoch: 352 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :374
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686506
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677395
INFO:root:FL Epoch: 352 Norm Difference for worker 374 is 0.08457
INFO:root:FL Epoch: 352 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1674
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686506
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689697
INFO:root:FL Epoch: 352 Norm Difference for worker 1674 is 0.016921
INFO:root:FL Epoch: 352 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1237
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686506
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670848
INFO:root:FL Epoch: 352 Norm Difference for worker 1237 is 0.088115
INFO:root:FL Epoch: 352 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :72
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 72 is 0.024023
INFO:root:FL Epoch: 352 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.69407838232377 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.6607221961021423                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1237, 882, 946, 571, 1547, 1187, 1344, 1663, 105, 1843]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1237
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680503
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688766
INFO:root:FL Epoch: 353 Norm Difference for worker 1237 is 0.073072
INFO:root:FL Epoch: 353 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :882
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703581
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687953
INFO:root:FL Epoch: 353 Norm Difference for worker 882 is 0.000539
INFO:root:FL Epoch: 353 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :946
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683800
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698011
INFO:root:FL Epoch: 353 Norm Difference for worker 946 is 0.034806
INFO:root:FL Epoch: 353 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :571
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690394
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702083
INFO:root:FL Epoch: 353 Norm Difference for worker 571 is 0.139943
INFO:root:FL Epoch: 353 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1547
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696987
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682877
INFO:root:FL Epoch: 353 Norm Difference for worker 1547 is 0.027837
INFO:root:FL Epoch: 353 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1187
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696987
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690935
INFO:root:FL Epoch: 353 Norm Difference for worker 1187 is 0.04183
INFO:root:FL Epoch: 353 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1344
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693690
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687998
INFO:root:FL Epoch: 353 Norm Difference for worker 1344 is 0.148392
INFO:root:FL Epoch: 353 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1663
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696987
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696153
INFO:root:FL Epoch: 353 Norm Difference for worker 1663 is 0.051793
INFO:root:FL Epoch: 353 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :105
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690394
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 105 is 0.168291
INFO:root:FL Epoch: 353 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1843
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687097
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662568
INFO:root:FL Epoch: 353 Norm Difference for worker 1843 is 0.16775
INFO:root:FL Epoch: 353 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.6942925242816701 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.6563262939453125                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [660, 1494, 1242, 1335, 1418, 184, 1837, 178, 10, 14]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 201 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :660
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701356
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693986
INFO:root:FL Epoch: 354 Norm Difference for worker 660 is 0.128636
INFO:root:FL Epoch: 354 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1494
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701356
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696885
INFO:root:FL Epoch: 354 Norm Difference for worker 1494 is 0.108789
INFO:root:FL Epoch: 354 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1242
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690099
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689969
INFO:root:FL Epoch: 354 Norm Difference for worker 1242 is 0.038354
INFO:root:FL Epoch: 354 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1335
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690099
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682206
INFO:root:FL Epoch: 354 Norm Difference for worker 1335 is 0.14785
INFO:root:FL Epoch: 354 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1418
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697604
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693159
INFO:root:FL Epoch: 354 Norm Difference for worker 1418 is 0.13661
INFO:root:FL Epoch: 354 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :184
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 184 is 0.087567
INFO:root:FL Epoch: 354 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1837
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693851
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694990
INFO:root:FL Epoch: 354 Norm Difference for worker 1837 is 0.112192
INFO:root:FL Epoch: 354 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :178
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 178 is 0.117804
INFO:root:FL Epoch: 354 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :10
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 10 is 0.032465
INFO:root:FL Epoch: 354 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :14
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 14 is 0.030657
INFO:root:FL Epoch: 354 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.6937857270240784 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.6676217913627625                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [196, 1723, 1727, 1583, 929, 174, 1542, 1680, 696, 659]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :196
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 196 is 0.018922
INFO:root:FL Epoch: 355 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1723
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696068
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706279
INFO:root:FL Epoch: 355 Norm Difference for worker 1723 is 0.126299
INFO:root:FL Epoch: 355 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1727
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690896
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694414
INFO:root:FL Epoch: 355 Norm Difference for worker 1727 is 0.107382
INFO:root:FL Epoch: 355 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1583
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696067
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686840
INFO:root:FL Epoch: 355 Norm Difference for worker 1583 is 0.196038
INFO:root:FL Epoch: 355 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :929
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696067
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697893
INFO:root:FL Epoch: 355 Norm Difference for worker 929 is 0.020482
INFO:root:FL Epoch: 355 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :174
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 174 is 0.053952
INFO:root:FL Epoch: 355 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1542
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696067
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687328
INFO:root:FL Epoch: 355 Norm Difference for worker 1542 is 0.015896
INFO:root:FL Epoch: 355 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1680
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696067
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683817
INFO:root:FL Epoch: 355 Norm Difference for worker 1680 is 0.032765
INFO:root:FL Epoch: 355 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :696
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688310
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693370
INFO:root:FL Epoch: 355 Norm Difference for worker 696 is 0.126685
INFO:root:FL Epoch: 355 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :659
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698653
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693162
INFO:root:FL Epoch: 355 Norm Difference for worker 659 is 0.056042
INFO:root:FL Epoch: 355 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.6931567928370308 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.6923556923866272                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [65, 648, 1515, 64, 1041, 823, 1336, 1648, 1233, 54]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 356 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :65
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687250
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 65 is 0.12416
INFO:root:FL Epoch: 356 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692989
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692157
INFO:root:FL Epoch: 356 Norm Difference for worker 648 is 0.040997
INFO:root:FL Epoch: 356 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1515
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693227
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702653
INFO:root:FL Epoch: 356 Norm Difference for worker 1515 is 0.129053
INFO:root:FL Epoch: 356 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :64
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 64 is 0.043158
INFO:root:FL Epoch: 356 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1041
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692831
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693222
INFO:root:FL Epoch: 356 Norm Difference for worker 1041 is 0.096507
INFO:root:FL Epoch: 356 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :823
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693306
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690900
INFO:root:FL Epoch: 356 Norm Difference for worker 823 is 0.023656
INFO:root:FL Epoch: 356 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1336
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692910
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691243
INFO:root:FL Epoch: 356 Norm Difference for worker 1336 is 0.038147
INFO:root:FL Epoch: 356 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1648
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692831
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693242
INFO:root:FL Epoch: 356 Norm Difference for worker 1648 is 0.043936
INFO:root:FL Epoch: 356 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1233
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692752
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693760
INFO:root:FL Epoch: 356 Norm Difference for worker 1233 is 0.012287
INFO:root:FL Epoch: 356 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :54
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693068
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 54 is 0.033699
INFO:root:FL Epoch: 356 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.6930791910956887 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.7065638899803162                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1333, 1745, 1844, 1776, 288, 308, 1198, 441, 1571, 614]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1333
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697234
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694666
INFO:root:FL Epoch: 357 Norm Difference for worker 1333 is 0.068933
INFO:root:FL Epoch: 357 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1745
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690570
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694819
INFO:root:FL Epoch: 357 Norm Difference for worker 1745 is 0.06764
INFO:root:FL Epoch: 357 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1844
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693365
INFO:root:FL Epoch: 357 Norm Difference for worker 1844 is 0.113213
INFO:root:FL Epoch: 357 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1776
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697234
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690641
INFO:root:FL Epoch: 357 Norm Difference for worker 1776 is 0.110807
INFO:root:FL Epoch: 357 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :288
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691903
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 288 is 0.054336
INFO:root:FL Epoch: 357 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :308
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 308 is 0.047871
INFO:root:FL Epoch: 357 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1198
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693722
INFO:root:FL Epoch: 357 Norm Difference for worker 1198 is 0.076744
INFO:root:FL Epoch: 357 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :441
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691903
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691490
INFO:root:FL Epoch: 357 Norm Difference for worker 441 is 6.9e-05
INFO:root:FL Epoch: 357 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1571
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694569
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691966
INFO:root:FL Epoch: 357 Norm Difference for worker 1571 is 0.073515
INFO:root:FL Epoch: 357 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :614
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694569
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691629
INFO:root:FL Epoch: 357 Norm Difference for worker 614 is 0.00567
INFO:root:FL Epoch: 357 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.6932206048684961 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.6880335211753845                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1581, 104, 380, 887, 392, 1518, 120, 905, 1181, 65]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1581
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694698
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682228
INFO:root:FL Epoch: 358 Norm Difference for worker 1581 is 0.184355
INFO:root:FL Epoch: 358 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :104
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 104 is 0.085593
INFO:root:FL Epoch: 358 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :380
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691371
INFO:root:FL Epoch: 358 Norm Difference for worker 380 is 0.081291
INFO:root:FL Epoch: 358 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :887
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693744
INFO:root:FL Epoch: 358 Norm Difference for worker 887 is 0.111085
INFO:root:FL Epoch: 358 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :392
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693160
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686370
INFO:root:FL Epoch: 358 Norm Difference for worker 392 is 0.104749
INFO:root:FL Epoch: 358 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1518
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694186
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693254
INFO:root:FL Epoch: 358 Norm Difference for worker 1518 is 0.058905
INFO:root:FL Epoch: 358 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :120
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 120 is 0.014788
INFO:root:FL Epoch: 358 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :905
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692135
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687883
INFO:root:FL Epoch: 358 Norm Difference for worker 905 is 0.11069
INFO:root:FL Epoch: 358 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1181
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691110
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693756
INFO:root:FL Epoch: 358 Norm Difference for worker 1181 is 0.060593
INFO:root:FL Epoch: 358 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :65
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695211
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 65 is 0.103137
INFO:root:FL Epoch: 358 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.6930845905752743 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.7086610198020935                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [676, 755, 955, 1854, 1219, 281, 1836, 832, 953, 1498]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :676
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691726
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690806
INFO:root:FL Epoch: 359 Norm Difference for worker 676 is 0.061198
INFO:root:FL Epoch: 359 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :755
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699424
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693694
INFO:root:FL Epoch: 359 Norm Difference for worker 755 is 0.066127
INFO:root:FL Epoch: 359 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :955
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696345
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693347
INFO:root:FL Epoch: 359 Norm Difference for worker 955 is 0.046546
INFO:root:FL Epoch: 359 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1854
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688647
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690724
INFO:root:FL Epoch: 359 Norm Difference for worker 1854 is 0.050107
INFO:root:FL Epoch: 359 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1219
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694805
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694310
INFO:root:FL Epoch: 359 Norm Difference for worker 1219 is 0.186914
INFO:root:FL Epoch: 359 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :281
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 281 is 0.021032
INFO:root:FL Epoch: 359 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1836
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690187
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693584
INFO:root:FL Epoch: 359 Norm Difference for worker 1836 is 0.055591
INFO:root:FL Epoch: 359 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :832
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694805
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693422
INFO:root:FL Epoch: 359 Norm Difference for worker 832 is 0.031945
INFO:root:FL Epoch: 359 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :953
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691726
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694664
INFO:root:FL Epoch: 359 Norm Difference for worker 953 is 0.16643
INFO:root:FL Epoch: 359 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1498
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694805
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696481
INFO:root:FL Epoch: 359 Norm Difference for worker 1498 is 0.032019
INFO:root:FL Epoch: 359 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.6933409466462976 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.7284526824951172                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [752, 1335, 1381, 1057, 813, 767, 214, 100, 80, 1821]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :752
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693749
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693362
INFO:root:FL Epoch: 360 Norm Difference for worker 752 is 0.100593
INFO:root:FL Epoch: 360 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1335
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700690
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692903
INFO:root:FL Epoch: 360 Norm Difference for worker 1335 is 0.26053
INFO:root:FL Epoch: 360 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1381
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690279
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690612
INFO:root:FL Epoch: 360 Norm Difference for worker 1381 is 0.07891
INFO:root:FL Epoch: 360 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1057
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700690
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691288
INFO:root:FL Epoch: 360 Norm Difference for worker 1057 is 0.051265
INFO:root:FL Epoch: 360 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :813
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676397
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718361
INFO:root:FL Epoch: 360 Norm Difference for worker 813 is 0.029877
INFO:root:FL Epoch: 360 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :767
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686809
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700805
INFO:root:FL Epoch: 360 Norm Difference for worker 767 is 0.002982
INFO:root:FL Epoch: 360 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :214
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697220
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 214 is 0.008675
INFO:root:FL Epoch: 360 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :100
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.661300
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 100 is 0.098947
INFO:root:FL Epoch: 360 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :80
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 80 is 0.019512
INFO:root:FL Epoch: 360 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1821
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676397
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687735
INFO:root:FL Epoch: 360 Norm Difference for worker 1821 is 0.109151
INFO:root:FL Epoch: 360 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.6930896219085244 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.7001047730445862                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 1618, 643, 1710, 966, 640, 1848, 1504]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692095
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.6662254929542542 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.686423122882843 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.068455
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689679
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.661835253238678 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.6853805541992187 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.077503
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695945
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.6626970171928406 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.6855840027332306 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.075724
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1618
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691784
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694282
INFO:root:FL Epoch: 361 Norm Difference for worker 1618 is 0.074763
INFO:root:FL Epoch: 361 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :643
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691785
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688764
INFO:root:FL Epoch: 361 Norm Difference for worker 643 is 0.122004
INFO:root:FL Epoch: 361 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1710
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695251
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690012
INFO:root:FL Epoch: 361 Norm Difference for worker 1710 is 0.248869
INFO:root:FL Epoch: 361 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :966
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693171
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691932
INFO:root:FL Epoch: 361 Norm Difference for worker 966 is 0.071975
INFO:root:FL Epoch: 361 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :640
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692478
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689328
INFO:root:FL Epoch: 361 Norm Difference for worker 640 is 0.019436
INFO:root:FL Epoch: 361 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1848
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691784
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691149
INFO:root:FL Epoch: 361 Norm Difference for worker 1848 is 0.114283
INFO:root:FL Epoch: 361 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1504
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695945
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693295
INFO:root:FL Epoch: 361 Norm Difference for worker 1504 is 0.116911
INFO:root:FL Epoch: 361 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.6940987530876609 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.6602841019630432                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [648, 714, 824, 991, 1179, 1599, 585, 1926, 50, 1021]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :648
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693706
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693266
INFO:root:FL Epoch: 362 Norm Difference for worker 648 is 0.064508
INFO:root:FL Epoch: 362 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :714
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703732
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693286
INFO:root:FL Epoch: 362 Norm Difference for worker 714 is 0.150522
INFO:root:FL Epoch: 362 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :824
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700390
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690474
INFO:root:FL Epoch: 362 Norm Difference for worker 824 is 0.220478
INFO:root:FL Epoch: 362 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :991
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683679
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684489
INFO:root:FL Epoch: 362 Norm Difference for worker 991 is 0.063573
INFO:root:FL Epoch: 362 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1179
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690363
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694347
INFO:root:FL Epoch: 362 Norm Difference for worker 1179 is 0.060174
INFO:root:FL Epoch: 362 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1599
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693706
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701960
INFO:root:FL Epoch: 362 Norm Difference for worker 1599 is 0.039456
INFO:root:FL Epoch: 362 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :585
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697048
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693526
INFO:root:FL Epoch: 362 Norm Difference for worker 585 is 0.050015
INFO:root:FL Epoch: 362 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1926
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693706
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697384
INFO:root:FL Epoch: 362 Norm Difference for worker 1926 is 0.007423
INFO:root:FL Epoch: 362 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :50
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 50 is 0.177545
INFO:root:FL Epoch: 362 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1021
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697048
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690743
INFO:root:FL Epoch: 362 Norm Difference for worker 1021 is 0.007038
INFO:root:FL Epoch: 362 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.6936570546206307 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.6711272597312927                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [1332, 1401, 480, 1193, 838, 313, 1411, 1295, 877, 456]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :1332
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697849
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695451
INFO:root:FL Epoch: 363 Norm Difference for worker 1332 is 0.08901
INFO:root:FL Epoch: 363 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1401
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686715
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694373
INFO:root:FL Epoch: 363 Norm Difference for worker 1401 is 0.113466
INFO:root:FL Epoch: 363 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :480
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697849
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693245
INFO:root:FL Epoch: 363 Norm Difference for worker 480 is 0.030385
INFO:root:FL Epoch: 363 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1193
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684488
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681401
INFO:root:FL Epoch: 363 Norm Difference for worker 1193 is 0.238215
INFO:root:FL Epoch: 363 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :838
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697849
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693193
INFO:root:FL Epoch: 363 Norm Difference for worker 838 is 0.061801
INFO:root:FL Epoch: 363 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :313
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 313 is 0.004209
INFO:root:FL Epoch: 363 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1411
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700075
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693509
INFO:root:FL Epoch: 363 Norm Difference for worker 1411 is 0.024892
INFO:root:FL Epoch: 363 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1295
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688942
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694409
INFO:root:FL Epoch: 363 Norm Difference for worker 1295 is 0.04132
INFO:root:FL Epoch: 363 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :877
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691168
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697045
INFO:root:FL Epoch: 363 Norm Difference for worker 877 is 0.104747
INFO:root:FL Epoch: 363 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :456
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686715
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693470
INFO:root:FL Epoch: 363 Norm Difference for worker 456 is 0.019959
INFO:root:FL Epoch: 363 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.6933647359118742 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.6810389757156372                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [161, 1851, 1054, 165, 574, 185, 319, 539, 667, 303]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.10024938 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 364 Num points on workers: [201 200 200 201 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :161
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687130
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 161 is 0.037447
INFO:root:FL Epoch: 364 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1851
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695835
INFO:root:FL Epoch: 364 Norm Difference for worker 1851 is 0.022887
INFO:root:FL Epoch: 364 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1054
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695658
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692567
INFO:root:FL Epoch: 364 Norm Difference for worker 1054 is 0.05126
INFO:root:FL Epoch: 364 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :165
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692003
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 165 is 0.034771
INFO:root:FL Epoch: 364 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :574
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693463
INFO:root:FL Epoch: 364 Norm Difference for worker 574 is 0.090132
INFO:root:FL Epoch: 364 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :185
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 185 is 0.050423
INFO:root:FL Epoch: 364 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :319
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 319 is 0.010884
INFO:root:FL Epoch: 364 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :539
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690067
INFO:root:FL Epoch: 364 Norm Difference for worker 539 is 0.079438
INFO:root:FL Epoch: 364 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :667
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693221
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691275
INFO:root:FL Epoch: 364 Norm Difference for worker 667 is 0.009991
INFO:root:FL Epoch: 364 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :303
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 303 is 0.090783
INFO:root:FL Epoch: 364 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.6932014507405898 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.6892011761665344                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [184, 1587, 703, 353, 1442, 1376, 959, 669, 1830, 1102]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 365 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :184
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 184 is 0.092722
INFO:root:FL Epoch: 365 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1587
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694341
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693483
INFO:root:FL Epoch: 365 Norm Difference for worker 1587 is 0.057929
INFO:root:FL Epoch: 365 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :703
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693550
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 365 Norm Difference for worker 703 is 0.064039
INFO:root:FL Epoch: 365 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :353
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692364
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 365 Norm Difference for worker 353 is 0.011741
INFO:root:FL Epoch: 365 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1442
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692364
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695360
INFO:root:FL Epoch: 365 Norm Difference for worker 1442 is 0.053568
INFO:root:FL Epoch: 365 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1376
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694736
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 365 Norm Difference for worker 1376 is 0.032795
INFO:root:FL Epoch: 365 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :959
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691573
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698832
INFO:root:FL Epoch: 365 Norm Difference for worker 959 is 0.13245
INFO:root:FL Epoch: 365 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :669
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693550
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693262
INFO:root:FL Epoch: 365 Norm Difference for worker 669 is 0.01205
INFO:root:FL Epoch: 365 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1830
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693946
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692470
INFO:root:FL Epoch: 365 Norm Difference for worker 1830 is 0.02237
INFO:root:FL Epoch: 365 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1102
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693946
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700038
INFO:root:FL Epoch: 365 Norm Difference for worker 1102 is 0.136803
INFO:root:FL Epoch: 365 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.6931821213049048 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.6904821395874023                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1351, 1724, 887, 1192, 624, 1905, 629, 890, 1653, 1794]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1351
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692083
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697125
INFO:root:FL Epoch: 366 Norm Difference for worker 1351 is 0.179097
INFO:root:FL Epoch: 366 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1724
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692083
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698662
INFO:root:FL Epoch: 366 Norm Difference for worker 1724 is 0.009876
INFO:root:FL Epoch: 366 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :887
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692617
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686558
INFO:root:FL Epoch: 366 Norm Difference for worker 887 is 0.15168
INFO:root:FL Epoch: 366 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1192
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693684
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695517
INFO:root:FL Epoch: 366 Norm Difference for worker 1192 is 0.09583
INFO:root:FL Epoch: 366 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :624
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693572
INFO:root:FL Epoch: 366 Norm Difference for worker 624 is 0.018982
INFO:root:FL Epoch: 366 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1905
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692350
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689309
INFO:root:FL Epoch: 366 Norm Difference for worker 1905 is 0.042612
INFO:root:FL Epoch: 366 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :629
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692884
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693192
INFO:root:FL Epoch: 366 Norm Difference for worker 629 is 0.007771
INFO:root:FL Epoch: 366 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :890
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693418
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693264
INFO:root:FL Epoch: 366 Norm Difference for worker 890 is 0.041015
INFO:root:FL Epoch: 366 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1653
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689765
INFO:root:FL Epoch: 366 Norm Difference for worker 1653 is 0.174408
INFO:root:FL Epoch: 366 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1794
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692617
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691785
INFO:root:FL Epoch: 366 Norm Difference for worker 1794 is 0.039618
INFO:root:FL Epoch: 366 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.6931069282924428 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.6973098516464233                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [1509, 1066, 558, 1605, 399, 1525, 1148, 677, 1492, 327]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 367 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :1509
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693987
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694105
INFO:root:FL Epoch: 367 Norm Difference for worker 1509 is 0.052461
INFO:root:FL Epoch: 367 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1066
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693571
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692938
INFO:root:FL Epoch: 367 Norm Difference for worker 1066 is 0.021008
INFO:root:FL Epoch: 367 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :558
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691910
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693786
INFO:root:FL Epoch: 367 Norm Difference for worker 558 is 0.121713
INFO:root:FL Epoch: 367 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1605
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691910
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694907
INFO:root:FL Epoch: 367 Norm Difference for worker 1605 is 0.028198
INFO:root:FL Epoch: 367 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :399
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693987
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692368
INFO:root:FL Epoch: 367 Norm Difference for worker 399 is 0.019765
INFO:root:FL Epoch: 367 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1525
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692325
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696100
INFO:root:FL Epoch: 367 Norm Difference for worker 1525 is 0.032072
INFO:root:FL Epoch: 367 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1148
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692740
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691031
INFO:root:FL Epoch: 367 Norm Difference for worker 1148 is 0.134548
INFO:root:FL Epoch: 367 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :677
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692622
INFO:root:FL Epoch: 367 Norm Difference for worker 677 is 0.036054
INFO:root:FL Epoch: 367 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1492
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694402
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686063
INFO:root:FL Epoch: 367 Norm Difference for worker 1492 is 0.086796
INFO:root:FL Epoch: 367 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :327
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 327 is 0.068163
INFO:root:FL Epoch: 367 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.6931455976822797 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.6932817101478577                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [783, 277, 1708, 1063, 169, 1279, 247, 1366, 304, 1678]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 368 Num points on workers: [200 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :783
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685015
INFO:root:FL Epoch: 368 Norm Difference for worker 783 is 0.122793
INFO:root:FL Epoch: 368 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :277
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 277 is 0.003602
INFO:root:FL Epoch: 368 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1708
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693161
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693153
INFO:root:FL Epoch: 368 Norm Difference for worker 1708 is 0.030942
INFO:root:FL Epoch: 368 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1063
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693134
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693515
INFO:root:FL Epoch: 368 Norm Difference for worker 1063 is 0.033936
INFO:root:FL Epoch: 368 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :169
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 169 is 0.077879
INFO:root:FL Epoch: 368 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1279
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693200
INFO:root:FL Epoch: 368 Norm Difference for worker 1279 is 0.026188
INFO:root:FL Epoch: 368 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :247
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 247 is 0.144977
INFO:root:FL Epoch: 368 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1366
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691506
INFO:root:FL Epoch: 368 Norm Difference for worker 1366 is 0.017919
INFO:root:FL Epoch: 368 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :304
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 304 is 0.070552
INFO:root:FL Epoch: 368 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1678
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692086
INFO:root:FL Epoch: 368 Norm Difference for worker 1678 is 0.003444
INFO:root:FL Epoch: 368 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.6931022826363059 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.697947084903717                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [897, 768, 199, 1231, 1007, 245, 1031, 439, 680, 841]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :897
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692680
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689632
INFO:root:FL Epoch: 369 Norm Difference for worker 897 is 0.031755
INFO:root:FL Epoch: 369 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :768
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694116
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702916
INFO:root:FL Epoch: 369 Norm Difference for worker 768 is 0.136007
INFO:root:FL Epoch: 369 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :199
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 199 is 0.063784
INFO:root:FL Epoch: 369 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1231
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693637
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690881
INFO:root:FL Epoch: 369 Norm Difference for worker 1231 is 0.020699
INFO:root:FL Epoch: 369 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1007
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693637
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693652
INFO:root:FL Epoch: 369 Norm Difference for worker 1007 is 0.166745
INFO:root:FL Epoch: 369 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :245
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 245 is 0.05425
INFO:root:FL Epoch: 369 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1031
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691722
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688397
INFO:root:FL Epoch: 369 Norm Difference for worker 1031 is 0.069963
INFO:root:FL Epoch: 369 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :439
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693637
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691896
INFO:root:FL Epoch: 369 Norm Difference for worker 439 is 0.087795
INFO:root:FL Epoch: 369 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :680
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692201
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689551
INFO:root:FL Epoch: 369 Norm Difference for worker 680 is 0.121562
INFO:root:FL Epoch: 369 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :841
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694116
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686504
INFO:root:FL Epoch: 369 Norm Difference for worker 841 is 0.084223
INFO:root:FL Epoch: 369 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.6930780165335712 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.7053338289260864                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [78, 158, 1509, 571, 30, 818, 201, 1021, 185, 750]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 370 Num points on workers: [201 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :78
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692009
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 78 is 0.094118
INFO:root:FL Epoch: 370 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :158
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 158 is 0.04724
INFO:root:FL Epoch: 370 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1509
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696855
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694031
INFO:root:FL Epoch: 370 Norm Difference for worker 1509 is 0.072957
INFO:root:FL Epoch: 370 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :571
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694432
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700057
INFO:root:FL Epoch: 370 Norm Difference for worker 571 is 0.034012
INFO:root:FL Epoch: 370 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :30
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692009
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 30 is 0.023214
INFO:root:FL Epoch: 370 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :818
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690798
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687814
INFO:root:FL Epoch: 370 Norm Difference for worker 818 is 0.143461
INFO:root:FL Epoch: 370 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :201
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704807
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 201 is 0.080313
INFO:root:FL Epoch: 370 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1021
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698066
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695246
INFO:root:FL Epoch: 370 Norm Difference for worker 1021 is 0.044504
INFO:root:FL Epoch: 370 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :185
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692817
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 185 is 0.061942
INFO:root:FL Epoch: 370 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :750
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689587
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693153
INFO:root:FL Epoch: 370 Norm Difference for worker 750 is 0.112315
INFO:root:FL Epoch: 370 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.6930811370120329 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.7024292945861816                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 1061, 1042, 1852, 1271, 1167, 671, 986]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693190
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692826
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.6676303148269653 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.6867600977420807 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.070181
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695962
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692286
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.6656435132026672 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.6862841010093689 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.074264
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698734
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690003
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.6631239652633667 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.6856850564479828 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.079455
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1061
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695038
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678749
INFO:root:FL Epoch: 371 Norm Difference for worker 1061 is 0.141736
INFO:root:FL Epoch: 371 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1042
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693190
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697613
INFO:root:FL Epoch: 371 Norm Difference for worker 1042 is 0.088808
INFO:root:FL Epoch: 371 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1852
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695962
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691912
INFO:root:FL Epoch: 371 Norm Difference for worker 1852 is 0.037894
INFO:root:FL Epoch: 371 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1271
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693190
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697268
INFO:root:FL Epoch: 371 Norm Difference for worker 1271 is 0.032231
INFO:root:FL Epoch: 371 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1167
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693190
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694841
INFO:root:FL Epoch: 371 Norm Difference for worker 1167 is 0.129184
INFO:root:FL Epoch: 371 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :671
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694114
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691641
INFO:root:FL Epoch: 371 Norm Difference for worker 671 is 0.01657
INFO:root:FL Epoch: 371 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :986
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696886
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681725
INFO:root:FL Epoch: 371 Norm Difference for worker 986 is 0.13588
INFO:root:FL Epoch: 371 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.6931594645275789 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.6921438574790955                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1304, 439, 523, 1858, 473, 17, 1491, 1571, 364, 119]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1304
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692947
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693240
INFO:root:FL Epoch: 372 Norm Difference for worker 1304 is 0.032643
INFO:root:FL Epoch: 372 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :439
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693449
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686545
INFO:root:FL Epoch: 372 Norm Difference for worker 439 is 0.10094
INFO:root:FL Epoch: 372 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :523
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692947
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690293
INFO:root:FL Epoch: 372 Norm Difference for worker 523 is 0.159714
INFO:root:FL Epoch: 372 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1858
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693248
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695519
INFO:root:FL Epoch: 372 Norm Difference for worker 1858 is 0.072586
INFO:root:FL Epoch: 372 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :473
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693348
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695063
INFO:root:FL Epoch: 372 Norm Difference for worker 473 is 0.055644
INFO:root:FL Epoch: 372 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :17
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682386
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 17 is 0.165229
INFO:root:FL Epoch: 372 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1491
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697418
INFO:root:FL Epoch: 372 Norm Difference for worker 1491 is 0.030903
INFO:root:FL Epoch: 372 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1571
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693248
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694455
INFO:root:FL Epoch: 372 Norm Difference for worker 1571 is 0.045092
INFO:root:FL Epoch: 372 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :364
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692746
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694355
INFO:root:FL Epoch: 372 Norm Difference for worker 364 is 0.057669
INFO:root:FL Epoch: 372 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :119
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694017
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 119 is 0.199521
INFO:root:FL Epoch: 372 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.6942441919270683 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.6572808623313904                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [1519, 1509, 112, 1748, 415, 1017, 782, 1715, 1356, 1342]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :1519
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679201
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694753
INFO:root:FL Epoch: 373 Norm Difference for worker 1519 is 0.052643
INFO:root:FL Epoch: 373 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1509
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675548
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694192
INFO:root:FL Epoch: 373 Norm Difference for worker 1509 is 0.006277
INFO:root:FL Epoch: 373 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :112
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 112 is 0.045536
INFO:root:FL Epoch: 373 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1748
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701121
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693485
INFO:root:FL Epoch: 373 Norm Difference for worker 1748 is 0.116455
INFO:root:FL Epoch: 373 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :415
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693814
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696617
INFO:root:FL Epoch: 373 Norm Difference for worker 415 is 0.05377
INFO:root:FL Epoch: 373 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1017
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697468
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702203
INFO:root:FL Epoch: 373 Norm Difference for worker 1017 is 0.010547
INFO:root:FL Epoch: 373 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :782
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686508
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694288
INFO:root:FL Epoch: 373 Norm Difference for worker 782 is 0.012791
INFO:root:FL Epoch: 373 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1715
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701121
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696388
INFO:root:FL Epoch: 373 Norm Difference for worker 1715 is 0.03786
INFO:root:FL Epoch: 373 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1356
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690161
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701488
INFO:root:FL Epoch: 373 Norm Difference for worker 1356 is 0.137194
INFO:root:FL Epoch: 373 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1342
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690161
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688668
INFO:root:FL Epoch: 373 Norm Difference for worker 1342 is 0.087141
INFO:root:FL Epoch: 373 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.6934206415625179 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.6788364052772522                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1498, 804, 643, 1075, 1437, 74, 979, 516, 1748, 1798]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1498
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690368
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695216
INFO:root:FL Epoch: 374 Norm Difference for worker 1498 is 0.022721
INFO:root:FL Epoch: 374 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :804
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693246
INFO:root:FL Epoch: 374 Norm Difference for worker 804 is 0.010437
INFO:root:FL Epoch: 374 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :643
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701199
INFO:root:FL Epoch: 374 Norm Difference for worker 643 is 0.081925
INFO:root:FL Epoch: 374 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1075
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684244
INFO:root:FL Epoch: 374 Norm Difference for worker 1075 is 0.050933
INFO:root:FL Epoch: 374 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1437
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691347
INFO:root:FL Epoch: 374 Norm Difference for worker 1437 is 0.035765
INFO:root:FL Epoch: 374 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :74
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691033
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 74 is 0.096002
INFO:root:FL Epoch: 374 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :979
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691810
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693618
INFO:root:FL Epoch: 374 Norm Difference for worker 979 is 0.096041
INFO:root:FL Epoch: 374 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :516
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693251
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693840
INFO:root:FL Epoch: 374 Norm Difference for worker 516 is 0.110976
INFO:root:FL Epoch: 374 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1748
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696134
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693205
INFO:root:FL Epoch: 374 Norm Difference for worker 1748 is 0.100395
INFO:root:FL Epoch: 374 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1798
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690368
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698854
INFO:root:FL Epoch: 374 Norm Difference for worker 1798 is 0.121187
INFO:root:FL Epoch: 374 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.6937618080307456 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.6682490706443787                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [317, 105, 1425, 1249, 401, 243, 53, 960, 1525, 1533]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 375 Num points on workers: [201 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :317
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 317 is 0.009312
INFO:root:FL Epoch: 375 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :105
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.715735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 105 is 0.159692
INFO:root:FL Epoch: 375 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1425
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698508
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686908
INFO:root:FL Epoch: 375 Norm Difference for worker 1425 is 0.016074
INFO:root:FL Epoch: 375 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1249
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698508
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689666
INFO:root:FL Epoch: 375 Norm Difference for worker 1249 is 0.202349
INFO:root:FL Epoch: 375 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :401
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698508
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687665
INFO:root:FL Epoch: 375 Norm Difference for worker 401 is 0.008776
INFO:root:FL Epoch: 375 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :243
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 243 is 0.024666
INFO:root:FL Epoch: 375 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :53
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690944
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 53 is 0.075438
INFO:root:FL Epoch: 375 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :960
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695987
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 375 Norm Difference for worker 960 is 0.104451
INFO:root:FL Epoch: 375 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1525
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695987
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 375 Norm Difference for worker 1525 is 0.09953
INFO:root:FL Epoch: 375 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1533
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693465
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695729
INFO:root:FL Epoch: 375 Norm Difference for worker 1533 is 0.011192
INFO:root:FL Epoch: 375 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.6932630258447984 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.6857023239135742                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1397, 18, 956, 910, 205, 740, 1557, 1744, 425, 1208]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 376 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1397
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696164
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685566
INFO:root:FL Epoch: 376 Norm Difference for worker 1397 is 0.22406
INFO:root:FL Epoch: 376 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :18
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 18 is 0.04151
INFO:root:FL Epoch: 376 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :956
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693175
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692582
INFO:root:FL Epoch: 376 Norm Difference for worker 956 is 0.01288
INFO:root:FL Epoch: 376 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :910
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692428
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694830
INFO:root:FL Epoch: 376 Norm Difference for worker 910 is 0.072817
INFO:root:FL Epoch: 376 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :205
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 205 is 0.063235
INFO:root:FL Epoch: 376 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :740
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692428
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691961
INFO:root:FL Epoch: 376 Norm Difference for worker 740 is 0.040809
INFO:root:FL Epoch: 376 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1557
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692428
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690770
INFO:root:FL Epoch: 376 Norm Difference for worker 1557 is 0.118364
INFO:root:FL Epoch: 376 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1744
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696164
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700447
INFO:root:FL Epoch: 376 Norm Difference for worker 1744 is 0.05034
INFO:root:FL Epoch: 376 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :425
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693922
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697862
INFO:root:FL Epoch: 376 Norm Difference for worker 425 is 0.142406
INFO:root:FL Epoch: 376 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1208
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693175
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693230
INFO:root:FL Epoch: 376 Norm Difference for worker 1208 is 0.012678
INFO:root:FL Epoch: 376 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.6930977842387032 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.6986222863197327                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [1407, 59, 1055, 261, 1932, 581, 1253, 23, 462, 1153]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :1407
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693708
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691139
INFO:root:FL Epoch: 377 Norm Difference for worker 1407 is 0.054405
INFO:root:FL Epoch: 377 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :59
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 59 is 0.117459
INFO:root:FL Epoch: 377 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1055
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693162
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691087
INFO:root:FL Epoch: 377 Norm Difference for worker 1055 is 0.104506
INFO:root:FL Epoch: 377 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :261
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 261 is 0.084175
INFO:root:FL Epoch: 377 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1932
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693162
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685882
INFO:root:FL Epoch: 377 Norm Difference for worker 1932 is 0.065311
INFO:root:FL Epoch: 377 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :581
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693162
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691532
INFO:root:FL Epoch: 377 Norm Difference for worker 581 is 0.017229
INFO:root:FL Epoch: 377 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1253
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693708
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700162
INFO:root:FL Epoch: 377 Norm Difference for worker 1253 is 0.134181
INFO:root:FL Epoch: 377 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :23
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692070
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 23 is 0.035061
INFO:root:FL Epoch: 377 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :462
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692616
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 377 Norm Difference for worker 462 is 0.002992
INFO:root:FL Epoch: 377 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1153
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692070
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698413
INFO:root:FL Epoch: 377 Norm Difference for worker 1153 is 0.058676
INFO:root:FL Epoch: 377 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.6931017497006584 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.6980287432670593                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1066, 1905, 777, 1310, 1028, 1906, 169, 573, 888, 1462]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1066
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694075
INFO:root:FL Epoch: 378 Norm Difference for worker 1066 is 0.019501
INFO:root:FL Epoch: 378 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1905
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692966
INFO:root:FL Epoch: 378 Norm Difference for worker 1905 is 0.052669
INFO:root:FL Epoch: 378 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :777
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694982
INFO:root:FL Epoch: 378 Norm Difference for worker 777 is 0.007613
INFO:root:FL Epoch: 378 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1310
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691211
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693197
INFO:root:FL Epoch: 378 Norm Difference for worker 1310 is 0.052829
INFO:root:FL Epoch: 378 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1028
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691698
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692553
INFO:root:FL Epoch: 378 Norm Difference for worker 1028 is 0.140323
INFO:root:FL Epoch: 378 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1906
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692185
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693189
INFO:root:FL Epoch: 378 Norm Difference for worker 1906 is 0.008899
INFO:root:FL Epoch: 378 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :169
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 169 is 0.087895
INFO:root:FL Epoch: 378 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :573
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692672
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692117
INFO:root:FL Epoch: 378 Norm Difference for worker 573 is 0.012295
INFO:root:FL Epoch: 378 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :888
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691698
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696227
INFO:root:FL Epoch: 378 Norm Difference for worker 888 is 0.015461
INFO:root:FL Epoch: 378 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1462
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694133
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689483
INFO:root:FL Epoch: 378 Norm Difference for worker 1462 is 0.15849
INFO:root:FL Epoch: 378 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.6932234588791343 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.6878685355186462                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1554, 794, 1231, 1576, 294, 838, 310, 790, 612, 300]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1554
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692632
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669074
INFO:root:FL Epoch: 379 Norm Difference for worker 1554 is 0.254669
INFO:root:FL Epoch: 379 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :794
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692103
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685293
INFO:root:FL Epoch: 379 Norm Difference for worker 794 is 0.149896
INFO:root:FL Epoch: 379 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1231
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692632
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689333
INFO:root:FL Epoch: 379 Norm Difference for worker 1231 is 0.037528
INFO:root:FL Epoch: 379 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1576
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693690
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692707
INFO:root:FL Epoch: 379 Norm Difference for worker 1576 is 0.044902
INFO:root:FL Epoch: 379 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :294
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700952
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 294 is 0.131067
INFO:root:FL Epoch: 379 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :838
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694749
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693158
INFO:root:FL Epoch: 379 Norm Difference for worker 838 is 0.02226
INFO:root:FL Epoch: 379 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :310
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 310 is 0.002735
INFO:root:FL Epoch: 379 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :790
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695808
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 379 Norm Difference for worker 790 is 0.044113
INFO:root:FL Epoch: 379 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :612
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694749
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677645
INFO:root:FL Epoch: 379 Norm Difference for worker 612 is 0.112721
INFO:root:FL Epoch: 379 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :300
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688311
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 300 is 0.047931
INFO:root:FL Epoch: 379 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.6940712753464194 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.6608776450157166                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [932, 1259, 1268, 1635, 1840, 651, 1586, 332, 1409, 1110]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :932
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690405
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676811
INFO:root:FL Epoch: 380 Norm Difference for worker 932 is 0.052188
INFO:root:FL Epoch: 380 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1259
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693685
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695191
INFO:root:FL Epoch: 380 Norm Difference for worker 1259 is 0.056255
INFO:root:FL Epoch: 380 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1268
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706808
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693337
INFO:root:FL Epoch: 380 Norm Difference for worker 1268 is 0.022088
INFO:root:FL Epoch: 380 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1635
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700247
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689984
INFO:root:FL Epoch: 380 Norm Difference for worker 1635 is 0.219703
INFO:root:FL Epoch: 380 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1840
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706808
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692017
INFO:root:FL Epoch: 380 Norm Difference for worker 1840 is 0.187781
INFO:root:FL Epoch: 380 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :651
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700247
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698271
INFO:root:FL Epoch: 380 Norm Difference for worker 651 is 0.011114
INFO:root:FL Epoch: 380 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1586
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706808
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695654
INFO:root:FL Epoch: 380 Norm Difference for worker 1586 is 0.092801
INFO:root:FL Epoch: 380 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :332
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 332 is 0.011812
INFO:root:FL Epoch: 380 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1409
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696966
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693467
INFO:root:FL Epoch: 380 Norm Difference for worker 1409 is 0.062124
INFO:root:FL Epoch: 380 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1110
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690405
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689288
INFO:root:FL Epoch: 380 Norm Difference for worker 1110 is 0.09294
INFO:root:FL Epoch: 380 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.6932747258859522 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.6851030588150024                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 1679, 116, 928, 1045, 563, 1144, 438]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689283
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.6522169709205627 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.6831517398357392 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.067454
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689141
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686960
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.6525655388832092 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.6832311391830445 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.066727
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691564
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699681
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.6535033583641052 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.683445394039154 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.064771
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1679
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691535
INFO:root:FL Epoch: 381 Norm Difference for worker 1679 is 0.089885
INFO:root:FL Epoch: 381 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :116
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 116 is 0.117571
INFO:root:FL Epoch: 381 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :928
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692372
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692264
INFO:root:FL Epoch: 381 Norm Difference for worker 928 is 0.069579
INFO:root:FL Epoch: 381 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1045
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691564
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703242
INFO:root:FL Epoch: 381 Norm Difference for worker 1045 is 0.127163
INFO:root:FL Epoch: 381 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :563
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693180
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690865
INFO:root:FL Epoch: 381 Norm Difference for worker 563 is 0.1016
INFO:root:FL Epoch: 381 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1144
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693987
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689063
INFO:root:FL Epoch: 381 Norm Difference for worker 1144 is 0.042922
INFO:root:FL Epoch: 381 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :438
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689141
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677754
INFO:root:FL Epoch: 381 Norm Difference for worker 438 is 0.194314
INFO:root:FL Epoch: 381 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.693846162627725 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.6660900712013245                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [305, 780, 1929, 1520, 481, 1295, 101, 560, 999, 452]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 382 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :305
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679807
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 305 is 0.052583
INFO:root:FL Epoch: 382 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :780
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701753
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691697
INFO:root:FL Epoch: 382 Norm Difference for worker 780 is 0.143064
INFO:root:FL Epoch: 382 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1929
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696267
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688540
INFO:root:FL Epoch: 382 Norm Difference for worker 1929 is 0.042115
INFO:root:FL Epoch: 382 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1520
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688037
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690823
INFO:root:FL Epoch: 382 Norm Difference for worker 1520 is 0.03436
INFO:root:FL Epoch: 382 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :481
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699010
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698293
INFO:root:FL Epoch: 382 Norm Difference for worker 481 is 0.03878
INFO:root:FL Epoch: 382 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1295
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682550
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697482
INFO:root:FL Epoch: 382 Norm Difference for worker 1295 is 0.07451
INFO:root:FL Epoch: 382 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :101
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 101 is 0.099794
INFO:root:FL Epoch: 382 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :560
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696267
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694217
INFO:root:FL Epoch: 382 Norm Difference for worker 560 is 0.047954
INFO:root:FL Epoch: 382 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :999
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707240
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691834
INFO:root:FL Epoch: 382 Norm Difference for worker 999 is 0.075928
INFO:root:FL Epoch: 382 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :452
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699010
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693742
INFO:root:FL Epoch: 382 Norm Difference for worker 452 is 0.163634
INFO:root:FL Epoch: 382 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.6932641127530266 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.6856464743614197                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [1594, 712, 1782, 1693, 835, 153, 986, 618, 24, 1431]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :1594
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690917
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693377
INFO:root:FL Epoch: 383 Norm Difference for worker 1594 is 0.063323
INFO:root:FL Epoch: 383 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :712
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695434
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695698
INFO:root:FL Epoch: 383 Norm Difference for worker 712 is 0.105443
INFO:root:FL Epoch: 383 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1782
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690917
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692156
INFO:root:FL Epoch: 383 Norm Difference for worker 1782 is 0.124561
INFO:root:FL Epoch: 383 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1693
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693928
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691180
INFO:root:FL Epoch: 383 Norm Difference for worker 1693 is 0.022526
INFO:root:FL Epoch: 383 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :835
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693175
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695174
INFO:root:FL Epoch: 383 Norm Difference for worker 835 is 0.030012
INFO:root:FL Epoch: 383 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :153
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 153 is 0.140348
INFO:root:FL Epoch: 383 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :986
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691670
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690257
INFO:root:FL Epoch: 383 Norm Difference for worker 986 is 0.120207
INFO:root:FL Epoch: 383 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :618
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693176
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689704
INFO:root:FL Epoch: 383 Norm Difference for worker 618 is 0.064108
INFO:root:FL Epoch: 383 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :24
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690164
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 24 is 0.008823
INFO:root:FL Epoch: 383 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1431
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692423
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693226
INFO:root:FL Epoch: 383 Norm Difference for worker 1431 is 0.007633
INFO:root:FL Epoch: 383 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.6931229549295762 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.6954253911972046                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [459, 540, 192, 1368, 424, 223, 444, 1119, 917, 1924]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :459
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688290
INFO:root:FL Epoch: 384 Norm Difference for worker 459 is 0.087121
INFO:root:FL Epoch: 384 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :540
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693377
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692837
INFO:root:FL Epoch: 384 Norm Difference for worker 540 is 0.043559
INFO:root:FL Epoch: 384 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :192
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693605
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693764
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 192 is 0.015845
INFO:root:FL Epoch: 384 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1368
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692467
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693646
INFO:root:FL Epoch: 384 Norm Difference for worker 1368 is 0.028055
INFO:root:FL Epoch: 384 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :424
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693605
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690975
INFO:root:FL Epoch: 384 Norm Difference for worker 424 is 0.044614
INFO:root:FL Epoch: 384 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :223
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693318
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 223 is 0.04398
INFO:root:FL Epoch: 384 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :444
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693150
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682987
INFO:root:FL Epoch: 384 Norm Difference for worker 444 is 0.188996
INFO:root:FL Epoch: 384 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1119
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692922
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690611
INFO:root:FL Epoch: 384 Norm Difference for worker 1119 is 0.091142
INFO:root:FL Epoch: 384 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :917
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693377
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696902
INFO:root:FL Epoch: 384 Norm Difference for worker 917 is 0.02606
INFO:root:FL Epoch: 384 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1924
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694287
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693407
INFO:root:FL Epoch: 384 Norm Difference for worker 1924 is 0.060501
INFO:root:FL Epoch: 384 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.6931446369956521 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.7167341113090515                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [1334, 1921, 1397, 757, 1041, 1479, 1249, 1807, 357, 1506]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 385 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :1334
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698082
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695159
INFO:root:FL Epoch: 385 Norm Difference for worker 1334 is 0.04579
INFO:root:FL Epoch: 385 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1921
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688756
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699851
INFO:root:FL Epoch: 385 Norm Difference for worker 1921 is 0.018147
INFO:root:FL Epoch: 385 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1397
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686424
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689234
INFO:root:FL Epoch: 385 Norm Difference for worker 1397 is 0.139459
INFO:root:FL Epoch: 385 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :757
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695751
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694533
INFO:root:FL Epoch: 385 Norm Difference for worker 757 is 0.060732
INFO:root:FL Epoch: 385 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1041
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698082
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683158
INFO:root:FL Epoch: 385 Norm Difference for worker 1041 is 0.071441
INFO:root:FL Epoch: 385 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1479
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688756
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701832
INFO:root:FL Epoch: 385 Norm Difference for worker 1479 is 0.040398
INFO:root:FL Epoch: 385 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1249
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695750
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694584
INFO:root:FL Epoch: 385 Norm Difference for worker 1249 is 0.149169
INFO:root:FL Epoch: 385 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1807
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684093
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688678
INFO:root:FL Epoch: 385 Norm Difference for worker 1807 is 0.177567
INFO:root:FL Epoch: 385 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :357
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691087
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696034
INFO:root:FL Epoch: 385 Norm Difference for worker 357 is 0.013462
INFO:root:FL Epoch: 385 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1506
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700413
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691179
INFO:root:FL Epoch: 385 Norm Difference for worker 1506 is 0.000101
INFO:root:FL Epoch: 385 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.6937513702055987 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.7427979111671448                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [546, 1815, 707, 353, 765, 248, 1947, 1395, 1735, 1729]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :546
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699169
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689894
INFO:root:FL Epoch: 386 Norm Difference for worker 546 is 0.013878
INFO:root:FL Epoch: 386 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1815
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689474
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679728
INFO:root:FL Epoch: 386 Norm Difference for worker 1815 is 0.046959
INFO:root:FL Epoch: 386 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :707
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699169
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686502
INFO:root:FL Epoch: 386 Norm Difference for worker 707 is 0.043172
INFO:root:FL Epoch: 386 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :353
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694322
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690498
INFO:root:FL Epoch: 386 Norm Difference for worker 353 is 0.048315
INFO:root:FL Epoch: 386 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :765
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699169
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695884
INFO:root:FL Epoch: 386 Norm Difference for worker 765 is 0.113699
INFO:root:FL Epoch: 386 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :248
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 248 is 0.073825
INFO:root:FL Epoch: 386 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1947
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708865
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693646
INFO:root:FL Epoch: 386 Norm Difference for worker 1947 is 0.059291
INFO:root:FL Epoch: 386 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1395
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708865
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697975
INFO:root:FL Epoch: 386 Norm Difference for worker 1395 is 0.096767
INFO:root:FL Epoch: 386 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1735
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699169
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700731
INFO:root:FL Epoch: 386 Norm Difference for worker 1735 is 0.042887
INFO:root:FL Epoch: 386 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1729
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694322
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690867
INFO:root:FL Epoch: 386 Norm Difference for worker 1729 is 0.129299
INFO:root:FL Epoch: 386 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.693196763010586 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.7206955552101135                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [134, 1507, 700, 1293, 1148, 473, 855, 1266, 170, 422]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 387 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :134
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 134 is 0.082332
INFO:root:FL Epoch: 387 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1507
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701670
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694013
INFO:root:FL Epoch: 387 Norm Difference for worker 1507 is 0.070527
INFO:root:FL Epoch: 387 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :700
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701670
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692273
INFO:root:FL Epoch: 387 Norm Difference for worker 700 is 0.126529
INFO:root:FL Epoch: 387 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1293
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688081
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 387 Norm Difference for worker 1293 is 0.137385
INFO:root:FL Epoch: 387 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1148
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701670
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687920
INFO:root:FL Epoch: 387 Norm Difference for worker 1148 is 0.184239
INFO:root:FL Epoch: 387 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :473
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701670
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692405
INFO:root:FL Epoch: 387 Norm Difference for worker 473 is 0.108425
INFO:root:FL Epoch: 387 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :855
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690799
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693802
INFO:root:FL Epoch: 387 Norm Difference for worker 855 is 0.039605
INFO:root:FL Epoch: 387 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1266
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685363
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701184
INFO:root:FL Epoch: 387 Norm Difference for worker 1266 is 0.088208
INFO:root:FL Epoch: 387 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :170
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 170 is 0.17718
INFO:root:FL Epoch: 387 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :422
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693517
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699306
INFO:root:FL Epoch: 387 Norm Difference for worker 422 is 0.068539
INFO:root:FL Epoch: 387 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.6931577324867249 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.6922827959060669                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [832, 1256, 1254, 1459, 72, 786, 887, 1099, 1137, 333]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 388 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :832
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693061
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693306
INFO:root:FL Epoch: 388 Norm Difference for worker 832 is 0.077459
INFO:root:FL Epoch: 388 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1256
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692802
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695261
INFO:root:FL Epoch: 388 Norm Difference for worker 1256 is 0.041453
INFO:root:FL Epoch: 388 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1254
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693493
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690605
INFO:root:FL Epoch: 388 Norm Difference for worker 1254 is 0.086358
INFO:root:FL Epoch: 388 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1459
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693320
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692849
INFO:root:FL Epoch: 388 Norm Difference for worker 1459 is 0.045345
INFO:root:FL Epoch: 388 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :72
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 72 is 0.038132
INFO:root:FL Epoch: 388 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :786
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693061
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687623
INFO:root:FL Epoch: 388 Norm Difference for worker 786 is 0.096014
INFO:root:FL Epoch: 388 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :887
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690231
INFO:root:FL Epoch: 388 Norm Difference for worker 887 is 0.116308
INFO:root:FL Epoch: 388 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1099
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693320
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690919
INFO:root:FL Epoch: 388 Norm Difference for worker 1099 is 0.112921
INFO:root:FL Epoch: 388 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1137
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692975
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692157
INFO:root:FL Epoch: 388 Norm Difference for worker 1137 is 0.012417
INFO:root:FL Epoch: 388 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :333
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691294
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 333 is 0.100158
INFO:root:FL Epoch: 388 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.6930792156387778 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.7066069841384888                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [1513, 991, 1679, 1102, 716, 905, 546, 26, 1404, 1045]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :1513
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687888
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694885
INFO:root:FL Epoch: 389 Norm Difference for worker 1513 is 0.071521
INFO:root:FL Epoch: 389 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :991
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695911
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693175
INFO:root:FL Epoch: 389 Norm Difference for worker 991 is 0.112681
INFO:root:FL Epoch: 389 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1679
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697248
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703956
INFO:root:FL Epoch: 389 Norm Difference for worker 1679 is 0.039912
INFO:root:FL Epoch: 389 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1102
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695911
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689758
INFO:root:FL Epoch: 389 Norm Difference for worker 1102 is 0.177516
INFO:root:FL Epoch: 389 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :716
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693237
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687738
INFO:root:FL Epoch: 389 Norm Difference for worker 716 is 0.074749
INFO:root:FL Epoch: 389 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :905
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693237
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696803
INFO:root:FL Epoch: 389 Norm Difference for worker 905 is 0.140129
INFO:root:FL Epoch: 389 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :546
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693237
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694786
INFO:root:FL Epoch: 389 Norm Difference for worker 546 is 0.018542
INFO:root:FL Epoch: 389 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :26
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 26 is 0.082934
INFO:root:FL Epoch: 389 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1404
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697248
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693968
INFO:root:FL Epoch: 389 Norm Difference for worker 1404 is 0.001973
INFO:root:FL Epoch: 389 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1045
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694574
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695305
INFO:root:FL Epoch: 389 Norm Difference for worker 1045 is 0.161283
INFO:root:FL Epoch: 389 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.6931686120874742 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.6914485692977905                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [481, 1862, 29, 100, 807, 1488, 787, 447, 839, 251]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 390 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :481
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692639
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692055
INFO:root:FL Epoch: 390 Norm Difference for worker 481 is 0.028503
INFO:root:FL Epoch: 390 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1862
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693489
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692964
INFO:root:FL Epoch: 390 Norm Difference for worker 1862 is 0.03461
INFO:root:FL Epoch: 390 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :29
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693049
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 29 is 0.00241
INFO:root:FL Epoch: 390 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :100
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 100 is 0.117275
INFO:root:FL Epoch: 390 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :807
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692979
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693172
INFO:root:FL Epoch: 390 Norm Difference for worker 807 is 0.006353
INFO:root:FL Epoch: 390 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1488
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693319
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688161
INFO:root:FL Epoch: 390 Norm Difference for worker 1488 is 0.03005
INFO:root:FL Epoch: 390 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :787
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692809
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687634
INFO:root:FL Epoch: 390 Norm Difference for worker 787 is 0.146937
INFO:root:FL Epoch: 390 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :447
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693319
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689972
INFO:root:FL Epoch: 390 Norm Difference for worker 447 is 0.035873
INFO:root:FL Epoch: 390 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :839
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 390 Norm Difference for worker 839 is 0.026954
INFO:root:FL Epoch: 390 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :251
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 251 is 0.051826
INFO:root:FL Epoch: 390 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.6931655862752129 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.6916751265525818                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 586, 541, 389, 613, 1869, 1176, 937]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692412
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688711
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.6577758193016052 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.6844305634498596 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.069093
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692706
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687881
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.6568032503128052 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.6842049360275269 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.071112
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692412
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686739
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.6573556661605835 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.6843330025672912 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.069965
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :586
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692706
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693599
INFO:root:FL Epoch: 391 Norm Difference for worker 586 is 0.005963
INFO:root:FL Epoch: 391 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :541
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692854
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692359
INFO:root:FL Epoch: 391 Norm Difference for worker 541 is 0.036252
INFO:root:FL Epoch: 391 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :389
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693001
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692790
INFO:root:FL Epoch: 391 Norm Difference for worker 389 is 0.019416
INFO:root:FL Epoch: 391 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :613
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692854
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693184
INFO:root:FL Epoch: 391 Norm Difference for worker 613 is 0.01441
INFO:root:FL Epoch: 391 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1869
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692559
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692646
INFO:root:FL Epoch: 391 Norm Difference for worker 1869 is 0.031163
INFO:root:FL Epoch: 391 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1176
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692854
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697217
INFO:root:FL Epoch: 391 Norm Difference for worker 1176 is 0.013922
INFO:root:FL Epoch: 391 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :937
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693738
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691673
INFO:root:FL Epoch: 391 Norm Difference for worker 937 is 0.048277
INFO:root:FL Epoch: 391 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.6935515508932226 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.674316942691803                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [70, 1309, 1645, 252, 695, 1298, 1816, 1469, 1559, 596]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 392 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :70
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687794
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 70 is 0.13413
INFO:root:FL Epoch: 392 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1309
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695229
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693352
INFO:root:FL Epoch: 392 Norm Difference for worker 1309 is 0.026997
INFO:root:FL Epoch: 392 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1645
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691427
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698048
INFO:root:FL Epoch: 392 Norm Difference for worker 1645 is 0.081483
INFO:root:FL Epoch: 392 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :252
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 252 is 0.006579
INFO:root:FL Epoch: 392 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :695
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691427
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684962
INFO:root:FL Epoch: 392 Norm Difference for worker 695 is 0.127019
INFO:root:FL Epoch: 392 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1298
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699031
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694421
INFO:root:FL Epoch: 392 Norm Difference for worker 1298 is 0.039604
INFO:root:FL Epoch: 392 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1816
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695229
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689190
INFO:root:FL Epoch: 392 Norm Difference for worker 1816 is 0.032915
INFO:root:FL Epoch: 392 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1469
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691427
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695906
INFO:root:FL Epoch: 392 Norm Difference for worker 1469 is 0.051508
INFO:root:FL Epoch: 392 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1559
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700932
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695346
INFO:root:FL Epoch: 392 Norm Difference for worker 1559 is 0.010769
INFO:root:FL Epoch: 392 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :596
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702833
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695265
INFO:root:FL Epoch: 392 Norm Difference for worker 596 is 0.067586
INFO:root:FL Epoch: 392 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.693667867604424 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.6708194613456726                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [1910, 681, 119, 86, 1536, 40, 1747, 1300, 59, 902]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :1910
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686627
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682051
INFO:root:FL Epoch: 393 Norm Difference for worker 1910 is 0.08905
INFO:root:FL Epoch: 393 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :681
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697919
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692886
INFO:root:FL Epoch: 393 Norm Difference for worker 681 is 0.100727
INFO:root:FL Epoch: 393 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :119
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 119 is 0.158307
INFO:root:FL Epoch: 393 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :86
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695660
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 86 is 0.052185
INFO:root:FL Epoch: 393 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1536
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688886
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680336
INFO:root:FL Epoch: 393 Norm Difference for worker 1536 is 0.010278
INFO:root:FL Epoch: 393 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :40
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 40 is 0.122116
INFO:root:FL Epoch: 393 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1747
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697919
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695617
INFO:root:FL Epoch: 393 Norm Difference for worker 1747 is 0.04005
INFO:root:FL Epoch: 393 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1300
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686627
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696965
INFO:root:FL Epoch: 393 Norm Difference for worker 1300 is 0.039812
INFO:root:FL Epoch: 393 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :59
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 59 is 0.152893
INFO:root:FL Epoch: 393 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :902
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697919
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691068
INFO:root:FL Epoch: 393 Norm Difference for worker 902 is 0.046146
INFO:root:FL Epoch: 393 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.6933539018911474 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.6814872622489929                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [774, 1926, 1801, 399, 1725, 1837, 123, 912, 1829, 387]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 394 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :774
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693216
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691661
INFO:root:FL Epoch: 394 Norm Difference for worker 774 is 0.009004
INFO:root:FL Epoch: 394 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1926
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692043
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691653
INFO:root:FL Epoch: 394 Norm Difference for worker 1926 is 0.036871
INFO:root:FL Epoch: 394 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1801
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694389
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693201
INFO:root:FL Epoch: 394 Norm Difference for worker 1801 is 0.039846
INFO:root:FL Epoch: 394 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :399
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699080
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692127
INFO:root:FL Epoch: 394 Norm Difference for worker 399 is 0.036862
INFO:root:FL Epoch: 394 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1725
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693216
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693748
INFO:root:FL Epoch: 394 Norm Difference for worker 1725 is 0.036719
INFO:root:FL Epoch: 394 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1837
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699080
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693261
INFO:root:FL Epoch: 394 Norm Difference for worker 1837 is 0.066459
INFO:root:FL Epoch: 394 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :123
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694389
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697248
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 123 is 0.016455
INFO:root:FL Epoch: 394 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :912
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693216
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685241
INFO:root:FL Epoch: 394 Norm Difference for worker 912 is 0.151911
INFO:root:FL Epoch: 394 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1829
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695562
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683108
INFO:root:FL Epoch: 394 Norm Difference for worker 1829 is 0.129314
INFO:root:FL Epoch: 394 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :387
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699080
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691806
INFO:root:FL Epoch: 394 Norm Difference for worker 387 is 0.136899
INFO:root:FL Epoch: 394 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.6931099470923928 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.6969200372695923                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [291, 813, 50, 1335, 830, 653, 483, 1654, 1248, 274]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 395 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :291
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 291 is 0.145656
INFO:root:FL Epoch: 395 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :813
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695414
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694258
INFO:root:FL Epoch: 395 Norm Difference for worker 813 is 0.040945
INFO:root:FL Epoch: 395 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :50
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 50 is 0.189018
INFO:root:FL Epoch: 395 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1335
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693531
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682424
INFO:root:FL Epoch: 395 Norm Difference for worker 1335 is 0.194828
INFO:root:FL Epoch: 395 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :830
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693531
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689981
INFO:root:FL Epoch: 395 Norm Difference for worker 830 is 0.209198
INFO:root:FL Epoch: 395 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :653
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 395 Norm Difference for worker 653 is 0.051566
INFO:root:FL Epoch: 395 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :483
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693154
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690781
INFO:root:FL Epoch: 395 Norm Difference for worker 483 is 0.013653
INFO:root:FL Epoch: 395 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1654
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693531
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695308
INFO:root:FL Epoch: 395 Norm Difference for worker 1654 is 0.075102
INFO:root:FL Epoch: 395 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1248
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692778
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692425
INFO:root:FL Epoch: 395 Norm Difference for worker 1248 is 0.075999
INFO:root:FL Epoch: 395 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :274
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 274 is 0.028294
INFO:root:FL Epoch: 395 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.6937878482482013 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.6675662398338318                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [1385, 108, 1824, 1767, 1165, 138, 227, 1226, 114, 486]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 201 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :1385
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693483
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689407
INFO:root:FL Epoch: 396 Norm Difference for worker 1385 is 0.001644
INFO:root:FL Epoch: 396 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :108
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 108 is 0.020577
INFO:root:FL Epoch: 396 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1824
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696075
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694601
INFO:root:FL Epoch: 396 Norm Difference for worker 1824 is 0.152132
INFO:root:FL Epoch: 396 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1767
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698666
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693496
INFO:root:FL Epoch: 396 Norm Difference for worker 1767 is 0.112517
INFO:root:FL Epoch: 396 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1165
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693483
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696849
INFO:root:FL Epoch: 396 Norm Difference for worker 1165 is 0.078168
INFO:root:FL Epoch: 396 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :138
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 138 is 0.00689
INFO:root:FL Epoch: 396 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :227
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693979
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 227 is 0.112673
INFO:root:FL Epoch: 396 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1226
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696075
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699097
INFO:root:FL Epoch: 396 Norm Difference for worker 1226 is 0.042675
INFO:root:FL Epoch: 396 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :114
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698666
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 114 is 0.035372
INFO:root:FL Epoch: 396 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :486
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693483
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698830
INFO:root:FL Epoch: 396 Norm Difference for worker 486 is 0.036346
INFO:root:FL Epoch: 396 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.6931276636965135 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.6949378252029419                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [337, 1927, 777, 117, 1379, 1198, 527, 1053, 1645, 917]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :337
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 337 is 0.170985
INFO:root:FL Epoch: 397 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1927
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692791
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694493
INFO:root:FL Epoch: 397 Norm Difference for worker 1927 is 0.07225
INFO:root:FL Epoch: 397 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :777
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693955
INFO:root:FL Epoch: 397 Norm Difference for worker 777 is 0.003925
INFO:root:FL Epoch: 397 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :117
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692805
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 117 is 0.03504
INFO:root:FL Epoch: 397 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1379
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693685
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691040
INFO:root:FL Epoch: 397 Norm Difference for worker 1379 is 0.065438
INFO:root:FL Epoch: 397 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1198
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693328
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693239
INFO:root:FL Epoch: 397 Norm Difference for worker 1198 is 0.084266
INFO:root:FL Epoch: 397 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :527
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692970
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685667
INFO:root:FL Epoch: 397 Norm Difference for worker 527 is 0.091018
INFO:root:FL Epoch: 397 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1053
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692970
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694387
INFO:root:FL Epoch: 397 Norm Difference for worker 1053 is 0.036835
INFO:root:FL Epoch: 397 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1645
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693685
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693408
INFO:root:FL Epoch: 397 Norm Difference for worker 1645 is 0.104329
INFO:root:FL Epoch: 397 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :917
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692612
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688996
INFO:root:FL Epoch: 397 Norm Difference for worker 917 is 0.080347
INFO:root:FL Epoch: 397 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.6930862875545726 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.7091024518013                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1469, 1630, 1186, 1921, 1671, 732, 997, 506, 1188, 398]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 398 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1469
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696438
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691390
INFO:root:FL Epoch: 398 Norm Difference for worker 1469 is 0.005789
INFO:root:FL Epoch: 398 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1630
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694856
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679102
INFO:root:FL Epoch: 398 Norm Difference for worker 1630 is 0.056276
INFO:root:FL Epoch: 398 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1186
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693272
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693561
INFO:root:FL Epoch: 398 Norm Difference for worker 1186 is 0.015709
INFO:root:FL Epoch: 398 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1921
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693272
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690451
INFO:root:FL Epoch: 398 Norm Difference for worker 1921 is 0.045378
INFO:root:FL Epoch: 398 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1671
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686941
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694279
INFO:root:FL Epoch: 398 Norm Difference for worker 1671 is 0.011586
INFO:root:FL Epoch: 398 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :732
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691690
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692373
INFO:root:FL Epoch: 398 Norm Difference for worker 732 is 0.075476
INFO:root:FL Epoch: 398 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :997
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693272
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693416
INFO:root:FL Epoch: 398 Norm Difference for worker 997 is 0.019347
INFO:root:FL Epoch: 398 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :506
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691689
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 398 Norm Difference for worker 506 is 0.009474
INFO:root:FL Epoch: 398 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1188
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694856
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693545
INFO:root:FL Epoch: 398 Norm Difference for worker 1188 is 0.044033
INFO:root:FL Epoch: 398 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :398
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690107
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691920
INFO:root:FL Epoch: 398 Norm Difference for worker 398 is 0.09963
INFO:root:FL Epoch: 398 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.6930790543556213 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.7035669684410095                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [33, 656, 758, 379, 1800, 821, 1258, 725, 768, 46]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 399 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :33
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 33 is 0.077694
INFO:root:FL Epoch: 399 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :656
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691128
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681862
INFO:root:FL Epoch: 399 Norm Difference for worker 656 is 0.145101
INFO:root:FL Epoch: 399 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :758
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693201
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694415
INFO:root:FL Epoch: 399 Norm Difference for worker 758 is 0.016561
INFO:root:FL Epoch: 399 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :379
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691128
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693166
INFO:root:FL Epoch: 399 Norm Difference for worker 379 is 0.001703
INFO:root:FL Epoch: 399 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1800
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694238
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690368
INFO:root:FL Epoch: 399 Norm Difference for worker 1800 is 0.105987
INFO:root:FL Epoch: 399 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :821
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693201
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 399 Norm Difference for worker 821 is 0.031323
INFO:root:FL Epoch: 399 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1258
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690091
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693674
INFO:root:FL Epoch: 399 Norm Difference for worker 1258 is 0.219002
INFO:root:FL Epoch: 399 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :725
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692164
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693299
INFO:root:FL Epoch: 399 Norm Difference for worker 725 is 0.047138
INFO:root:FL Epoch: 399 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :768
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695274
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680774
INFO:root:FL Epoch: 399 Norm Difference for worker 768 is 0.135183
INFO:root:FL Epoch: 399 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :46
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689644
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 46 is 0.067657
INFO:root:FL Epoch: 399 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.6930781743105721 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.7056145071983337                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [1374, 653, 800, 738, 1855, 248, 298, 573, 1627, 1083]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :1374
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691985
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694900
INFO:root:FL Epoch: 400 Norm Difference for worker 1374 is 0.002732
INFO:root:FL Epoch: 400 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :653
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689507
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694783
INFO:root:FL Epoch: 400 Norm Difference for worker 653 is 0.065015
INFO:root:FL Epoch: 400 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :800
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688268
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693657
INFO:root:FL Epoch: 400 Norm Difference for worker 800 is 0.077556
INFO:root:FL Epoch: 400 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :738
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691985
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693168
INFO:root:FL Epoch: 400 Norm Difference for worker 738 is 0.044914
INFO:root:FL Epoch: 400 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1855
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689507
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682463
INFO:root:FL Epoch: 400 Norm Difference for worker 1855 is 0.063133
INFO:root:FL Epoch: 400 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :248
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 248 is 0.113016
INFO:root:FL Epoch: 400 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :298
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 298 is 0.11104
INFO:root:FL Epoch: 400 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :573
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695702
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689802
INFO:root:FL Epoch: 400 Norm Difference for worker 573 is 0.004766
INFO:root:FL Epoch: 400 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1627
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694463
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691687
INFO:root:FL Epoch: 400 Norm Difference for worker 1627 is 0.006182
INFO:root:FL Epoch: 400 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1083
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689507
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700491
INFO:root:FL Epoch: 400 Norm Difference for worker 1083 is 0.013259
INFO:root:FL Epoch: 400 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.6931006698047414 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.7118176817893982                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 163, 138, 1190, 701, 1254, 563, 1004]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697018
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695850
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.6715659499168396 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.6877121746540069 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.080637
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695168
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695866
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.6744475960731506 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.6884171485900878 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.074754
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698868
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693165
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.677644670009613 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.689206862449646 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.068248
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :163
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 163 is 0.020801
INFO:root:FL Epoch: 401 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :138
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691582
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 138 is 0.0283
INFO:root:FL Epoch: 401 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1190
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691468
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688644
INFO:root:FL Epoch: 401 Norm Difference for worker 1190 is 0.173826
INFO:root:FL Epoch: 401 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :701
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695168
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691554
INFO:root:FL Epoch: 401 Norm Difference for worker 701 is 0.013109
INFO:root:FL Epoch: 401 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1254
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691468
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701566
INFO:root:FL Epoch: 401 Norm Difference for worker 1254 is 0.050944
INFO:root:FL Epoch: 401 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :563
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697018
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693348
INFO:root:FL Epoch: 401 Norm Difference for worker 563 is 0.115993
INFO:root:FL Epoch: 401 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1004
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695168
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692511
INFO:root:FL Epoch: 401 Norm Difference for worker 1004 is 0.054638
INFO:root:FL Epoch: 401 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.693280461956473 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.6848183274269104                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [607, 1517, 1264, 1385, 623, 1075, 1805, 731, 742, 1898]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :607
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690673
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692709
INFO:root:FL Epoch: 402 Norm Difference for worker 607 is 0.128519
INFO:root:FL Epoch: 402 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1517
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695691
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693560
INFO:root:FL Epoch: 402 Norm Difference for worker 1517 is 0.042046
INFO:root:FL Epoch: 402 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1264
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694855
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686574
INFO:root:FL Epoch: 402 Norm Difference for worker 1264 is 0.242317
INFO:root:FL Epoch: 402 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1385
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693310
INFO:root:FL Epoch: 402 Norm Difference for worker 1385 is 0.027369
INFO:root:FL Epoch: 402 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :623
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694018
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694198
INFO:root:FL Epoch: 402 Norm Difference for worker 623 is 0.047639
INFO:root:FL Epoch: 402 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1075
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693376
INFO:root:FL Epoch: 402 Norm Difference for worker 1075 is 0.06447
INFO:root:FL Epoch: 402 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1805
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690673
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683610
INFO:root:FL Epoch: 402 Norm Difference for worker 1805 is 0.113231
INFO:root:FL Epoch: 402 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :731
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693182
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691437
INFO:root:FL Epoch: 402 Norm Difference for worker 731 is 0.135639
INFO:root:FL Epoch: 402 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :742
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692346
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691910
INFO:root:FL Epoch: 402 Norm Difference for worker 742 is 0.013947
INFO:root:FL Epoch: 402 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1898
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695691
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695190
INFO:root:FL Epoch: 402 Norm Difference for worker 1898 is 0.084375
INFO:root:FL Epoch: 402 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.693102990879732 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.7121686339378357                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1697, 438, 1000, 1152, 674, 1882, 1176, 1868, 78, 1171]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1697
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689556
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691437
INFO:root:FL Epoch: 403 Norm Difference for worker 1697 is 0.017117
INFO:root:FL Epoch: 403 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :438
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698978
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685031
INFO:root:FL Epoch: 403 Norm Difference for worker 438 is 0.235047
INFO:root:FL Epoch: 403 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1000
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691440
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693947
INFO:root:FL Epoch: 403 Norm Difference for worker 1000 is 0.071043
INFO:root:FL Epoch: 403 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1152
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695209
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689294
INFO:root:FL Epoch: 403 Norm Difference for worker 1152 is 0.131682
INFO:root:FL Epoch: 403 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :674
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689556
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679910
INFO:root:FL Epoch: 403 Norm Difference for worker 674 is 0.129846
INFO:root:FL Epoch: 403 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1882
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693325
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693185
INFO:root:FL Epoch: 403 Norm Difference for worker 1882 is 0.093747
INFO:root:FL Epoch: 403 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1176
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700862
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693484
INFO:root:FL Epoch: 403 Norm Difference for worker 1176 is 0.03201
INFO:root:FL Epoch: 403 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1868
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691440
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691466
INFO:root:FL Epoch: 403 Norm Difference for worker 1868 is 0.040761
INFO:root:FL Epoch: 403 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :78
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695209
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 78 is 0.101572
INFO:root:FL Epoch: 403 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1171
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697093
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694886
INFO:root:FL Epoch: 403 Norm Difference for worker 1171 is 0.034478
INFO:root:FL Epoch: 403 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.693092381252962 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.6995678544044495                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [42, 1565, 994, 591, 1772, 1731, 767, 1854, 1609, 1682]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 404 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :42
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 42 is 0.026879
INFO:root:FL Epoch: 404 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1565
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691248
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694558
INFO:root:FL Epoch: 404 Norm Difference for worker 1565 is 0.066359
INFO:root:FL Epoch: 404 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :994
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693808
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692450
INFO:root:FL Epoch: 404 Norm Difference for worker 994 is 0.033117
INFO:root:FL Epoch: 404 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :591
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690608
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694208
INFO:root:FL Epoch: 404 Norm Difference for worker 591 is 0.043035
INFO:root:FL Epoch: 404 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1772
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689968
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683801
INFO:root:FL Epoch: 404 Norm Difference for worker 1772 is 0.117314
INFO:root:FL Epoch: 404 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1731
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693168
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698647
INFO:root:FL Epoch: 404 Norm Difference for worker 1731 is 0.029456
INFO:root:FL Epoch: 404 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :767
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693808
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685334
INFO:root:FL Epoch: 404 Norm Difference for worker 767 is 0.06236
INFO:root:FL Epoch: 404 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1854
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692528
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694841
INFO:root:FL Epoch: 404 Norm Difference for worker 1854 is 0.035129
INFO:root:FL Epoch: 404 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1609
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694448
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691646
INFO:root:FL Epoch: 404 Norm Difference for worker 1609 is 0.053428
INFO:root:FL Epoch: 404 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1682
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692528
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691816
INFO:root:FL Epoch: 404 Norm Difference for worker 1682 is 0.103406
INFO:root:FL Epoch: 404 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.6930783426060396 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.7041545510292053                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1229, 1879, 783, 290, 1711, 787, 1366, 1837, 1562, 898]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1229
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691018
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692495
INFO:root:FL Epoch: 405 Norm Difference for worker 1229 is 0.075732
INFO:root:FL Epoch: 405 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1879
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689923
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692078
INFO:root:FL Epoch: 405 Norm Difference for worker 1879 is 0.032786
INFO:root:FL Epoch: 405 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :783
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695397
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690757
INFO:root:FL Epoch: 405 Norm Difference for worker 783 is 0.07264
INFO:root:FL Epoch: 405 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :290
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692112
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693386
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 290 is 0.005429
INFO:root:FL Epoch: 405 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1711
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691018
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684037
INFO:root:FL Epoch: 405 Norm Difference for worker 1711 is 0.070308
INFO:root:FL Epoch: 405 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :787
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696491
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688061
INFO:root:FL Epoch: 405 Norm Difference for worker 787 is 0.151524
INFO:root:FL Epoch: 405 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1366
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696491
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693879
INFO:root:FL Epoch: 405 Norm Difference for worker 1366 is 0.01893
INFO:root:FL Epoch: 405 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1837
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695397
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696143
INFO:root:FL Epoch: 405 Norm Difference for worker 1837 is 0.015423
INFO:root:FL Epoch: 405 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1562
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697586
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693310
INFO:root:FL Epoch: 405 Norm Difference for worker 1562 is 0.110199
INFO:root:FL Epoch: 405 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :898
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693207
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696684
INFO:root:FL Epoch: 405 Norm Difference for worker 898 is 0.016754
INFO:root:FL Epoch: 405 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.693114161491394 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.6964072585105896                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [43, 1346, 1944, 1012, 832, 366, 1013, 1230, 475, 495]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 406 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :43
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 43 is 0.011232
INFO:root:FL Epoch: 406 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1346
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692827
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693076
INFO:root:FL Epoch: 406 Norm Difference for worker 1346 is 0.015278
INFO:root:FL Epoch: 406 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1944
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694780
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698533
INFO:root:FL Epoch: 406 Norm Difference for worker 1944 is 0.158645
INFO:root:FL Epoch: 406 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1012
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692827
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692031
INFO:root:FL Epoch: 406 Norm Difference for worker 1012 is 0.067038
INFO:root:FL Epoch: 406 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :832
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691164
INFO:root:FL Epoch: 406 Norm Difference for worker 832 is 0.074519
INFO:root:FL Epoch: 406 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :366
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689066
INFO:root:FL Epoch: 406 Norm Difference for worker 366 is 0.076219
INFO:root:FL Epoch: 406 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1013
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693803
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693215
INFO:root:FL Epoch: 406 Norm Difference for worker 1013 is 0.086318
INFO:root:FL Epoch: 406 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1230
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695493
INFO:root:FL Epoch: 406 Norm Difference for worker 1230 is 0.12022
INFO:root:FL Epoch: 406 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :475
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693809
INFO:root:FL Epoch: 406 Norm Difference for worker 475 is 0.016327
INFO:root:FL Epoch: 406 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :495
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693478
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696886
INFO:root:FL Epoch: 406 Norm Difference for worker 495 is 0.074741
INFO:root:FL Epoch: 406 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.6934118972105139 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.6791673898696899                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1183, 943, 1373, 1473, 992, 757, 1475, 680, 491, 1743]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1183
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697470
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680448
INFO:root:FL Epoch: 407 Norm Difference for worker 1183 is 0.097132
INFO:root:FL Epoch: 407 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :943
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690431
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693337
INFO:root:FL Epoch: 407 Norm Difference for worker 943 is 0.185847
INFO:root:FL Epoch: 407 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1373
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694654
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689017
INFO:root:FL Epoch: 407 Norm Difference for worker 1373 is 0.031048
INFO:root:FL Epoch: 407 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1473
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694654
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697005
INFO:root:FL Epoch: 407 Norm Difference for worker 1473 is 0.116513
INFO:root:FL Epoch: 407 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :992
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691838
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692056
INFO:root:FL Epoch: 407 Norm Difference for worker 992 is 0.034949
INFO:root:FL Epoch: 407 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :757
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696062
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687673
INFO:root:FL Epoch: 407 Norm Difference for worker 757 is 0.029122
INFO:root:FL Epoch: 407 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1475
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696062
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691950
INFO:root:FL Epoch: 407 Norm Difference for worker 1475 is 0.000352
INFO:root:FL Epoch: 407 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :680
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698878
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693580
INFO:root:FL Epoch: 407 Norm Difference for worker 680 is 0.080696
INFO:root:FL Epoch: 407 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :491
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697470
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682531
INFO:root:FL Epoch: 407 Norm Difference for worker 491 is 0.217512
INFO:root:FL Epoch: 407 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1743
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700286
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693166
INFO:root:FL Epoch: 407 Norm Difference for worker 1743 is 0.09048
INFO:root:FL Epoch: 407 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.693093082484077 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.6994356513023376                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [1623, 1108, 1748, 150, 1450, 611, 673, 1016, 676, 1248]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :1623
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692540
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691777
INFO:root:FL Epoch: 408 Norm Difference for worker 1623 is 0.017364
INFO:root:FL Epoch: 408 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1108
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691286
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 408 Norm Difference for worker 1108 is 0.03995
INFO:root:FL Epoch: 408 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1748
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689406
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685634
INFO:root:FL Epoch: 408 Norm Difference for worker 1748 is 0.078756
INFO:root:FL Epoch: 408 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :150
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 150 is 0.106794
INFO:root:FL Epoch: 408 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1450
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692540
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699018
INFO:root:FL Epoch: 408 Norm Difference for worker 1450 is 0.074035
INFO:root:FL Epoch: 408 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :611
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693794
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693766
INFO:root:FL Epoch: 408 Norm Difference for worker 611 is 0.050164
INFO:root:FL Epoch: 408 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :673
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695674
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696406
INFO:root:FL Epoch: 408 Norm Difference for worker 673 is 0.061668
INFO:root:FL Epoch: 408 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1016
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694421
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691294
INFO:root:FL Epoch: 408 Norm Difference for worker 1016 is 0.107314
INFO:root:FL Epoch: 408 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :676
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692540
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688891
INFO:root:FL Epoch: 408 Norm Difference for worker 676 is 0.092102
INFO:root:FL Epoch: 408 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1248
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695047
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693166
INFO:root:FL Epoch: 408 Norm Difference for worker 1248 is 0.074547
INFO:root:FL Epoch: 408 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.6932085787548738 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.6887588500976562                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1095, 1034, 884, 1106, 854, 1812, 1365, 1153, 368, 741]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1095
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694517
INFO:root:FL Epoch: 409 Norm Difference for worker 1095 is 0.05059
INFO:root:FL Epoch: 409 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1034
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693597
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689770
INFO:root:FL Epoch: 409 Norm Difference for worker 1034 is 0.096309
INFO:root:FL Epoch: 409 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :884
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693597
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683975
INFO:root:FL Epoch: 409 Norm Difference for worker 884 is 0.102611
INFO:root:FL Epoch: 409 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1106
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692040
INFO:root:FL Epoch: 409 Norm Difference for worker 1106 is 0.0075
INFO:root:FL Epoch: 409 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :854
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691837
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693201
INFO:root:FL Epoch: 409 Norm Difference for worker 854 is 0.014203
INFO:root:FL Epoch: 409 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1812
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691403
INFO:root:FL Epoch: 409 Norm Difference for worker 1812 is 0.054841
INFO:root:FL Epoch: 409 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1365
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692277
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693157
INFO:root:FL Epoch: 409 Norm Difference for worker 1365 is 0.006359
INFO:root:FL Epoch: 409 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1153
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693597
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688896
INFO:root:FL Epoch: 409 Norm Difference for worker 1153 is 0.070562
INFO:root:FL Epoch: 409 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :368
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694036
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 409 Norm Difference for worker 368 is 0.00114
INFO:root:FL Epoch: 409 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :741
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687497
INFO:root:FL Epoch: 409 Norm Difference for worker 741 is 0.152795
INFO:root:FL Epoch: 409 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.6931116686147802 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.6967090964317322                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [1588, 1566, 1373, 38, 609, 48, 1939, 569, 905, 90]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :1588
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693865
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694026
INFO:root:FL Epoch: 410 Norm Difference for worker 1588 is 0.033157
INFO:root:FL Epoch: 410 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1566
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693509
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683498
INFO:root:FL Epoch: 410 Norm Difference for worker 1566 is 0.144403
INFO:root:FL Epoch: 410 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1373
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694220
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689486
INFO:root:FL Epoch: 410 Norm Difference for worker 1373 is 0.076985
INFO:root:FL Epoch: 410 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :38
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 38 is 0.145702
INFO:root:FL Epoch: 410 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :609
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694220
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694962
INFO:root:FL Epoch: 410 Norm Difference for worker 609 is 0.11112
INFO:root:FL Epoch: 410 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :48
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 48 is 0.038289
INFO:root:FL Epoch: 410 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1939
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693509
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692648
INFO:root:FL Epoch: 410 Norm Difference for worker 1939 is 0.020708
INFO:root:FL Epoch: 410 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :569
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693509
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689330
INFO:root:FL Epoch: 410 Norm Difference for worker 569 is 0.076593
INFO:root:FL Epoch: 410 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :905
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692798
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693783
INFO:root:FL Epoch: 410 Norm Difference for worker 905 is 0.132742
INFO:root:FL Epoch: 410 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :90
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 90 is 0.07572
INFO:root:FL Epoch: 410 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.6938807964324951 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.6652408242225647                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 1347, 1697, 1523, 1370, 1900, 1837, 1578]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676564
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693933
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.6391476988792419 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.6802481174468994 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.054468
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685056
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686141
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.6369014382362366 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.6797639489173889 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.059231
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687886
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690068
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.6349554657936096 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.6793480277061462 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.063366
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1347
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699209
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695182
INFO:root:FL Epoch: 411 Norm Difference for worker 1347 is 0.03919
INFO:root:FL Epoch: 411 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1697
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685056
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691538
INFO:root:FL Epoch: 411 Norm Difference for worker 1697 is 0.037019
INFO:root:FL Epoch: 411 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1523
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699209
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691598
INFO:root:FL Epoch: 411 Norm Difference for worker 1523 is 0.115698
INFO:root:FL Epoch: 411 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1370
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676564
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681634
INFO:root:FL Epoch: 411 Norm Difference for worker 1370 is 0.059852
INFO:root:FL Epoch: 411 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1900
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696378
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696591
INFO:root:FL Epoch: 411 Norm Difference for worker 1900 is 0.057458
INFO:root:FL Epoch: 411 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1837
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693548
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693236
INFO:root:FL Epoch: 411 Norm Difference for worker 1837 is 0.074907
INFO:root:FL Epoch: 411 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1578
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699209
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694896
INFO:root:FL Epoch: 411 Norm Difference for worker 1578 is 0.057268
INFO:root:FL Epoch: 411 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.6936172667671653 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.672293484210968                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1440, 141, 1453, 738, 655, 1904, 396, 1209, 903, 881]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 412 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1440
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697584
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692897
INFO:root:FL Epoch: 412 Norm Difference for worker 1440 is 0.106299
INFO:root:FL Epoch: 412 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :141
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 141 is 0.102703
INFO:root:FL Epoch: 412 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1453
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693369
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689107
INFO:root:FL Epoch: 412 Norm Difference for worker 1453 is 0.011952
INFO:root:FL Epoch: 412 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :738
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693369
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690194
INFO:root:FL Epoch: 412 Norm Difference for worker 738 is 0.017863
INFO:root:FL Epoch: 412 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :655
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689154
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674129
INFO:root:FL Epoch: 412 Norm Difference for worker 655 is 0.150301
INFO:root:FL Epoch: 412 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1904
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684939
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693909
INFO:root:FL Epoch: 412 Norm Difference for worker 1904 is 0.081575
INFO:root:FL Epoch: 412 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :396
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687047
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695863
INFO:root:FL Epoch: 412 Norm Difference for worker 396 is 0.01355
INFO:root:FL Epoch: 412 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1209
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695477
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664284
INFO:root:FL Epoch: 412 Norm Difference for worker 1209 is 0.113827
INFO:root:FL Epoch: 412 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :903
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689154
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689290
INFO:root:FL Epoch: 412 Norm Difference for worker 903 is 0.129743
INFO:root:FL Epoch: 412 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :881
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691262
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691263
INFO:root:FL Epoch: 412 Norm Difference for worker 881 is 0.041417
INFO:root:FL Epoch: 412 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.6948470157735488 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.6465610265731812                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [459, 6, 1260, 1890, 606, 1654, 276, 718, 1641, 1195]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 413 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :459
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699058
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690369
INFO:root:FL Epoch: 413 Norm Difference for worker 459 is 0.117339
INFO:root:FL Epoch: 413 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :6
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 6 is 0.108712
INFO:root:FL Epoch: 413 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1260
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679968
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684128
INFO:root:FL Epoch: 413 Norm Difference for worker 1260 is 0.001284
INFO:root:FL Epoch: 413 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1890
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713375
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693211
INFO:root:FL Epoch: 413 Norm Difference for worker 1890 is 0.145915
INFO:root:FL Epoch: 413 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :606
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699058
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674945
INFO:root:FL Epoch: 413 Norm Difference for worker 606 is 0.043801
INFO:root:FL Epoch: 413 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1654
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689513
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680639
INFO:root:FL Epoch: 413 Norm Difference for worker 1654 is 0.009447
INFO:root:FL Epoch: 413 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :276
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 276 is 0.141183
INFO:root:FL Epoch: 413 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :718
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694286
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685020
INFO:root:FL Epoch: 413 Norm Difference for worker 718 is 0.045293
INFO:root:FL Epoch: 413 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1641
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699058
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697539
INFO:root:FL Epoch: 413 Norm Difference for worker 1641 is 0.033341
INFO:root:FL Epoch: 413 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1195
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713375
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696837
INFO:root:FL Epoch: 413 Norm Difference for worker 1195 is 0.048595
INFO:root:FL Epoch: 413 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.6937467175371507 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.6686450839042664                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [1250, 1532, 1790, 1295, 290, 1589, 1759, 1893, 1747, 1008]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :1250
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693455
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693862
INFO:root:FL Epoch: 414 Norm Difference for worker 1250 is 0.099602
INFO:root:FL Epoch: 414 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1532
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683531
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693392
INFO:root:FL Epoch: 414 Norm Difference for worker 1532 is 0.038973
INFO:root:FL Epoch: 414 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1790
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688493
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694058
INFO:root:FL Epoch: 414 Norm Difference for worker 1790 is 0.045435
INFO:root:FL Epoch: 414 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1295
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690974
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691800
INFO:root:FL Epoch: 414 Norm Difference for worker 1295 is 0.053155
INFO:root:FL Epoch: 414 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :290
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697676
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 290 is 0.022941
INFO:root:FL Epoch: 414 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1589
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690974
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693761
INFO:root:FL Epoch: 414 Norm Difference for worker 1589 is 0.043019
INFO:root:FL Epoch: 414 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1759
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690974
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693333
INFO:root:FL Epoch: 414 Norm Difference for worker 1759 is 0.036678
INFO:root:FL Epoch: 414 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1893
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686012
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685679
INFO:root:FL Epoch: 414 Norm Difference for worker 1893 is 0.052364
INFO:root:FL Epoch: 414 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1747
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693455
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691497
INFO:root:FL Epoch: 414 Norm Difference for worker 1747 is 0.04196
INFO:root:FL Epoch: 414 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1008
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693455
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693362
INFO:root:FL Epoch: 414 Norm Difference for worker 1008 is 0.095162
INFO:root:FL Epoch: 414 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.6932710163733539 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.6852918863296509                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [1413, 172, 86, 370, 1824, 1386, 472, 1000, 637, 1934]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 415 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :1413
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694755
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693172
INFO:root:FL Epoch: 415 Norm Difference for worker 1413 is 0.019122
INFO:root:FL Epoch: 415 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :172
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 172 is 0.003328
INFO:root:FL Epoch: 415 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :86
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 86 is 0.056586
INFO:root:FL Epoch: 415 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :370
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692390
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698003
INFO:root:FL Epoch: 415 Norm Difference for worker 370 is 0.028356
INFO:root:FL Epoch: 415 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1824
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693967
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693277
INFO:root:FL Epoch: 415 Norm Difference for worker 1824 is 0.098379
INFO:root:FL Epoch: 415 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1386
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690812
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693164
INFO:root:FL Epoch: 415 Norm Difference for worker 1386 is 0.089902
INFO:root:FL Epoch: 415 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :472
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696333
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693424
INFO:root:FL Epoch: 415 Norm Difference for worker 472 is 0.028407
INFO:root:FL Epoch: 415 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1000
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692390
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687431
INFO:root:FL Epoch: 415 Norm Difference for worker 1000 is 0.054172
INFO:root:FL Epoch: 415 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :637
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693178
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688800
INFO:root:FL Epoch: 415 Norm Difference for worker 637 is 0.088159
INFO:root:FL Epoch: 415 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1934
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693178
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692314
INFO:root:FL Epoch: 415 Norm Difference for worker 1934 is 0.017245
INFO:root:FL Epoch: 415 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.6931822089587941 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.6904760003089905                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [337, 431, 1785, 716, 52, 758, 1794, 162, 1203, 898]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 416 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :337
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 337 is 0.157545
INFO:root:FL Epoch: 416 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :431
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692081
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696259
INFO:root:FL Epoch: 416 Norm Difference for worker 431 is 0.004913
INFO:root:FL Epoch: 416 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1785
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692883
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687071
INFO:root:FL Epoch: 416 Norm Difference for worker 1785 is 0.056891
INFO:root:FL Epoch: 416 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :716
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692616
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690221
INFO:root:FL Epoch: 416 Norm Difference for worker 716 is 0.089615
INFO:root:FL Epoch: 416 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :52
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 52 is 0.012797
INFO:root:FL Epoch: 416 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :758
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692081
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693525
INFO:root:FL Epoch: 416 Norm Difference for worker 758 is 0.012805
INFO:root:FL Epoch: 416 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1794
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692883
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696777
INFO:root:FL Epoch: 416 Norm Difference for worker 1794 is 0.044007
INFO:root:FL Epoch: 416 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :162
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 162 is 0.084051
INFO:root:FL Epoch: 416 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1203
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692883
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689171
INFO:root:FL Epoch: 416 Norm Difference for worker 1203 is 0.082717
INFO:root:FL Epoch: 416 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :898
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693418
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691072
INFO:root:FL Epoch: 416 Norm Difference for worker 898 is 0.070845
INFO:root:FL Epoch: 416 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.6931617470348582 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.691968560218811                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1578, 1877, 1722, 1440, 1829, 671, 994, 651, 1136, 1386]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1578
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692912
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691664
INFO:root:FL Epoch: 417 Norm Difference for worker 1578 is 0.020476
INFO:root:FL Epoch: 417 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1877
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694033
INFO:root:FL Epoch: 417 Norm Difference for worker 1877 is 0.001052
INFO:root:FL Epoch: 417 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1722
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692912
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694821
INFO:root:FL Epoch: 417 Norm Difference for worker 1722 is 0.042837
INFO:root:FL Epoch: 417 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1440
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696000
INFO:root:FL Epoch: 417 Norm Difference for worker 1440 is 0.077864
INFO:root:FL Epoch: 417 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1829
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692676
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690275
INFO:root:FL Epoch: 417 Norm Difference for worker 1829 is 0.136151
INFO:root:FL Epoch: 417 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :671
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693266
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693212
INFO:root:FL Epoch: 417 Norm Difference for worker 671 is 0.025938
INFO:root:FL Epoch: 417 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :994
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693620
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694195
INFO:root:FL Epoch: 417 Norm Difference for worker 994 is 0.026021
INFO:root:FL Epoch: 417 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :651
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693502
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693156
INFO:root:FL Epoch: 417 Norm Difference for worker 651 is 0.037722
INFO:root:FL Epoch: 417 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1136
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692794
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684568
INFO:root:FL Epoch: 417 Norm Difference for worker 1136 is 0.182945
INFO:root:FL Epoch: 417 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1386
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692912
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691908
INFO:root:FL Epoch: 417 Norm Difference for worker 1386 is 0.096841
INFO:root:FL Epoch: 417 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.6933450348236981 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.6818655133247375                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [1394, 446, 1001, 597, 430, 98, 478, 1158, 171, 285]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :1394
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693212
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686573
INFO:root:FL Epoch: 418 Norm Difference for worker 1394 is 0.016033
INFO:root:FL Epoch: 418 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :446
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694346
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692962
INFO:root:FL Epoch: 418 Norm Difference for worker 446 is 0.093676
INFO:root:FL Epoch: 418 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1001
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690942
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678886
INFO:root:FL Epoch: 418 Norm Difference for worker 1001 is 0.126203
INFO:root:FL Epoch: 418 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :597
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693212
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686622
INFO:root:FL Epoch: 418 Norm Difference for worker 597 is 0.051963
INFO:root:FL Epoch: 418 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :430
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696615
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692252
INFO:root:FL Epoch: 418 Norm Difference for worker 430 is 0.116453
INFO:root:FL Epoch: 418 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :98
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695342
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 98 is 0.047291
INFO:root:FL Epoch: 418 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :478
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690942
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690541
INFO:root:FL Epoch: 418 Norm Difference for worker 478 is 0.114057
INFO:root:FL Epoch: 418 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1158
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690942
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689531
INFO:root:FL Epoch: 418 Norm Difference for worker 1158 is 0.113093
INFO:root:FL Epoch: 418 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :171
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689808
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 171 is 0.121055
INFO:root:FL Epoch: 418 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :285
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690367
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 285 is 0.011488
INFO:root:FL Epoch: 418 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.6937380257774802 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.6688809990882874                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [1565, 1770, 855, 807, 185, 421, 1904, 1529, 162, 1104]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :1565
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695906
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693721
INFO:root:FL Epoch: 419 Norm Difference for worker 1565 is 0.036976
INFO:root:FL Epoch: 419 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1770
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690992
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703588
INFO:root:FL Epoch: 419 Norm Difference for worker 1770 is 0.023165
INFO:root:FL Epoch: 419 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :855
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690992
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695989
INFO:root:FL Epoch: 419 Norm Difference for worker 855 is 0.100786
INFO:root:FL Epoch: 419 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :807
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690992
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697718
INFO:root:FL Epoch: 419 Norm Difference for worker 807 is 0.03552
INFO:root:FL Epoch: 419 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :185
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 185 is 0.030933
INFO:root:FL Epoch: 419 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :421
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693449
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685645
INFO:root:FL Epoch: 419 Norm Difference for worker 421 is 0.099603
INFO:root:FL Epoch: 419 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1904
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690992
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694142
INFO:root:FL Epoch: 419 Norm Difference for worker 1904 is 0.084035
INFO:root:FL Epoch: 419 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1529
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700819
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692210
INFO:root:FL Epoch: 419 Norm Difference for worker 1529 is 0.118238
INFO:root:FL Epoch: 419 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :162
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 162 is 0.084896
INFO:root:FL Epoch: 419 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1104
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688535
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695472
INFO:root:FL Epoch: 419 Norm Difference for worker 1104 is 0.040921
INFO:root:FL Epoch: 419 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.6937717655125786 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.6679853796958923                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1780, 132, 501, 1727, 1308, 1584, 1596, 1485, 854, 363]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 420 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1780
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698569
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693474
INFO:root:FL Epoch: 420 Norm Difference for worker 1780 is 0.06094
INFO:root:FL Epoch: 420 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :132
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 132 is 0.013989
INFO:root:FL Epoch: 420 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :501
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683277
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697163
INFO:root:FL Epoch: 420 Norm Difference for worker 501 is 0.025561
INFO:root:FL Epoch: 420 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1727
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701118
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692415
INFO:root:FL Epoch: 420 Norm Difference for worker 1727 is 0.100353
INFO:root:FL Epoch: 420 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1308
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693472
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693302
INFO:root:FL Epoch: 420 Norm Difference for worker 1308 is 0.007372
INFO:root:FL Epoch: 420 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1584
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690923
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684636
INFO:root:FL Epoch: 420 Norm Difference for worker 1584 is 0.087893
INFO:root:FL Epoch: 420 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1596
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690923
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691244
INFO:root:FL Epoch: 420 Norm Difference for worker 1596 is 0.028396
INFO:root:FL Epoch: 420 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1485
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696021
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697205
INFO:root:FL Epoch: 420 Norm Difference for worker 1485 is 0.051222
INFO:root:FL Epoch: 420 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :854
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698569
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695784
INFO:root:FL Epoch: 420 Norm Difference for worker 854 is 0.052908
INFO:root:FL Epoch: 420 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :363
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685826
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688965
INFO:root:FL Epoch: 420 Norm Difference for worker 363 is 0.163927
INFO:root:FL Epoch: 420 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.6942286245963153 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.6575927138328552                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 331, 252, 1598, 852, 1672, 738, 1413]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679319
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689530
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.6314745545387268 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.6786126375198365 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.05498
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672077
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689545
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.6306421160697937 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.6784383475780487 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.056759
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697424
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694254
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.6329233050346375 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.6789174377918243 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.051888
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :331
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 331 is 0.061651
INFO:root:FL Epoch: 421 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :252
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698692
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 252 is 0.000409
INFO:root:FL Epoch: 421 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1598
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679319
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695217
INFO:root:FL Epoch: 421 Norm Difference for worker 1598 is 0.094531
INFO:root:FL Epoch: 421 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :852
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697424
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698809
INFO:root:FL Epoch: 421 Norm Difference for worker 852 is 0.102373
INFO:root:FL Epoch: 421 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1672
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693803
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689651
INFO:root:FL Epoch: 421 Norm Difference for worker 1672 is 0.025395
INFO:root:FL Epoch: 421 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :738
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690182
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693814
INFO:root:FL Epoch: 421 Norm Difference for worker 738 is 0.001762
INFO:root:FL Epoch: 421 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1413
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686561
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693772
INFO:root:FL Epoch: 421 Norm Difference for worker 1413 is 0.015162
INFO:root:FL Epoch: 421 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.6944877645548653 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.6526612639427185                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [265, 1432, 207, 1520, 890, 723, 1096, 1450, 440, 1471]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 422 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :265
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 265 is 0.091058
INFO:root:FL Epoch: 422 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1432
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706403
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694783
INFO:root:FL Epoch: 422 Norm Difference for worker 1432 is 0.133288
INFO:root:FL Epoch: 422 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :207
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700702
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 207 is 0.029955
INFO:root:FL Epoch: 422 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1520
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689867
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689657
INFO:root:FL Epoch: 422 Norm Difference for worker 1520 is 0.00014
INFO:root:FL Epoch: 422 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :890
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677465
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689709
INFO:root:FL Epoch: 422 Norm Difference for worker 890 is 0.03257
INFO:root:FL Epoch: 422 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :723
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694001
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690559
INFO:root:FL Epoch: 422 Norm Difference for worker 723 is 0.100015
INFO:root:FL Epoch: 422 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1096
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698135
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683295
INFO:root:FL Epoch: 422 Norm Difference for worker 1096 is 0.031736
INFO:root:FL Epoch: 422 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1450
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714671
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696384
INFO:root:FL Epoch: 422 Norm Difference for worker 1450 is 0.141557
INFO:root:FL Epoch: 422 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :440
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685733
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711472
INFO:root:FL Epoch: 422 Norm Difference for worker 440 is 0.020758
INFO:root:FL Epoch: 422 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1471
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702269
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692423
INFO:root:FL Epoch: 422 Norm Difference for worker 1471 is 0.089216
INFO:root:FL Epoch: 422 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.6936580924426808 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.6710973381996155                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [1477, 1688, 190, 1382, 1904, 742, 1629, 178, 1346, 1406]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 423 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :1477
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700085
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699003
INFO:root:FL Epoch: 423 Norm Difference for worker 1477 is 0.011316
INFO:root:FL Epoch: 423 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1688
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691166
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689287
INFO:root:FL Epoch: 423 Norm Difference for worker 1688 is 0.15056
INFO:root:FL Epoch: 423 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :190
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 190 is 0.137839
INFO:root:FL Epoch: 423 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1382
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697855
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692502
INFO:root:FL Epoch: 423 Norm Difference for worker 1382 is 0.038171
INFO:root:FL Epoch: 423 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1904
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684476
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688216
INFO:root:FL Epoch: 423 Norm Difference for worker 1904 is 0.095446
INFO:root:FL Epoch: 423 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :742
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693396
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695349
INFO:root:FL Epoch: 423 Norm Difference for worker 742 is 0.045551
INFO:root:FL Epoch: 423 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1629
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695626
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693312
INFO:root:FL Epoch: 423 Norm Difference for worker 1629 is 0.007381
INFO:root:FL Epoch: 423 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :178
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 178 is 0.109147
INFO:root:FL Epoch: 423 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1346
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693396
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691682
INFO:root:FL Epoch: 423 Norm Difference for worker 1346 is 0.038484
INFO:root:FL Epoch: 423 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1406
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686706
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683395
INFO:root:FL Epoch: 423 Norm Difference for worker 1406 is 0.073671
INFO:root:FL Epoch: 423 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.693988817579606 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.6627067923545837                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [1005, 998, 1599, 1223, 719, 279, 1149, 66, 805, 1920]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :1005
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699809
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693768
INFO:root:FL Epoch: 424 Norm Difference for worker 1005 is 0.032495
INFO:root:FL Epoch: 424 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :998
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696717
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690449
INFO:root:FL Epoch: 424 Norm Difference for worker 998 is 0.050899
INFO:root:FL Epoch: 424 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1599
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696717
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690967
INFO:root:FL Epoch: 424 Norm Difference for worker 1599 is 0.008545
INFO:root:FL Epoch: 424 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1223
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705992
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694515
INFO:root:FL Epoch: 424 Norm Difference for worker 1223 is 0.132905
INFO:root:FL Epoch: 424 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :719
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699809
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701066
INFO:root:FL Epoch: 424 Norm Difference for worker 719 is 0.037898
INFO:root:FL Epoch: 424 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :279
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690146
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 279 is 0.073369
INFO:root:FL Epoch: 424 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1149
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699809
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693256
INFO:root:FL Epoch: 424 Norm Difference for worker 1149 is 0.131024
INFO:root:FL Epoch: 424 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :66
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 66 is 0.112054
INFO:root:FL Epoch: 424 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :805
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702901
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693180
INFO:root:FL Epoch: 424 Norm Difference for worker 805 is 0.059126
INFO:root:FL Epoch: 424 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1920
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705992
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688160
INFO:root:FL Epoch: 424 Norm Difference for worker 1920 is 0.03076
INFO:root:FL Epoch: 424 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.693230060970082 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.6874918341636658                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [125, 315, 593, 250, 1008, 1364, 824, 487, 695, 198]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 425 Num points on workers: [201 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :125
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693730
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 125 is 0.049317
INFO:root:FL Epoch: 425 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :315
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694296
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 315 is 0.000871
INFO:root:FL Epoch: 425 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :593
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693278
INFO:root:FL Epoch: 425 Norm Difference for worker 593 is 0.037439
INFO:root:FL Epoch: 425 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :250
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 250 is 0.11061
INFO:root:FL Epoch: 425 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1008
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694280
INFO:root:FL Epoch: 425 Norm Difference for worker 1008 is 0.093661
INFO:root:FL Epoch: 425 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1364
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694298
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693423
INFO:root:FL Epoch: 425 Norm Difference for worker 1364 is 0.031351
INFO:root:FL Epoch: 425 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :824
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694865
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697495
INFO:root:FL Epoch: 425 Norm Difference for worker 824 is 0.140121
INFO:root:FL Epoch: 425 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :487
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694298
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687303
INFO:root:FL Epoch: 425 Norm Difference for worker 487 is 0.090333
INFO:root:FL Epoch: 425 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :695
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693730
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685662
INFO:root:FL Epoch: 425 Norm Difference for worker 695 is 0.118778
INFO:root:FL Epoch: 425 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :198
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 198 is 0.059648
INFO:root:FL Epoch: 425 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.6931063918506398 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.6973885297775269                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [1053, 684, 410, 840, 477, 530, 660, 1267, 513, 296]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 426 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :1053
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692733
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692420
INFO:root:FL Epoch: 426 Norm Difference for worker 1053 is 0.051061
INFO:root:FL Epoch: 426 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :684
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694849
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690659
INFO:root:FL Epoch: 426 Norm Difference for worker 684 is 0.020952
INFO:root:FL Epoch: 426 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :410
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694003
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693232
INFO:root:FL Epoch: 426 Norm Difference for worker 410 is 0.076368
INFO:root:FL Epoch: 426 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :840
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692733
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690988
INFO:root:FL Epoch: 426 Norm Difference for worker 840 is 0.025158
INFO:root:FL Epoch: 426 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :477
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691886
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687094
INFO:root:FL Epoch: 426 Norm Difference for worker 477 is 0.082038
INFO:root:FL Epoch: 426 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :530
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692627
INFO:root:FL Epoch: 426 Norm Difference for worker 530 is 0.112715
INFO:root:FL Epoch: 426 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :660
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694003
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688887
INFO:root:FL Epoch: 426 Norm Difference for worker 660 is 0.070594
INFO:root:FL Epoch: 426 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1267
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692733
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691658
INFO:root:FL Epoch: 426 Norm Difference for worker 1267 is 0.008858
INFO:root:FL Epoch: 426 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :513
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687070
INFO:root:FL Epoch: 426 Norm Difference for worker 513 is 0.106582
INFO:root:FL Epoch: 426 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :296
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 296 is 0.019196
INFO:root:FL Epoch: 426 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.6930782479398391 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.7057324051856995                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [358, 1702, 890, 850, 371, 1285, 1450, 49, 1623, 1502]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :358
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695727
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698977
INFO:root:FL Epoch: 427 Norm Difference for worker 358 is 0.083136
INFO:root:FL Epoch: 427 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1702
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691975
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691297
INFO:root:FL Epoch: 427 Norm Difference for worker 1702 is 0.01179
INFO:root:FL Epoch: 427 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :890
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698228
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692796
INFO:root:FL Epoch: 427 Norm Difference for worker 890 is 0.071359
INFO:root:FL Epoch: 427 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :850
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691975
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697123
INFO:root:FL Epoch: 427 Norm Difference for worker 850 is 0.125031
INFO:root:FL Epoch: 427 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :371
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690724
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689609
INFO:root:FL Epoch: 427 Norm Difference for worker 371 is 0.130993
INFO:root:FL Epoch: 427 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1285
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691243
INFO:root:FL Epoch: 427 Norm Difference for worker 1285 is 0.083472
INFO:root:FL Epoch: 427 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1450
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696198
INFO:root:FL Epoch: 427 Norm Difference for worker 1450 is 0.082724
INFO:root:FL Epoch: 427 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :49
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 49 is 0.020298
INFO:root:FL Epoch: 427 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1623
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694476
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695199
INFO:root:FL Epoch: 427 Norm Difference for worker 1623 is 0.010881
INFO:root:FL Epoch: 427 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1502
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695727
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696552
INFO:root:FL Epoch: 427 Norm Difference for worker 1502 is 0.028795
INFO:root:FL Epoch: 427 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.6933655002537895 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.7295345664024353                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [1496, 1175, 188, 1530, 250, 1880, 417, 73, 781, 931]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 428 Num points on workers: [200 200 201 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :1496
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704511
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680974
INFO:root:FL Epoch: 428 Norm Difference for worker 1496 is 0.073331
INFO:root:FL Epoch: 428 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1175
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697361
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668155
INFO:root:FL Epoch: 428 Norm Difference for worker 1175 is 0.057889
INFO:root:FL Epoch: 428 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :188
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 188 is 0.064411
INFO:root:FL Epoch: 428 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1530
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679487
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688567
INFO:root:FL Epoch: 428 Norm Difference for worker 1530 is 0.183703
INFO:root:FL Epoch: 428 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :250
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 250 is 0.13721
INFO:root:FL Epoch: 428 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1880
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683061
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699894
INFO:root:FL Epoch: 428 Norm Difference for worker 1880 is 0.002369
INFO:root:FL Epoch: 428 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :417
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693786
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692866
INFO:root:FL Epoch: 428 Norm Difference for worker 417 is 0.120258
INFO:root:FL Epoch: 428 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :73
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693786
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682804
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 73 is 0.149667
INFO:root:FL Epoch: 428 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :781
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700936
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689859
INFO:root:FL Epoch: 428 Norm Difference for worker 781 is 0.047643
INFO:root:FL Epoch: 428 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :931
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672337
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699894
INFO:root:FL Epoch: 428 Norm Difference for worker 931 is 0.071493
INFO:root:FL Epoch: 428 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.6935213453629437 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.7355615496635437                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [573, 1218, 1481, 1222, 962, 866, 753, 639, 467, 1324]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :573
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689855
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699776
INFO:root:FL Epoch: 429 Norm Difference for worker 573 is 0.039532
INFO:root:FL Epoch: 429 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1218
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681545
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701030
INFO:root:FL Epoch: 429 Norm Difference for worker 1218 is 0.094088
INFO:root:FL Epoch: 429 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1481
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702320
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691310
INFO:root:FL Epoch: 429 Norm Difference for worker 1481 is 0.070608
INFO:root:FL Epoch: 429 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1222
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689855
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693604
INFO:root:FL Epoch: 429 Norm Difference for worker 1222 is 0.09086
INFO:root:FL Epoch: 429 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :962
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685700
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688570
INFO:root:FL Epoch: 429 Norm Difference for worker 962 is 0.144402
INFO:root:FL Epoch: 429 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :866
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689855
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683277
INFO:root:FL Epoch: 429 Norm Difference for worker 866 is 0.027854
INFO:root:FL Epoch: 429 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :753
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681545
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703544
INFO:root:FL Epoch: 429 Norm Difference for worker 753 is 0.004143
INFO:root:FL Epoch: 429 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :639
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689855
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691559
INFO:root:FL Epoch: 429 Norm Difference for worker 639 is 0.155362
INFO:root:FL Epoch: 429 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :467
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669079
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684459
INFO:root:FL Epoch: 429 Norm Difference for worker 467 is 0.030275
INFO:root:FL Epoch: 429 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1324
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698165
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691791
INFO:root:FL Epoch: 429 Norm Difference for worker 1324 is 0.147092
INFO:root:FL Epoch: 429 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.6930915187386906 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.7102676630020142                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [510, 1930, 1874, 1305, 567, 1866, 16, 1329, 1868, 483]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 430 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :510
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694989
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692800
INFO:root:FL Epoch: 430 Norm Difference for worker 510 is 0.064346
INFO:root:FL Epoch: 430 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1930
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694989
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691877
INFO:root:FL Epoch: 430 Norm Difference for worker 1930 is 0.097888
INFO:root:FL Epoch: 430 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1874
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698384
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693284
INFO:root:FL Epoch: 430 Norm Difference for worker 1874 is 0.135204
INFO:root:FL Epoch: 430 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1305
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701779
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685785
INFO:root:FL Epoch: 430 Norm Difference for worker 1305 is 0.157995
INFO:root:FL Epoch: 430 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :567
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688198
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690768
INFO:root:FL Epoch: 430 Norm Difference for worker 567 is 0.060591
INFO:root:FL Epoch: 430 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1866
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698384
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687070
INFO:root:FL Epoch: 430 Norm Difference for worker 1866 is 0.13918
INFO:root:FL Epoch: 430 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :16
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 16 is 0.02282
INFO:root:FL Epoch: 430 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1329
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689896
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693976
INFO:root:FL Epoch: 430 Norm Difference for worker 1329 is 0.144774
INFO:root:FL Epoch: 430 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1868
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696687
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684831
INFO:root:FL Epoch: 430 Norm Difference for worker 1868 is 0.026532
INFO:root:FL Epoch: 430 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :483
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683105
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689690
INFO:root:FL Epoch: 430 Norm Difference for worker 483 is 0.014485
INFO:root:FL Epoch: 430 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.6934414260527667 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.6780644059181213                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 1386, 1380, 347, 1315, 1866, 1628, 201]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696302
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688382
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.6479855179786682 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.6821955859661102 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.062063
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691743
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691042
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.6496819853782654 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.6825770914554596 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.05851
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684144
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685867
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.6466431021690369 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.681895524263382 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.06488
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1386
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694782
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690453
INFO:root:FL Epoch: 431 Norm Difference for worker 1386 is 0.125043
INFO:root:FL Epoch: 431 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1380
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702382
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692181
INFO:root:FL Epoch: 431 Norm Difference for worker 1380 is 0.059343
INFO:root:FL Epoch: 431 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :347
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688703
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695618
INFO:root:FL Epoch: 431 Norm Difference for worker 347 is 0.019888
INFO:root:FL Epoch: 431 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1315
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684144
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690735
INFO:root:FL Epoch: 431 Norm Difference for worker 1315 is 0.03244
INFO:root:FL Epoch: 431 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1866
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690223
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690319
INFO:root:FL Epoch: 431 Norm Difference for worker 1866 is 0.086358
INFO:root:FL Epoch: 431 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1628
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687183
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659847
INFO:root:FL Epoch: 431 Norm Difference for worker 1628 is 0.204677
INFO:root:FL Epoch: 431 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :201
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 201 is 0.093539
INFO:root:FL Epoch: 431 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.6938571789685417 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.6658180952072144                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1163, 172, 1453, 1739, 840, 1608, 371, 1040, 702, 1686]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 432 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1163
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687989
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700049
INFO:root:FL Epoch: 432 Norm Difference for worker 1163 is 0.053619
INFO:root:FL Epoch: 432 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :172
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 172 is 0.042647
INFO:root:FL Epoch: 432 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1453
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701845
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691615
INFO:root:FL Epoch: 432 Norm Difference for worker 1453 is 0.04365
INFO:root:FL Epoch: 432 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1739
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690760
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690193
INFO:root:FL Epoch: 432 Norm Difference for worker 1739 is 0.038352
INFO:root:FL Epoch: 432 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :840
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693531
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693230
INFO:root:FL Epoch: 432 Norm Difference for worker 840 is 0.067607
INFO:root:FL Epoch: 432 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1608
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701845
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693774
INFO:root:FL Epoch: 432 Norm Difference for worker 1608 is 0.076203
INFO:root:FL Epoch: 432 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :371
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704616
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 432 Norm Difference for worker 371 is 0.177461
INFO:root:FL Epoch: 432 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1040
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685217
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700183
INFO:root:FL Epoch: 432 Norm Difference for worker 1040 is 0.001327
INFO:root:FL Epoch: 432 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :702
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685217
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694093
INFO:root:FL Epoch: 432 Norm Difference for worker 702 is 0.10401
INFO:root:FL Epoch: 432 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1686
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685217
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693295
INFO:root:FL Epoch: 432 Norm Difference for worker 1686 is 0.072364
INFO:root:FL Epoch: 432 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.6932062296306386 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.6889030337333679                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [936, 1529, 428, 1022, 1797, 133, 96, 1201, 1407, 422]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :936
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690995
INFO:root:FL Epoch: 433 Norm Difference for worker 936 is 0.140358
INFO:root:FL Epoch: 433 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1529
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694007
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692099
INFO:root:FL Epoch: 433 Norm Difference for worker 1529 is 0.089358
INFO:root:FL Epoch: 433 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :428
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691455
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692909
INFO:root:FL Epoch: 433 Norm Difference for worker 428 is 0.047036
INFO:root:FL Epoch: 433 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1022
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694432
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687828
INFO:root:FL Epoch: 433 Norm Difference for worker 1022 is 0.145256
INFO:root:FL Epoch: 433 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1797
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691880
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693788
INFO:root:FL Epoch: 433 Norm Difference for worker 1797 is 0.180565
INFO:root:FL Epoch: 433 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :133
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.675297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 133 is 0.184736
INFO:root:FL Epoch: 433 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :96
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 96 is 0.11138
INFO:root:FL Epoch: 433 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1201
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692306
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702810
INFO:root:FL Epoch: 433 Norm Difference for worker 1201 is 0.066977
INFO:root:FL Epoch: 433 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1407
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689859
INFO:root:FL Epoch: 433 Norm Difference for worker 1407 is 0.059051
INFO:root:FL Epoch: 433 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :422
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694857
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693306
INFO:root:FL Epoch: 433 Norm Difference for worker 422 is 0.110147
INFO:root:FL Epoch: 433 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.6934626488124623 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.6773009300231934                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1767, 1620, 569, 55, 953, 253, 598, 295, 1199, 545]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1767
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699664
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696766
INFO:root:FL Epoch: 434 Norm Difference for worker 1767 is 0.099034
INFO:root:FL Epoch: 434 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1620
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683690
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693333
INFO:root:FL Epoch: 434 Norm Difference for worker 1620 is 0.025408
INFO:root:FL Epoch: 434 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :569
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691677
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682620
INFO:root:FL Epoch: 434 Norm Difference for worker 569 is 0.066565
INFO:root:FL Epoch: 434 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :55
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 55 is 0.092744
INFO:root:FL Epoch: 434 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :953
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694872
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684989
INFO:root:FL Epoch: 434 Norm Difference for worker 953 is 0.177733
INFO:root:FL Epoch: 434 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :253
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 253 is 0.005156
INFO:root:FL Epoch: 434 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :598
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696470
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680977
INFO:root:FL Epoch: 434 Norm Difference for worker 598 is 0.101909
INFO:root:FL Epoch: 434 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :295
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698067
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 295 is 0.085652
INFO:root:FL Epoch: 434 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1199
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693275
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690838
INFO:root:FL Epoch: 434 Norm Difference for worker 1199 is 0.207018
INFO:root:FL Epoch: 434 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :545
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694872
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682498
INFO:root:FL Epoch: 434 Norm Difference for worker 545 is 0.042074
INFO:root:FL Epoch: 434 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.6930865329854629 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.7008046507835388                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [444, 1452, 461, 140, 1000, 1210, 747, 33, 1773, 375]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :444
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690888
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686024
INFO:root:FL Epoch: 435 Norm Difference for worker 444 is 0.152211
INFO:root:FL Epoch: 435 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1452
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690888
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691791
INFO:root:FL Epoch: 435 Norm Difference for worker 1452 is 0.021428
INFO:root:FL Epoch: 435 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :461
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693939
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688321
INFO:root:FL Epoch: 435 Norm Difference for worker 461 is 0.068253
INFO:root:FL Epoch: 435 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :140
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 140 is 0.007155
INFO:root:FL Epoch: 435 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1000
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692413
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697896
INFO:root:FL Epoch: 435 Norm Difference for worker 1000 is 0.081604
INFO:root:FL Epoch: 435 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1210
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691651
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698245
INFO:root:FL Epoch: 435 Norm Difference for worker 1210 is 0.140161
INFO:root:FL Epoch: 435 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :747
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691651
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691942
INFO:root:FL Epoch: 435 Norm Difference for worker 747 is 0.023013
INFO:root:FL Epoch: 435 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :33
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 435 Norm Difference for worker 33 is 0.073333
INFO:root:FL Epoch: 435 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1773
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693939
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693334
INFO:root:FL Epoch: 435 Norm Difference for worker 1773 is 0.033149
INFO:root:FL Epoch: 435 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :375
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693176
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685790
INFO:root:FL Epoch: 435 Norm Difference for worker 375 is 0.145934
INFO:root:FL Epoch: 435 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.6933231213513542 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.727634072303772                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1596, 104, 1138, 367, 1834, 289, 475, 1888, 1798, 51]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 436 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1596
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700504
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697476
INFO:root:FL Epoch: 436 Norm Difference for worker 1596 is 0.036425
INFO:root:FL Epoch: 436 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :104
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 104 is 0.047349
INFO:root:FL Epoch: 436 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1138
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686940
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690529
INFO:root:FL Epoch: 436 Norm Difference for worker 1138 is 0.074436
INFO:root:FL Epoch: 436 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :367
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690331
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697435
INFO:root:FL Epoch: 436 Norm Difference for worker 367 is 0.083329
INFO:root:FL Epoch: 436 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1834
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690331
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687612
INFO:root:FL Epoch: 436 Norm Difference for worker 1834 is 0.003394
INFO:root:FL Epoch: 436 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :289
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 289 is 0.052604
INFO:root:FL Epoch: 436 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :475
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697113
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690166
INFO:root:FL Epoch: 436 Norm Difference for worker 475 is 0.006509
INFO:root:FL Epoch: 436 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1888
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703896
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693311
INFO:root:FL Epoch: 436 Norm Difference for worker 1888 is 0.089475
INFO:root:FL Epoch: 436 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1798
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693722
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693802
INFO:root:FL Epoch: 436 Norm Difference for worker 1798 is 0.157839
INFO:root:FL Epoch: 436 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :51
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 51 is 0.104873
INFO:root:FL Epoch: 436 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.6930954701760236 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.699013888835907                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [945, 15, 304, 957, 1361, 1848, 1090, 284, 1715, 208]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 437 Num points on workers: [200 201 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :945
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693749
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693277
INFO:root:FL Epoch: 437 Norm Difference for worker 945 is 0.028363
INFO:root:FL Epoch: 437 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :15
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689933
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 15 is 0.079101
INFO:root:FL Epoch: 437 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :304
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 304 is 0.086445
INFO:root:FL Epoch: 437 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :957
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695504
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693273
INFO:root:FL Epoch: 437 Norm Difference for worker 957 is 0.050284
INFO:root:FL Epoch: 437 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1361
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694334
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695456
INFO:root:FL Epoch: 437 Norm Difference for worker 1361 is 0.007961
INFO:root:FL Epoch: 437 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1848
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693749
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691468
INFO:root:FL Epoch: 437 Norm Difference for worker 1848 is 0.099978
INFO:root:FL Epoch: 437 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1090
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693749
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693169
INFO:root:FL Epoch: 437 Norm Difference for worker 1090 is 0.089525
INFO:root:FL Epoch: 437 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :284
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 284 is 0.050377
INFO:root:FL Epoch: 437 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1715
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692579
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692153
INFO:root:FL Epoch: 437 Norm Difference for worker 1715 is 0.015794
INFO:root:FL Epoch: 437 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :208
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 208 is 0.041293
INFO:root:FL Epoch: 437 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.6935205424533171 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.6753183007240295                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [421, 1169, 907, 1176, 1511, 288, 1524, 1826, 1157, 919]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :421
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686530
INFO:root:FL Epoch: 438 Norm Difference for worker 421 is 0.105053
INFO:root:FL Epoch: 438 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1169
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687912
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697485
INFO:root:FL Epoch: 438 Norm Difference for worker 1169 is 0.048168
INFO:root:FL Epoch: 438 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :907
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689434
INFO:root:FL Epoch: 438 Norm Difference for worker 907 is 0.009163
INFO:root:FL Epoch: 438 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1176
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696907
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693260
INFO:root:FL Epoch: 438 Norm Difference for worker 1176 is 0.025649
INFO:root:FL Epoch: 438 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1511
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698706
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693189
INFO:root:FL Epoch: 438 Norm Difference for worker 1511 is 0.012369
INFO:root:FL Epoch: 438 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :288
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689711
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699033
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 288 is 0.012081
INFO:root:FL Epoch: 438 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1524
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695108
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697797
INFO:root:FL Epoch: 438 Norm Difference for worker 1524 is 0.055901
INFO:root:FL Epoch: 438 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1826
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691611
INFO:root:FL Epoch: 438 Norm Difference for worker 1826 is 0.071824
INFO:root:FL Epoch: 438 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1157
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687912
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695323
INFO:root:FL Epoch: 438 Norm Difference for worker 1157 is 0.010813
INFO:root:FL Epoch: 438 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :919
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700505
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693124
INFO:root:FL Epoch: 438 Norm Difference for worker 919 is 0.061538
INFO:root:FL Epoch: 438 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.6934605240821838 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.6773790717124939                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1124, 583, 333, 158, 126, 459, 786, 991, 1294, 367]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1124
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691684
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693022
INFO:root:FL Epoch: 439 Norm Difference for worker 1124 is 0.094657
INFO:root:FL Epoch: 439 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :583
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694863
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693246
INFO:root:FL Epoch: 439 Norm Difference for worker 583 is 0.003542
INFO:root:FL Epoch: 439 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :333
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692451
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 333 is 0.09739
INFO:root:FL Epoch: 439 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :158
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 158 is 0.117831
INFO:root:FL Epoch: 439 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :126
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 126 is 0.00985
INFO:root:FL Epoch: 439 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :459
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698042
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693688
INFO:root:FL Epoch: 439 Norm Difference for worker 459 is 0.060855
INFO:root:FL Epoch: 439 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :786
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691684
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700596
INFO:root:FL Epoch: 439 Norm Difference for worker 786 is 0.046288
INFO:root:FL Epoch: 439 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :991
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690095
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688232
INFO:root:FL Epoch: 439 Norm Difference for worker 991 is 0.060595
INFO:root:FL Epoch: 439 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1294
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701221
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687859
INFO:root:FL Epoch: 439 Norm Difference for worker 1294 is 0.040645
INFO:root:FL Epoch: 439 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :367
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693274
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690937
INFO:root:FL Epoch: 439 Norm Difference for worker 367 is 0.004212
INFO:root:FL Epoch: 439 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.6932048657361198 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.6889863014221191                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1829, 1217, 584, 1479, 451, 1313, 1673, 401, 885, 1525]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1829
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693573
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688821
INFO:root:FL Epoch: 440 Norm Difference for worker 1829 is 0.123019
INFO:root:FL Epoch: 440 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1217
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692322
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681550
INFO:root:FL Epoch: 440 Norm Difference for worker 1217 is 0.201576
INFO:root:FL Epoch: 440 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :584
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691071
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697456
INFO:root:FL Epoch: 440 Norm Difference for worker 584 is 0.069043
INFO:root:FL Epoch: 440 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1479
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691666
INFO:root:FL Epoch: 440 Norm Difference for worker 1479 is 0.053735
INFO:root:FL Epoch: 440 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :451
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693503
INFO:root:FL Epoch: 440 Norm Difference for worker 451 is 0.072538
INFO:root:FL Epoch: 440 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1313
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697167
INFO:root:FL Epoch: 440 Norm Difference for worker 1313 is 0.027753
INFO:root:FL Epoch: 440 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1673
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693573
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693260
INFO:root:FL Epoch: 440 Norm Difference for worker 1673 is 0.012499
INFO:root:FL Epoch: 440 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :401
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692322
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693279
INFO:root:FL Epoch: 440 Norm Difference for worker 401 is 0.034924
INFO:root:FL Epoch: 440 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :885
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694407
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687379
INFO:root:FL Epoch: 440 Norm Difference for worker 885 is 0.162363
INFO:root:FL Epoch: 440 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1525
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688484
INFO:root:FL Epoch: 440 Norm Difference for worker 1525 is 0.076684
INFO:root:FL Epoch: 440 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.6934802041334265 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.6766870617866516                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 1644, 1050, 1137, 72, 1710, 325, 74]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684986
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687900
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.6467176675796509 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.6819121181964874 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.061924
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683326
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676198
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.6460174918174744 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.6817561745643616 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.063395
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689965
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677010
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.6476736664772034 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.6821257412433624 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.059918
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1644
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694945
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689199
INFO:root:FL Epoch: 441 Norm Difference for worker 1644 is 0.037715
INFO:root:FL Epoch: 441 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1050
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688306
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695328
INFO:root:FL Epoch: 441 Norm Difference for worker 1050 is 0.018604
INFO:root:FL Epoch: 441 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1137
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686646
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699797
INFO:root:FL Epoch: 441 Norm Difference for worker 1137 is 0.044661
INFO:root:FL Epoch: 441 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :72
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 72 is 0.008385
INFO:root:FL Epoch: 441 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1710
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688306
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695033
INFO:root:FL Epoch: 441 Norm Difference for worker 1710 is 0.159877
INFO:root:FL Epoch: 441 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :325
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693285
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 325 is 0.149279
INFO:root:FL Epoch: 441 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :74
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 74 is 0.0842
INFO:root:FL Epoch: 441 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.6936232061947093 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.672114908695221                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1904, 830, 1706, 724, 105, 669, 1838, 1426, 1525, 348]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1904
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691247
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700817
INFO:root:FL Epoch: 442 Norm Difference for worker 1904 is 0.108048
INFO:root:FL Epoch: 442 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :830
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684870
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683426
INFO:root:FL Epoch: 442 Norm Difference for worker 830 is 0.171865
INFO:root:FL Epoch: 442 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1706
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699751
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692618
INFO:root:FL Epoch: 442 Norm Difference for worker 1706 is 0.051615
INFO:root:FL Epoch: 442 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :724
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697625
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693226
INFO:root:FL Epoch: 442 Norm Difference for worker 724 is 0.065805
INFO:root:FL Epoch: 442 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :105
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 105 is 0.157492
INFO:root:FL Epoch: 442 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :669
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689121
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690949
INFO:root:FL Epoch: 442 Norm Difference for worker 669 is 0.014585
INFO:root:FL Epoch: 442 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1838
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678492
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691337
INFO:root:FL Epoch: 442 Norm Difference for worker 1838 is 0.053182
INFO:root:FL Epoch: 442 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1426
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693373
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694053
INFO:root:FL Epoch: 442 Norm Difference for worker 1426 is 0.066482
INFO:root:FL Epoch: 442 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1525
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695499
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694574
INFO:root:FL Epoch: 442 Norm Difference for worker 1525 is 0.082115
INFO:root:FL Epoch: 442 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :348
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695499
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703685
INFO:root:FL Epoch: 442 Norm Difference for worker 348 is 0.07106
INFO:root:FL Epoch: 442 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.6936796167317558 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.6704853177070618                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1577, 779, 512, 235, 243, 191, 1671, 634, 443, 1020]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1577
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697995
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691126
INFO:root:FL Epoch: 443 Norm Difference for worker 1577 is 0.027542
INFO:root:FL Epoch: 443 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :779
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700287
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693069
INFO:root:FL Epoch: 443 Norm Difference for worker 779 is 0.128589
INFO:root:FL Epoch: 443 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :512
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688825
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697792
INFO:root:FL Epoch: 443 Norm Difference for worker 512 is 0.041192
INFO:root:FL Epoch: 443 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :235
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697995
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 235 is 0.113587
INFO:root:FL Epoch: 443 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :243
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693343
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 243 is 0.021594
INFO:root:FL Epoch: 443 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :191
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691117
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 191 is 0.0206
INFO:root:FL Epoch: 443 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1671
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688825
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693238
INFO:root:FL Epoch: 443 Norm Difference for worker 1671 is 0.010992
INFO:root:FL Epoch: 443 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :634
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691117
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693146
INFO:root:FL Epoch: 443 Norm Difference for worker 634 is 0.095087
INFO:root:FL Epoch: 443 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :443
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695702
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693121
INFO:root:FL Epoch: 443 Norm Difference for worker 443 is 0.140573
INFO:root:FL Epoch: 443 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1020
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695702
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691943
INFO:root:FL Epoch: 443 Norm Difference for worker 1020 is 0.026368
INFO:root:FL Epoch: 443 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.693187373525956 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.6901268362998962                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [563, 1407, 1882, 1071, 1689, 574, 1118, 399, 1608, 1747]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :563
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692547
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679658
INFO:root:FL Epoch: 444 Norm Difference for worker 563 is 0.083626
INFO:root:FL Epoch: 444 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1407
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693454
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691501
INFO:root:FL Epoch: 444 Norm Difference for worker 1407 is 0.0519
INFO:root:FL Epoch: 444 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1882
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692849
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690917
INFO:root:FL Epoch: 444 Norm Difference for worker 1882 is 0.065616
INFO:root:FL Epoch: 444 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1071
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693454
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694333
INFO:root:FL Epoch: 444 Norm Difference for worker 1071 is 0.027377
INFO:root:FL Epoch: 444 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1689
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693168
INFO:root:FL Epoch: 444 Norm Difference for worker 1689 is 0.022524
INFO:root:FL Epoch: 444 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :574
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692244
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693881
INFO:root:FL Epoch: 444 Norm Difference for worker 574 is 0.060671
INFO:root:FL Epoch: 444 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1118
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689554
INFO:root:FL Epoch: 444 Norm Difference for worker 1118 is 0.028053
INFO:root:FL Epoch: 444 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :399
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693757
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693934
INFO:root:FL Epoch: 444 Norm Difference for worker 399 is 0.001312
INFO:root:FL Epoch: 444 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1608
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693152
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692715
INFO:root:FL Epoch: 444 Norm Difference for worker 1608 is 0.062403
INFO:root:FL Epoch: 444 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1747
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694059
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691522
INFO:root:FL Epoch: 444 Norm Difference for worker 1747 is 0.019785
INFO:root:FL Epoch: 444 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.6931439988753375 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.6934250593185425                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [1111, 1878, 1505, 1084, 1040, 1173, 1446, 805, 871, 453]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 445 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :1111
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693064
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694404
INFO:root:FL Epoch: 445 Norm Difference for worker 1111 is 0.004148
INFO:root:FL Epoch: 445 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1878
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693092
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690036
INFO:root:FL Epoch: 445 Norm Difference for worker 1878 is 0.146557
INFO:root:FL Epoch: 445 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1505
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691863
INFO:root:FL Epoch: 445 Norm Difference for worker 1505 is 0.057695
INFO:root:FL Epoch: 445 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1084
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689902
INFO:root:FL Epoch: 445 Norm Difference for worker 1084 is 0.207118
INFO:root:FL Epoch: 445 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1040
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693119
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695312
INFO:root:FL Epoch: 445 Norm Difference for worker 1040 is 0.018407
INFO:root:FL Epoch: 445 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1173
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693231
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691646
INFO:root:FL Epoch: 445 Norm Difference for worker 1173 is 0.063068
INFO:root:FL Epoch: 445 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1446
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693064
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 445 Norm Difference for worker 1446 is 0.003352
INFO:root:FL Epoch: 445 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :805
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692950
INFO:root:FL Epoch: 445 Norm Difference for worker 805 is 0.030407
INFO:root:FL Epoch: 445 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :871
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693120
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693253
INFO:root:FL Epoch: 445 Norm Difference for worker 871 is 0.075792
INFO:root:FL Epoch: 445 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :453
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693203
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 445 Norm Difference for worker 453 is 0.007912
INFO:root:FL Epoch: 445 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.6930813298505896 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.7023583054542542                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [1056, 1824, 1566, 228, 917, 527, 169, 279, 1402, 1605]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :1056
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690438
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694887
INFO:root:FL Epoch: 446 Norm Difference for worker 1056 is 0.03629
INFO:root:FL Epoch: 446 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1824
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688605
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687986
INFO:root:FL Epoch: 446 Norm Difference for worker 1824 is 0.097472
INFO:root:FL Epoch: 446 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1566
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695023
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691273
INFO:root:FL Epoch: 446 Norm Difference for worker 1566 is 0.152818
INFO:root:FL Epoch: 446 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :228
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693319
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 228 is 0.050559
INFO:root:FL Epoch: 446 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :917
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693189
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692332
INFO:root:FL Epoch: 446 Norm Difference for worker 917 is 0.037817
INFO:root:FL Epoch: 446 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :527
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693189
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692898
INFO:root:FL Epoch: 446 Norm Difference for worker 527 is 0.077624
INFO:root:FL Epoch: 446 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :169
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 169 is 0.033766
INFO:root:FL Epoch: 446 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :279
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 279 is 0.087454
INFO:root:FL Epoch: 446 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1402
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690438
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698389
INFO:root:FL Epoch: 446 Norm Difference for worker 1402 is 0.009533
INFO:root:FL Epoch: 446 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1605
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693189
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693235
INFO:root:FL Epoch: 446 Norm Difference for worker 1605 is 0.017221
INFO:root:FL Epoch: 446 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.6931250375859878 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.6952152848243713                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [4, 146, 1929, 1862, 226, 1490, 914, 1000, 1175, 116]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 447 Num points on workers: [201 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :4
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 4 is 0.057915
INFO:root:FL Epoch: 447 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :146
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 146 is 0.120626
INFO:root:FL Epoch: 447 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1929
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692323
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692842
INFO:root:FL Epoch: 447 Norm Difference for worker 1929 is 0.004375
INFO:root:FL Epoch: 447 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1862
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691570
INFO:root:FL Epoch: 447 Norm Difference for worker 1862 is 0.016701
INFO:root:FL Epoch: 447 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :226
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 226 is 0.047241
INFO:root:FL Epoch: 447 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1490
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692530
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691430
INFO:root:FL Epoch: 447 Norm Difference for worker 1490 is 0.095575
INFO:root:FL Epoch: 447 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :914
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692943
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691213
INFO:root:FL Epoch: 447 Norm Difference for worker 914 is 0.131756
INFO:root:FL Epoch: 447 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1000
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697274
INFO:root:FL Epoch: 447 Norm Difference for worker 1000 is 0.03783
INFO:root:FL Epoch: 447 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1175
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685714
INFO:root:FL Epoch: 447 Norm Difference for worker 1175 is 0.082212
INFO:root:FL Epoch: 447 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :116
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 116 is 0.069494
INFO:root:FL Epoch: 447 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.693077935891993 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.7051482796669006                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [949, 1443, 890, 852, 689, 1895, 1574, 607, 277, 950]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :949
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696797
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695885
INFO:root:FL Epoch: 448 Norm Difference for worker 949 is 0.017122
INFO:root:FL Epoch: 448 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1443
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689639
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693680
INFO:root:FL Epoch: 448 Norm Difference for worker 1443 is 0.125706
INFO:root:FL Epoch: 448 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :890
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694411
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692454
INFO:root:FL Epoch: 448 Norm Difference for worker 890 is 0.081382
INFO:root:FL Epoch: 448 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :852
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694411
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689588
INFO:root:FL Epoch: 448 Norm Difference for worker 852 is 0.028256
INFO:root:FL Epoch: 448 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :689
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694411
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692492
INFO:root:FL Epoch: 448 Norm Difference for worker 689 is 0.00654
INFO:root:FL Epoch: 448 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1895
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693218
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692158
INFO:root:FL Epoch: 448 Norm Difference for worker 1895 is 0.049523
INFO:root:FL Epoch: 448 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1574
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693218
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695606
INFO:root:FL Epoch: 448 Norm Difference for worker 1574 is 0.012861
INFO:root:FL Epoch: 448 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :607
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690832
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683485
INFO:root:FL Epoch: 448 Norm Difference for worker 607 is 0.092576
INFO:root:FL Epoch: 448 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :277
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 277 is 0.032484
INFO:root:FL Epoch: 448 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :950
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689639
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685697
INFO:root:FL Epoch: 448 Norm Difference for worker 950 is 0.101849
INFO:root:FL Epoch: 448 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.6931118404164034 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.7133426070213318                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [1522, 782, 758, 912, 1379, 1210, 1104, 1023, 1212, 1352]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :1522
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695347
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693165
INFO:root:FL Epoch: 449 Norm Difference for worker 1522 is 0.112954
INFO:root:FL Epoch: 449 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :782
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687348
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691547
INFO:root:FL Epoch: 449 Norm Difference for worker 782 is 0.050534
INFO:root:FL Epoch: 449 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :758
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689348
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691675
INFO:root:FL Epoch: 449 Norm Difference for worker 758 is 0.027609
INFO:root:FL Epoch: 449 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :912
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687348
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682415
INFO:root:FL Epoch: 449 Norm Difference for worker 912 is 0.093897
INFO:root:FL Epoch: 449 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1379
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695347
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692131
INFO:root:FL Epoch: 449 Norm Difference for worker 1379 is 0.017204
INFO:root:FL Epoch: 449 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1210
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689348
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683905
INFO:root:FL Epoch: 449 Norm Difference for worker 1210 is 0.117252
INFO:root:FL Epoch: 449 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1104
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697346
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695079
INFO:root:FL Epoch: 449 Norm Difference for worker 1104 is 0.003852
INFO:root:FL Epoch: 449 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1023
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695347
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693389
INFO:root:FL Epoch: 449 Norm Difference for worker 1023 is 0.144403
INFO:root:FL Epoch: 449 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1212
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695347
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694905
INFO:root:FL Epoch: 449 Norm Difference for worker 1212 is 0.11797
INFO:root:FL Epoch: 449 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1352
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693347
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684045
INFO:root:FL Epoch: 449 Norm Difference for worker 1352 is 0.093325
INFO:root:FL Epoch: 449 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.6930790228002212 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.7064477205276489                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [389, 411, 375, 1747, 319, 522, 1311, 1796, 76, 1590]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :389
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695877
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693400
INFO:root:FL Epoch: 450 Norm Difference for worker 389 is 0.04382
INFO:root:FL Epoch: 450 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :411
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693234
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698341
INFO:root:FL Epoch: 450 Norm Difference for worker 411 is 0.012009
INFO:root:FL Epoch: 450 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :375
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687949
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689316
INFO:root:FL Epoch: 450 Norm Difference for worker 375 is 0.130783
INFO:root:FL Epoch: 450 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1747
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691913
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693278
INFO:root:FL Epoch: 450 Norm Difference for worker 1747 is 0.016573
INFO:root:FL Epoch: 450 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :319
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 319 is 0.026415
INFO:root:FL Epoch: 450 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :522
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693234
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691751
INFO:root:FL Epoch: 450 Norm Difference for worker 522 is 0.012845
INFO:root:FL Epoch: 450 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1311
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695877
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691656
INFO:root:FL Epoch: 450 Norm Difference for worker 1311 is 0.101705
INFO:root:FL Epoch: 450 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1796
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689270
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692217
INFO:root:FL Epoch: 450 Norm Difference for worker 1796 is 0.063659
INFO:root:FL Epoch: 450 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :76
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686628
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 76 is 0.107701
INFO:root:FL Epoch: 450 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1590
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694556
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694650
INFO:root:FL Epoch: 450 Norm Difference for worker 1590 is 0.021102
INFO:root:FL Epoch: 450 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.6931389149497537 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.6938719153404236                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 1108, 1097, 1433, 1247, 1404, 1313, 684]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693437
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692086
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.6621562242507935 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.6854562819004059 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.064422
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693437
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690904
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.6633886098861694 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.6857477009296418 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.061879
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693220
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691079
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.6623573303222656 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.6855038166046142 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.064007
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1108
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693437
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689082
INFO:root:FL Epoch: 451 Norm Difference for worker 1108 is 0.059033
INFO:root:FL Epoch: 451 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1097
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693075
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687897
INFO:root:FL Epoch: 451 Norm Difference for worker 1097 is 0.110901
INFO:root:FL Epoch: 451 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1433
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692286
INFO:root:FL Epoch: 451 Norm Difference for worker 1433 is 0.011111
INFO:root:FL Epoch: 451 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1247
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692713
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699226
INFO:root:FL Epoch: 451 Norm Difference for worker 1247 is 0.09474
INFO:root:FL Epoch: 451 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1404
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693292
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693169
INFO:root:FL Epoch: 451 Norm Difference for worker 1404 is 0.007414
INFO:root:FL Epoch: 451 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1313
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694677
INFO:root:FL Epoch: 451 Norm Difference for worker 1313 is 0.025825
INFO:root:FL Epoch: 451 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :684
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692785
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693171
INFO:root:FL Epoch: 451 Norm Difference for worker 684 is 0.007539
INFO:root:FL Epoch: 451 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.6934400726767147 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.6781167984008789                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1459, 1133, 1333, 1274, 6, 1294, 853, 1204, 312, 111]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1459
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694776
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691949
INFO:root:FL Epoch: 452 Norm Difference for worker 1459 is 0.019982
INFO:root:FL Epoch: 452 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1133
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696291
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693669
INFO:root:FL Epoch: 452 Norm Difference for worker 1133 is 0.044248
INFO:root:FL Epoch: 452 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1333
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699320
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688877
INFO:root:FL Epoch: 452 Norm Difference for worker 1333 is 0.020425
INFO:root:FL Epoch: 452 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1274
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688718
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689511
INFO:root:FL Epoch: 452 Norm Difference for worker 1274 is 0.146975
INFO:root:FL Epoch: 452 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :6
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 6 is 0.159858
INFO:root:FL Epoch: 452 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1294
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693262
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697259
INFO:root:FL Epoch: 452 Norm Difference for worker 1294 is 0.030695
INFO:root:FL Epoch: 452 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :853
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693262
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695608
INFO:root:FL Epoch: 452 Norm Difference for worker 853 is 0.036757
INFO:root:FL Epoch: 452 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1204
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696291
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687426
INFO:root:FL Epoch: 452 Norm Difference for worker 1204 is 0.152159
INFO:root:FL Epoch: 452 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :312
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 312 is 0.039588
INFO:root:FL Epoch: 452 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :111
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 111 is 0.047567
INFO:root:FL Epoch: 452 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.6939542924656588 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.6634994149208069                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1448, 287, 1140, 793, 1896, 421, 213, 1873, 1936, 764]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 453 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1448
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699620
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689574
INFO:root:FL Epoch: 453 Norm Difference for worker 1448 is 0.031336
INFO:root:FL Epoch: 453 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :287
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 287 is 0.169478
INFO:root:FL Epoch: 453 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1140
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702630
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692546
INFO:root:FL Epoch: 453 Norm Difference for worker 1140 is 0.118481
INFO:root:FL Epoch: 453 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :793
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696610
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695455
INFO:root:FL Epoch: 453 Norm Difference for worker 793 is 0.04251
INFO:root:FL Epoch: 453 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1896
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687580
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686032
INFO:root:FL Epoch: 453 Norm Difference for worker 1896 is 0.043649
INFO:root:FL Epoch: 453 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :421
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690590
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707739
INFO:root:FL Epoch: 453 Norm Difference for worker 421 is 0.081042
INFO:root:FL Epoch: 453 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :213
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 213 is 0.054891
INFO:root:FL Epoch: 453 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1873
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693600
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690436
INFO:root:FL Epoch: 453 Norm Difference for worker 1873 is 0.01583
INFO:root:FL Epoch: 453 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1936
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690590
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697413
INFO:root:FL Epoch: 453 Norm Difference for worker 1936 is 0.04514
INFO:root:FL Epoch: 453 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :764
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684570
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684558
INFO:root:FL Epoch: 453 Norm Difference for worker 764 is 0.102427
INFO:root:FL Epoch: 453 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.6935009009697858 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.6759791970252991                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [20, 53, 1915, 859, 1637, 1037, 375, 528, 1448, 1070]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 454 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :20
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691565
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699314
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 20 is 0.093621
INFO:root:FL Epoch: 454 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :53
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 53 is 0.026379
INFO:root:FL Epoch: 454 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1915
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691565
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685818
INFO:root:FL Epoch: 454 Norm Difference for worker 1915 is 0.103091
INFO:root:FL Epoch: 454 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :859
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695029
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692636
INFO:root:FL Epoch: 454 Norm Difference for worker 859 is 0.077991
INFO:root:FL Epoch: 454 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1637
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695029
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693309
INFO:root:FL Epoch: 454 Norm Difference for worker 1637 is 0.022952
INFO:root:FL Epoch: 454 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1037
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696761
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693462
INFO:root:FL Epoch: 454 Norm Difference for worker 1037 is 0.025302
INFO:root:FL Epoch: 454 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :375
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695029
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690858
INFO:root:FL Epoch: 454 Norm Difference for worker 375 is 0.18555
INFO:root:FL Epoch: 454 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :528
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695029
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685720
INFO:root:FL Epoch: 454 Norm Difference for worker 528 is 0.041076
INFO:root:FL Epoch: 454 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1448
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688102
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689365
INFO:root:FL Epoch: 454 Norm Difference for worker 1448 is 0.025718
INFO:root:FL Epoch: 454 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1070
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688102
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692138
INFO:root:FL Epoch: 454 Norm Difference for worker 1070 is 0.073344
INFO:root:FL Epoch: 454 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.6933126624892739 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.683296263217926                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [248, 1827, 377, 1118, 1287, 306, 1415, 336, 1237, 1124]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 455 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :248
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 248 is 0.114274
INFO:root:FL Epoch: 455 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1827
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694186
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693242
INFO:root:FL Epoch: 455 Norm Difference for worker 1827 is 0.046618
INFO:root:FL Epoch: 455 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :377
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691216
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695613
INFO:root:FL Epoch: 455 Norm Difference for worker 377 is 0.023975
INFO:root:FL Epoch: 455 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1118
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692206
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695813
INFO:root:FL Epoch: 455 Norm Difference for worker 1118 is 0.004761
INFO:root:FL Epoch: 455 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1287
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693196
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693861
INFO:root:FL Epoch: 455 Norm Difference for worker 1287 is 0.012888
INFO:root:FL Epoch: 455 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :306
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 306 is 0.04444
INFO:root:FL Epoch: 455 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1415
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693196
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694563
INFO:root:FL Epoch: 455 Norm Difference for worker 1415 is 0.011177
INFO:root:FL Epoch: 455 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :336
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 336 is 0.161724
INFO:root:FL Epoch: 455 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1237
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692206
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697631
INFO:root:FL Epoch: 455 Norm Difference for worker 1237 is 0.096123
INFO:root:FL Epoch: 455 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1124
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693196
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689874
INFO:root:FL Epoch: 455 Norm Difference for worker 1124 is 0.083376
INFO:root:FL Epoch: 455 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.6933742165565491 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.680648922920227                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1208, 847, 1418, 97, 558, 674, 1098, 1624, 983, 1079]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1208
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696999
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692942
INFO:root:FL Epoch: 456 Norm Difference for worker 1208 is 0.009012
INFO:root:FL Epoch: 456 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :847
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696999
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692096
INFO:root:FL Epoch: 456 Norm Difference for worker 847 is 0.09231
INFO:root:FL Epoch: 456 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1418
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693226
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692275
INFO:root:FL Epoch: 456 Norm Difference for worker 1418 is 0.090964
INFO:root:FL Epoch: 456 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :97
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 97 is 0.020321
INFO:root:FL Epoch: 456 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :558
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691969
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 456 Norm Difference for worker 558 is 0.136606
INFO:root:FL Epoch: 456 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :674
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694484
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691613
INFO:root:FL Epoch: 456 Norm Difference for worker 674 is 0.138396
INFO:root:FL Epoch: 456 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1098
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688195
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693408
INFO:root:FL Epoch: 456 Norm Difference for worker 1098 is 0.063982
INFO:root:FL Epoch: 456 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1624
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699515
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694317
INFO:root:FL Epoch: 456 Norm Difference for worker 1624 is 0.059086
INFO:root:FL Epoch: 456 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :983
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688195
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676386
INFO:root:FL Epoch: 456 Norm Difference for worker 983 is 0.078426
INFO:root:FL Epoch: 456 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1079
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688195
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687928
INFO:root:FL Epoch: 456 Norm Difference for worker 1079 is 0.068699
INFO:root:FL Epoch: 456 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.6931066302692189 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.697354793548584                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [301, 892, 1357, 946, 1812, 217, 198, 160, 97, 78]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.0997009 0.1001994 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 457 Num points on workers: [201 200 200 200 200 201 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :301
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 301 is 0.127898
INFO:root:FL Epoch: 457 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :892
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694173
INFO:root:FL Epoch: 457 Norm Difference for worker 892 is 0.028087
INFO:root:FL Epoch: 457 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1357
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694571
INFO:root:FL Epoch: 457 Norm Difference for worker 1357 is 0.061286
INFO:root:FL Epoch: 457 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :946
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693156
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692436
INFO:root:FL Epoch: 457 Norm Difference for worker 946 is 0.074231
INFO:root:FL Epoch: 457 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1812
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694416
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689773
INFO:root:FL Epoch: 457 Norm Difference for worker 1812 is 0.035819
INFO:root:FL Epoch: 457 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :217
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 217 is 0.09146
INFO:root:FL Epoch: 457 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :198
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 198 is 0.054543
INFO:root:FL Epoch: 457 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :160
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 160 is 0.06261
INFO:root:FL Epoch: 457 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :97
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 97 is 0.037189
INFO:root:FL Epoch: 457 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :78
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 78 is 0.053072
INFO:root:FL Epoch: 457 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.6932750484522652 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.6850925087928772                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [993, 92, 497, 26, 364, 1508, 1296, 1117, 1009, 867]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 458 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :993
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693989
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686567
INFO:root:FL Epoch: 458 Norm Difference for worker 993 is 0.142564
INFO:root:FL Epoch: 458 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :92
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691029
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 92 is 0.200819
INFO:root:FL Epoch: 458 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :497
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696415
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690494
INFO:root:FL Epoch: 458 Norm Difference for worker 497 is 0.176809
INFO:root:FL Epoch: 458 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :26
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 26 is 0.126086
INFO:root:FL Epoch: 458 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :364
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692371
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691404
INFO:root:FL Epoch: 458 Norm Difference for worker 364 is 0.038959
INFO:root:FL Epoch: 458 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1508
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695606
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693257
INFO:root:FL Epoch: 458 Norm Difference for worker 1508 is 0.049201
INFO:root:FL Epoch: 458 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1296
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694797
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693872
INFO:root:FL Epoch: 458 Norm Difference for worker 1296 is 0.041129
INFO:root:FL Epoch: 458 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1117
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692371
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693153
INFO:root:FL Epoch: 458 Norm Difference for worker 1117 is 0.018172
INFO:root:FL Epoch: 458 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1009
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689945
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692369
INFO:root:FL Epoch: 458 Norm Difference for worker 1009 is 0.010825
INFO:root:FL Epoch: 458 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :867
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693989
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 458 Norm Difference for worker 867 is 0.05998
INFO:root:FL Epoch: 458 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.6930782233967501 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.7042559385299683                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [1706, 1346, 133, 699, 374, 827, 367, 1408, 741, 952]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 459 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :1706
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689894
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690292
INFO:root:FL Epoch: 459 Norm Difference for worker 1706 is 0.012975
INFO:root:FL Epoch: 459 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1346
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693208
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694131
INFO:root:FL Epoch: 459 Norm Difference for worker 1346 is 0.018036
INFO:root:FL Epoch: 459 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :133
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 133 is 0.187663
INFO:root:FL Epoch: 459 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :699
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692103
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 459 Norm Difference for worker 699 is 0.004905
INFO:root:FL Epoch: 459 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :374
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697627
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689150
INFO:root:FL Epoch: 459 Norm Difference for worker 374 is 0.138425
INFO:root:FL Epoch: 459 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :827
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694313
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692342
INFO:root:FL Epoch: 459 Norm Difference for worker 827 is 0.004745
INFO:root:FL Epoch: 459 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :367
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688789
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692771
INFO:root:FL Epoch: 459 Norm Difference for worker 367 is 0.048545
INFO:root:FL Epoch: 459 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1408
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697627
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690281
INFO:root:FL Epoch: 459 Norm Difference for worker 1408 is 0.079932
INFO:root:FL Epoch: 459 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :741
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692103
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684894
INFO:root:FL Epoch: 459 Norm Difference for worker 741 is 0.129498
INFO:root:FL Epoch: 459 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :952
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693208
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692084
INFO:root:FL Epoch: 459 Norm Difference for worker 952 is 0.024929
INFO:root:FL Epoch: 459 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.6932140693945044 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.6884246468544006                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [580, 445, 1191, 908, 25, 749, 812, 244, 593, 618]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :580
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693632
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688976
INFO:root:FL Epoch: 460 Norm Difference for worker 580 is 0.139927
INFO:root:FL Epoch: 460 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :445
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695202
INFO:root:FL Epoch: 460 Norm Difference for worker 445 is 0.025607
INFO:root:FL Epoch: 460 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1191
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697864
INFO:root:FL Epoch: 460 Norm Difference for worker 1191 is 0.137766
INFO:root:FL Epoch: 460 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :908
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693889
INFO:root:FL Epoch: 460 Norm Difference for worker 908 is 0.161384
INFO:root:FL Epoch: 460 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :25
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694105
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 25 is 0.065125
INFO:root:FL Epoch: 460 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :749
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689027
INFO:root:FL Epoch: 460 Norm Difference for worker 749 is 0.035634
INFO:root:FL Epoch: 460 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :812
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691738
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693163
INFO:root:FL Epoch: 460 Norm Difference for worker 812 is 0.026951
INFO:root:FL Epoch: 460 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :244
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 244 is 0.131393
INFO:root:FL Epoch: 460 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :593
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692685
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692732
INFO:root:FL Epoch: 460 Norm Difference for worker 593 is 0.029679
INFO:root:FL Epoch: 460 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :618
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692212
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685714
INFO:root:FL Epoch: 460 Norm Difference for worker 618 is 0.064398
INFO:root:FL Epoch: 460 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.6939073029686423 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.6646023988723755                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 607, 837, 17, 896, 1404, 909, 1212]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684877
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682040
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.639334499835968 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.6802885591983795 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.052758
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690670
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671200
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.6365957260131836 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.679698371887207 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.058565
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681981
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674265
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.6359196901321411 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.679553747177124 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.060001
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :607
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696463
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692557
INFO:root:FL Epoch: 461 Norm Difference for worker 607 is 0.135832
INFO:root:FL Epoch: 461 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :837
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690670
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672917
INFO:root:FL Epoch: 461 Norm Difference for worker 837 is 0.118245
INFO:root:FL Epoch: 461 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :17
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681025
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 17 is 0.105229
INFO:root:FL Epoch: 461 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :896
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690670
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696993
INFO:root:FL Epoch: 461 Norm Difference for worker 896 is 0.068603
INFO:root:FL Epoch: 461 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1404
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693567
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693178
INFO:root:FL Epoch: 461 Norm Difference for worker 1404 is 0.055293
INFO:root:FL Epoch: 461 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :909
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702256
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693791
INFO:root:FL Epoch: 461 Norm Difference for worker 909 is 0.109233
INFO:root:FL Epoch: 461 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1212
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699359
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680823
INFO:root:FL Epoch: 461 Norm Difference for worker 1212 is 0.062167
INFO:root:FL Epoch: 461 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.6944303126896129 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.6537114381790161                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [1587, 831, 1744, 981, 535, 1490, 1495, 634, 1243, 571]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :1587
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685908
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699216
INFO:root:FL Epoch: 462 Norm Difference for worker 1587 is 0.086795
INFO:root:FL Epoch: 462 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :831
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669810
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694219
INFO:root:FL Epoch: 462 Norm Difference for worker 831 is 0.000978
INFO:root:FL Epoch: 462 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1744
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681883
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690492
INFO:root:FL Epoch: 462 Norm Difference for worker 1744 is 0.098336
INFO:root:FL Epoch: 462 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :981
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693957
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698015
INFO:root:FL Epoch: 462 Norm Difference for worker 981 is 0.163009
INFO:root:FL Epoch: 462 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :535
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702006
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697483
INFO:root:FL Epoch: 462 Norm Difference for worker 535 is 0.06483
INFO:root:FL Epoch: 462 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1490
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681883
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692152
INFO:root:FL Epoch: 462 Norm Difference for worker 1490 is 0.134838
INFO:root:FL Epoch: 462 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1495
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685908
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701039
INFO:root:FL Epoch: 462 Norm Difference for worker 1495 is 0.136649
INFO:root:FL Epoch: 462 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :634
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718104
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693149
INFO:root:FL Epoch: 462 Norm Difference for worker 634 is 0.096349
INFO:root:FL Epoch: 462 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1243
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710055
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696222
INFO:root:FL Epoch: 462 Norm Difference for worker 1243 is 0.114029
INFO:root:FL Epoch: 462 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :571
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697981
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696444
INFO:root:FL Epoch: 462 Norm Difference for worker 571 is 0.079732
INFO:root:FL Epoch: 462 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.6930831565576441 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.7017154693603516                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [335, 1320, 78, 417, 3, 371, 1139, 1410, 1867, 738]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 463 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :335
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693184
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 335 is 0.099567
INFO:root:FL Epoch: 463 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1320
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695743
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693833
INFO:root:FL Epoch: 463 Norm Difference for worker 1320 is 0.170249
INFO:root:FL Epoch: 463 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :78
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 78 is 0.071879
INFO:root:FL Epoch: 463 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :417
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693170
INFO:root:FL Epoch: 463 Norm Difference for worker 417 is 0.089211
INFO:root:FL Epoch: 463 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :3
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 3 is 0.064036
INFO:root:FL Epoch: 463 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :371
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690624
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681296
INFO:root:FL Epoch: 463 Norm Difference for worker 371 is 0.126747
INFO:root:FL Epoch: 463 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1139
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694037
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693279
INFO:root:FL Epoch: 463 Norm Difference for worker 1139 is 0.153115
INFO:root:FL Epoch: 463 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1410
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694890
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695077
INFO:root:FL Epoch: 463 Norm Difference for worker 1410 is 0.067355
INFO:root:FL Epoch: 463 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1867
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694890
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692132
INFO:root:FL Epoch: 463 Norm Difference for worker 1867 is 0.051498
INFO:root:FL Epoch: 463 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :738
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693184
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695438
INFO:root:FL Epoch: 463 Norm Difference for worker 738 is 0.020236
INFO:root:FL Epoch: 463 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.6930966237012077 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.6988166570663452                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [740, 258, 895, 807, 468, 1002, 239, 675, 1571, 1007]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 464 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :740
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692598
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694162
INFO:root:FL Epoch: 464 Norm Difference for worker 740 is 0.028536
INFO:root:FL Epoch: 464 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :258
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692598
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 258 is 0.013324
INFO:root:FL Epoch: 464 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :895
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693729
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693978
INFO:root:FL Epoch: 464 Norm Difference for worker 895 is 0.033797
INFO:root:FL Epoch: 464 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :807
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694294
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693097
INFO:root:FL Epoch: 464 Norm Difference for worker 807 is 0.006383
INFO:root:FL Epoch: 464 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :468
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693729
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 464 Norm Difference for worker 468 is 0.029371
INFO:root:FL Epoch: 464 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1002
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688477
INFO:root:FL Epoch: 464 Norm Difference for worker 1002 is 0.035456
INFO:root:FL Epoch: 464 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :239
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692598
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 239 is 0.220545
INFO:root:FL Epoch: 464 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :675
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694380
INFO:root:FL Epoch: 464 Norm Difference for worker 675 is 0.003056
INFO:root:FL Epoch: 464 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1571
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689752
INFO:root:FL Epoch: 464 Norm Difference for worker 1571 is 0.056533
INFO:root:FL Epoch: 464 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1007
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692598
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693731
INFO:root:FL Epoch: 464 Norm Difference for worker 1007 is 0.15371
INFO:root:FL Epoch: 464 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.6931159741738263 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.7138364911079407                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [81, 351, 1764, 1030, 751, 1163, 582, 323, 1265, 143]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 465 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :81
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 81 is 0.032511
INFO:root:FL Epoch: 465 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :351
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691309
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689519
INFO:root:FL Epoch: 465 Norm Difference for worker 351 is 0.00606
INFO:root:FL Epoch: 465 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1764
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689972
INFO:root:FL Epoch: 465 Norm Difference for worker 1764 is 0.076518
INFO:root:FL Epoch: 465 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1030
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691309
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695278
INFO:root:FL Epoch: 465 Norm Difference for worker 1030 is 0.014188
INFO:root:FL Epoch: 465 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :751
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692097
INFO:root:FL Epoch: 465 Norm Difference for worker 751 is 0.021944
INFO:root:FL Epoch: 465 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1163
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699501
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689829
INFO:root:FL Epoch: 465 Norm Difference for worker 1163 is 0.020671
INFO:root:FL Epoch: 465 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :582
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700016
INFO:root:FL Epoch: 465 Norm Difference for worker 582 is 0.066376
INFO:root:FL Epoch: 465 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :323
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689261
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 323 is 0.035707
INFO:root:FL Epoch: 465 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1265
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697453
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693226
INFO:root:FL Epoch: 465 Norm Difference for worker 1265 is 0.006739
INFO:root:FL Epoch: 465 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :143
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687213
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 143 is 0.132667
INFO:root:FL Epoch: 465 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.6931001123260049 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.7117477059364319                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1824, 1524, 512, 513, 1770, 173, 1460, 639, 1261, 1732]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1824
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687788
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678107
INFO:root:FL Epoch: 466 Norm Difference for worker 1824 is 0.081857
INFO:root:FL Epoch: 466 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1524
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681378
INFO:root:FL Epoch: 466 Norm Difference for worker 1524 is 0.02229
INFO:root:FL Epoch: 466 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :512
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693330
INFO:root:FL Epoch: 466 Norm Difference for worker 512 is 0.013396
INFO:root:FL Epoch: 466 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :513
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695160
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684286
INFO:root:FL Epoch: 466 Norm Difference for worker 513 is 0.072695
INFO:root:FL Epoch: 466 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1770
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695160
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690906
INFO:root:FL Epoch: 466 Norm Difference for worker 1770 is 0.030429
INFO:root:FL Epoch: 466 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :173
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 173 is 0.013222
INFO:root:FL Epoch: 466 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1460
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691474
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691668
INFO:root:FL Epoch: 466 Norm Difference for worker 1460 is 0.024951
INFO:root:FL Epoch: 466 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :639
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693864
INFO:root:FL Epoch: 466 Norm Difference for worker 639 is 0.120983
INFO:root:FL Epoch: 466 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1261
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693317
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691924
INFO:root:FL Epoch: 466 Norm Difference for worker 1261 is 0.043366
INFO:root:FL Epoch: 466 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1732
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691474
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694247
INFO:root:FL Epoch: 466 Norm Difference for worker 1732 is 0.042827
INFO:root:FL Epoch: 466 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.6930972688338336 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.7112833261489868                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1773, 938, 657, 1319, 1905, 21, 745, 488, 408, 1595]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 467 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1773
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697245
INFO:root:FL Epoch: 467 Norm Difference for worker 1773 is 0.034994
INFO:root:FL Epoch: 467 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :938
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704094
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695320
INFO:root:FL Epoch: 467 Norm Difference for worker 938 is 0.04547
INFO:root:FL Epoch: 467 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :657
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696904
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698809
INFO:root:FL Epoch: 467 Norm Difference for worker 657 is 0.004761
INFO:root:FL Epoch: 467 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1319
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674584
INFO:root:FL Epoch: 467 Norm Difference for worker 1319 is 0.130942
INFO:root:FL Epoch: 467 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1905
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702296
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693896
INFO:root:FL Epoch: 467 Norm Difference for worker 1905 is 0.043605
INFO:root:FL Epoch: 467 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :21
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 21 is 0.060314
INFO:root:FL Epoch: 467 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :745
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689714
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686426
INFO:root:FL Epoch: 467 Norm Difference for worker 745 is 0.115368
INFO:root:FL Epoch: 467 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :488
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695550
INFO:root:FL Epoch: 467 Norm Difference for worker 488 is 0.002703
INFO:root:FL Epoch: 467 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :408
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695106
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693300
INFO:root:FL Epoch: 467 Norm Difference for worker 408 is 0.057155
INFO:root:FL Epoch: 467 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1595
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689714
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694321
INFO:root:FL Epoch: 467 Norm Difference for worker 1595 is 0.095655
INFO:root:FL Epoch: 467 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.6931450051419875 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.7167664766311646                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1586, 1317, 626, 1406, 854, 1493, 724, 1905, 1504, 843]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1586
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684081
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683417
INFO:root:FL Epoch: 468 Norm Difference for worker 1586 is 0.032965
INFO:root:FL Epoch: 468 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1317
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688750
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693152
INFO:root:FL Epoch: 468 Norm Difference for worker 1317 is 0.078597
INFO:root:FL Epoch: 468 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :626
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684081
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689799
INFO:root:FL Epoch: 468 Norm Difference for worker 626 is 0.067488
INFO:root:FL Epoch: 468 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1406
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695754
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692042
INFO:root:FL Epoch: 468 Norm Difference for worker 1406 is 0.107903
INFO:root:FL Epoch: 468 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :854
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695754
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684855
INFO:root:FL Epoch: 468 Norm Difference for worker 854 is 0.013606
INFO:root:FL Epoch: 468 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1493
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688750
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685945
INFO:root:FL Epoch: 468 Norm Difference for worker 1493 is 0.042137
INFO:root:FL Epoch: 468 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :724
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700424
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693555
INFO:root:FL Epoch: 468 Norm Difference for worker 724 is 0.036628
INFO:root:FL Epoch: 468 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1905
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695754
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690852
INFO:root:FL Epoch: 468 Norm Difference for worker 1905 is 0.062658
INFO:root:FL Epoch: 468 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1504
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702758
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693499
INFO:root:FL Epoch: 468 Norm Difference for worker 1504 is 0.119671
INFO:root:FL Epoch: 468 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :843
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691085
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693408
INFO:root:FL Epoch: 468 Norm Difference for worker 843 is 0.021479
INFO:root:FL Epoch: 468 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.6930793804280898 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.7067106366157532                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [554, 1448, 934, 1333, 217, 1698, 1453, 379, 1803, 488]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :554
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690543
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693194
INFO:root:FL Epoch: 469 Norm Difference for worker 554 is 0.031089
INFO:root:FL Epoch: 469 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1448
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691891
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694252
INFO:root:FL Epoch: 469 Norm Difference for worker 1448 is 0.011713
INFO:root:FL Epoch: 469 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :934
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687849
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697135
INFO:root:FL Epoch: 469 Norm Difference for worker 934 is 0.020262
INFO:root:FL Epoch: 469 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1333
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693238
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691616
INFO:root:FL Epoch: 469 Norm Difference for worker 1333 is 0.037939
INFO:root:FL Epoch: 469 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :217
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 217 is 0.071694
INFO:root:FL Epoch: 469 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1698
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691891
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691937
INFO:root:FL Epoch: 469 Norm Difference for worker 1698 is 0.032815
INFO:root:FL Epoch: 469 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1453
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691891
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695880
INFO:root:FL Epoch: 469 Norm Difference for worker 1453 is 0.007557
INFO:root:FL Epoch: 469 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :379
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698627
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692360
INFO:root:FL Epoch: 469 Norm Difference for worker 379 is 0.01462
INFO:root:FL Epoch: 469 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1803
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694585
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691989
INFO:root:FL Epoch: 469 Norm Difference for worker 1803 is 0.012813
INFO:root:FL Epoch: 469 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :488
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687849
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688560
INFO:root:FL Epoch: 469 Norm Difference for worker 488 is 0.012877
INFO:root:FL Epoch: 469 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.6930984959882849 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.6985206007957458                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [709, 1445, 1569, 618, 1559, 1202, 1010, 484, 1465, 613]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :709
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695305
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695306
INFO:root:FL Epoch: 470 Norm Difference for worker 709 is 0.037546
INFO:root:FL Epoch: 470 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1445
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692626
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682597
INFO:root:FL Epoch: 470 Norm Difference for worker 1445 is 0.179875
INFO:root:FL Epoch: 470 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1569
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693697
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693731
INFO:root:FL Epoch: 470 Norm Difference for worker 1569 is 0.018414
INFO:root:FL Epoch: 470 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :618
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693698
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693090
INFO:root:FL Epoch: 470 Norm Difference for worker 618 is 0.069179
INFO:root:FL Epoch: 470 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1559
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691554
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692607
INFO:root:FL Epoch: 470 Norm Difference for worker 1559 is 0.047121
INFO:root:FL Epoch: 470 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1202
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692626
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690849
INFO:root:FL Epoch: 470 Norm Difference for worker 1202 is 0.037282
INFO:root:FL Epoch: 470 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1010
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691018
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690555
INFO:root:FL Epoch: 470 Norm Difference for worker 1010 is 0.018443
INFO:root:FL Epoch: 470 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :484
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694233
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691496
INFO:root:FL Epoch: 470 Norm Difference for worker 484 is 0.081554
INFO:root:FL Epoch: 470 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1465
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693697
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694319
INFO:root:FL Epoch: 470 Norm Difference for worker 1465 is 0.133742
INFO:root:FL Epoch: 470 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :613
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691554
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693439
INFO:root:FL Epoch: 470 Norm Difference for worker 613 is 0.010218
INFO:root:FL Epoch: 470 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.6936678465674905 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.6708206534385681                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 151, 1654, 1080, 91, 1467, 1247, 1165]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686628
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684615
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.6432819962501526 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.68115074634552 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.057185
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686628
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680784
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.6451569199562073 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.6815649628639221 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.053237
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682111
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680689
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.6455022692680359 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.6816416323184967 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.052511
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :151
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693402
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 151 is 0.037865
INFO:root:FL Epoch: 471 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1654
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697918
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682635
INFO:root:FL Epoch: 471 Norm Difference for worker 1654 is 0.046788
INFO:root:FL Epoch: 471 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1080
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693402
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687689
INFO:root:FL Epoch: 471 Norm Difference for worker 1080 is 0.029272
INFO:root:FL Epoch: 471 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :91
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 91 is 0.021789
INFO:root:FL Epoch: 471 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1467
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691144
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692270
INFO:root:FL Epoch: 471 Norm Difference for worker 1467 is 0.109692
INFO:root:FL Epoch: 471 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1247
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691144
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695603
INFO:root:FL Epoch: 471 Norm Difference for worker 1247 is 0.119901
INFO:root:FL Epoch: 471 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1165
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688886
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693238
INFO:root:FL Epoch: 471 Norm Difference for worker 1165 is 0.055651
INFO:root:FL Epoch: 471 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.6935655720093671 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.6738724708557129                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [55, 1275, 894, 1719, 433, 1880, 1000, 1374, 879, 853]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 472 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :55
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 55 is 0.091355
INFO:root:FL Epoch: 472 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1275
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687497
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677837
INFO:root:FL Epoch: 472 Norm Difference for worker 1275 is 0.086478
INFO:root:FL Epoch: 472 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :894
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693337
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694416
INFO:root:FL Epoch: 472 Norm Difference for worker 894 is 0.026918
INFO:root:FL Epoch: 472 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1719
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695283
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695933
INFO:root:FL Epoch: 472 Norm Difference for worker 1719 is 0.045827
INFO:root:FL Epoch: 472 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :433
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695283
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693221
INFO:root:FL Epoch: 472 Norm Difference for worker 433 is 0.131941
INFO:root:FL Epoch: 472 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1880
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695283
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694008
INFO:root:FL Epoch: 472 Norm Difference for worker 1880 is 0.050082
INFO:root:FL Epoch: 472 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1000
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687497
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679979
INFO:root:FL Epoch: 472 Norm Difference for worker 1000 is 0.024581
INFO:root:FL Epoch: 472 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1374
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699176
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693251
INFO:root:FL Epoch: 472 Norm Difference for worker 1374 is 0.030775
INFO:root:FL Epoch: 472 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :879
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699176
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700626
INFO:root:FL Epoch: 472 Norm Difference for worker 879 is 0.052492
INFO:root:FL Epoch: 472 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :853
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689444
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687927
INFO:root:FL Epoch: 472 Norm Difference for worker 853 is 0.026708
INFO:root:FL Epoch: 472 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.6933172871084774 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.6830843091011047                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [548, 1156, 785, 1590, 1674, 880, 1577, 662, 1528, 386]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :548
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693198
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694070
INFO:root:FL Epoch: 473 Norm Difference for worker 548 is 0.105424
INFO:root:FL Epoch: 473 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1156
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694210
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693148
INFO:root:FL Epoch: 473 Norm Difference for worker 1156 is 0.066979
INFO:root:FL Epoch: 473 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :785
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690164
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690918
INFO:root:FL Epoch: 473 Norm Difference for worker 785 is 0.046988
INFO:root:FL Epoch: 473 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1590
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694210
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692316
INFO:root:FL Epoch: 473 Norm Difference for worker 1590 is 0.002531
INFO:root:FL Epoch: 473 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1674
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698255
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690824
INFO:root:FL Epoch: 473 Norm Difference for worker 1674 is 0.056182
INFO:root:FL Epoch: 473 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :880
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691175
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688951
INFO:root:FL Epoch: 473 Norm Difference for worker 880 is 0.046263
INFO:root:FL Epoch: 473 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1577
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696232
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694010
INFO:root:FL Epoch: 473 Norm Difference for worker 1577 is 0.017648
INFO:root:FL Epoch: 473 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :662
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696233
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692397
INFO:root:FL Epoch: 473 Norm Difference for worker 662 is 0.020759
INFO:root:FL Epoch: 473 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1528
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693198
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692226
INFO:root:FL Epoch: 473 Norm Difference for worker 1528 is 0.09917
INFO:root:FL Epoch: 473 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :386
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696232
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693160
INFO:root:FL Epoch: 473 Norm Difference for worker 386 is 0.020139
INFO:root:FL Epoch: 473 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.6931620310334599 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.6919414401054382                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1866, 1598, 830, 460, 382, 1338, 838, 193, 457, 1938]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1866
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693510
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688533
INFO:root:FL Epoch: 474 Norm Difference for worker 1866 is 0.114104
INFO:root:FL Epoch: 474 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1598
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692907
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690460
INFO:root:FL Epoch: 474 Norm Difference for worker 1598 is 0.103029
INFO:root:FL Epoch: 474 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :830
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693389
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687446
INFO:root:FL Epoch: 474 Norm Difference for worker 830 is 0.179872
INFO:root:FL Epoch: 474 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :460
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692786
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686137
INFO:root:FL Epoch: 474 Norm Difference for worker 460 is 0.117953
INFO:root:FL Epoch: 474 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :382
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692786
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690543
INFO:root:FL Epoch: 474 Norm Difference for worker 382 is 0.048554
INFO:root:FL Epoch: 474 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1338
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693027
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689187
INFO:root:FL Epoch: 474 Norm Difference for worker 1338 is 0.07054
INFO:root:FL Epoch: 474 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :838
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693220
INFO:root:FL Epoch: 474 Norm Difference for worker 838 is 0.023505
INFO:root:FL Epoch: 474 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :193
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692907
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693074
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 193 is 0.033848
INFO:root:FL Epoch: 474 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :457
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693389
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692787
INFO:root:FL Epoch: 474 Norm Difference for worker 457 is 0.062771
INFO:root:FL Epoch: 474 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1938
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694378
INFO:root:FL Epoch: 474 Norm Difference for worker 1938 is 0.031947
INFO:root:FL Epoch: 474 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.6933970381231869 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.6797427535057068                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1290, 213, 1351, 1815, 282, 152, 1723, 1823, 752, 1239]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 475 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1290
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695937
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693406
INFO:root:FL Epoch: 475 Norm Difference for worker 1290 is 0.06451
INFO:root:FL Epoch: 475 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :213
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694588
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 213 is 0.043459
INFO:root:FL Epoch: 475 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1351
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687840
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671768
INFO:root:FL Epoch: 475 Norm Difference for worker 1351 is 0.14475
INFO:root:FL Epoch: 475 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1815
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698636
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692072
INFO:root:FL Epoch: 475 Norm Difference for worker 1815 is 0.109496
INFO:root:FL Epoch: 475 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :282
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.687689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 282 is 0.021566
INFO:root:FL Epoch: 475 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :152
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 152 is 0.018522
INFO:root:FL Epoch: 475 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1723
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693238
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693972
INFO:root:FL Epoch: 475 Norm Difference for worker 1723 is 0.065046
INFO:root:FL Epoch: 475 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1823
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694588
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691975
INFO:root:FL Epoch: 475 Norm Difference for worker 1823 is 0.020322
INFO:root:FL Epoch: 475 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :752
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691889
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691557
INFO:root:FL Epoch: 475 Norm Difference for worker 752 is 0.029604
INFO:root:FL Epoch: 475 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1239
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693238
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687773
INFO:root:FL Epoch: 475 Norm Difference for worker 1239 is 0.000152
INFO:root:FL Epoch: 475 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.6935214330168331 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.6752914786338806                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [1494, 1738, 1857, 453, 1466, 1132, 1586, 1646, 1059, 419]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 476 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :1494
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700517
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693501
INFO:root:FL Epoch: 476 Norm Difference for worker 1494 is 0.081573
INFO:root:FL Epoch: 476 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1738
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698715
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693568
INFO:root:FL Epoch: 476 Norm Difference for worker 1738 is 0.062149
INFO:root:FL Epoch: 476 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1857
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689706
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696278
INFO:root:FL Epoch: 476 Norm Difference for worker 1857 is 0.037579
INFO:root:FL Epoch: 476 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :453
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693309
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694283
INFO:root:FL Epoch: 476 Norm Difference for worker 453 is 0.037103
INFO:root:FL Epoch: 476 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1466
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700517
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693431
INFO:root:FL Epoch: 476 Norm Difference for worker 1466 is 0.044167
INFO:root:FL Epoch: 476 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1132
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695111
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693165
INFO:root:FL Epoch: 476 Norm Difference for worker 1132 is 0.054318
INFO:root:FL Epoch: 476 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1586
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702318
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694024
INFO:root:FL Epoch: 476 Norm Difference for worker 1586 is 0.060479
INFO:root:FL Epoch: 476 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1646
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686102
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699595
INFO:root:FL Epoch: 476 Norm Difference for worker 1646 is 0.138033
INFO:root:FL Epoch: 476 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1059
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696913
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691490
INFO:root:FL Epoch: 476 Norm Difference for worker 1059 is 0.192159
INFO:root:FL Epoch: 476 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :419
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684300
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693922
INFO:root:FL Epoch: 476 Norm Difference for worker 419 is 0.047432
INFO:root:FL Epoch: 476 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.6932537906310138 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.6861820816993713                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [952, 411, 415, 1448, 552, 1943, 679, 1277, 1416, 35]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 477 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :952
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693871
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 477 Norm Difference for worker 952 is 0.018353
INFO:root:FL Epoch: 477 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :411
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693870
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693384
INFO:root:FL Epoch: 477 Norm Difference for worker 411 is 0.010146
INFO:root:FL Epoch: 477 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :415
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692473
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692756
INFO:root:FL Epoch: 477 Norm Difference for worker 415 is 0.010164
INFO:root:FL Epoch: 477 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1448
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692473
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693225
INFO:root:FL Epoch: 477 Norm Difference for worker 1448 is 0.013185
INFO:root:FL Epoch: 477 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :552
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695268
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692002
INFO:root:FL Epoch: 477 Norm Difference for worker 552 is 0.034522
INFO:root:FL Epoch: 477 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1943
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695268
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690672
INFO:root:FL Epoch: 477 Norm Difference for worker 1943 is 0.060012
INFO:root:FL Epoch: 477 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :679
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691774
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696738
INFO:root:FL Epoch: 477 Norm Difference for worker 679 is 0.155656
INFO:root:FL Epoch: 477 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1277
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691774
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690944
INFO:root:FL Epoch: 477 Norm Difference for worker 1277 is 0.020596
INFO:root:FL Epoch: 477 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1416
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693871
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692020
INFO:root:FL Epoch: 477 Norm Difference for worker 1416 is 0.042748
INFO:root:FL Epoch: 477 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :35
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697013
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 35 is 0.018401
INFO:root:FL Epoch: 477 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.6933811517322764 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.6803693175315857                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [1457, 196, 409, 1243, 850, 1688, 1945, 529, 1824, 301]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 478 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :1457
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690658
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692376
INFO:root:FL Epoch: 478 Norm Difference for worker 1457 is 0.041953
INFO:root:FL Epoch: 478 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :196
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694516
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 196 is 0.026729
INFO:root:FL Epoch: 478 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :409
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697088
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678475
INFO:root:FL Epoch: 478 Norm Difference for worker 409 is 0.14757
INFO:root:FL Epoch: 478 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1243
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695802
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693619
INFO:root:FL Epoch: 478 Norm Difference for worker 1243 is 0.081649
INFO:root:FL Epoch: 478 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :850
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697088
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694895
INFO:root:FL Epoch: 478 Norm Difference for worker 850 is 0.110936
INFO:root:FL Epoch: 478 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1688
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689372
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689544
INFO:root:FL Epoch: 478 Norm Difference for worker 1688 is 0.124382
INFO:root:FL Epoch: 478 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1945
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697164
INFO:root:FL Epoch: 478 Norm Difference for worker 1945 is 0.016348
INFO:root:FL Epoch: 478 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :529
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693230
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693178
INFO:root:FL Epoch: 478 Norm Difference for worker 529 is 0.038369
INFO:root:FL Epoch: 478 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1824
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697088
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693161
INFO:root:FL Epoch: 478 Norm Difference for worker 1824 is 0.099406
INFO:root:FL Epoch: 478 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :301
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 301 is 0.115139
INFO:root:FL Epoch: 478 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.6931599694139817 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.6921039819717407                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [1556, 1805, 396, 462, 693, 700, 492, 688, 164, 1734]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :1556
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693356
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683217
INFO:root:FL Epoch: 479 Norm Difference for worker 1556 is 0.082959
INFO:root:FL Epoch: 479 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1805
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693356
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688959
INFO:root:FL Epoch: 479 Norm Difference for worker 1805 is 0.105139
INFO:root:FL Epoch: 479 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :396
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694187
INFO:root:FL Epoch: 479 Norm Difference for worker 396 is 0.030838
INFO:root:FL Epoch: 479 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :462
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693461
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692958
INFO:root:FL Epoch: 479 Norm Difference for worker 462 is 0.01179
INFO:root:FL Epoch: 479 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :693
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693252
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692666
INFO:root:FL Epoch: 479 Norm Difference for worker 693 is 0.023459
INFO:root:FL Epoch: 479 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :700
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693252
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690560
INFO:root:FL Epoch: 479 Norm Difference for worker 700 is 0.097192
INFO:root:FL Epoch: 479 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :492
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693461
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694255
INFO:root:FL Epoch: 479 Norm Difference for worker 492 is 0.059706
INFO:root:FL Epoch: 479 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :688
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693148
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689815
INFO:root:FL Epoch: 479 Norm Difference for worker 688 is 0.047423
INFO:root:FL Epoch: 479 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :164
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694620
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 164 is 0.028136
INFO:root:FL Epoch: 479 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1734
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693043
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693838
INFO:root:FL Epoch: 479 Norm Difference for worker 1734 is 0.009965
INFO:root:FL Epoch: 479 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.6931921664406272 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.6898065209388733                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [616, 1015, 305, 191, 1119, 1854, 1670, 983, 1569, 980]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :616
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693153
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687468
INFO:root:FL Epoch: 480 Norm Difference for worker 616 is 0.109354
INFO:root:FL Epoch: 480 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1015
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691480
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684677
INFO:root:FL Epoch: 480 Norm Difference for worker 1015 is 0.095329
INFO:root:FL Epoch: 480 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :305
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694899
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 305 is 0.082895
INFO:root:FL Epoch: 480 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :191
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 191 is 0.00337
INFO:root:FL Epoch: 480 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1119
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692818
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694862
INFO:root:FL Epoch: 480 Norm Difference for worker 1119 is 0.094507
INFO:root:FL Epoch: 480 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1854
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693153
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692382
INFO:root:FL Epoch: 480 Norm Difference for worker 1854 is 0.054841
INFO:root:FL Epoch: 480 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1670
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693822
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694780
INFO:root:FL Epoch: 480 Norm Difference for worker 1670 is 0.048451
INFO:root:FL Epoch: 480 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :983
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693153
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689787
INFO:root:FL Epoch: 480 Norm Difference for worker 983 is 0.060869
INFO:root:FL Epoch: 480 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1569
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693822
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693449
INFO:root:FL Epoch: 480 Norm Difference for worker 1569 is 0.030231
INFO:root:FL Epoch: 480 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :980
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693153
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692458
INFO:root:FL Epoch: 480 Norm Difference for worker 980 is 0.069138
INFO:root:FL Epoch: 480 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.6931275094256681 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.6949557662010193                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 561, 481, 321, 674, 79, 14, 483]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693329
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691664
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.6664995551109314 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.6864887416362763 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.057639
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693691
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687586
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.6643595695495605 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.6859781682491303 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.062043
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692968
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691764
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.6654120087623596 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.6862288236618042 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.059875
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :561
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692607
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691964
INFO:root:FL Epoch: 481 Norm Difference for worker 561 is 0.009912
INFO:root:FL Epoch: 481 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :481
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694233
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694435
INFO:root:FL Epoch: 481 Norm Difference for worker 481 is 0.021621
INFO:root:FL Epoch: 481 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :321
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692968
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 321 is 0.055036
INFO:root:FL Epoch: 481 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :674
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693149
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695605
INFO:root:FL Epoch: 481 Norm Difference for worker 674 is 0.118207
INFO:root:FL Epoch: 481 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :79
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 79 is 0.032919
INFO:root:FL Epoch: 481 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :14
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693385
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 14 is 0.005357
INFO:root:FL Epoch: 481 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :483
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692968
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691370
INFO:root:FL Epoch: 481 Norm Difference for worker 483 is 0.021227
INFO:root:FL Epoch: 481 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.6931185617166407 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.6959076523780823                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [949, 863, 340, 58, 1181, 242, 1945, 1451, 1473, 477]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :949
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692324
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693147
INFO:root:FL Epoch: 482 Norm Difference for worker 949 is 0.019333
INFO:root:FL Epoch: 482 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :863
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693978
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692593
INFO:root:FL Epoch: 482 Norm Difference for worker 863 is 0.034433
INFO:root:FL Epoch: 482 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :340
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692875
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687850
INFO:root:FL Epoch: 482 Norm Difference for worker 340 is 0.059673
INFO:root:FL Epoch: 482 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :58
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692048
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691767
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 58 is 0.047564
INFO:root:FL Epoch: 482 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1181
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693978
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690797
INFO:root:FL Epoch: 482 Norm Difference for worker 1181 is 0.066669
INFO:root:FL Epoch: 482 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :242
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 242 is 0.004047
INFO:root:FL Epoch: 482 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1945
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693427
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692790
INFO:root:FL Epoch: 482 Norm Difference for worker 1945 is 0.041494
INFO:root:FL Epoch: 482 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1451
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696950
INFO:root:FL Epoch: 482 Norm Difference for worker 1451 is 0.050559
INFO:root:FL Epoch: 482 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1473
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693978
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691221
INFO:root:FL Epoch: 482 Norm Difference for worker 1473 is 0.076471
INFO:root:FL Epoch: 482 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :477
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693151
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693191
INFO:root:FL Epoch: 482 Norm Difference for worker 477 is 0.059844
INFO:root:FL Epoch: 482 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.6931041899849387 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.6976808905601501                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [849, 1204, 1327, 924, 1031, 409, 912, 401, 117, 1136]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 483 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :849
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694062
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686956
INFO:root:FL Epoch: 483 Norm Difference for worker 849 is 0.171286
INFO:root:FL Epoch: 483 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1204
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691161
INFO:root:FL Epoch: 483 Norm Difference for worker 1204 is 0.117699
INFO:root:FL Epoch: 483 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1327
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691962
INFO:root:FL Epoch: 483 Norm Difference for worker 1327 is 0.075533
INFO:root:FL Epoch: 483 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :924
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693610
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686143
INFO:root:FL Epoch: 483 Norm Difference for worker 924 is 0.147727
INFO:root:FL Epoch: 483 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1031
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693610
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697015
INFO:root:FL Epoch: 483 Norm Difference for worker 1031 is 0.052437
INFO:root:FL Epoch: 483 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :409
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692705
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686732
INFO:root:FL Epoch: 483 Norm Difference for worker 409 is 0.114959
INFO:root:FL Epoch: 483 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :912
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692705
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697744
INFO:root:FL Epoch: 483 Norm Difference for worker 912 is 0.084282
INFO:root:FL Epoch: 483 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :401
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692323
INFO:root:FL Epoch: 483 Norm Difference for worker 401 is 0.04793
INFO:root:FL Epoch: 483 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :117
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 117 is 0.034914
INFO:root:FL Epoch: 483 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1136
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693157
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693411
INFO:root:FL Epoch: 483 Norm Difference for worker 1136 is 0.163465
INFO:root:FL Epoch: 483 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.6932277398950913 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.687617301940918                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [528, 141, 406, 1149, 639, 932, 865, 1944, 1827, 1174]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 484 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :528
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694272
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695379
INFO:root:FL Epoch: 484 Norm Difference for worker 528 is 0.042919
INFO:root:FL Epoch: 484 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :141
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 141 is 0.098508
INFO:root:FL Epoch: 484 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :406
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693717
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689802
INFO:root:FL Epoch: 484 Norm Difference for worker 406 is 0.069888
INFO:root:FL Epoch: 484 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1149
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693717
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693216
INFO:root:FL Epoch: 484 Norm Difference for worker 1149 is 0.075191
INFO:root:FL Epoch: 484 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :639
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690944
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693284
INFO:root:FL Epoch: 484 Norm Difference for worker 639 is 0.095959
INFO:root:FL Epoch: 484 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :932
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693717
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687749
INFO:root:FL Epoch: 484 Norm Difference for worker 932 is 0.088214
INFO:root:FL Epoch: 484 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :865
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692053
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695400
INFO:root:FL Epoch: 484 Norm Difference for worker 865 is 0.060651
INFO:root:FL Epoch: 484 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1944
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693163
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679540
INFO:root:FL Epoch: 484 Norm Difference for worker 1944 is 0.135965
INFO:root:FL Epoch: 484 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1827
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692608
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694128
INFO:root:FL Epoch: 484 Norm Difference for worker 1827 is 0.03273
INFO:root:FL Epoch: 484 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1174
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694272
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690905
INFO:root:FL Epoch: 484 Norm Difference for worker 1174 is 0.026376
INFO:root:FL Epoch: 484 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.6937546309302834 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.6684370636940002                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [496, 203, 42, 22, 915, 382, 62, 1040, 29, 779]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 485 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :496
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693460
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693277
INFO:root:FL Epoch: 485 Norm Difference for worker 496 is 0.075367
INFO:root:FL Epoch: 485 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :203
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698154
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 203 is 0.04611
INFO:root:FL Epoch: 485 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :42
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 42 is 0.008565
INFO:root:FL Epoch: 485 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :22
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693460
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 22 is 0.080445
INFO:root:FL Epoch: 485 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :915
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688456
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699773
INFO:root:FL Epoch: 485 Norm Difference for worker 915 is 0.139075
INFO:root:FL Epoch: 485 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :382
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693460
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690256
INFO:root:FL Epoch: 485 Norm Difference for worker 382 is 0.032478
INFO:root:FL Epoch: 485 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :62
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 62 is 0.044301
INFO:root:FL Epoch: 485 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1040
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688456
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695530
INFO:root:FL Epoch: 485 Norm Difference for worker 1040 is 0.008398
INFO:root:FL Epoch: 485 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :29
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691713
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 29 is 0.002011
INFO:root:FL Epoch: 485 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :779
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693460
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693812
INFO:root:FL Epoch: 485 Norm Difference for worker 779 is 0.129474
INFO:root:FL Epoch: 485 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.6934278361937579 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.6785677671432495                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1637, 577, 971, 1234, 1712, 1120, 733, 1188, 1270, 393]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1637
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696193
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696951
INFO:root:FL Epoch: 486 Norm Difference for worker 1637 is 0.010102
INFO:root:FL Epoch: 486 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :577
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690318
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692412
INFO:root:FL Epoch: 486 Norm Difference for worker 577 is 0.051123
INFO:root:FL Epoch: 486 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :971
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691786
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686884
INFO:root:FL Epoch: 486 Norm Difference for worker 971 is 0.078065
INFO:root:FL Epoch: 486 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1234
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699130
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693304
INFO:root:FL Epoch: 486 Norm Difference for worker 1234 is 0.094585
INFO:root:FL Epoch: 486 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1712
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688849
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696611
INFO:root:FL Epoch: 486 Norm Difference for worker 1712 is 0.055038
INFO:root:FL Epoch: 486 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1120
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693255
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691352
INFO:root:FL Epoch: 486 Norm Difference for worker 1120 is 0.004696
INFO:root:FL Epoch: 486 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :733
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694724
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691270
INFO:root:FL Epoch: 486 Norm Difference for worker 733 is 0.120656
INFO:root:FL Epoch: 486 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1188
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690318
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688760
INFO:root:FL Epoch: 486 Norm Difference for worker 1188 is 0.013384
INFO:root:FL Epoch: 486 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1270
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691786
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685462
INFO:root:FL Epoch: 486 Norm Difference for worker 1270 is 0.054322
INFO:root:FL Epoch: 486 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :393
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694724
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693253
INFO:root:FL Epoch: 486 Norm Difference for worker 393 is 0.010459
INFO:root:FL Epoch: 486 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.693341472569634 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.6820171475410461                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1318, 1307, 1255, 86, 1583, 73, 1774, 1361, 1191, 72]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1318
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697687
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687775
INFO:root:FL Epoch: 487 Norm Difference for worker 1318 is 0.098736
INFO:root:FL Epoch: 487 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1307
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693210
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692251
INFO:root:FL Epoch: 487 Norm Difference for worker 1307 is 0.103084
INFO:root:FL Epoch: 487 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1255
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693210
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685201
INFO:root:FL Epoch: 487 Norm Difference for worker 1255 is 0.11191
INFO:root:FL Epoch: 487 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :86
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 86 is 0.022969
INFO:root:FL Epoch: 487 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1583
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693210
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692412
INFO:root:FL Epoch: 487 Norm Difference for worker 1583 is 0.147945
INFO:root:FL Epoch: 487 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :73
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685231
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 73 is 0.177895
INFO:root:FL Epoch: 487 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1774
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694329
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696324
INFO:root:FL Epoch: 487 Norm Difference for worker 1774 is 0.022622
INFO:root:FL Epoch: 487 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1361
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692090
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691912
INFO:root:FL Epoch: 487 Norm Difference for worker 1361 is 0.069565
INFO:root:FL Epoch: 487 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1191
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690971
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697264
INFO:root:FL Epoch: 487 Norm Difference for worker 1191 is 0.097537
INFO:root:FL Epoch: 487 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :72
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696568
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 72 is 0.017344
INFO:root:FL Epoch: 487 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.6930815402199241 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.7022934556007385                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [1497, 860, 1140, 427, 1056, 1259, 134, 1401, 937, 1377]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 488 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :1497
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694099
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691105
INFO:root:FL Epoch: 488 Norm Difference for worker 1497 is 0.107932
INFO:root:FL Epoch: 488 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :860
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693189
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692615
INFO:root:FL Epoch: 488 Norm Difference for worker 860 is 0.127656
INFO:root:FL Epoch: 488 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1140
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691368
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704282
INFO:root:FL Epoch: 488 Norm Difference for worker 1140 is 0.073254
INFO:root:FL Epoch: 488 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :427
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692278
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687145
INFO:root:FL Epoch: 488 Norm Difference for worker 427 is 0.005917
INFO:root:FL Epoch: 488 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1056
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691368
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693193
INFO:root:FL Epoch: 488 Norm Difference for worker 1056 is 0.037832
INFO:root:FL Epoch: 488 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1259
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691368
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694868
INFO:root:FL Epoch: 488 Norm Difference for worker 1259 is 0.00163
INFO:root:FL Epoch: 488 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :134
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 134 is 0.089786
INFO:root:FL Epoch: 488 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1401
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692278
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693360
INFO:root:FL Epoch: 488 Norm Difference for worker 1401 is 0.038137
INFO:root:FL Epoch: 488 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :937
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694099
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693297
INFO:root:FL Epoch: 488 Norm Difference for worker 937 is 0.070767
INFO:root:FL Epoch: 488 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1377
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690457
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690840
INFO:root:FL Epoch: 488 Norm Difference for worker 1377 is 0.100375
INFO:root:FL Epoch: 488 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.6930876163875356 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.7005481719970703                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [858, 1611, 442, 1751, 1626, 1430, 557, 6, 1406, 1934]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :858
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692488
INFO:root:FL Epoch: 489 Norm Difference for worker 858 is 0.0415
INFO:root:FL Epoch: 489 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1611
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698602
INFO:root:FL Epoch: 489 Norm Difference for worker 1611 is 0.016086
INFO:root:FL Epoch: 489 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :442
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691700
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694045
INFO:root:FL Epoch: 489 Norm Difference for worker 442 is 0.06217
INFO:root:FL Epoch: 489 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1751
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692437
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693816
INFO:root:FL Epoch: 489 Norm Difference for worker 1751 is 0.01834
INFO:root:FL Epoch: 489 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1626
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694649
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693182
INFO:root:FL Epoch: 489 Norm Difference for worker 1626 is 0.112848
INFO:root:FL Epoch: 489 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1430
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692437
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693375
INFO:root:FL Epoch: 489 Norm Difference for worker 1430 is 0.030819
INFO:root:FL Epoch: 489 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :557
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693174
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692516
INFO:root:FL Epoch: 489 Norm Difference for worker 557 is 0.014468
INFO:root:FL Epoch: 489 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :6
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693912
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 6 is 0.167002
INFO:root:FL Epoch: 489 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1406
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694649
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689489
INFO:root:FL Epoch: 489 Norm Difference for worker 1406 is 0.088787
INFO:root:FL Epoch: 489 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1934
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695387
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693999
INFO:root:FL Epoch: 489 Norm Difference for worker 1934 is 0.02302
INFO:root:FL Epoch: 489 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.6935760659330031 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.6735454201698303                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [406, 1256, 1544, 894, 738, 923, 1701, 1105, 182, 95]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 490 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :406
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695323
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697355
INFO:root:FL Epoch: 490 Norm Difference for worker 406 is 0.049917
INFO:root:FL Epoch: 490 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1256
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691363
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689722
INFO:root:FL Epoch: 490 Norm Difference for worker 1256 is 0.041862
INFO:root:FL Epoch: 490 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1544
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695323
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684162
INFO:root:FL Epoch: 490 Norm Difference for worker 1544 is 0.037223
INFO:root:FL Epoch: 490 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :894
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689384
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690611
INFO:root:FL Epoch: 490 Norm Difference for worker 894 is 0.00477
INFO:root:FL Epoch: 490 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :738
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691363
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691484
INFO:root:FL Epoch: 490 Norm Difference for worker 738 is 0.017091
INFO:root:FL Epoch: 490 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :923
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683444
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697185
INFO:root:FL Epoch: 490 Norm Difference for worker 923 is 0.024601
INFO:root:FL Epoch: 490 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1701
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699283
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693364
INFO:root:FL Epoch: 490 Norm Difference for worker 1701 is 0.024497
INFO:root:FL Epoch: 490 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1105
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693343
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693945
INFO:root:FL Epoch: 490 Norm Difference for worker 1105 is 0.088749
INFO:root:FL Epoch: 490 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :182
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 182 is 0.129509
INFO:root:FL Epoch: 490 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :95
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 95 is 0.11693
INFO:root:FL Epoch: 490 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.6933841775445377 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.6802497506141663                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 1088, 523, 382, 1677, 98, 89, 290]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693231
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681005
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.653529942035675 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.6834514737129211 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.054906
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691933
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682686
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.6535225510597229 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.6834497630596161 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.054921
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691933
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688882
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.6541056036949158 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.6835833489894867 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.053706
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1088
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690635
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696312
INFO:root:FL Epoch: 491 Norm Difference for worker 1088 is 0.05426
INFO:root:FL Epoch: 491 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :523
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691933
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687081
INFO:root:FL Epoch: 491 Norm Difference for worker 523 is 0.139732
INFO:root:FL Epoch: 491 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :382
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694530
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696621
INFO:root:FL Epoch: 491 Norm Difference for worker 382 is 0.02564
INFO:root:FL Epoch: 491 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1677
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694530
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695049
INFO:root:FL Epoch: 491 Norm Difference for worker 1677 is 0.012684
INFO:root:FL Epoch: 491 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :98
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 98 is 0.094515
INFO:root:FL Epoch: 491 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :89
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685442
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 89 is 0.185209
INFO:root:FL Epoch: 491 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :290
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 290 is 0.023145
INFO:root:FL Epoch: 491 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.6939272074138417 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.6641315817832947                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [331, 1080, 1356, 698, 1944, 796, 259, 384, 392, 19]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 492 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :331
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691343
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 331 is 0.049083
INFO:root:FL Epoch: 492 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1080
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690636
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690890
INFO:root:FL Epoch: 492 Norm Difference for worker 1080 is 0.034505
INFO:root:FL Epoch: 492 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1356
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699471
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693151
INFO:root:FL Epoch: 492 Norm Difference for worker 1356 is 0.095116
INFO:root:FL Epoch: 492 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :698
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693581
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686252
INFO:root:FL Epoch: 492 Norm Difference for worker 698 is 0.007224
INFO:root:FL Epoch: 492 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1944
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684746
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682398
INFO:root:FL Epoch: 492 Norm Difference for worker 1944 is 0.117917
INFO:root:FL Epoch: 492 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :796
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690636
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695981
INFO:root:FL Epoch: 492 Norm Difference for worker 796 is 0.12989
INFO:root:FL Epoch: 492 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :259
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 259 is 0.102064
INFO:root:FL Epoch: 492 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :384
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699471
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687112
INFO:root:FL Epoch: 492 Norm Difference for worker 384 is 0.059538
INFO:root:FL Epoch: 492 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :392
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711250
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693890
INFO:root:FL Epoch: 492 Norm Difference for worker 392 is 0.080654
INFO:root:FL Epoch: 492 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :19
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 19 is 0.003955
INFO:root:FL Epoch: 492 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.6936253589742324 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.6720519661903381                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [1392, 707, 927, 1825, 923, 1449, 169, 1319, 496, 681]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :1392
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695507
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691714
INFO:root:FL Epoch: 493 Norm Difference for worker 1392 is 0.026901
INFO:root:FL Epoch: 493 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :707
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697639
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696216
INFO:root:FL Epoch: 493 Norm Difference for worker 707 is 0.045317
INFO:root:FL Epoch: 493 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :927
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695507
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696158
INFO:root:FL Epoch: 493 Norm Difference for worker 927 is 0.055443
INFO:root:FL Epoch: 493 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1825
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689110
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689591
INFO:root:FL Epoch: 493 Norm Difference for worker 1825 is 0.124746
INFO:root:FL Epoch: 493 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :923
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686978
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682344
INFO:root:FL Epoch: 493 Norm Difference for worker 923 is 0.040033
INFO:root:FL Epoch: 493 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1449
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689110
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697429
INFO:root:FL Epoch: 493 Norm Difference for worker 1449 is 0.057829
INFO:root:FL Epoch: 493 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :169
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 169 is 0.090175
INFO:root:FL Epoch: 493 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1319
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689110
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689235
INFO:root:FL Epoch: 493 Norm Difference for worker 1319 is 0.162462
INFO:root:FL Epoch: 493 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :496
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697639
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689387
INFO:root:FL Epoch: 493 Norm Difference for worker 496 is 0.061298
INFO:root:FL Epoch: 493 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :681
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697639
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693150
INFO:root:FL Epoch: 493 Norm Difference for worker 681 is 0.095538
INFO:root:FL Epoch: 493 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.693144843858831 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.6933455467224121                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [999, 311, 1767, 1021, 1187, 1460, 822, 1804, 711, 228]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 494 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :999
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693199
INFO:root:FL Epoch: 494 Norm Difference for worker 999 is 0.02959
INFO:root:FL Epoch: 494 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :311
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693207
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 311 is 0.083248
INFO:root:FL Epoch: 494 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1767
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693147
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688685
INFO:root:FL Epoch: 494 Norm Difference for worker 1767 is 0.059238
INFO:root:FL Epoch: 494 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1021
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693227
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693154
INFO:root:FL Epoch: 494 Norm Difference for worker 1021 is 0.020543
INFO:root:FL Epoch: 494 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1187
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693187
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694067
INFO:root:FL Epoch: 494 Norm Difference for worker 1187 is 0.003097
INFO:root:FL Epoch: 494 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1460
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693028
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691816
INFO:root:FL Epoch: 494 Norm Difference for worker 1460 is 0.040112
INFO:root:FL Epoch: 494 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :822
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693167
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690996
INFO:root:FL Epoch: 494 Norm Difference for worker 822 is 0.096955
INFO:root:FL Epoch: 494 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1804
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693207
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692256
INFO:root:FL Epoch: 494 Norm Difference for worker 1804 is 0.038688
INFO:root:FL Epoch: 494 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :711
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693127
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692427
INFO:root:FL Epoch: 494 Norm Difference for worker 711 is 0.019198
INFO:root:FL Epoch: 494 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :228
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 228 is 0.069536
INFO:root:FL Epoch: 494 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.6931600325247821 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.6921010613441467                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [780, 63, 1298, 1777, 1947, 227, 1603, 1502, 1894, 1344]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 495 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :780
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692938
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690820
INFO:root:FL Epoch: 495 Norm Difference for worker 780 is 0.09274
INFO:root:FL Epoch: 495 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :63
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.683326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 63 is 0.123705
INFO:root:FL Epoch: 495 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1298
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692615
INFO:root:FL Epoch: 495 Norm Difference for worker 1298 is 0.036957
INFO:root:FL Epoch: 495 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1777
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694950
INFO:root:FL Epoch: 495 Norm Difference for worker 1777 is 0.007062
INFO:root:FL Epoch: 495 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1947
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693671
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693402
INFO:root:FL Epoch: 495 Norm Difference for worker 1947 is 0.013803
INFO:root:FL Epoch: 495 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :227
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693566
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 495 Norm Difference for worker 227 is 0.070945
INFO:root:FL Epoch: 495 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1603
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693043
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693565
INFO:root:FL Epoch: 495 Norm Difference for worker 1603 is 0.02407
INFO:root:FL Epoch: 495 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1502
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693462
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691396
INFO:root:FL Epoch: 495 Norm Difference for worker 1502 is 0.036393
INFO:root:FL Epoch: 495 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1894
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693776
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697566
INFO:root:FL Epoch: 495 Norm Difference for worker 1894 is 0.018508
INFO:root:FL Epoch: 495 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1344
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693357
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695737
INFO:root:FL Epoch: 495 Norm Difference for worker 1344 is 0.079692
INFO:root:FL Epoch: 495 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.6930909612599541 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.6998491287231445                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [83, 593, 676, 1241, 405, 1473, 912, 335, 726, 15]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 496 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :83
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 83 is 0.027819
INFO:root:FL Epoch: 496 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :593
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693838
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693582
INFO:root:FL Epoch: 496 Norm Difference for worker 593 is 0.024808
INFO:root:FL Epoch: 496 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :676
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693169
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693317
INFO:root:FL Epoch: 496 Norm Difference for worker 676 is 0.065195
INFO:root:FL Epoch: 496 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1241
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691834
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689182
INFO:root:FL Epoch: 496 Norm Difference for worker 1241 is 0.048832
INFO:root:FL Epoch: 496 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :405
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691834
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686624
INFO:root:FL Epoch: 496 Norm Difference for worker 405 is 0.075068
INFO:root:FL Epoch: 496 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1473
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693170
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693347
INFO:root:FL Epoch: 496 Norm Difference for worker 1473 is 0.076428
INFO:root:FL Epoch: 496 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :912
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693170
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687480
INFO:root:FL Epoch: 496 Norm Difference for worker 912 is 0.104588
INFO:root:FL Epoch: 496 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :335
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 335 is 0.102935
INFO:root:FL Epoch: 496 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :726
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692502
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690743
INFO:root:FL Epoch: 496 Norm Difference for worker 726 is 0.076687
INFO:root:FL Epoch: 496 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :15
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 15 is 0.052442
INFO:root:FL Epoch: 496 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.6931238665300257 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.7147222757339478                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [733, 220, 907, 1530, 605, 307, 873, 1496, 391, 607]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 497 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :733
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691240
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686567
INFO:root:FL Epoch: 497 Norm Difference for worker 733 is 0.067184
INFO:root:FL Epoch: 497 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :220
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695510
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 220 is 0.024022
INFO:root:FL Epoch: 497 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :907
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697644
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692022
INFO:root:FL Epoch: 497 Norm Difference for worker 907 is 0.028989
INFO:root:FL Epoch: 497 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1530
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693375
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683809
INFO:root:FL Epoch: 497 Norm Difference for worker 1530 is 0.170492
INFO:root:FL Epoch: 497 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :605
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695510
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693325
INFO:root:FL Epoch: 497 Norm Difference for worker 605 is 0.064525
INFO:root:FL Epoch: 497 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :307
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686034
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 307 is 0.011193
INFO:root:FL Epoch: 497 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :873
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695510
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695094
INFO:root:FL Epoch: 497 Norm Difference for worker 873 is 0.047126
INFO:root:FL Epoch: 497 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1496
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686971
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693969
INFO:root:FL Epoch: 497 Norm Difference for worker 1496 is 0.080978
INFO:root:FL Epoch: 497 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :391
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689106
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696710
INFO:root:FL Epoch: 497 Norm Difference for worker 391 is 0.001095
INFO:root:FL Epoch: 497 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :607
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691240
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693572
INFO:root:FL Epoch: 497 Norm Difference for worker 607 is 0.062951
INFO:root:FL Epoch: 497 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.6932967164937187 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.7263661026954651                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [1400, 441, 67, 585, 632, 280, 890, 1637, 897, 1319]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :1400
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683876
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703094
INFO:root:FL Epoch: 498 Norm Difference for worker 1400 is 0.018489
INFO:root:FL Epoch: 498 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :441
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693681
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696334
INFO:root:FL Epoch: 498 Norm Difference for worker 441 is 0.01929
INFO:root:FL Epoch: 498 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :67
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 67 is 0.173199
INFO:root:FL Epoch: 498 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :585
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696950
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682083
INFO:root:FL Epoch: 498 Norm Difference for worker 585 is 0.030889
INFO:root:FL Epoch: 498 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :632
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693681
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698707
INFO:root:FL Epoch: 498 Norm Difference for worker 632 is 0.028308
INFO:root:FL Epoch: 498 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :280
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.680607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.689612
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 280 is 0.012417
INFO:root:FL Epoch: 498 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :890
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696950
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689320
INFO:root:FL Epoch: 498 Norm Difference for worker 890 is 0.082399
INFO:root:FL Epoch: 498 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1637
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690413
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684917
INFO:root:FL Epoch: 498 Norm Difference for worker 1637 is 0.052175
INFO:root:FL Epoch: 498 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :897
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690413
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689874
INFO:root:FL Epoch: 498 Norm Difference for worker 897 is 0.003764
INFO:root:FL Epoch: 498 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1319
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690413
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694647
INFO:root:FL Epoch: 498 Norm Difference for worker 1319 is 0.099528
INFO:root:FL Epoch: 498 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.693098716876086 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.7115200161933899                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1014, 1779, 1466, 1440, 1234, 808, 479, 1215, 188, 1752]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1014
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695134
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691837
INFO:root:FL Epoch: 499 Norm Difference for worker 1014 is 0.031018
INFO:root:FL Epoch: 499 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1779
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693313
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693866
INFO:root:FL Epoch: 499 Norm Difference for worker 1779 is 0.036659
INFO:root:FL Epoch: 499 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1466
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696954
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694303
INFO:root:FL Epoch: 499 Norm Difference for worker 1466 is 0.084938
INFO:root:FL Epoch: 499 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1440
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689672
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693603
INFO:root:FL Epoch: 499 Norm Difference for worker 1440 is 0.049184
INFO:root:FL Epoch: 499 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1234
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695134
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693644
INFO:root:FL Epoch: 499 Norm Difference for worker 1234 is 0.071417
INFO:root:FL Epoch: 499 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :808
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696954
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691507
INFO:root:FL Epoch: 499 Norm Difference for worker 808 is 0.025705
INFO:root:FL Epoch: 499 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :479
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695134
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687835
INFO:root:FL Epoch: 499 Norm Difference for worker 479 is 0.046692
INFO:root:FL Epoch: 499 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1215
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695134
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693080
INFO:root:FL Epoch: 499 Norm Difference for worker 1215 is 0.110726
INFO:root:FL Epoch: 499 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :188
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 188 is 0.06242
INFO:root:FL Epoch: 499 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1752
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698775
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693174
INFO:root:FL Epoch: 499 Norm Difference for worker 1752 is 0.121334
INFO:root:FL Epoch: 499 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.6931170645882102 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.696075439453125                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [465, 1676, 1137, 1286, 1292, 469, 679, 551, 1025, 1649]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :465
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694029
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692517
INFO:root:FL Epoch: 500 Norm Difference for worker 465 is 0.041929
INFO:root:FL Epoch: 500 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1676
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694029
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695909
INFO:root:FL Epoch: 500 Norm Difference for worker 1676 is 0.094662
INFO:root:FL Epoch: 500 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1137
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693444
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693488
INFO:root:FL Epoch: 500 Norm Difference for worker 1137 is 0.013122
INFO:root:FL Epoch: 500 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1286
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692859
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681382
INFO:root:FL Epoch: 500 Norm Difference for worker 1286 is 0.130839
INFO:root:FL Epoch: 500 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1292
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692859
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692174
INFO:root:FL Epoch: 500 Norm Difference for worker 1292 is 0.001878
INFO:root:FL Epoch: 500 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :469
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691982
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694779
INFO:root:FL Epoch: 500 Norm Difference for worker 469 is 0.052578
INFO:root:FL Epoch: 500 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :679
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694321
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688089
INFO:root:FL Epoch: 500 Norm Difference for worker 679 is 0.139617
INFO:root:FL Epoch: 500 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :551
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694029
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693138
INFO:root:FL Epoch: 500 Norm Difference for worker 551 is 0.050518
INFO:root:FL Epoch: 500 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1025
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694029
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693175
INFO:root:FL Epoch: 500 Norm Difference for worker 1025 is 0.03341
INFO:root:FL Epoch: 500 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1649
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693444
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694973
INFO:root:FL Epoch: 500 Norm Difference for worker 1649 is 0.027454
INFO:root:FL Epoch: 500 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.6931446405018077 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.6933630108833313                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/report/1d/stats.csv ******
